{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c13260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSetting 1:\\nMIN_LIST_LEN = 12\\nMAX_LIST_LEN = 12\\nMAX_STEPS = 96\\nSUCCESS_REWARD = 1.0\\nSTEP_REWARD = -0.3\\nCOMPARISON_ENTROPY_MULTIPLIER = -0.00\\nNONFINAL_SWAP_REWARD = 0.35\\nFINAL_SWAP_REWARD = 1.0\\nINVALID_ACTION_REWARD = -10.0\\nLONGTERM_GAMMA = 0.99\\nSHORTTERM_GAMMA = 0.7\\nEPS_START = 0.5\\nEPS_END = 0.05\\nEPS_DECAY = 1000\\nLR_SCHEDULER_GAMMA = 0.98\\nNUM_EPISODES = 200000\\nEPISODES_SAVE = 1000\\nckpt_57000_0.9390_44.94.pth\\n\\n\\nSetting 2:\\nMIN_LIST_LEN = 12\\nMAX_LIST_LEN = 12\\nMAX_STEPS = 96\\nSUCCESS_REWARD = 1.0\\nSTEP_REWARD = -0.3\\nCOMPARISON_ENTROPY_MULTIPLIER = -0.00\\nNONFINAL_SWAP_REWARD = 0.35\\nFINAL_SWAP_REWARD = 1.0\\nINVALID_ACTION_REWARD = -10.0\\nLONGTERM_GAMMA = 0.99\\nSHORTTERM_GAMMA = 0.7\\nEPS_START = 0.5\\nEPS_END = 0.05\\nEPS_DECAY = 4000\\nLR_SCHEDULER_GAMMA = 0.98\\nNUM_EPISODES = 200000\\nEPISODES_SAVE = 1000\\nckpt_86000_0.9440_51.48.pth\\n\\nSetting 3:\\nMIN_LIST_LEN = 8\\nMAX_LIST_LEN = 8\\nMAX_STEPS = 64\\nCONTEXT_LEN=256\\nEMBED_DIM=128\\nNUM_LAYERS=3\\nSUCCESS_REWARD = 0.29\\nSTEP_REWARD = -0.3\\nCOMPARISON_ENTROPY_MULTIPLIER = -0.00\\nNONFINAL_SWAP_REWARD = 0.0\\nFINAL_SWAP_REWARD = 1.0\\nINVALID_ACTION_REWARD = -10.0\\nLONGTERM_GAMMA = 0.9999\\nSHORTTERM_GAMMA = 0.7\\nEPS_START = 0.5\\nEPS_END = 0.05\\nEPS_DECAY = 6000\\nLR_SCHEDULER_GAMMA = 0.98\\nNUM_EPISODES = 200000\\nEPISODES_SAVE = 1000\\nckpt_67000_0.9730_20.56_vs_21.42.pth\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Setting 1:\n",
    "MIN_LIST_LEN = 12\n",
    "MAX_LIST_LEN = 12\n",
    "MAX_STEPS = 96\n",
    "SUCCESS_REWARD = 1.0\n",
    "STEP_REWARD = -0.3\n",
    "COMPARISON_ENTROPY_MULTIPLIER = -0.00\n",
    "NONFINAL_SWAP_REWARD = 0.35\n",
    "FINAL_SWAP_REWARD = 1.0\n",
    "INVALID_ACTION_REWARD = -10.0\n",
    "LONGTERM_GAMMA = 0.99\n",
    "SHORTTERM_GAMMA = 0.7\n",
    "EPS_START = 0.5\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "LR_SCHEDULER_GAMMA = 0.98\n",
    "NUM_EPISODES = 200000\n",
    "EPISODES_SAVE = 1000\n",
    "ckpt_57000_0.9390_44.94.pth\n",
    "\n",
    "\n",
    "Setting 2:\n",
    "MIN_LIST_LEN = 12\n",
    "MAX_LIST_LEN = 12\n",
    "MAX_STEPS = 96\n",
    "SUCCESS_REWARD = 1.0\n",
    "STEP_REWARD = -0.3\n",
    "COMPARISON_ENTROPY_MULTIPLIER = -0.00\n",
    "NONFINAL_SWAP_REWARD = 0.35\n",
    "FINAL_SWAP_REWARD = 1.0\n",
    "INVALID_ACTION_REWARD = -10.0\n",
    "LONGTERM_GAMMA = 0.99\n",
    "SHORTTERM_GAMMA = 0.7\n",
    "EPS_START = 0.5\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 4000\n",
    "LR_SCHEDULER_GAMMA = 0.98\n",
    "NUM_EPISODES = 200000\n",
    "EPISODES_SAVE = 1000\n",
    "ckpt_86000_0.9440_51.48.pth\n",
    "\n",
    "Setting 3:\n",
    "MIN_LIST_LEN = 8\n",
    "MAX_LIST_LEN = 8\n",
    "MAX_STEPS = 64\n",
    "CONTEXT_LEN=256\n",
    "EMBED_DIM=128\n",
    "NUM_LAYERS=3\n",
    "SUCCESS_REWARD = 0.29\n",
    "STEP_REWARD = -0.3\n",
    "COMPARISON_ENTROPY_MULTIPLIER = -0.00\n",
    "NONFINAL_SWAP_REWARD = 0.0\n",
    "FINAL_SWAP_REWARD = 1.0\n",
    "INVALID_ACTION_REWARD = -10.0\n",
    "LONGTERM_GAMMA = 0.9999\n",
    "SHORTTERM_GAMMA = 0.7\n",
    "EPS_START = 0.5\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 6000\n",
    "LR_SCHEDULER_GAMMA = 0.98\n",
    "NUM_EPISODES = 200000\n",
    "EPISODES_SAVE = 1000\n",
    "ckpt_67000_0.9730_20.56_vs_21.42.pth\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ba0d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import math\n",
    "import random\n",
    "\n",
    "MIN_LIST_LEN = 6\n",
    "MAX_LIST_LEN = 12\n",
    "MAX_STEPS = 80\n",
    "\n",
    "CONTEXT_LEN=320\n",
    "EMBED_DIM=128\n",
    "NUM_LAYERS=3\n",
    "\n",
    "SUCCESS_REWARD = 0.29\n",
    "STEP_REWARD = -0.3\n",
    "COMPARISON_ENTROPY_MULTIPLIER = -0.00\n",
    "NONFINAL_SWAP_REWARD = 0.0\n",
    "FINAL_SWAP_REWARD = 1.0\n",
    "INVALID_ACTION_REWARD = -10.0\n",
    "LONGTERM_GAMMA = 0.9999\n",
    "SHORTTERM_GAMMA = 0.7\n",
    "\n",
    "EPS_START = 0.5\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 3000\n",
    "LR_SCHEDULER_GAMMA = 0.98\n",
    "NUM_EPISODES = 200000\n",
    "EPISODES_SAVE = 1000\n",
    "OUTPUT_DIR = '/home/mcwave/code/autocode/datasets/rl_sort_transformer_easy/list6_12_transformer3_128_gamma07_step80_v3_merge_2_sorted'\n",
    "\n",
    "# Define the vocabulary\n",
    "vocab = {\n",
    "    'Comparison': 0,\n",
    "    'Swap': 1,\n",
    "    'less': 2,\n",
    "    'equal': 3,\n",
    "    'more': 4,\n",
    "    '0': 5,\n",
    "    '1': 6,\n",
    "    '2': 7,\n",
    "    '3': 8,\n",
    "    '4': 9,\n",
    "    '5': 10,\n",
    "    '6': 11,\n",
    "    '7': 12,\n",
    "    '8': 13,\n",
    "    '9': 14,\n",
    "    '10': 15,\n",
    "    '11': 16,\n",
    "    '12': 17,\n",
    "    '13': 18,\n",
    "    '14': 19,\n",
    "    '15': 20,\n",
    "    'len1': 21,\n",
    "    'len2': 22,\n",
    "    'len3': 23,\n",
    "    'len4': 24,\n",
    "    'len5': 25,\n",
    "    'len6': 26,\n",
    "    'len7': 27,\n",
    "    'len8': 28,\n",
    "    'len9': 29,\n",
    "    'len10': 30,\n",
    "    'len11': 31,\n",
    "    'len12': 32,\n",
    "    'len13': 33,\n",
    "    'len14': 34,\n",
    "    'len15': 35,\n",
    "    'len16': 36,\n",
    "}\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "def compute_entropy(N, alpha=1):\n",
    "    K = 2**N\n",
    "    values = np.arange(K)\n",
    "    unnormalized_probs = np.exp(-alpha * values)\n",
    "    Z = unnormalized_probs.sum()\n",
    "    probs = unnormalized_probs / Z\n",
    "    return values, -np.log2(probs)\n",
    "\n",
    "_, int_entropy = compute_entropy(4)\n",
    "\n",
    "def get_entropy_of_integer(x):\n",
    "    x = min(15, abs(x))\n",
    "    return int_entropy[x]\n",
    "\n",
    "def compute_min_delta_entropy(comparisons):\n",
    "    # Initialize the result list to store minDelta values\n",
    "    min_delta = None\n",
    "\n",
    "    # Iterate through each pair in the comparisons list\n",
    "    i = len(comparisons) - 1\n",
    "    xi, yi = comparisons[i]\n",
    "    if i == 0:\n",
    "        # For i = 0, use the first case directly\n",
    "        min_delta = (xi, min(yi, yi - xi), 0)\n",
    "    else:\n",
    "        # For i > 0, compute all possible options and select the minimal one\n",
    "        options = []\n",
    "\n",
    "        # Simple Entropy\n",
    "        simple_entropy = (xi, min(yi, yi - xi), 0)\n",
    "        options.append(simple_entropy)\n",
    "\n",
    "        # First Delta Entropy\n",
    "        xi_prev, yi_prev = comparisons[i - 1]\n",
    "        first_delta_entropy = (xi - xi_prev, yi - yi_prev, 0)\n",
    "        options.append(first_delta_entropy)\n",
    "\n",
    "        # Second Delta Entropy (only valid for i > 1)\n",
    "        if i > 1:\n",
    "            xi_prev2, yi_prev2 = comparisons[i - 2]\n",
    "            second_delta_entropy = (\n",
    "                (xi - xi_prev) - (xi_prev - xi_prev2),\n",
    "                (yi - yi_prev) - (yi_prev - yi_prev2),\n",
    "                0,\n",
    "            )\n",
    "            options.append(second_delta_entropy)\n",
    "\n",
    "        # Arbitrary Position Entropy (only valid for i > 1)\n",
    "        for j in range(i):\n",
    "            xj, yj = comparisons[j]\n",
    "            arbitrary_position_entropy = (\n",
    "                xi - xj,\n",
    "                yi - yj,\n",
    "                min(j, i - j),\n",
    "            )\n",
    "            options.append(arbitrary_position_entropy)\n",
    "\n",
    "        # Find the option with the minimal sum\n",
    "        min_delta = min(options, key=lambda t: sum([get_entropy_of_integer(x) for x in t]))\n",
    "\n",
    "    entropy = sum([get_entropy_of_integer(x) for x in min_delta])\n",
    "    if len(comparisons) == 1:\n",
    "        return 3 * entropy\n",
    "    else:\n",
    "        return entropy\n",
    "\n",
    "def generate_unique_random_list(length, min_value=1, max_value=100):\n",
    "    \"\"\"\n",
    "    Generates a list of unique random integers within a specified range.\n",
    "    If duplicates are detected, the list is regenerated.\n",
    "    \n",
    "    Args:\n",
    "        length (int): The length of the list to generate.\n",
    "        min_value (int): The minimum possible value (inclusive).\n",
    "        max_value (int): The maximum possible value (inclusive).\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of unique random integers.\n",
    "    \"\"\"\n",
    "    if length > (max_value - min_value + 1):\n",
    "        raise ValueError(\"Length exceeds the range of unique values available.\")\n",
    "    \n",
    "    while True:\n",
    "        random_list = [random.randint(min_value, max_value) for _ in range(length)]\n",
    "        if len(set(random_list)) == length:\n",
    "            return random_list\n",
    "\n",
    "def split_random_pairs(l):\n",
    "        \"\"\"\n",
    "        Splits the sorted list into two lists by randomly assigning each pair of consecutive elements.\n",
    "        Each pair ((0,1), (2,3), (4,5), ...) is randomly separated into the two lists.\n",
    "        If the list has an odd number of elements, the last element is randomly assigned to one of the lists.\n",
    "        :return: A tuple containing two lists with the split elements.\n",
    "        \"\"\"\n",
    "        list1 = []\n",
    "        list2 = []\n",
    "        n = len(l)\n",
    "        i = 0\n",
    "        while i < n - 1:\n",
    "            pair = [l[i], l[i + 1]]\n",
    "            random.shuffle(pair)\n",
    "            list1.append(pair[0])\n",
    "            list2.append(pair[1])\n",
    "            i += 2\n",
    "        #\n",
    "        return list1, list2\n",
    "        \n",
    "def inplace_merge(arr, start, mid, end):\n",
    "    \"\"\"\n",
    "    In-place merge of arr[start:mid] and arr[mid:end], both sorted.\n",
    "    Merges so that arr[start:end] is sorted.\n",
    "    Uses only Compare and Swap operations and counts them.\n",
    "    \"\"\"\n",
    "    compares = 0\n",
    "    swaps = 0\n",
    "    \n",
    "    i = start\n",
    "    j = mid\n",
    "    \n",
    "    # While both subarrays have elements to compare\n",
    "    while i < j and j < end:\n",
    "        # Compare element from left half and right half\n",
    "        compares += 1\n",
    "        if arr[i] <= arr[j]:\n",
    "            # If left element is smaller or equal, move on\n",
    "            i += 1\n",
    "        else:\n",
    "            # The element at j is smaller and should be inserted at position i\n",
    "            # We'll shift elements from i...j-1 by one step to the right\n",
    "            # and place arr[j] at position i.\n",
    "\n",
    "            # Save the element to be inserted\n",
    "            to_insert = arr[j]\n",
    "\n",
    "            # Move all elements from [i...j-1] one position right\n",
    "            # This is done by swapping pairs to simulate a rotation.\n",
    "            k = j\n",
    "            while k > i:\n",
    "                # Compare arr[k-1] with to_insert as we \"slide\" it over.\n",
    "                # Even though we know arr[k-1] < to_insert might not matter for correctness,\n",
    "                # we count this as a compare for fairness. We are effectively \"checking\"\n",
    "                # positions for insertion.\n",
    "                compares += 1\n",
    "                \n",
    "                # Swap arr[k] and arr[k-1]\n",
    "                arr[k], arr[k-1] = arr[k-1], arr[k]\n",
    "                swaps += 1\n",
    "                k -= 1                    \n",
    "\n",
    "            # Now arr[i] = to_insert, and we have effectively inserted the element\n",
    "            arr[i] = to_insert\n",
    "\n",
    "            # Move pointers:\n",
    "            i += 1\n",
    "            j += 1\n",
    "            if arr == sorted(arr):\n",
    "                return compares, swaps\n",
    "\n",
    "    return compares, swaps\n",
    "\n",
    "def merge_two_sorted_halves(arr):\n",
    "    \"\"\"\n",
    "    Given an array where the first half is sorted and the second half is sorted,\n",
    "    merge them in-place and count the number of compare and swap operations.\n",
    "    \"\"\"\n",
    "    n = len(arr)\n",
    "    mid = n // 2\n",
    "    compares, swaps = inplace_merge(arr, 0, mid, n)\n",
    "    return compares + swaps\n",
    "        \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the environment\n",
    "class SortingEnv:\n",
    "    def __init__(self):\n",
    "        self.max_steps = MAX_STEPS\n",
    "\n",
    "    def reset(self):\n",
    "        self.length = random.randint(MIN_LIST_LEN // 2, MAX_LIST_LEN // 2) * 2\n",
    "        self.list = [random.randint(1, 100) for _ in range(self.length)]\n",
    "        self.list = generate_unique_random_list(self.length)\n",
    "        #l1, l2 = split_random_pairs(self.list)\n",
    "        #self.list = l1 + l2\n",
    "        self.list = sorted(self.list[0:self.length//2]) + sorted(self.list[self.length//2:])\n",
    "        self.original_list = list(self.list)\n",
    "        self.optimal_steps = merge_two_sorted_halves(list(self.list))\n",
    "        self.sorted_list = sorted(self.list)\n",
    "        self.indices = None\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        initial_token = 'len{}'.format(self.length)\n",
    "        return vocab[initial_token], self.list.copy()\n",
    "    \n",
    "    def get_list(self):\n",
    "        return self.list\n",
    "    \n",
    "    def get_original_list(self):\n",
    "        return self.original_list\n",
    "    \n",
    "    def get_list_len(self):\n",
    "        return len(self.list)\n",
    "    \n",
    "    def get_optimal_steps(self):\n",
    "        return self.optimal_steps\n",
    "\n",
    "    def step(self, action_tokens):\n",
    "        action = action_tokens[0]\n",
    "        reward = -0.01  # default penalty\n",
    "        response_token = None\n",
    "\n",
    "        if action == vocab['Comparison']:\n",
    "            if len(action_tokens) != 3:\n",
    "                reward = INVALID_ACTION_REWARD\n",
    "                self.done = True\n",
    "                return response_token, reward, self.done, self.list.copy()\n",
    "            index1 = action_tokens[1] - vocab['0']\n",
    "            index2 = action_tokens[2] - vocab['0']\n",
    "            if index1 >= self.length or index2 >= self.length or index1 < 0 or index2 < 0:\n",
    "                reward = INVALID_ACTION_REWARD\n",
    "                self.done = True\n",
    "                return response_token, reward, self.done, self.list.copy()\n",
    "            self.indices = (index1, index2)\n",
    "            if self.list[index1] < self.list[index2]:\n",
    "                response_token = vocab['less']\n",
    "                reward = STEP_REWARD\n",
    "            elif self.list[index1] == self.list[index2]:\n",
    "                response_token = vocab['equal']\n",
    "                reward = STEP_REWARD * 2\n",
    "            else:\n",
    "                response_token = vocab['more']\n",
    "                reward = STEP_REWARD\n",
    "        elif action == vocab['Swap']:\n",
    "            if self.indices is None:\n",
    "                reward = INVALID_ACTION_REWARD\n",
    "                self.done = True\n",
    "                return response_token, reward, self.done, self.list.copy()\n",
    "            index1, index2 = self.indices\n",
    "            final_pos_1 = self.sorted_list.index(self.list[index1])\n",
    "            final_pos_2 = self.sorted_list.index(self.list[index2])\n",
    "            if final_pos_1 == index2 or final_pos_2 == index1:\n",
    "                is_swap_final = True\n",
    "            else:\n",
    "                is_swap_final = False\n",
    "            prev_list = self.list.copy()\n",
    "            self.list[index1], self.list[index2] = self.list[index2], self.list[index1]\n",
    "            if self.list == sorted(self.list):\n",
    "                reward = SUCCESS_REWARD\n",
    "                self.done = True\n",
    "            #elif prev_list[index1] > prev_list[index2] and self.list[index1] <= self.list[index2]:\n",
    "            #    reward = 0.1\n",
    "            elif (index1 < index2 and prev_list[index1] > prev_list[index2] and self.list[index1] <= self.list[index2]) or \\\n",
    "                (index1 > index2 and prev_list[index1] < prev_list[index2] and self.list[index1] >= self.list[index2]):\n",
    "                reward = FINAL_SWAP_REWARD if is_swap_final else NONFINAL_SWAP_REWARD\n",
    "            elif (index1 < index2 and prev_list[index1] < prev_list[index2] and self.list[index1] >= self.list[index2]) or \\\n",
    "                (index1 > index2 and prev_list[index1] > prev_list[index2] and self.list[index1] <= self.list[index2]):\n",
    "                reward = -FINAL_SWAP_REWARD\n",
    "            else:\n",
    "                reward = STEP_REWARD\n",
    "            self.indices = None\n",
    "        else:\n",
    "            reward = INVALID_ACTION_REWARD\n",
    "            self.done = True\n",
    "\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= self.max_steps:\n",
    "            self.done = True\n",
    "        return response_token, reward, self.done, self.list.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0cf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding for Transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=CONTEXT_LEN):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # (max_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # Even indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # Odd indices\n",
    "        pe = pe.unsqueeze(1)  # (max_len, 1, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Transformer Model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=EMBED_DIM, nhead=8, num_layers=NUM_LAYERS):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.decoder = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.embedding.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "def decode(input_tokens, inv_vocab):\n",
    "    return ' '.join([inv_vocab[x] for x in input_tokens])\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, episode, folder, filename):\n",
    "    \"\"\"\n",
    "    Save the model and optimizer state to the designated filepath.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to save.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer whose state to save.\n",
    "        episode (int): The current episode number.\n",
    "        filepath (str): The path where to save the checkpoint.\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    # Save the checkpoint\n",
    "    torch.save({\n",
    "        'episode': episode,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, filepath)\n",
    "    print(f\"Checkpoint saved at episode {episode} to {filepath}\")\n",
    "\n",
    "def load_checkpoint(filepath, model, optimizer):\n",
    "    \"\"\"\n",
    "    Load the model and optimizer state from the designated filepath.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path from where to load the checkpoint.\n",
    "        model (nn.Module): The model into which to load the state_dict.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer into which to load the state.\n",
    "\n",
    "    Returns:\n",
    "        int: The episode number to resume from.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(filepath):\n",
    "        checkpoint = torch.load(filepath, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        episode = checkpoint['episode']\n",
    "        print(f\"Checkpoint loaded from {filepath}, resuming from episode {episode}\")\n",
    "        return episode\n",
    "    else:\n",
    "        print(f\"No checkpoint found at {filepath}, starting from scratch.\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a13cca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, len12, loss:-59.3486, fail, steps:12, opt steps:34, total reward:-16.4000, 0.3815305233001709 sec\n",
      "Episode 1, len6, loss:-69.2498, fail, steps:35, opt steps:7, total reward:-23.1000, 0.21028637886047363 sec\n",
      "Episode 2, len10, loss:-42.7938, fail, steps:3, opt steps:34, total reward:-10.6000, 0.020933866500854492 sec\n",
      "Episode 3, len8, loss:-61.0553, fail, steps:17, opt steps:24, total reward:-16.2000, 0.09106159210205078 sec\n",
      "Episode 4, len10, loss:-51.7851, fail, steps:8, opt steps:19, total reward:-12.8000, 0.04406905174255371 sec\n",
      "Episode 5, len10, loss:-46.4834, fail, steps:3, opt steps:30, total reward:-11.6000, 0.017412662506103516 sec\n",
      "Episode 6, len6, loss:-8.8487, fail, steps:0, opt steps:3, total reward:-10.0000, 0.003130674362182617 sec\n",
      "Episode 7, len10, loss:-27.9581, fail, steps:2, opt steps:31, total reward:-9.3000, 0.010460138320922852 sec\n",
      "Episode 8, len12, loss:-129.5599, fail, steps:56, opt steps:69, total reward:-30.1000, 0.3892827033996582 sec\n",
      "Episode 9, len12, loss:-167.6327, fail, steps:78, opt steps:50, total reward:-37.3000, 0.4533820152282715 sec\n",
      "Episode 10, len12, loss:-86.3171, fail, steps:18, opt steps:39, total reward:-17.5000, 0.11392903327941895 sec\n",
      "Episode 11, len12, loss:-146.3001, fail, steps:62, opt steps:47, total reward:-32.6000, 0.34758472442626953 sec\n",
      "Episode 12, len10, loss:-70.6081, fail, steps:15, opt steps:33, total reward:-17.3000, 0.08899164199829102 sec\n",
      "Episode 13, len6, loss:-57.0159, fail, steps:80, opt steps:12, total reward:-23.3000, 0.4726076126098633 sec\n",
      "Episode 14, len6, loss:-69.8772, fail, steps:80, opt steps:12, total reward:-25.9000, 0.5004880428314209 sec\n",
      "Episode 15, len6, loss:-12.9193, fail, steps:0, opt steps:5, total reward:-10.0000, 0.017822265625 sec\n",
      "Episode 16, len8, loss:-41.8913, fail, steps:5, opt steps:23, total reward:-12.2000, 0.02917003631591797 sec\n",
      "Episode 17, len10, loss:-109.4407, fail, steps:80, opt steps:42, total reward:-26.6000, 0.4574856758117676 sec\n",
      "Episode 18, len8, loss:-98.1098, fail, steps:80, opt steps:31, total reward:-25.5000, 0.5035874843597412 sec\n",
      "Episode 19, len6, loss:-80.3184, fail, steps:80, opt steps:6, total reward:-25.5000, 0.511183500289917 sec\n",
      "Episode 20, len6, loss:-14.8074, fail, steps:0, opt steps:13, total reward:-10.0000, 0.01938939094543457 sec\n",
      "Episode 21, len12, loss:-105.2645, fail, steps:80, opt steps:43, total reward:-25.5000, 0.49921321868896484 sec\n",
      "Episode 22, len6, loss:-44.9187, fail, steps:4, opt steps:6, total reward:-11.9000, 0.059008121490478516 sec\n",
      "Episode 23, len10, loss:-69.9162, fail, steps:10, opt steps:37, total reward:-13.7000, 0.05972099304199219 sec\n",
      "Episode 24, len10, loss:-100.1779, fail, steps:80, opt steps:43, total reward:-21.9000, 0.4629862308502197 sec\n",
      "Episode 25, len12, loss:-71.2471, fail, steps:12, opt steps:28, total reward:-14.0000, 0.08170342445373535 sec\n",
      "Episode 26, len12, loss:-125.9388, fail, steps:80, opt steps:25, total reward:-27.2000, 0.4761638641357422 sec\n",
      "Episode 27, len8, loss:-108.8250, fail, steps:39, opt steps:7, total reward:-23.6000, 0.23409175872802734 sec\n",
      "Episode 28, len6, loss:-52.1815, fail, steps:7, opt steps:8, total reward:-13.5000, 0.04527020454406738 sec\n",
      "Episode 29, len12, loss:-111.5872, fail, steps:80, opt steps:58, total reward:-24.9000, 0.4650881290435791 sec\n",
      "Episode 30, len8, loss:-85.6250, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5229628086090088 sec\n",
      "Episode 31, len12, loss:-142.0156, fail, steps:68, opt steps:44, total reward:-33.6000, 0.43292832374572754 sec\n",
      "Episode 32, len8, loss:-103.6111, fail, steps:80, opt steps:20, total reward:-25.5000, 0.5105476379394531 sec\n",
      "Episode 33, len10, loss:-16.2857, fail, steps:0, opt steps:21, total reward:-10.0000, 0.019826173782348633 sec\n",
      "Episode 34, len12, loss:-107.8218, fail, steps:80, opt steps:23, total reward:-24.5000, 0.47191953659057617 sec\n",
      "Episode 35, len10, loss:-113.0361, fail, steps:80, opt steps:32, total reward:-25.5000, 0.5514326095581055 sec\n",
      "Episode 36, len6, loss:-93.8764, fail, steps:43, opt steps:5, total reward:-25.0000, 0.2826242446899414 sec\n",
      "Episode 37, len10, loss:-114.1468, fail, steps:80, opt steps:33, total reward:-25.9000, 0.4882321357727051 sec\n",
      "Episode 38, len8, loss:-87.7845, fail, steps:80, opt steps:17, total reward:-23.8000, 0.5186800956726074 sec\n",
      "Episode 39, len10, loss:-109.8910, fail, steps:80, opt steps:33, total reward:-25.8000, 0.5248913764953613 sec\n",
      "Episode 40, len10, loss:-102.4119, fail, steps:80, opt steps:40, total reward:-24.2000, 0.517143964767456 sec\n",
      "Episode 41, len10, loss:-97.1341, fail, steps:80, opt steps:33, total reward:-24.2000, 0.5170724391937256 sec\n",
      "Episode 42, len8, loss:-53.6168, fail, steps:4, opt steps:12, total reward:-11.9000, 0.043389320373535156 sec\n",
      "Episode 43, len8, loss:-102.2706, fail, steps:80, opt steps:9, total reward:-26.2000, 0.4699537754058838 sec\n",
      "Episode 44, len6, loss:-18.3420, fail, steps:0, opt steps:13, total reward:-10.0000, 0.01619100570678711 sec\n",
      "Episode 45, len8, loss:-6.1160, succeed, steps:32, opt steps:6, total reward:-9.0100, 0.18793797492980957 sec\n",
      "Episode 46, len8, loss:-107.2178, fail, steps:80, opt steps:21, total reward:-26.6000, 0.4670381546020508 sec\n",
      "Episode 47, len12, loss:-128.1413, fail, steps:49, opt steps:43, total reward:-26.5000, 0.31292080879211426 sec\n",
      "Episode 48, len10, loss:-94.3569, fail, steps:44, opt steps:23, total reward:-23.0000, 0.2739524841308594 sec\n",
      "Episode 49, len12, loss:-101.6694, fail, steps:22, opt steps:53, total reward:-18.7000, 0.1358201503753662 sec\n",
      "Episode 50, len8, loss:-88.1018, fail, steps:80, opt steps:17, total reward:-23.3000, 0.46614599227905273 sec\n",
      "Episode 51, len8, loss:-87.1232, fail, steps:80, opt steps:27, total reward:-22.8000, 0.514136552810669 sec\n",
      "Episode 52, len6, loss:-113.2722, fail, steps:61, opt steps:5, total reward:-29.8000, 0.39350390434265137 sec\n",
      "Episode 53, len8, loss:-87.6158, fail, steps:32, opt steps:6, total reward:-19.7000, 0.20812630653381348 sec\n",
      "Episode 54, len6, loss:-81.4012, fail, steps:80, opt steps:3, total reward:-25.5000, 0.4954233169555664 sec\n",
      "Episode 55, len12, loss:-88.5002, fail, steps:80, opt steps:35, total reward:-25.1000, 0.52126145362854 sec\n",
      "Episode 56, len12, loss:-103.3555, fail, steps:80, opt steps:43, total reward:-26.5000, 0.5191283226013184 sec\n",
      "Episode 57, len10, loss:-91.0502, fail, steps:80, opt steps:38, total reward:-22.1000, 0.5295882225036621 sec\n",
      "Episode 58, len8, loss:-97.4250, fail, steps:80, opt steps:22, total reward:-24.9000, 0.513314962387085 sec\n",
      "Episode 59, len10, loss:-119.2733, fail, steps:80, opt steps:29, total reward:-26.9000, 0.5123231410980225 sec\n",
      "Episode 60, len10, loss:-96.8330, fail, steps:80, opt steps:20, total reward:-24.8000, 0.581672191619873 sec\n",
      "Episode 61, len6, loss:-54.9762, fail, steps:10, opt steps:7, total reward:-12.4000, 0.0779726505279541 sec\n",
      "Episode 62, len10, loss:-103.5205, fail, steps:80, opt steps:30, total reward:-25.8000, 0.48647356033325195 sec\n",
      "Episode 63, len6, loss:-98.9765, fail, steps:64, opt steps:8, total reward:-28.6000, 0.4174191951751709 sec\n",
      "Episode 64, len8, loss:-92.2279, fail, steps:80, opt steps:30, total reward:-24.8000, 0.5141253471374512 sec\n",
      "Episode 65, len10, loss:-73.8318, fail, steps:20, opt steps:37, total reward:-15.7000, 0.14366722106933594 sec\n",
      "Episode 66, len6, loss:-19.3691, fail, steps:0, opt steps:18, total reward:-10.0000, 0.007825136184692383 sec\n",
      "Episode 67, len6, loss:-19.5365, fail, steps:0, opt steps:13, total reward:-10.0000, 0.0034132003784179688 sec\n",
      "Episode 68, len8, loss:-96.0597, fail, steps:80, opt steps:25, total reward:-24.6000, 0.45462775230407715 sec\n",
      "Episode 69, len6, loss:-84.6010, fail, steps:80, opt steps:8, total reward:-26.8000, 0.5058248043060303 sec\n",
      "Episode 70, len6, loss:-73.5287, fail, steps:80, opt steps:16, total reward:-26.2000, 0.5073363780975342 sec\n",
      "Episode 71, len8, loss:-87.1456, fail, steps:80, opt steps:18, total reward:-23.7000, 0.5405423641204834 sec\n",
      "Episode 72, len10, loss:-119.5599, fail, steps:80, opt steps:23, total reward:-25.6000, 0.506516695022583 sec\n",
      "Episode 73, len8, loss:-96.1758, fail, steps:80, opt steps:26, total reward:-25.8000, 0.5244905948638916 sec\n",
      "Episode 74, len8, loss:-97.6795, fail, steps:80, opt steps:26, total reward:-26.1000, 0.5315260887145996 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 75, len12, loss:-132.6651, fail, steps:80, opt steps:49, total reward:-26.9000, 0.5142624378204346 sec\n",
      "Episode 76, len12, loss:-111.7576, fail, steps:80, opt steps:60, total reward:-24.2000, 0.5182344913482666 sec\n",
      "Episode 77, len6, loss:-78.8509, fail, steps:80, opt steps:15, total reward:-25.8000, 0.5280673503875732 sec\n",
      "Episode 78, len12, loss:-19.2355, fail, steps:0, opt steps:38, total reward:-10.0000, 0.02114129066467285 sec\n",
      "Episode 79, len6, loss:-84.0911, fail, steps:80, opt steps:10, total reward:-26.9000, 0.46300721168518066 sec\n",
      "Episode 80, len6, loss:-49.5115, fail, steps:12, opt steps:14, total reward:-13.0000, 0.0804591178894043 sec\n",
      "Episode 81, len10, loss:-107.8937, fail, steps:80, opt steps:40, total reward:-23.9000, 0.4694788455963135 sec\n",
      "Episode 82, len10, loss:-126.8754, fail, steps:80, opt steps:22, total reward:-27.6000, 0.49091362953186035 sec\n",
      "Episode 83, len12, loss:-90.2695, fail, steps:15, opt steps:57, total reward:-15.9000, 0.10538053512573242 sec\n",
      "Episode 84, len6, loss:-75.3975, fail, steps:80, opt steps:12, total reward:-23.9000, 0.4724154472351074 sec\n",
      "Episode 85, len10, loss:-140.7511, fail, steps:59, opt steps:35, total reward:-28.8000, 0.38165736198425293 sec\n",
      "Episode 86, len6, loss:-69.0988, fail, steps:30, opt steps:13, total reward:-18.4000, 0.19646596908569336 sec\n",
      "Episode 87, len6, loss:-63.2255, fail, steps:20, opt steps:14, total reward:-14.7000, 0.12936091423034668 sec\n",
      "Episode 88, len6, loss:-93.5860, fail, steps:80, opt steps:3, total reward:-26.9000, 0.47315549850463867 sec\n",
      "Episode 89, len12, loss:-109.6952, fail, steps:37, opt steps:24, total reward:-20.2000, 0.24151611328125 sec\n",
      "Episode 90, len12, loss:-122.7915, fail, steps:80, opt steps:49, total reward:-25.5000, 0.49698472023010254 sec\n",
      "Episode 91, len8, loss:-96.7365, fail, steps:80, opt steps:21, total reward:-23.5000, 0.5628635883331299 sec\n",
      "Episode 92, len8, loss:-106.1523, fail, steps:44, opt steps:22, total reward:-24.0000, 0.2911531925201416 sec\n",
      "Episode 93, len8, loss:-102.3054, fail, steps:80, opt steps:27, total reward:-25.4000, 0.5150468349456787 sec\n",
      "Episode 94, len10, loss:-113.2334, fail, steps:80, opt steps:33, total reward:-24.8000, 0.520916223526001 sec\n",
      "Episode 95, len8, loss:-90.5167, fail, steps:80, opt steps:19, total reward:-22.6000, 0.5055019855499268 sec\n",
      "Episode 96, len8, loss:-100.1646, fail, steps:80, opt steps:27, total reward:-25.1000, 0.5293223857879639 sec\n",
      "Episode 97, len10, loss:-114.7411, fail, steps:80, opt steps:35, total reward:-25.8000, 0.5291461944580078 sec\n",
      "Episode 98, len8, loss:-120.6415, fail, steps:49, opt steps:22, total reward:-26.8000, 0.3303523063659668 sec\n",
      "Episode 99, len10, loss:-109.1362, fail, steps:80, opt steps:43, total reward:-24.4000, 0.521522045135498 sec\n",
      "Episode 100, len8, loss:-94.7851, fail, steps:80, opt steps:13, total reward:-24.1000, 0.5284833908081055 sec\n",
      "Episode 101, len6, loss:-83.7853, fail, steps:80, opt steps:20, total reward:-25.5000, 0.5216615200042725 sec\n",
      "Episode 102, len6, loss:-112.1061, fail, steps:50, opt steps:13, total reward:-27.5000, 0.32785582542419434 sec\n",
      "Episode 103, len6, loss:-67.8508, fail, steps:25, opt steps:20, total reward:-15.9000, 0.16533231735229492 sec\n",
      "Episode 104, len12, loss:-194.4494, fail, steps:76, opt steps:15, total reward:-37.7000, 0.45633363723754883 sec\n",
      "Episode 105, len12, loss:-110.1368, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5266482830047607 sec\n",
      "Episode 106, len8, loss:-96.7578, fail, steps:80, opt steps:16, total reward:-24.8000, 0.5217766761779785 sec\n",
      "Episode 107, len6, loss:-75.3340, fail, steps:80, opt steps:21, total reward:-23.9000, 0.5108532905578613 sec\n",
      "Episode 108, len6, loss:-71.2669, fail, steps:80, opt steps:14, total reward:-23.6000, 0.507843017578125 sec\n",
      "Episode 109, len10, loss:-114.5241, fail, steps:80, opt steps:47, total reward:-25.1000, 0.5303659439086914 sec\n",
      "Episode 110, len6, loss:-84.3031, fail, steps:40, opt steps:10, total reward:-20.8000, 0.267869234085083 sec\n",
      "Episode 111, len6, loss:-74.5517, fail, steps:80, opt steps:11, total reward:-24.1000, 0.5638430118560791 sec\n",
      "Episode 112, len12, loss:-164.4970, fail, steps:76, opt steps:50, total reward:-33.6000, 0.4968869686126709 sec\n",
      "Episode 113, len10, loss:-115.9541, fail, steps:80, opt steps:46, total reward:-25.1000, 0.52848219871521 sec\n",
      "Episode 114, len12, loss:-119.3734, fail, steps:80, opt steps:39, total reward:-25.8000, 0.5281591415405273 sec\n",
      "Episode 115, len8, loss:-20.4483, fail, steps:0, opt steps:15, total reward:-10.0000, 0.021131038665771484 sec\n",
      "Episode 116, len12, loss:-113.3973, fail, steps:80, opt steps:55, total reward:-23.1000, 0.4804656505584717 sec\n",
      "Episode 117, len6, loss:-91.2499, fail, steps:80, opt steps:3, total reward:-26.9000, 0.4932863712310791 sec\n",
      "Episode 118, len6, loss:-83.2544, fail, steps:80, opt steps:8, total reward:-26.1000, 0.5201783180236816 sec\n",
      "Episode 119, len10, loss:-142.7148, fail, steps:73, opt steps:25, total reward:-30.1000, 0.4686713218688965 sec\n",
      "Episode 120, len8, loss:-54.5732, fail, steps:4, opt steps:24, total reward:-10.9000, 0.041559457778930664 sec\n",
      "Episode 121, len12, loss:-119.2772, fail, steps:80, opt steps:59, total reward:-24.5000, 0.474684476852417 sec\n",
      "Episode 122, len8, loss:-88.1489, fail, steps:35, opt steps:33, total reward:-21.2000, 0.23446440696716309 sec\n",
      "Episode 123, len6, loss:-68.3249, fail, steps:80, opt steps:11, total reward:-22.3000, 0.4762699604034424 sec\n",
      "Episode 124, len8, loss:-98.0904, fail, steps:80, opt steps:17, total reward:-26.5000, 0.5083456039428711 sec\n",
      "Episode 125, len6, loss:-63.1268, fail, steps:80, opt steps:19, total reward:-23.4000, 0.5285091400146484 sec\n",
      "Episode 126, len6, loss:-75.6642, fail, steps:80, opt steps:3, total reward:-26.8000, 0.5267128944396973 sec\n",
      "Episode 127, len6, loss:-81.1468, fail, steps:80, opt steps:11, total reward:-26.1000, 0.5321402549743652 sec\n",
      "Episode 128, len8, loss:-102.1591, fail, steps:80, opt steps:6, total reward:-25.4000, 0.537184476852417 sec\n",
      "Episode 129, len6, loss:-21.0288, fail, steps:0, opt steps:15, total reward:-10.0000, 0.02120184898376465 sec\n",
      "Episode 130, len8, loss:-97.7865, fail, steps:80, opt steps:24, total reward:-25.5000, 0.5222008228302002 sec\n",
      "Episode 131, len8, loss:-68.2254, fail, steps:15, opt steps:23, total reward:-15.2000, 0.10385608673095703 sec\n",
      "Episode 132, len6, loss:-70.4193, fail, steps:80, opt steps:12, total reward:-25.1000, 0.48913097381591797 sec\n",
      "Episode 133, len6, loss:-84.8048, fail, steps:80, opt steps:15, total reward:-25.2000, 0.5012660026550293 sec\n",
      "Episode 134, len10, loss:-21.2005, fail, steps:0, opt steps:25, total reward:-10.0000, 0.018492698669433594 sec\n",
      "Episode 135, len12, loss:-139.3965, fail, steps:54, opt steps:43, total reward:-26.7000, 0.3098018169403076 sec\n",
      "Episode 136, len6, loss:-77.6232, fail, steps:80, opt steps:17, total reward:-25.4000, 0.5017955303192139 sec\n",
      "Episode 137, len6, loss:-103.6741, fail, steps:68, opt steps:18, total reward:-29.8000, 0.4448530673980713 sec\n",
      "Episode 138, len6, loss:-64.6866, fail, steps:80, opt steps:17, total reward:-23.4000, 0.5244095325469971 sec\n",
      "Episode 139, len8, loss:-96.5515, fail, steps:80, opt steps:33, total reward:-25.1000, 0.5288023948669434 sec\n",
      "Episode 140, len10, loss:-118.3056, fail, steps:80, opt steps:18, total reward:-25.9000, 0.5119585990905762 sec\n",
      "Episode 141, len8, loss:-89.7341, fail, steps:80, opt steps:20, total reward:-24.5000, 0.5224659442901611 sec\n",
      "Episode 142, len8, loss:-113.8176, fail, steps:49, opt steps:25, total reward:-25.1000, 0.3346405029296875 sec\n",
      "Episode 143, len6, loss:-76.5206, fail, steps:80, opt steps:15, total reward:-25.4000, 0.5197532176971436 sec\n",
      "Episode 144, len10, loss:-120.2211, fail, steps:38, opt steps:18, total reward:-22.9000, 0.2484273910522461 sec\n",
      "Episode 145, len12, loss:-162.3417, fail, steps:62, opt steps:52, total reward:-30.7000, 0.39240574836730957 sec\n",
      "Episode 146, len8, loss:-100.3679, fail, steps:80, opt steps:25, total reward:-24.1000, 0.5646424293518066 sec\n",
      "Episode 147, len12, loss:-124.5437, fail, steps:80, opt steps:45, total reward:-26.2000, 0.5142519474029541 sec\n",
      "Episode 148, len8, loss:-107.3570, fail, steps:80, opt steps:15, total reward:-26.8000, 0.5263965129852295 sec\n",
      "Episode 149, len6, loss:-77.0504, fail, steps:80, opt steps:18, total reward:-24.7000, 0.538703203201294 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 150, len10, loss:-110.4729, fail, steps:80, opt steps:47, total reward:-24.1000, 0.5348355770111084 sec\n",
      "Episode 151, len12, loss:-133.4990, fail, steps:44, opt steps:43, total reward:-23.3000, 0.2986025810241699 sec\n",
      "Episode 152, len8, loss:-105.1942, fail, steps:80, opt steps:30, total reward:-26.5000, 0.5050051212310791 sec\n",
      "Episode 153, len10, loss:-107.3640, fail, steps:80, opt steps:45, total reward:-25.4000, 0.5285718441009521 sec\n",
      "Episode 154, len6, loss:-82.0589, fail, steps:80, opt steps:8, total reward:-26.5000, 0.5219759941101074 sec\n",
      "Episode 155, len12, loss:-110.3832, fail, steps:80, opt steps:69, total reward:-23.4000, 0.5340633392333984 sec\n",
      "Episode 156, len8, loss:-105.0339, fail, steps:80, opt steps:19, total reward:-25.8000, 0.5296108722686768 sec\n",
      "Episode 157, len6, loss:-85.8270, fail, steps:24, opt steps:21, total reward:-18.6000, 0.17052817344665527 sec\n",
      "Episode 158, len10, loss:-120.7726, fail, steps:80, opt steps:15, total reward:-26.5000, 0.49132537841796875 sec\n",
      "Episode 159, len6, loss:-54.6142, fail, steps:11, opt steps:18, total reward:-12.0000, 0.0861368179321289 sec\n",
      "Episode 160, len10, loss:-124.4407, fail, steps:39, opt steps:22, total reward:-23.8000, 0.2327895164489746 sec\n",
      "Episode 161, len6, loss:-96.5722, fail, steps:39, opt steps:21, total reward:-22.8000, 0.23968935012817383 sec\n",
      "Episode 162, len12, loss:-21.5796, fail, steps:0, opt steps:59, total reward:-10.0000, 0.010115385055541992 sec\n",
      "Episode 163, len10, loss:-22.0300, fail, steps:0, opt steps:17, total reward:-10.0000, 0.003458261489868164 sec\n",
      "Episode 164, len10, loss:-110.9693, fail, steps:80, opt steps:12, total reward:-24.7000, 0.4866905212402344 sec\n",
      "Episode 165, len6, loss:-79.5045, fail, steps:80, opt steps:8, total reward:-24.7000, 0.519669771194458 sec\n",
      "Episode 166, len8, loss:-105.5024, fail, steps:80, opt steps:15, total reward:-25.9000, 0.5508279800415039 sec\n",
      "Episode 167, len8, loss:-104.9819, fail, steps:80, opt steps:16, total reward:-26.1000, 0.5273613929748535 sec\n",
      "Episode 168, len10, loss:-114.5952, fail, steps:80, opt steps:48, total reward:-25.8000, 0.5262534618377686 sec\n",
      "Episode 169, len12, loss:-119.6091, fail, steps:80, opt steps:25, total reward:-25.8000, 0.5268120765686035 sec\n",
      "Episode 170, len6, loss:-75.3531, fail, steps:80, opt steps:7, total reward:-23.4000, 0.537285566329956 sec\n",
      "Episode 171, len6, loss:-83.1053, fail, steps:80, opt steps:21, total reward:-24.8000, 0.5307929515838623 sec\n",
      "Episode 172, len10, loss:-124.6148, fail, steps:80, opt steps:23, total reward:-26.1000, 0.5343406200408936 sec\n",
      "Episode 173, len12, loss:-119.4735, fail, steps:80, opt steps:54, total reward:-25.1000, 0.5342767238616943 sec\n",
      "Episode 174, len10, loss:-64.3721, fail, steps:9, opt steps:35, total reward:-11.4000, 0.07713174819946289 sec\n",
      "Episode 175, len10, loss:-109.0130, fail, steps:80, opt steps:43, total reward:-23.8000, 0.4861922264099121 sec\n",
      "Episode 176, len8, loss:-101.5033, fail, steps:80, opt steps:24, total reward:-25.2000, 0.5032405853271484 sec\n",
      "Episode 177, len6, loss:-131.0649, fail, steps:69, opt steps:19, total reward:-32.8000, 0.45225000381469727 sec\n",
      "Episode 178, len12, loss:-130.2653, fail, steps:80, opt steps:46, total reward:-25.5000, 0.5142290592193604 sec\n",
      "Episode 179, len8, loss:-86.0794, fail, steps:18, opt steps:33, total reward:-16.5000, 0.12416672706604004 sec\n",
      "Episode 180, len6, loss:-75.2834, fail, steps:80, opt steps:15, total reward:-23.6000, 0.4725911617279053 sec\n",
      "Episode 181, len12, loss:-128.9167, fail, steps:80, opt steps:25, total reward:-25.5000, 0.5090000629425049 sec\n",
      "Episode 182, len6, loss:-65.7267, fail, steps:80, opt steps:6, total reward:-20.5000, 0.5187232494354248 sec\n",
      "Episode 183, len8, loss:-99.6078, fail, steps:33, opt steps:25, total reward:-19.8000, 0.20345497131347656 sec\n",
      "Episode 184, len6, loss:-94.6724, fail, steps:80, opt steps:5, total reward:-26.9000, 0.4953429698944092 sec\n",
      "Episode 185, len6, loss:-71.6867, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5363531112670898 sec\n",
      "Episode 186, len12, loss:-132.5743, fail, steps:46, opt steps:53, total reward:-23.6000, 0.35752248764038086 sec\n",
      "Episode 187, len12, loss:-141.9311, fail, steps:43, opt steps:62, total reward:-24.0000, 0.27568840980529785 sec\n",
      "Episode 188, len6, loss:-71.8716, fail, steps:80, opt steps:16, total reward:-23.4000, 0.5119435787200928 sec\n",
      "Episode 189, len10, loss:-120.6056, fail, steps:80, opt steps:31, total reward:-26.8000, 0.5202524662017822 sec\n",
      "Episode 190, len6, loss:-70.6292, fail, steps:18, opt steps:7, total reward:-16.1000, 0.1320352554321289 sec\n",
      "Episode 191, len6, loss:-79.7446, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5054934024810791 sec\n",
      "Episode 192, len12, loss:-132.3284, fail, steps:80, opt steps:40, total reward:-26.5000, 0.5129117965698242 sec\n",
      "Episode 193, len6, loss:-82.0467, fail, steps:80, opt steps:14, total reward:-24.8000, 0.5226924419403076 sec\n",
      "Episode 194, len10, loss:-122.7509, fail, steps:80, opt steps:31, total reward:-26.8000, 0.5264787673950195 sec\n",
      "Episode 195, len6, loss:-84.4859, fail, steps:80, opt steps:13, total reward:-25.2000, 0.5208485126495361 sec\n",
      "Episode 196, len6, loss:-88.7515, fail, steps:80, opt steps:13, total reward:-24.9000, 0.5141861438751221 sec\n",
      "Episode 197, len12, loss:-169.3181, fail, steps:75, opt steps:45, total reward:-31.9000, 0.5076651573181152 sec\n",
      "Episode 198, len6, loss:-129.4497, fail, steps:72, opt steps:16, total reward:-31.7000, 0.4811992645263672 sec\n",
      "Episode 199, len8, loss:-84.7845, fail, steps:80, opt steps:29, total reward:-23.8000, 0.5268871784210205 sec\n",
      "Episode 200, len12, loss:-155.2333, fail, steps:53, opt steps:43, total reward:-27.3000, 0.3605844974517822 sec\n",
      "Episode 201, len8, loss:-94.2554, fail, steps:80, opt steps:24, total reward:-24.4000, 0.5271403789520264 sec\n",
      "Episode 202, len6, loss:-78.0695, fail, steps:80, opt steps:7, total reward:-24.7000, 0.5925099849700928 sec\n",
      "Episode 203, len6, loss:-81.5052, fail, steps:80, opt steps:14, total reward:-24.4000, 0.5366063117980957 sec\n",
      "Episode 204, len6, loss:-132.7694, fail, steps:69, opt steps:8, total reward:-32.9000, 0.4503200054168701 sec\n",
      "Episode 205, len12, loss:-151.2457, fail, steps:59, opt steps:41, total reward:-28.4000, 0.39952707290649414 sec\n",
      "Episode 206, len12, loss:-104.9781, fail, steps:25, opt steps:32, total reward:-18.9000, 0.1697673797607422 sec\n",
      "Episode 207, len6, loss:-74.7229, fail, steps:80, opt steps:13, total reward:-23.7000, 0.5093746185302734 sec\n",
      "Episode 208, len6, loss:-73.0127, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5356853008270264 sec\n",
      "Episode 209, len6, loss:-73.0767, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5417165756225586 sec\n",
      "Episode 210, len12, loss:-122.4893, fail, steps:80, opt steps:47, total reward:-24.6000, 0.5094916820526123 sec\n",
      "Episode 211, len10, loss:-116.2282, fail, steps:39, opt steps:37, total reward:-22.4000, 0.2728271484375 sec\n",
      "Episode 212, len6, loss:-78.1525, fail, steps:80, opt steps:15, total reward:-24.4000, 0.5138907432556152 sec\n",
      "Episode 213, len12, loss:-121.0068, fail, steps:80, opt steps:32, total reward:-24.4000, 0.5293076038360596 sec\n",
      "Episode 214, len8, loss:-92.3181, fail, steps:80, opt steps:26, total reward:-24.0000, 0.54337477684021 sec\n",
      "Episode 215, len8, loss:-99.2844, fail, steps:80, opt steps:26, total reward:-25.4000, 0.5368661880493164 sec\n",
      "Episode 216, len12, loss:-114.5066, fail, steps:80, opt steps:59, total reward:-24.1000, 0.5342767238616943 sec\n",
      "Episode 217, len12, loss:-130.4955, fail, steps:80, opt steps:43, total reward:-25.8000, 0.5298795700073242 sec\n",
      "Episode 218, len8, loss:-86.4815, fail, steps:22, opt steps:19, total reward:-16.3000, 0.16238999366760254 sec\n",
      "Episode 219, len6, loss:-79.4671, fail, steps:80, opt steps:11, total reward:-24.1000, 0.5003702640533447 sec\n",
      "Episode 220, len10, loss:-103.8617, fail, steps:80, opt steps:44, total reward:-22.8000, 0.5665571689605713 sec\n",
      "Episode 221, len8, loss:-92.4497, fail, steps:80, opt steps:33, total reward:-23.7000, 0.535423755645752 sec\n",
      "Episode 222, len12, loss:-118.7034, fail, steps:80, opt steps:42, total reward:-25.5000, 0.5215587615966797 sec\n",
      "Episode 223, len12, loss:-130.5658, fail, steps:80, opt steps:31, total reward:-26.5000, 0.524122953414917 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 224, len12, loss:-115.6143, fail, steps:80, opt steps:51, total reward:-25.1000, 0.5317409038543701 sec\n",
      "Episode 225, len12, loss:-106.4172, fail, steps:80, opt steps:49, total reward:-24.1000, 0.5351014137268066 sec\n",
      "Episode 226, len10, loss:-115.9714, fail, steps:80, opt steps:41, total reward:-25.1000, 0.5331845283508301 sec\n",
      "Episode 227, len12, loss:-122.4235, fail, steps:80, opt steps:35, total reward:-25.4000, 0.5392296314239502 sec\n",
      "Episode 228, len12, loss:-124.3955, fail, steps:80, opt steps:40, total reward:-26.1000, 0.5338590145111084 sec\n",
      "Episode 229, len10, loss:-89.4874, fail, steps:80, opt steps:55, total reward:-20.8000, 0.5318224430084229 sec\n",
      "Episode 230, len10, loss:-107.1731, fail, steps:80, opt steps:34, total reward:-24.5000, 0.5270659923553467 sec\n",
      "Episode 231, len10, loss:-112.0203, fail, steps:80, opt steps:35, total reward:-25.4000, 0.5922696590423584 sec\n",
      "Episode 232, len8, loss:-102.2744, fail, steps:80, opt steps:6, total reward:-25.8000, 0.5311322212219238 sec\n",
      "Episode 233, len10, loss:-91.0194, fail, steps:17, opt steps:17, total reward:-15.8000, 0.12755155563354492 sec\n",
      "Episode 234, len12, loss:-104.1877, fail, steps:80, opt steps:41, total reward:-22.7000, 0.5047669410705566 sec\n",
      "Episode 235, len10, loss:-183.5140, fail, steps:79, opt steps:32, total reward:-35.1000, 0.5208995342254639 sec\n",
      "Episode 236, len12, loss:-121.6771, fail, steps:80, opt steps:77, total reward:-24.9000, 0.5109400749206543 sec\n",
      "Episode 237, len10, loss:-102.5922, fail, steps:80, opt steps:33, total reward:-23.5000, 0.520972490310669 sec\n",
      "Episode 238, len10, loss:-115.1846, fail, steps:80, opt steps:55, total reward:-24.1000, 0.5315825939178467 sec\n",
      "Episode 239, len8, loss:-106.4799, fail, steps:80, opt steps:24, total reward:-26.2000, 0.5198695659637451 sec\n",
      "Episode 240, len12, loss:-124.9911, fail, steps:80, opt steps:39, total reward:-24.8000, 0.5291013717651367 sec\n",
      "Episode 241, len10, loss:-126.7348, fail, steps:80, opt steps:15, total reward:-26.1000, 0.5341989994049072 sec\n",
      "Episode 242, len8, loss:-108.7792, fail, steps:80, opt steps:28, total reward:-26.1000, 0.5349223613739014 sec\n",
      "Episode 243, len8, loss:-88.3758, fail, steps:19, opt steps:33, total reward:-16.1000, 0.13609910011291504 sec\n",
      "Episode 244, len12, loss:-123.4861, fail, steps:80, opt steps:55, total reward:-24.7000, 0.5065228939056396 sec\n",
      "Episode 245, len12, loss:-108.8144, fail, steps:80, opt steps:55, total reward:-23.4000, 0.5251092910766602 sec\n",
      "Episode 246, len6, loss:-90.9031, fail, steps:80, opt steps:8, total reward:-27.5000, 0.5713038444519043 sec\n",
      "Episode 247, len8, loss:-95.0406, fail, steps:80, opt steps:12, total reward:-23.4000, 0.5327315330505371 sec\n",
      "Episode 248, len6, loss:-23.9981, fail, steps:0, opt steps:21, total reward:-10.0000, 0.0209505558013916 sec\n",
      "Episode 249, len6, loss:-79.1521, fail, steps:80, opt steps:11, total reward:-25.1000, 0.47800755500793457 sec\n",
      "Episode 250, len12, loss:-114.9275, fail, steps:80, opt steps:35, total reward:-24.4000, 0.5144836902618408 sec\n",
      "Episode 251, len12, loss:-120.1759, fail, steps:80, opt steps:56, total reward:-25.4000, 0.527226448059082 sec\n",
      "Episode 252, len12, loss:-135.3453, fail, steps:80, opt steps:29, total reward:-26.8000, 0.5245187282562256 sec\n",
      "Episode 253, len12, loss:-130.9699, fail, steps:80, opt steps:39, total reward:-25.8000, 0.5277738571166992 sec\n",
      "Episode 254, len12, loss:-122.2001, fail, steps:80, opt steps:43, total reward:-24.7000, 0.5396041870117188 sec\n",
      "Episode 255, len8, loss:-87.0364, fail, steps:80, opt steps:25, total reward:-22.4000, 0.5406932830810547 sec\n",
      "Episode 256, len10, loss:-124.3159, fail, steps:80, opt steps:43, total reward:-26.2000, 0.522449254989624 sec\n",
      "Episode 257, len8, loss:-95.8262, fail, steps:80, opt steps:21, total reward:-24.4000, 0.5387613773345947 sec\n",
      "Episode 258, len10, loss:-115.5510, fail, steps:80, opt steps:36, total reward:-25.1000, 0.5351114273071289 sec\n",
      "Episode 259, len12, loss:-128.3631, fail, steps:80, opt steps:68, total reward:-25.8000, 0.5304145812988281 sec\n",
      "Episode 260, len8, loss:-104.3938, fail, steps:80, opt steps:12, total reward:-25.1000, 0.5338160991668701 sec\n",
      "Episode 261, len6, loss:-77.5055, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5491690635681152 sec\n",
      "Episode 262, len10, loss:-112.1275, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5426061153411865 sec\n",
      "Episode 263, len8, loss:-89.0477, fail, steps:80, opt steps:24, total reward:-22.7000, 0.5444414615631104 sec\n",
      "Episode 264, len12, loss:-115.0080, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5950272083282471 sec\n",
      "Episode 265, len6, loss:-74.6369, fail, steps:80, opt steps:8, total reward:-24.0000, 0.54860520362854 sec\n",
      "Episode 266, len8, loss:-114.3316, fail, steps:80, opt steps:15, total reward:-26.5000, 0.5253403186798096 sec\n",
      "Episode 267, len6, loss:-83.9160, fail, steps:80, opt steps:15, total reward:-25.2000, 0.5234181880950928 sec\n",
      "Episode 268, len6, loss:-82.1528, fail, steps:80, opt steps:17, total reward:-25.1000, 0.5371134281158447 sec\n",
      "Episode 269, len10, loss:-175.4995, fail, steps:77, opt steps:36, total reward:-35.9000, 0.511793851852417 sec\n",
      "Episode 270, len6, loss:-56.1186, fail, steps:3, opt steps:16, total reward:-11.6000, 0.03720808029174805 sec\n",
      "Episode 271, len12, loss:-111.2882, fail, steps:80, opt steps:31, total reward:-24.4000, 0.48810911178588867 sec\n",
      "Episode 272, len6, loss:-73.0374, fail, steps:80, opt steps:8, total reward:-23.4000, 0.518286943435669 sec\n",
      "Episode 273, len12, loss:-111.2351, fail, steps:80, opt steps:47, total reward:-24.7000, 0.5302407741546631 sec\n",
      "Episode 274, len8, loss:-88.1001, fail, steps:80, opt steps:15, total reward:-24.1000, 0.5301468372344971 sec\n",
      "Episode 275, len8, loss:-85.5270, fail, steps:80, opt steps:25, total reward:-23.4000, 0.5886659622192383 sec\n",
      "Episode 276, len10, loss:-111.9919, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5419976711273193 sec\n",
      "Episode 277, len6, loss:-23.9271, fail, steps:0, opt steps:11, total reward:-10.0000, 0.021224260330200195 sec\n",
      "Episode 278, len10, loss:-104.4680, fail, steps:80, opt steps:43, total reward:-23.7000, 0.4875061511993408 sec\n",
      "Episode 279, len6, loss:-80.2137, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5199859142303467 sec\n",
      "Episode 280, len12, loss:-130.9209, fail, steps:80, opt steps:45, total reward:-26.6000, 0.49903416633605957 sec\n",
      "Episode 281, len6, loss:-79.0769, fail, steps:80, opt steps:16, total reward:-25.1000, 0.5240609645843506 sec\n",
      "Episode 282, len10, loss:-112.3534, fail, steps:80, opt steps:29, total reward:-25.1000, 0.5288949012756348 sec\n",
      "Episode 283, len12, loss:-118.3228, fail, steps:80, opt steps:57, total reward:-24.7000, 0.5399446487426758 sec\n",
      "Episode 284, len10, loss:-102.1408, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5463306903839111 sec\n",
      "Episode 285, len12, loss:-119.5622, fail, steps:80, opt steps:59, total reward:-25.4000, 0.5374956130981445 sec\n",
      "Episode 286, len8, loss:-86.4434, fail, steps:80, opt steps:9, total reward:-24.7000, 0.5427336692810059 sec\n",
      "Episode 287, len8, loss:-91.3904, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5436217784881592 sec\n",
      "Episode 288, len10, loss:-112.3254, fail, steps:80, opt steps:31, total reward:-25.8000, 0.531010627746582 sec\n",
      "Episode 289, len10, loss:-96.7558, fail, steps:80, opt steps:34, total reward:-23.4000, 0.5384132862091064 sec\n",
      "Episode 290, len12, loss:-124.1127, fail, steps:39, opt steps:61, total reward:-21.4000, 0.27619147300720215 sec\n",
      "Episode 291, len8, loss:-23.6435, fail, steps:0, opt steps:15, total reward:-10.0000, 0.012157917022705078 sec\n",
      "Episode 292, len10, loss:-104.7830, fail, steps:80, opt steps:40, total reward:-25.1000, 0.5343894958496094 sec\n",
      "Episode 293, len8, loss:-89.4212, fail, steps:80, opt steps:19, total reward:-24.5000, 0.5022528171539307 sec\n",
      "Episode 294, len6, loss:-73.1584, fail, steps:80, opt steps:7, total reward:-24.1000, 0.5213718414306641 sec\n",
      "Episode 295, len8, loss:-88.4165, fail, steps:80, opt steps:16, total reward:-23.1000, 0.5290017127990723 sec\n",
      "Episode 296, len10, loss:-87.6523, fail, steps:80, opt steps:34, total reward:-21.8000, 0.5271217823028564 sec\n",
      "Episode 297, len12, loss:-114.7957, fail, steps:80, opt steps:34, total reward:-24.9000, 0.5148453712463379 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 298, len8, loss:-116.9014, fail, steps:51, opt steps:13, total reward:-26.8000, 0.3343183994293213 sec\n",
      "Episode 299, len10, loss:-113.4996, fail, steps:80, opt steps:20, total reward:-26.1000, 0.5182127952575684 sec\n",
      "Episode 300, len12, loss:-83.7678, fail, steps:19, opt steps:53, total reward:-16.4000, 0.14023375511169434 sec\n",
      "Episode 301, len12, loss:-121.1990, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5073716640472412 sec\n",
      "Episode 302, len12, loss:-123.6743, fail, steps:80, opt steps:39, total reward:-25.4000, 0.5274467468261719 sec\n",
      "Episode 303, len10, loss:-113.9739, fail, steps:80, opt steps:30, total reward:-24.7000, 0.536067008972168 sec\n",
      "Episode 304, len12, loss:-130.9588, fail, steps:80, opt steps:48, total reward:-25.8000, 0.5267529487609863 sec\n",
      "Episode 305, len6, loss:-73.4684, fail, steps:80, opt steps:6, total reward:-25.4000, 0.5383098125457764 sec\n",
      "Episode 306, len10, loss:-98.2069, fail, steps:80, opt steps:39, total reward:-22.8000, 0.5299050807952881 sec\n",
      "Episode 307, len6, loss:-64.7422, fail, steps:80, opt steps:18, total reward:-23.1000, 0.5343277454376221 sec\n",
      "Episode 308, len8, loss:-102.4552, fail, steps:80, opt steps:6, total reward:-25.5000, 0.526397705078125 sec\n",
      "Episode 309, len10, loss:-104.2587, fail, steps:80, opt steps:35, total reward:-23.4000, 0.5380721092224121 sec\n",
      "Episode 310, len12, loss:-123.3087, fail, steps:80, opt steps:30, total reward:-25.1000, 0.5908458232879639 sec\n",
      "Episode 311, len8, loss:-87.3422, fail, steps:80, opt steps:24, total reward:-23.4000, 0.5424513816833496 sec\n",
      "Episode 312, len6, loss:-75.6021, fail, steps:17, opt steps:15, total reward:-15.8000, 0.12810969352722168 sec\n",
      "Episode 313, len10, loss:-108.8492, fail, steps:80, opt steps:50, total reward:-25.2000, 0.4833259582519531 sec\n",
      "Episode 314, len6, loss:-67.7020, fail, steps:80, opt steps:21, total reward:-23.5000, 0.5104279518127441 sec\n",
      "Episode 315, len8, loss:-98.3218, fail, steps:80, opt steps:18, total reward:-25.8000, 0.523345947265625 sec\n",
      "Episode 316, len6, loss:-70.5572, fail, steps:80, opt steps:18, total reward:-25.1000, 0.5292530059814453 sec\n",
      "Episode 317, len12, loss:-118.5962, fail, steps:80, opt steps:49, total reward:-24.7000, 0.5427608489990234 sec\n",
      "Episode 318, len6, loss:-68.8979, fail, steps:80, opt steps:13, total reward:-24.1000, 0.5361099243164062 sec\n",
      "Episode 319, len12, loss:-102.1430, fail, steps:80, opt steps:66, total reward:-22.2000, 0.520798921585083 sec\n",
      "Episode 320, len12, loss:-113.5403, fail, steps:80, opt steps:60, total reward:-24.1000, 0.535010576248169 sec\n",
      "Episode 321, len12, loss:-126.3777, fail, steps:80, opt steps:63, total reward:-26.1000, 0.5361888408660889 sec\n",
      "Episode 322, len12, loss:-117.2693, fail, steps:80, opt steps:55, total reward:-24.4000, 0.540081262588501 sec\n",
      "Episode 323, len8, loss:-82.8016, fail, steps:33, opt steps:25, total reward:-19.3000, 0.23182010650634766 sec\n",
      "Episode 324, len10, loss:-78.9202, fail, steps:5, opt steps:41, total reward:-12.2000, 0.04006457328796387 sec\n",
      "Episode 325, len6, loss:-56.4233, fail, steps:80, opt steps:19, total reward:-21.5000, 0.4767460823059082 sec\n",
      "Episode 326, len6, loss:-68.7576, fail, steps:80, opt steps:16, total reward:-23.4000, 0.5676870346069336 sec\n",
      "Episode 327, len6, loss:-74.2302, fail, steps:80, opt steps:15, total reward:-25.1000, 0.525097131729126 sec\n",
      "Episode 328, len8, loss:-85.6936, fail, steps:80, opt steps:23, total reward:-24.4000, 0.5321738719940186 sec\n",
      "Episode 329, len6, loss:-67.6726, fail, steps:80, opt steps:18, total reward:-23.4000, 0.5363421440124512 sec\n",
      "Episode 330, len6, loss:-70.9984, fail, steps:80, opt steps:13, total reward:-24.4000, 0.5362157821655273 sec\n",
      "Episode 331, len12, loss:-124.3364, fail, steps:80, opt steps:25, total reward:-25.8000, 0.5287840366363525 sec\n",
      "Episode 332, len12, loss:-119.8070, fail, steps:80, opt steps:46, total reward:-25.4000, 0.5385630130767822 sec\n",
      "Episode 333, len10, loss:-108.4873, fail, steps:80, opt steps:34, total reward:-25.4000, 0.5395236015319824 sec\n",
      "Episode 334, len6, loss:-77.6362, fail, steps:80, opt steps:13, total reward:-24.8000, 0.5299062728881836 sec\n",
      "Episode 335, len6, loss:-74.6503, fail, steps:80, opt steps:14, total reward:-24.5000, 0.524932861328125 sec\n",
      "Episode 336, len6, loss:-67.8480, fail, steps:80, opt steps:16, total reward:-23.4000, 0.539764404296875 sec\n",
      "Episode 337, len10, loss:-106.4800, fail, steps:80, opt steps:29, total reward:-24.4000, 0.5400571823120117 sec\n",
      "Episode 338, len12, loss:-125.2723, fail, steps:80, opt steps:47, total reward:-25.4000, 0.5405442714691162 sec\n",
      "Episode 339, len8, loss:-98.4216, fail, steps:80, opt steps:35, total reward:-25.8000, 0.5314176082611084 sec\n",
      "Episode 340, len10, loss:-103.4163, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5465006828308105 sec\n",
      "Episode 341, len6, loss:-64.8213, fail, steps:80, opt steps:17, total reward:-23.4000, 0.5950326919555664 sec\n",
      "Episode 342, len8, loss:-87.0854, fail, steps:80, opt steps:31, total reward:-22.7000, 0.544954776763916 sec\n",
      "Episode 343, len12, loss:-119.6208, fail, steps:80, opt steps:34, total reward:-24.1000, 0.5385761260986328 sec\n",
      "Episode 344, len12, loss:-126.3376, fail, steps:80, opt steps:58, total reward:-24.8000, 0.5329699516296387 sec\n",
      "Episode 345, len10, loss:-105.2109, fail, steps:80, opt steps:29, total reward:-23.7000, 0.543684720993042 sec\n",
      "Episode 346, len6, loss:-71.1392, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5439357757568359 sec\n",
      "Episode 347, len10, loss:-109.0446, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5535454750061035 sec\n",
      "Episode 348, len12, loss:-80.7787, fail, steps:15, opt steps:50, total reward:-13.2000, 0.1157066822052002 sec\n",
      "Episode 349, len6, loss:-74.6789, fail, steps:80, opt steps:19, total reward:-24.8000, 0.4902067184448242 sec\n",
      "Episode 350, len12, loss:-119.6187, fail, steps:80, opt steps:44, total reward:-25.2000, 0.5052404403686523 sec\n",
      "Episode 351, len8, loss:-98.3881, fail, steps:80, opt steps:7, total reward:-25.8000, 0.5203216075897217 sec\n",
      "Episode 352, len12, loss:-117.0460, fail, steps:80, opt steps:62, total reward:-24.1000, 0.5293753147125244 sec\n",
      "Episode 353, len10, loss:-121.2419, fail, steps:80, opt steps:21, total reward:-26.1000, 0.5328140258789062 sec\n",
      "Episode 354, len10, loss:-103.5538, fail, steps:80, opt steps:23, total reward:-24.0000, 0.545656681060791 sec\n",
      "Episode 355, len12, loss:-103.5720, fail, steps:80, opt steps:71, total reward:-23.1000, 0.5344686508178711 sec\n",
      "Episode 356, len10, loss:-98.4868, fail, steps:80, opt steps:39, total reward:-23.4000, 0.5913643836975098 sec\n",
      "Episode 357, len12, loss:-102.8125, fail, steps:80, opt steps:69, total reward:-23.1000, 0.5349698066711426 sec\n",
      "Episode 358, len12, loss:-112.0673, fail, steps:80, opt steps:34, total reward:-24.7000, 0.5418739318847656 sec\n",
      "Episode 359, len6, loss:-82.7984, fail, steps:80, opt steps:13, total reward:-26.1000, 0.5335919857025146 sec\n",
      "Episode 360, len12, loss:-119.9791, fail, steps:80, opt steps:27, total reward:-25.4000, 0.5385880470275879 sec\n",
      "Episode 361, len8, loss:-97.0190, fail, steps:80, opt steps:15, total reward:-25.4000, 0.5403895378112793 sec\n",
      "Episode 362, len12, loss:-124.0216, fail, steps:80, opt steps:46, total reward:-24.8000, 0.5291047096252441 sec\n",
      "Episode 363, len10, loss:-105.8049, fail, steps:80, opt steps:21, total reward:-25.1000, 0.5338244438171387 sec\n",
      "Episode 364, len8, loss:-85.9970, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5475907325744629 sec\n",
      "Episode 365, len10, loss:-111.4994, fail, steps:80, opt steps:37, total reward:-24.2000, 0.5216338634490967 sec\n",
      "Episode 366, len8, loss:-91.6137, fail, steps:80, opt steps:31, total reward:-24.4000, 0.5384654998779297 sec\n",
      "Episode 367, len12, loss:-122.0782, fail, steps:80, opt steps:57, total reward:-25.4000, 0.5397031307220459 sec\n",
      "Episode 368, len6, loss:-79.9636, fail, steps:80, opt steps:20, total reward:-25.1000, 0.533897876739502 sec\n",
      "Episode 369, len10, loss:-109.5804, fail, steps:80, opt steps:46, total reward:-24.4000, 0.5400209426879883 sec\n",
      "Episode 370, len10, loss:-25.5004, fail, steps:0, opt steps:38, total reward:-10.0000, 0.021399497985839844 sec\n",
      "Episode 371, len12, loss:-80.8518, fail, steps:9, opt steps:45, total reward:-13.4000, 0.05281233787536621 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 372, len12, loss:-117.4881, fail, steps:80, opt steps:45, total reward:-24.1000, 0.4801802635192871 sec\n",
      "Episode 373, len6, loss:-71.3614, fail, steps:80, opt steps:15, total reward:-24.4000, 0.5679550170898438 sec\n",
      "Episode 374, len10, loss:-99.2672, fail, steps:80, opt steps:47, total reward:-22.5000, 0.5148382186889648 sec\n",
      "Episode 375, len10, loss:-103.5552, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5383796691894531 sec\n",
      "Episode 376, len6, loss:-54.8161, fail, steps:80, opt steps:16, total reward:-19.8000, 0.5254702568054199 sec\n",
      "Episode 377, len12, loss:-126.0782, fail, steps:80, opt steps:21, total reward:-25.4000, 0.534414529800415 sec\n",
      "Episode 378, len10, loss:-128.5790, fail, steps:42, opt steps:32, total reward:-23.4000, 0.28013014793395996 sec\n",
      "Episode 379, len10, loss:-103.8999, fail, steps:80, opt steps:46, total reward:-23.7000, 0.5210192203521729 sec\n",
      "Episode 380, len12, loss:-123.9337, fail, steps:80, opt steps:54, total reward:-25.1000, 0.5273551940917969 sec\n",
      "Episode 381, len8, loss:-96.6714, fail, steps:80, opt steps:9, total reward:-24.7000, 0.5393931865692139 sec\n",
      "Episode 382, len10, loss:-117.9253, fail, steps:80, opt steps:13, total reward:-25.9000, 0.5135006904602051 sec\n",
      "Episode 383, len12, loss:-125.6602, fail, steps:80, opt steps:20, total reward:-25.4000, 0.5363192558288574 sec\n",
      "Episode 384, len8, loss:-95.8867, fail, steps:80, opt steps:25, total reward:-24.4000, 0.5367746353149414 sec\n",
      "Episode 385, len12, loss:-139.9089, fail, steps:80, opt steps:55, total reward:-26.8000, 0.5303118228912354 sec\n",
      "Episode 386, len10, loss:-100.6570, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5490720272064209 sec\n",
      "Episode 387, len12, loss:-127.0365, fail, steps:80, opt steps:34, total reward:-26.1000, 0.5370957851409912 sec\n",
      "Episode 388, len8, loss:-96.9888, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5436458587646484 sec\n",
      "Episode 389, len10, loss:-106.9191, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5494198799133301 sec\n",
      "Episode 390, len6, loss:-81.8808, fail, steps:80, opt steps:18, total reward:-25.1000, 0.5406203269958496 sec\n",
      "Episode 391, len6, loss:-70.0686, fail, steps:80, opt steps:21, total reward:-23.4000, 0.588021993637085 sec\n",
      "Episode 392, len12, loss:-116.5526, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5492079257965088 sec\n",
      "Episode 393, len12, loss:-121.1535, fail, steps:80, opt steps:46, total reward:-24.2000, 0.5243520736694336 sec\n",
      "Episode 394, len6, loss:-115.9531, fail, steps:56, opt steps:6, total reward:-27.3000, 0.36864328384399414 sec\n",
      "Episode 395, len10, loss:-109.9469, fail, steps:80, opt steps:35, total reward:-25.1000, 0.520172119140625 sec\n",
      "Episode 396, len12, loss:-25.5725, fail, steps:0, opt steps:57, total reward:-10.0000, 0.020877599716186523 sec\n",
      "Episode 397, len10, loss:-114.8046, fail, steps:80, opt steps:32, total reward:-25.1000, 0.48120903968811035 sec\n",
      "Episode 398, len6, loss:-82.3568, fail, steps:80, opt steps:15, total reward:-25.1000, 0.5103564262390137 sec\n",
      "Episode 399, len6, loss:-77.7253, fail, steps:80, opt steps:6, total reward:-24.7000, 0.531876802444458 sec\n",
      "Episode 400, len12, loss:-121.0411, fail, steps:80, opt steps:34, total reward:-24.0000, 0.538262128829956 sec\n",
      "Episode 401, len8, loss:-93.1614, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5444850921630859 sec\n",
      "Episode 402, len12, loss:-123.6844, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5439853668212891 sec\n",
      "Episode 403, len8, loss:-101.8343, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5436680316925049 sec\n",
      "Episode 404, len6, loss:-94.2342, fail, steps:29, opt steps:6, total reward:-18.8000, 0.1993858814239502 sec\n",
      "Episode 405, len6, loss:-87.2388, fail, steps:80, opt steps:3, total reward:-26.1000, 0.5046141147613525 sec\n",
      "Episode 406, len12, loss:-117.3265, fail, steps:80, opt steps:31, total reward:-24.7000, 0.5319299697875977 sec\n",
      "Episode 407, len6, loss:-76.4177, fail, steps:80, opt steps:13, total reward:-24.4000, 0.5846607685089111 sec\n",
      "Episode 408, len10, loss:-173.1064, fail, steps:77, opt steps:26, total reward:-33.8000, 0.5224161148071289 sec\n",
      "Episode 409, len6, loss:-83.1107, fail, steps:80, opt steps:6, total reward:-25.4000, 0.5359461307525635 sec\n",
      "Episode 410, len8, loss:-100.6643, fail, steps:80, opt steps:20, total reward:-25.5000, 0.5268673896789551 sec\n",
      "Episode 411, len6, loss:-80.5773, fail, steps:80, opt steps:13, total reward:-25.1000, 0.5342295169830322 sec\n",
      "Episode 412, len6, loss:-80.1945, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5482184886932373 sec\n",
      "Episode 413, len10, loss:-26.2953, fail, steps:0, opt steps:40, total reward:-10.0000, 0.02152395248413086 sec\n",
      "Episode 414, len6, loss:-65.6336, fail, steps:80, opt steps:20, total reward:-22.4000, 0.48476266860961914 sec\n",
      "Episode 415, len10, loss:-106.6252, fail, steps:80, opt steps:34, total reward:-24.7000, 0.5193512439727783 sec\n",
      "Episode 416, len6, loss:-75.0014, fail, steps:80, opt steps:3, total reward:-24.4000, 0.525902271270752 sec\n",
      "Episode 417, len8, loss:-91.1839, fail, steps:80, opt steps:20, total reward:-24.4000, 0.5302102565765381 sec\n",
      "Episode 418, len6, loss:-84.0676, fail, steps:80, opt steps:14, total reward:-24.8000, 0.526801347732544 sec\n",
      "Episode 419, len10, loss:-117.4725, fail, steps:80, opt steps:32, total reward:-25.1000, 0.5308232307434082 sec\n",
      "Episode 420, len12, loss:-128.4814, fail, steps:80, opt steps:37, total reward:-25.8000, 0.5288758277893066 sec\n",
      "Episode 421, len12, loss:-132.3699, fail, steps:80, opt steps:54, total reward:-26.1000, 0.5343174934387207 sec\n",
      "Episode 422, len6, loss:-76.8884, fail, steps:80, opt steps:11, total reward:-23.4000, 0.5901083946228027 sec\n",
      "Episode 423, len12, loss:-131.4430, fail, steps:80, opt steps:57, total reward:-25.4000, 0.5405173301696777 sec\n",
      "Episode 424, len6, loss:-72.0065, fail, steps:80, opt steps:15, total reward:-23.1000, 0.5359847545623779 sec\n",
      "Episode 425, len6, loss:-82.6334, fail, steps:80, opt steps:11, total reward:-25.1000, 0.5361959934234619 sec\n",
      "Episode 426, len10, loss:-117.8556, fail, steps:80, opt steps:30, total reward:-25.4000, 0.5406179428100586 sec\n",
      "Episode 427, len6, loss:-85.8712, fail, steps:80, opt steps:12, total reward:-25.4000, 0.5400528907775879 sec\n",
      "Episode 428, len12, loss:-123.3765, fail, steps:80, opt steps:39, total reward:-24.5000, 0.5273351669311523 sec\n",
      "Episode 429, len12, loss:-111.7170, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548454999923706 sec\n",
      "Episode 430, len8, loss:-100.9179, fail, steps:80, opt steps:12, total reward:-24.7000, 0.543830156326294 sec\n",
      "Episode 431, len12, loss:-136.2640, fail, steps:80, opt steps:74, total reward:-26.1000, 0.5369946956634521 sec\n",
      "Episode 432, len12, loss:-122.6173, fail, steps:80, opt steps:51, total reward:-24.7000, 0.5447659492492676 sec\n",
      "Episode 433, len10, loss:-113.0717, fail, steps:80, opt steps:41, total reward:-24.4000, 0.5400834083557129 sec\n",
      "Episode 434, len10, loss:-104.7671, fail, steps:80, opt steps:51, total reward:-23.7000, 0.5444498062133789 sec\n",
      "Episode 435, len12, loss:-128.0634, fail, steps:80, opt steps:41, total reward:-25.1000, 0.535346508026123 sec\n",
      "Episode 436, len6, loss:-70.1474, fail, steps:80, opt steps:14, total reward:-22.7000, 0.5432248115539551 sec\n",
      "Episode 437, len10, loss:-114.2736, fail, steps:80, opt steps:41, total reward:-26.1000, 0.5919923782348633 sec\n",
      "Episode 438, len12, loss:-109.0173, fail, steps:80, opt steps:49, total reward:-22.7000, 0.5460326671600342 sec\n",
      "Episode 439, len10, loss:-113.3546, fail, steps:80, opt steps:37, total reward:-24.1000, 0.5361998081207275 sec\n",
      "Episode 440, len6, loss:-71.8066, fail, steps:80, opt steps:13, total reward:-22.8000, 0.5298323631286621 sec\n",
      "Episode 441, len6, loss:-71.7374, fail, steps:80, opt steps:21, total reward:-23.4000, 0.5383975505828857 sec\n",
      "Episode 442, len12, loss:-120.9455, fail, steps:80, opt steps:41, total reward:-25.1000, 0.5355467796325684 sec\n",
      "Episode 443, len10, loss:-121.2809, fail, steps:80, opt steps:29, total reward:-25.8000, 0.5304384231567383 sec\n",
      "Episode 444, len8, loss:-104.7349, fail, steps:80, opt steps:17, total reward:-25.5000, 0.5257449150085449 sec\n",
      "Episode 445, len10, loss:-128.4604, fail, steps:80, opt steps:11, total reward:-26.8000, 0.5306570529937744 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 446, len6, loss:-73.3325, fail, steps:80, opt steps:21, total reward:-23.8000, 0.5285789966583252 sec\n",
      "Episode 447, len8, loss:-93.1777, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5479624271392822 sec\n",
      "Episode 448, len10, loss:-110.6940, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5493597984313965 sec\n",
      "Episode 449, len12, loss:-112.4438, fail, steps:80, opt steps:40, total reward:-23.4000, 0.5395045280456543 sec\n",
      "Episode 450, len10, loss:-119.1274, fail, steps:80, opt steps:33, total reward:-26.1000, 0.5362820625305176 sec\n",
      "Episode 451, len12, loss:-177.8925, fail, steps:57, opt steps:43, total reward:-28.9000, 0.37992262840270996 sec\n",
      "Episode 452, len8, loss:-103.5636, fail, steps:80, opt steps:15, total reward:-26.1000, 0.5791637897491455 sec\n",
      "Episode 453, len10, loss:-107.6780, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5425846576690674 sec\n",
      "Episode 454, len12, loss:-110.4917, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5459482669830322 sec\n",
      "Episode 455, len6, loss:-78.0976, fail, steps:80, opt steps:3, total reward:-24.1000, 0.5333590507507324 sec\n",
      "Episode 456, len6, loss:-83.1766, fail, steps:80, opt steps:13, total reward:-24.8000, 0.5301578044891357 sec\n",
      "Episode 457, len8, loss:-95.5245, fail, steps:80, opt steps:29, total reward:-24.4000, 0.5375380516052246 sec\n",
      "Episode 458, len12, loss:-120.7309, fail, steps:80, opt steps:50, total reward:-24.7000, 0.543565034866333 sec\n",
      "Episode 459, len6, loss:-73.7444, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5483298301696777 sec\n",
      "Episode 460, len8, loss:-125.0903, fail, steps:49, opt steps:19, total reward:-24.8000, 0.3335087299346924 sec\n",
      "Episode 461, len8, loss:-110.8598, fail, steps:80, opt steps:17, total reward:-25.8000, 0.5128636360168457 sec\n",
      "Episode 462, len12, loss:-107.1693, fail, steps:80, opt steps:64, total reward:-22.8000, 0.523045539855957 sec\n",
      "Episode 463, len6, loss:-77.0215, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5400247573852539 sec\n",
      "Episode 464, len6, loss:-77.2129, fail, steps:80, opt steps:5, total reward:-24.7000, 0.540179967880249 sec\n",
      "Episode 465, len6, loss:-75.9096, fail, steps:80, opt steps:18, total reward:-24.4000, 0.5917696952819824 sec\n",
      "Episode 466, len10, loss:-119.2584, fail, steps:80, opt steps:36, total reward:-25.4000, 0.5388612747192383 sec\n",
      "Episode 467, len8, loss:-94.5781, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5433444976806641 sec\n",
      "Episode 468, len8, loss:-81.2072, fail, steps:80, opt steps:30, total reward:-22.7000, 0.5445630550384521 sec\n",
      "Episode 469, len12, loss:-126.5740, fail, steps:80, opt steps:41, total reward:-25.4000, 0.5399847030639648 sec\n",
      "Episode 470, len8, loss:-103.8660, fail, steps:80, opt steps:19, total reward:-25.4000, 0.539780855178833 sec\n",
      "Episode 471, len12, loss:-127.3296, fail, steps:80, opt steps:32, total reward:-25.4000, 0.5402736663818359 sec\n",
      "Episode 472, len12, loss:-110.6730, fail, steps:80, opt steps:33, total reward:-23.4000, 0.540147066116333 sec\n",
      "Episode 473, len6, loss:-88.4346, fail, steps:80, opt steps:13, total reward:-25.8000, 0.5313208103179932 sec\n",
      "Episode 474, len10, loss:-103.2628, fail, steps:80, opt steps:24, total reward:-24.1000, 0.5344765186309814 sec\n",
      "Episode 475, len8, loss:-90.9420, fail, steps:80, opt steps:28, total reward:-24.1000, 0.5354304313659668 sec\n",
      "Episode 476, len6, loss:-75.4403, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5431804656982422 sec\n",
      "Episode 477, len6, loss:-87.7297, fail, steps:37, opt steps:13, total reward:-20.2000, 0.2531912326812744 sec\n",
      "Episode 478, len8, loss:-95.6552, fail, steps:80, opt steps:25, total reward:-24.8000, 0.5046281814575195 sec\n",
      "Episode 479, len8, loss:-100.4300, fail, steps:80, opt steps:15, total reward:-26.1000, 0.524871826171875 sec\n",
      "Episode 480, len8, loss:-85.5573, fail, steps:22, opt steps:13, total reward:-16.0000, 0.15538549423217773 sec\n",
      "Episode 481, len12, loss:-137.2744, fail, steps:80, opt steps:18, total reward:-26.8000, 0.5499038696289062 sec\n",
      "Episode 482, len8, loss:-92.0353, fail, steps:80, opt steps:22, total reward:-25.4000, 0.5257871150970459 sec\n",
      "Episode 483, len8, loss:-93.4757, fail, steps:80, opt steps:14, total reward:-25.1000, 0.5285451412200928 sec\n",
      "Episode 484, len12, loss:-129.9601, fail, steps:80, opt steps:51, total reward:-25.5000, 0.5215330123901367 sec\n",
      "Episode 485, len6, loss:-63.7661, fail, steps:80, opt steps:21, total reward:-22.7000, 0.5406255722045898 sec\n",
      "Episode 486, len12, loss:-123.7033, fail, steps:80, opt steps:39, total reward:-25.4000, 0.5375416278839111 sec\n",
      "Episode 487, len8, loss:-86.6216, fail, steps:80, opt steps:18, total reward:-23.8000, 0.5310711860656738 sec\n",
      "Episode 488, len6, loss:-72.8484, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5419602394104004 sec\n",
      "Episode 489, len10, loss:-107.6537, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5440902709960938 sec\n",
      "Episode 490, len10, loss:-94.6946, fail, steps:80, opt steps:27, total reward:-22.7000, 0.5437612533569336 sec\n",
      "Episode 491, len8, loss:-92.1512, fail, steps:80, opt steps:15, total reward:-25.4000, 0.5409722328186035 sec\n",
      "Episode 492, len12, loss:-121.8742, fail, steps:80, opt steps:36, total reward:-25.4000, 0.541093111038208 sec\n",
      "Episode 493, len8, loss:-82.5574, fail, steps:80, opt steps:9, total reward:-24.7000, 0.5448341369628906 sec\n",
      "Episode 494, len6, loss:-63.6638, fail, steps:3, opt steps:6, total reward:-11.6000, 0.038304805755615234 sec\n",
      "Episode 495, len10, loss:-118.9500, fail, steps:80, opt steps:27, total reward:-26.5000, 0.47391796112060547 sec\n",
      "Episode 496, len12, loss:-115.2615, fail, steps:80, opt steps:37, total reward:-23.4000, 0.5697841644287109 sec\n",
      "Episode 497, len8, loss:-81.1643, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5337517261505127 sec\n",
      "Episode 498, len6, loss:-71.0327, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5412936210632324 sec\n",
      "Episode 499, len8, loss:-87.9134, fail, steps:80, opt steps:17, total reward:-24.1000, 0.5330262184143066 sec\n",
      "Episode 500, len10, loss:-107.2811, fail, steps:80, opt steps:35, total reward:-26.1000, 0.5336487293243408 sec\n",
      "Episode 501, len10, loss:-110.4123, fail, steps:80, opt steps:37, total reward:-24.5000, 0.5245993137359619 sec\n",
      "Episode 502, len6, loss:-73.5575, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5406410694122314 sec\n",
      "Episode 503, len10, loss:-113.5193, fail, steps:80, opt steps:34, total reward:-25.1000, 0.5347132682800293 sec\n",
      "Episode 504, len10, loss:-103.4709, fail, steps:80, opt steps:30, total reward:-25.1000, 0.5351424217224121 sec\n",
      "Episode 505, len8, loss:-84.7161, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5500767230987549 sec\n",
      "Episode 506, len8, loss:-87.0430, fail, steps:80, opt steps:29, total reward:-23.8000, 0.5314359664916992 sec\n",
      "Episode 507, len8, loss:-109.8201, fail, steps:55, opt steps:20, total reward:-25.9000, 0.3752257823944092 sec\n",
      "Episode 508, len8, loss:-89.2106, fail, steps:80, opt steps:15, total reward:-25.1000, 0.5249695777893066 sec\n",
      "Episode 509, len10, loss:-112.3025, fail, steps:80, opt steps:39, total reward:-25.8000, 0.5248622894287109 sec\n",
      "Episode 510, len12, loss:-110.1893, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5396637916564941 sec\n",
      "Episode 511, len10, loss:-96.2889, fail, steps:80, opt steps:33, total reward:-23.7000, 0.5422213077545166 sec\n",
      "Episode 512, len8, loss:-95.4143, fail, steps:22, opt steps:23, total reward:-16.3000, 0.1625826358795166 sec\n",
      "Episode 513, len12, loss:-113.7070, fail, steps:80, opt steps:26, total reward:-25.4000, 0.5022895336151123 sec\n",
      "Episode 514, len10, loss:-101.7470, fail, steps:80, opt steps:34, total reward:-24.7000, 0.5284364223480225 sec\n",
      "Episode 515, len6, loss:-66.6888, fail, steps:80, opt steps:14, total reward:-24.0000, 0.593620777130127 sec\n",
      "Episode 516, len12, loss:-119.2569, fail, steps:80, opt steps:32, total reward:-25.5000, 0.5223875045776367 sec\n",
      "Episode 517, len6, loss:-74.5604, fail, steps:80, opt steps:15, total reward:-24.1000, 0.5301921367645264 sec\n",
      "Episode 518, len6, loss:-67.4799, fail, steps:80, opt steps:19, total reward:-24.1000, 0.5311524868011475 sec\n",
      "Episode 519, len12, loss:-108.8466, fail, steps:34, opt steps:30, total reward:-19.6000, 0.23518109321594238 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 520, len10, loss:-107.6707, fail, steps:80, opt steps:47, total reward:-25.4000, 0.5117337703704834 sec\n",
      "Episode 521, len6, loss:-70.8151, fail, steps:80, opt steps:15, total reward:-23.7000, 0.5318243503570557 sec\n",
      "Episode 522, len10, loss:-106.7407, fail, steps:80, opt steps:37, total reward:-24.4000, 0.5333845615386963 sec\n",
      "Episode 523, len8, loss:-86.4983, fail, steps:80, opt steps:28, total reward:-24.8000, 0.5285224914550781 sec\n",
      "Episode 524, len12, loss:-112.7726, fail, steps:80, opt steps:56, total reward:-24.4000, 0.5369865894317627 sec\n",
      "Episode 525, len12, loss:-120.7970, fail, steps:80, opt steps:49, total reward:-25.1000, 0.5322976112365723 sec\n",
      "Episode 526, len10, loss:-88.3426, fail, steps:80, opt steps:42, total reward:-22.7000, 0.5413787364959717 sec\n",
      "Episode 527, len12, loss:-105.8809, fail, steps:80, opt steps:43, total reward:-24.4000, 0.5377612113952637 sec\n",
      "Episode 528, len12, loss:-114.2836, fail, steps:80, opt steps:54, total reward:-24.8000, 0.5306518077850342 sec\n",
      "Episode 529, len8, loss:-72.4665, fail, steps:80, opt steps:17, total reward:-24.1000, 0.5338201522827148 sec\n",
      "Episode 530, len12, loss:-100.9402, fail, steps:80, opt steps:62, total reward:-22.4000, 0.5392522811889648 sec\n",
      "Episode 531, len8, loss:-72.0682, fail, steps:80, opt steps:19, total reward:-24.4000, 0.5412540435791016 sec\n",
      "Episode 532, len8, loss:-67.8033, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5986311435699463 sec\n",
      "Episode 533, len12, loss:-119.0041, fail, steps:80, opt steps:59, total reward:-25.1000, 0.5365767478942871 sec\n",
      "Episode 534, len6, loss:-78.7911, fail, steps:80, opt steps:7, total reward:-25.1000, 0.5373449325561523 sec\n",
      "Episode 535, len6, loss:-78.5842, fail, steps:80, opt steps:6, total reward:-24.4000, 0.5412278175354004 sec\n",
      "Episode 536, len12, loss:-121.4686, fail, steps:80, opt steps:47, total reward:-25.8000, 0.5314202308654785 sec\n",
      "Episode 537, len6, loss:-74.0812, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5512657165527344 sec\n",
      "Episode 538, len8, loss:-68.2938, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5470218658447266 sec\n",
      "Episode 539, len10, loss:-94.7720, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5489554405212402 sec\n",
      "Episode 540, len10, loss:-104.9123, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5454213619232178 sec\n",
      "Episode 541, len10, loss:-96.2459, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5451455116271973 sec\n",
      "Episode 542, len12, loss:-114.1095, fail, steps:80, opt steps:65, total reward:-24.7000, 0.5464096069335938 sec\n",
      "Episode 543, len10, loss:-97.9656, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5450198650360107 sec\n",
      "Episode 544, len10, loss:-96.9042, fail, steps:80, opt steps:22, total reward:-23.7000, 0.5450479984283447 sec\n",
      "Episode 545, len8, loss:-73.5503, fail, steps:80, opt steps:29, total reward:-24.7000, 0.598689079284668 sec\n",
      "Episode 546, len10, loss:-128.0230, fail, steps:61, opt steps:27, total reward:-27.7000, 0.41580796241760254 sec\n",
      "Episode 547, len6, loss:-75.6383, fail, steps:80, opt steps:10, total reward:-24.4000, 0.5303964614868164 sec\n",
      "Episode 548, len10, loss:-97.5333, fail, steps:80, opt steps:33, total reward:-25.4000, 0.5367610454559326 sec\n",
      "Episode 549, len10, loss:-27.0951, fail, steps:0, opt steps:29, total reward:-10.0000, 0.02107548713684082 sec\n",
      "Episode 550, len8, loss:-59.6601, fail, steps:80, opt steps:16, total reward:-24.7000, 0.48764705657958984 sec\n",
      "Episode 551, len6, loss:-69.1095, fail, steps:80, opt steps:21, total reward:-25.4000, 0.5156397819519043 sec\n",
      "Episode 552, len10, loss:-87.7384, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5293228626251221 sec\n",
      "Episode 553, len10, loss:-96.9455, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5359561443328857 sec\n",
      "Episode 554, len10, loss:-98.5797, fail, steps:80, opt steps:32, total reward:-24.4000, 0.5359647274017334 sec\n",
      "Episode 555, len8, loss:-73.7634, fail, steps:80, opt steps:31, total reward:-25.4000, 0.537672758102417 sec\n",
      "Episode 556, len6, loss:-69.4495, fail, steps:15, opt steps:15, total reward:-13.2000, 0.11419177055358887 sec\n",
      "Episode 557, len8, loss:-77.3180, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5014984607696533 sec\n",
      "Episode 558, len10, loss:-97.6367, fail, steps:80, opt steps:37, total reward:-24.8000, 0.5149929523468018 sec\n",
      "Episode 559, len10, loss:-99.4953, fail, steps:80, opt steps:20, total reward:-25.4000, 0.5306792259216309 sec\n",
      "Episode 560, len12, loss:-116.9520, fail, steps:80, opt steps:32, total reward:-25.4000, 0.5351154804229736 sec\n",
      "Episode 561, len12, loss:-105.2477, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5438201427459717 sec\n",
      "Episode 562, len10, loss:-107.9183, fail, steps:80, opt steps:28, total reward:-25.4000, 0.5888700485229492 sec\n",
      "Episode 563, len6, loss:-69.2341, fail, steps:80, opt steps:15, total reward:-23.4000, 0.5402514934539795 sec\n",
      "Episode 564, len12, loss:-116.0856, fail, steps:80, opt steps:40, total reward:-24.7000, 0.5435714721679688 sec\n",
      "Episode 565, len10, loss:-104.6746, fail, steps:80, opt steps:26, total reward:-26.1000, 0.5360603332519531 sec\n",
      "Episode 566, len12, loss:-98.4221, fail, steps:80, opt steps:69, total reward:-22.4000, 0.5407564640045166 sec\n",
      "Episode 567, len12, loss:-104.1466, fail, steps:80, opt steps:54, total reward:-23.7000, 0.5435290336608887 sec\n",
      "Episode 568, len10, loss:-94.9250, fail, steps:80, opt steps:19, total reward:-24.4000, 0.5395035743713379 sec\n",
      "Episode 569, len8, loss:-79.1814, fail, steps:80, opt steps:24, total reward:-23.4000, 0.5409343242645264 sec\n",
      "Episode 570, len8, loss:-69.1043, fail, steps:80, opt steps:36, total reward:-22.4000, 0.540212869644165 sec\n",
      "Episode 571, len10, loss:-125.6775, fail, steps:54, opt steps:42, total reward:-26.9000, 0.3728797435760498 sec\n",
      "Episode 572, len10, loss:-88.7839, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5350008010864258 sec\n",
      "Episode 573, len6, loss:-80.0553, fail, steps:80, opt steps:5, total reward:-24.8000, 0.5260279178619385 sec\n",
      "Episode 574, len10, loss:-96.5685, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5420057773590088 sec\n",
      "Episode 575, len10, loss:-89.3056, fail, steps:80, opt steps:49, total reward:-24.1000, 0.5343458652496338 sec\n",
      "Episode 576, len8, loss:-65.3898, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5435018539428711 sec\n",
      "Episode 577, len12, loss:-114.5572, fail, steps:80, opt steps:43, total reward:-25.1000, 0.5376839637756348 sec\n",
      "Episode 578, len12, loss:-106.4879, fail, steps:80, opt steps:56, total reward:-24.0000, 0.6033804416656494 sec\n",
      "Episode 579, len8, loss:-67.0774, fail, steps:80, opt steps:12, total reward:-23.5000, 0.5280306339263916 sec\n",
      "Episode 580, len8, loss:-57.5826, fail, steps:80, opt steps:30, total reward:-24.7000, 0.543616533279419 sec\n",
      "Episode 581, len8, loss:-74.6138, fail, steps:29, opt steps:28, total reward:-19.4000, 0.20910358428955078 sec\n",
      "Episode 582, len12, loss:-111.8202, fail, steps:80, opt steps:74, total reward:-25.4000, 0.5108304023742676 sec\n",
      "Episode 583, len8, loss:-27.8262, fail, steps:0, opt steps:36, total reward:-10.0000, 0.01977992057800293 sec\n",
      "Episode 584, len8, loss:-75.6341, fail, steps:80, opt steps:28, total reward:-25.4000, 0.4844093322753906 sec\n",
      "Episode 585, len12, loss:-112.8400, fail, steps:80, opt steps:63, total reward:-23.4000, 0.5311851501464844 sec\n",
      "Episode 586, len10, loss:-95.6664, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5384688377380371 sec\n",
      "Episode 587, len10, loss:-102.2031, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5383994579315186 sec\n",
      "Episode 588, len10, loss:-111.6110, fail, steps:80, opt steps:36, total reward:-26.8000, 0.5532135963439941 sec\n",
      "Episode 589, len6, loss:-67.4196, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5507628917694092 sec\n",
      "Episode 590, len12, loss:-110.5314, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5467450618743896 sec\n",
      "Episode 591, len10, loss:-28.1931, fail, steps:0, opt steps:20, total reward:-10.0000, 0.02161097526550293 sec\n",
      "Episode 592, len8, loss:-75.9269, fail, steps:80, opt steps:9, total reward:-25.4000, 0.48346590995788574 sec\n",
      "Episode 593, len6, loss:-72.3684, fail, steps:80, opt steps:6, total reward:-22.8000, 0.5065369606018066 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 594, len12, loss:-95.8319, fail, steps:80, opt steps:47, total reward:-23.4000, 0.5252082347869873 sec\n",
      "Episode 595, len10, loss:-91.6022, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5898957252502441 sec\n",
      "Episode 596, len10, loss:-92.5786, fail, steps:80, opt steps:31, total reward:-24.8000, 0.5263197422027588 sec\n",
      "Episode 597, len12, loss:-106.8253, fail, steps:80, opt steps:73, total reward:-24.4000, 0.5344254970550537 sec\n",
      "Episode 598, len8, loss:-62.1585, fail, steps:80, opt steps:21, total reward:-23.4000, 0.537877082824707 sec\n",
      "Episode 599, len10, loss:-100.6435, fail, steps:80, opt steps:47, total reward:-25.4000, 0.5385117530822754 sec\n",
      "Episode 600, len6, loss:-73.7455, fail, steps:80, opt steps:6, total reward:-23.5000, 0.5280616283416748 sec\n",
      "Episode 601, len6, loss:-80.1093, fail, steps:80, opt steps:6, total reward:-25.1000, 0.5327985286712646 sec\n",
      "Episode 602, len6, loss:-81.4553, fail, steps:80, opt steps:18, total reward:-25.4000, 0.5386853218078613 sec\n",
      "Episode 603, len10, loss:-96.2687, fail, steps:80, opt steps:39, total reward:-24.1000, 0.5356202125549316 sec\n",
      "Episode 604, len8, loss:-78.5812, fail, steps:80, opt steps:22, total reward:-25.1000, 0.5355896949768066 sec\n",
      "Episode 605, len8, loss:-81.0228, fail, steps:80, opt steps:15, total reward:-25.4000, 0.5398130416870117 sec\n",
      "Episode 606, len12, loss:-109.8200, fail, steps:80, opt steps:15, total reward:-24.1000, 0.5366864204406738 sec\n",
      "Episode 607, len10, loss:-94.9145, fail, steps:80, opt steps:41, total reward:-23.1000, 0.5353620052337646 sec\n",
      "Episode 608, len6, loss:-76.8691, fail, steps:80, opt steps:19, total reward:-24.4000, 0.5408711433410645 sec\n",
      "Episode 609, len8, loss:-76.4699, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5443861484527588 sec\n",
      "Episode 610, len8, loss:-64.6226, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5965862274169922 sec\n",
      "Episode 611, len6, loss:-71.7466, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5455708503723145 sec\n",
      "Episode 612, len10, loss:-106.7007, fail, steps:80, opt steps:32, total reward:-25.4000, 0.5418686866760254 sec\n",
      "Episode 613, len12, loss:-115.0510, fail, steps:80, opt steps:62, total reward:-24.1000, 0.5368449687957764 sec\n",
      "Episode 614, len6, loss:-72.5155, fail, steps:80, opt steps:8, total reward:-25.1000, 0.5354444980621338 sec\n",
      "Episode 615, len6, loss:-64.2091, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5433206558227539 sec\n",
      "Episode 616, len10, loss:-174.0981, fail, steps:79, opt steps:18, total reward:-34.5000, 0.527658224105835 sec\n",
      "Episode 617, len8, loss:-91.4308, fail, steps:80, opt steps:17, total reward:-25.8000, 0.5304281711578369 sec\n",
      "Episode 618, len8, loss:-74.8026, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5445539951324463 sec\n",
      "Episode 619, len6, loss:-72.6802, fail, steps:80, opt steps:15, total reward:-24.4000, 0.5385904312133789 sec\n",
      "Episode 620, len12, loss:-107.6858, fail, steps:80, opt steps:42, total reward:-24.4000, 0.5407540798187256 sec\n",
      "Episode 621, len10, loss:-103.4227, fail, steps:80, opt steps:30, total reward:-24.4000, 0.5412938594818115 sec\n",
      "Episode 622, len10, loss:-97.6924, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5495200157165527 sec\n",
      "Episode 623, len6, loss:-72.5576, fail, steps:80, opt steps:10, total reward:-24.7000, 0.5449254512786865 sec\n",
      "Episode 624, len8, loss:-84.4727, fail, steps:80, opt steps:19, total reward:-25.1000, 0.537426233291626 sec\n",
      "Episode 625, len8, loss:-82.8606, fail, steps:80, opt steps:28, total reward:-26.8000, 0.531416654586792 sec\n",
      "Episode 626, len10, loss:-86.5004, fail, steps:80, opt steps:37, total reward:-23.4000, 0.5899693965911865 sec\n",
      "Episode 627, len8, loss:-84.7959, fail, steps:80, opt steps:27, total reward:-25.4000, 0.5397520065307617 sec\n",
      "Episode 628, len6, loss:-81.8630, fail, steps:80, opt steps:6, total reward:-25.4000, 0.5403449535369873 sec\n",
      "Episode 629, len10, loss:-98.8381, fail, steps:80, opt steps:48, total reward:-25.4000, 0.542597770690918 sec\n",
      "Episode 630, len10, loss:-99.2446, fail, steps:80, opt steps:29, total reward:-25.1000, 0.537177562713623 sec\n",
      "Episode 631, len8, loss:-82.4028, fail, steps:80, opt steps:35, total reward:-24.7000, 0.5462594032287598 sec\n",
      "Episode 632, len8, loss:-61.1502, fail, steps:80, opt steps:12, total reward:-24.7000, 0.5478417873382568 sec\n",
      "Episode 633, len12, loss:-106.3741, fail, steps:80, opt steps:33, total reward:-24.4000, 0.5426368713378906 sec\n",
      "Episode 634, len10, loss:-94.1649, fail, steps:80, opt steps:47, total reward:-23.7000, 0.5447618961334229 sec\n",
      "Episode 635, len8, loss:-78.8501, fail, steps:80, opt steps:28, total reward:-25.4000, 0.5431389808654785 sec\n",
      "Episode 636, len8, loss:-71.2903, fail, steps:80, opt steps:11, total reward:-25.4000, 0.5405230522155762 sec\n",
      "Episode 637, len6, loss:-68.7799, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5492208003997803 sec\n",
      "Episode 638, len12, loss:-97.5576, fail, steps:80, opt steps:35, total reward:-22.4000, 0.5426599979400635 sec\n",
      "Episode 639, len10, loss:-96.6940, fail, steps:80, opt steps:47, total reward:-25.4000, 0.5426716804504395 sec\n",
      "Episode 640, len8, loss:-70.6039, fail, steps:80, opt steps:36, total reward:-24.4000, 0.540916919708252 sec\n",
      "Episode 641, len12, loss:-107.8285, fail, steps:80, opt steps:42, total reward:-23.7000, 0.5454862117767334 sec\n",
      "Episode 642, len6, loss:-68.3942, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5504517555236816 sec\n",
      "Episode 643, len8, loss:-63.2529, fail, steps:80, opt steps:36, total reward:-21.8000, 0.5329408645629883 sec\n",
      "Episode 644, len6, loss:-77.0567, fail, steps:80, opt steps:15, total reward:-24.8000, 0.5821335315704346 sec\n",
      "Episode 645, len6, loss:-69.4704, fail, steps:80, opt steps:16, total reward:-23.1000, 0.5370416641235352 sec\n",
      "Episode 646, len6, loss:-72.5195, fail, steps:80, opt steps:15, total reward:-25.4000, 0.5389852523803711 sec\n",
      "Episode 647, len6, loss:-28.9294, fail, steps:0, opt steps:7, total reward:-10.0000, 0.02155613899230957 sec\n",
      "Episode 648, len6, loss:-62.3236, fail, steps:80, opt steps:11, total reward:-22.7000, 0.4879722595214844 sec\n",
      "Episode 649, len8, loss:-85.8830, fail, steps:80, opt steps:27, total reward:-25.4000, 0.5160081386566162 sec\n",
      "Episode 650, len12, loss:-125.2304, fail, steps:80, opt steps:40, total reward:-25.8000, 0.516592264175415 sec\n",
      "Episode 651, len6, loss:-72.8538, fail, steps:80, opt steps:18, total reward:-25.1000, 0.5276103019714355 sec\n",
      "Episode 652, len12, loss:-109.2367, fail, steps:80, opt steps:40, total reward:-24.4000, 0.5374748706817627 sec\n",
      "Episode 653, len10, loss:-29.0033, fail, steps:0, opt steps:37, total reward:-10.0000, 0.020874977111816406 sec\n",
      "Episode 654, len10, loss:-101.0545, fail, steps:80, opt steps:36, total reward:-25.1000, 0.4807422161102295 sec\n",
      "Episode 655, len6, loss:-78.0817, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5202987194061279 sec\n",
      "Episode 656, len6, loss:-85.5602, fail, steps:26, opt steps:12, total reward:-18.5000, 0.18171906471252441 sec\n",
      "Episode 657, len6, loss:-75.0033, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5093677043914795 sec\n",
      "Episode 658, len12, loss:-113.0231, fail, steps:80, opt steps:45, total reward:-25.4000, 0.5752263069152832 sec\n",
      "Episode 659, len12, loss:-112.5940, fail, steps:80, opt steps:54, total reward:-25.4000, 0.5328423976898193 sec\n",
      "Episode 660, len6, loss:-69.4461, fail, steps:80, opt steps:18, total reward:-24.4000, 0.5350193977355957 sec\n",
      "Episode 661, len8, loss:-82.0295, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5424046516418457 sec\n",
      "Episode 662, len10, loss:-98.9377, fail, steps:80, opt steps:36, total reward:-24.7000, 0.543039083480835 sec\n",
      "Episode 663, len10, loss:-98.3913, fail, steps:80, opt steps:19, total reward:-24.1000, 0.5385472774505615 sec\n",
      "Episode 664, len12, loss:-117.6933, fail, steps:80, opt steps:33, total reward:-24.7000, 0.5452845096588135 sec\n",
      "Episode 665, len8, loss:-73.6877, fail, steps:80, opt steps:34, total reward:-22.7000, 0.5436913967132568 sec\n",
      "Episode 666, len12, loss:-29.6690, fail, steps:0, opt steps:56, total reward:-10.0000, 0.021558046340942383 sec\n",
      "Episode 667, len6, loss:-29.5949, fail, steps:0, opt steps:12, total reward:-10.0000, 0.0037488937377929688 sec\n",
      "Episode 668, len12, loss:-110.0938, fail, steps:80, opt steps:44, total reward:-24.4000, 0.48214244842529297 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 669, len12, loss:-107.9913, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5248684883117676 sec\n",
      "Episode 670, len6, loss:-80.7618, fail, steps:80, opt steps:12, total reward:-25.4000, 0.5255510807037354 sec\n",
      "Episode 671, len10, loss:-105.3056, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5349876880645752 sec\n",
      "Episode 672, len12, loss:-117.5574, fail, steps:80, opt steps:51, total reward:-24.7000, 0.5403766632080078 sec\n",
      "Episode 673, len8, loss:-86.7096, fail, steps:80, opt steps:6, total reward:-24.8000, 0.5294525623321533 sec\n",
      "Episode 674, len10, loss:-93.2763, fail, steps:80, opt steps:42, total reward:-22.7000, 0.5918912887573242 sec\n",
      "Episode 675, len6, loss:-75.7020, fail, steps:80, opt steps:11, total reward:-23.7000, 0.5439848899841309 sec\n",
      "Episode 676, len10, loss:-104.2398, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5441772937774658 sec\n",
      "Episode 677, len6, loss:-70.9176, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5485954284667969 sec\n",
      "Episode 678, len6, loss:-80.7000, fail, steps:80, opt steps:11, total reward:-24.7000, 0.544978141784668 sec\n",
      "Episode 679, len8, loss:-84.4100, fail, steps:80, opt steps:8, total reward:-23.7000, 0.54396653175354 sec\n",
      "Episode 680, len6, loss:-68.6235, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5477206707000732 sec\n",
      "Episode 681, len10, loss:-116.3124, fail, steps:80, opt steps:30, total reward:-25.1000, 0.5372047424316406 sec\n",
      "Episode 682, len8, loss:-82.0382, fail, steps:80, opt steps:21, total reward:-23.7000, 0.5440101623535156 sec\n",
      "Episode 683, len6, loss:-70.8313, fail, steps:80, opt steps:19, total reward:-22.7000, 0.5433018207550049 sec\n",
      "Episode 684, len8, loss:-156.2626, fail, steps:65, opt steps:35, total reward:-31.3000, 0.4333927631378174 sec\n",
      "Episode 685, len12, loss:-118.5308, fail, steps:80, opt steps:49, total reward:-24.7000, 0.5344302654266357 sec\n",
      "Episode 686, len6, loss:-78.2237, fail, steps:80, opt steps:7, total reward:-24.0000, 0.545769453048706 sec\n",
      "Episode 687, len10, loss:-98.8954, fail, steps:80, opt steps:28, total reward:-23.7000, 0.5438389778137207 sec\n",
      "Episode 688, len8, loss:-95.4030, fail, steps:80, opt steps:21, total reward:-25.8000, 0.5306863784790039 sec\n",
      "Episode 689, len10, loss:-96.9086, fail, steps:80, opt steps:33, total reward:-22.7000, 0.5429477691650391 sec\n",
      "Episode 690, len12, loss:-30.1141, fail, steps:0, opt steps:40, total reward:-10.0000, 0.021656513214111328 sec\n",
      "Episode 691, len10, loss:-109.0141, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5378732681274414 sec\n",
      "Episode 692, len12, loss:-110.1053, fail, steps:80, opt steps:69, total reward:-24.7000, 0.5199737548828125 sec\n",
      "Episode 693, len10, loss:-101.6497, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5345208644866943 sec\n",
      "Episode 694, len10, loss:-112.7123, fail, steps:80, opt steps:54, total reward:-25.4000, 0.5318942070007324 sec\n",
      "Episode 695, len8, loss:-79.6429, fail, steps:80, opt steps:22, total reward:-23.7000, 0.5393531322479248 sec\n",
      "Episode 696, len8, loss:-87.2185, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5403530597686768 sec\n",
      "Episode 697, len6, loss:-86.4866, fail, steps:80, opt steps:7, total reward:-24.8000, 0.5300140380859375 sec\n",
      "Episode 698, len8, loss:-79.6827, fail, steps:80, opt steps:25, total reward:-24.1000, 0.5323469638824463 sec\n",
      "Episode 699, len10, loss:-108.9176, fail, steps:80, opt steps:31, total reward:-25.1000, 0.5345122814178467 sec\n",
      "Episode 700, len8, loss:-91.6865, fail, steps:80, opt steps:4, total reward:-25.4000, 0.5383899211883545 sec\n",
      "Episode 701, len10, loss:-103.9785, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5491683483123779 sec\n",
      "Episode 702, len12, loss:-31.0821, fail, steps:0, opt steps:52, total reward:-10.0000, 0.02177143096923828 sec\n",
      "Episode 703, len8, loss:-77.5733, fail, steps:80, opt steps:27, total reward:-24.7000, 0.48799729347229004 sec\n",
      "Episode 704, len8, loss:-79.7772, fail, steps:80, opt steps:27, total reward:-23.4000, 0.5151326656341553 sec\n",
      "Episode 705, len12, loss:-110.8651, fail, steps:80, opt steps:57, total reward:-24.0000, 0.53560471534729 sec\n",
      "Episode 706, len6, loss:-88.2271, fail, steps:80, opt steps:5, total reward:-26.1000, 0.5770382881164551 sec\n",
      "Episode 707, len10, loss:-100.0284, fail, steps:80, opt steps:18, total reward:-24.4000, 0.5342280864715576 sec\n",
      "Episode 708, len10, loss:-104.6122, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5417821407318115 sec\n",
      "Episode 709, len6, loss:-69.3403, fail, steps:80, opt steps:15, total reward:-23.4000, 0.5372486114501953 sec\n",
      "Episode 710, len12, loss:-115.0008, fail, steps:80, opt steps:55, total reward:-24.7000, 0.5419652462005615 sec\n",
      "Episode 711, len6, loss:-71.2521, fail, steps:80, opt steps:14, total reward:-24.0000, 0.54624342918396 sec\n",
      "Episode 712, len8, loss:-77.2513, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5486612319946289 sec\n",
      "Episode 713, len6, loss:-74.7890, fail, steps:80, opt steps:11, total reward:-23.4000, 0.5405378341674805 sec\n",
      "Episode 714, len6, loss:-81.9254, fail, steps:80, opt steps:14, total reward:-24.4000, 0.5389103889465332 sec\n",
      "Episode 715, len12, loss:-108.6668, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5481345653533936 sec\n",
      "Episode 716, len10, loss:-98.0054, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5444271564483643 sec\n",
      "Episode 717, len6, loss:-89.1475, fail, steps:80, opt steps:19, total reward:-25.8000, 0.5319797992706299 sec\n",
      "Episode 718, len6, loss:-70.5792, fail, steps:80, opt steps:21, total reward:-23.7000, 0.5429913997650146 sec\n",
      "Episode 719, len8, loss:-68.2967, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5445406436920166 sec\n",
      "Episode 720, len8, loss:-74.3464, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5454628467559814 sec\n",
      "Episode 721, len10, loss:-109.9093, fail, steps:80, opt steps:16, total reward:-25.1000, 0.587822437286377 sec\n",
      "Episode 722, len8, loss:-77.8903, fail, steps:80, opt steps:28, total reward:-24.8000, 0.5300350189208984 sec\n",
      "Episode 723, len10, loss:-91.5741, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5432562828063965 sec\n",
      "Episode 724, len10, loss:-92.5723, fail, steps:80, opt steps:43, total reward:-23.4000, 0.5391650199890137 sec\n",
      "Episode 725, len12, loss:-114.7831, fail, steps:80, opt steps:60, total reward:-25.4000, 0.5405340194702148 sec\n",
      "Episode 726, len12, loss:-110.3059, fail, steps:80, opt steps:60, total reward:-24.7000, 0.543175220489502 sec\n",
      "Episode 727, len6, loss:-76.7867, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5488111972808838 sec\n",
      "Episode 728, len6, loss:-76.6660, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5433187484741211 sec\n",
      "Episode 729, len8, loss:-67.2893, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5468275547027588 sec\n",
      "Episode 730, len8, loss:-68.0700, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5450360774993896 sec\n",
      "Episode 731, len10, loss:-95.1818, fail, steps:80, opt steps:35, total reward:-25.4000, 0.5419256687164307 sec\n",
      "Episode 732, len6, loss:-81.5592, fail, steps:80, opt steps:10, total reward:-25.1000, 0.5364115238189697 sec\n",
      "Episode 733, len6, loss:-72.6255, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5488777160644531 sec\n",
      "Episode 734, len6, loss:-79.8565, fail, steps:80, opt steps:20, total reward:-24.7000, 0.545048713684082 sec\n",
      "Episode 735, len12, loss:-99.6629, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5490589141845703 sec\n",
      "Episode 736, len12, loss:-160.0414, fail, steps:61, opt steps:61, total reward:-28.0000, 0.4205031394958496 sec\n",
      "Episode 737, len6, loss:-85.5330, fail, steps:23, opt steps:10, total reward:-17.6000, 0.1628890037536621 sec\n",
      "Episode 738, len12, loss:-114.2982, fail, steps:80, opt steps:56, total reward:-25.4000, 0.5538349151611328 sec\n",
      "Episode 739, len10, loss:-100.0469, fail, steps:80, opt steps:26, total reward:-24.1000, 0.5198781490325928 sec\n",
      "Episode 740, len10, loss:-103.8158, fail, steps:80, opt steps:11, total reward:-25.1000, 0.5290429592132568 sec\n",
      "Episode 741, len6, loss:-78.9690, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5386190414428711 sec\n",
      "Episode 742, len6, loss:-2.2933, succeed, steps:25, opt steps:5, total reward:-6.9100, 0.1793968677520752 sec\n",
      "Episode 743, len12, loss:-111.4892, fail, steps:80, opt steps:32, total reward:-24.1000, 0.5011155605316162 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 744, len10, loss:-97.5272, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5300757884979248 sec\n",
      "Episode 745, len8, loss:-82.7651, fail, steps:80, opt steps:33, total reward:-24.7000, 0.5372226238250732 sec\n",
      "Episode 746, len8, loss:-87.9473, fail, steps:80, opt steps:26, total reward:-25.4000, 0.5367698669433594 sec\n",
      "Episode 747, len10, loss:-97.9016, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5452396869659424 sec\n",
      "Episode 748, len8, loss:-72.6196, fail, steps:80, opt steps:21, total reward:-22.7000, 0.5428023338317871 sec\n",
      "Episode 749, len8, loss:-80.5519, fail, steps:80, opt steps:19, total reward:-23.7000, 0.5442652702331543 sec\n",
      "Episode 750, len12, loss:-118.3949, fail, steps:80, opt steps:50, total reward:-24.7000, 0.5451359748840332 sec\n",
      "Episode 751, len12, loss:-119.0171, fail, steps:80, opt steps:31, total reward:-24.4000, 0.5403411388397217 sec\n",
      "Episode 752, len8, loss:-93.4875, fail, steps:80, opt steps:19, total reward:-25.8000, 0.5329883098602295 sec\n",
      "Episode 753, len10, loss:-102.6180, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5503947734832764 sec\n",
      "Episode 754, len10, loss:-115.7010, fail, steps:80, opt steps:28, total reward:-26.1000, 0.5870747566223145 sec\n",
      "Episode 755, len6, loss:-74.0414, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5506565570831299 sec\n",
      "Episode 756, len10, loss:-101.2016, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5455996990203857 sec\n",
      "Episode 757, len12, loss:-123.3079, fail, steps:80, opt steps:47, total reward:-24.7000, 0.5472254753112793 sec\n",
      "Episode 758, len8, loss:-92.1485, fail, steps:80, opt steps:7, total reward:-24.7000, 0.5456979274749756 sec\n",
      "Episode 759, len10, loss:-99.6351, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5535886287689209 sec\n",
      "Episode 760, len10, loss:-115.3242, fail, steps:80, opt steps:30, total reward:-26.8000, 0.5326027870178223 sec\n",
      "Episode 761, len8, loss:-74.6998, fail, steps:80, opt steps:21, total reward:-22.8000, 0.5316624641418457 sec\n",
      "Episode 762, len12, loss:-106.6927, fail, steps:80, opt steps:40, total reward:-23.4000, 0.5398976802825928 sec\n",
      "Episode 763, len6, loss:-87.3015, fail, steps:80, opt steps:21, total reward:-25.8000, 0.5305118560791016 sec\n",
      "Episode 764, len6, loss:-76.4749, fail, steps:80, opt steps:18, total reward:-25.4000, 0.5399923324584961 sec\n",
      "Episode 765, len12, loss:-108.7946, fail, steps:80, opt steps:53, total reward:-23.7000, 0.5444698333740234 sec\n",
      "Episode 766, len6, loss:-79.8326, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5455987453460693 sec\n",
      "Episode 767, len10, loss:-96.4220, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5486495494842529 sec\n",
      "Episode 768, len10, loss:-90.1535, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5992884635925293 sec\n",
      "Episode 769, len8, loss:-77.9439, fail, steps:80, opt steps:29, total reward:-24.1000, 0.5448558330535889 sec\n",
      "Episode 770, len8, loss:-88.1590, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5440213680267334 sec\n",
      "Episode 771, len8, loss:-75.4188, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5497088432312012 sec\n",
      "Episode 772, len10, loss:-109.2260, fail, steps:80, opt steps:43, total reward:-25.8000, 0.5315296649932861 sec\n",
      "Episode 773, len10, loss:-94.9784, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5493342876434326 sec\n",
      "Episode 774, len8, loss:-76.2513, fail, steps:80, opt steps:27, total reward:-25.4000, 0.5409624576568604 sec\n",
      "Episode 775, len8, loss:-79.5900, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5446004867553711 sec\n",
      "Episode 776, len8, loss:-74.1932, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5485272407531738 sec\n",
      "Episode 777, len10, loss:-104.2319, fail, steps:80, opt steps:39, total reward:-25.4000, 0.541146993637085 sec\n",
      "Episode 778, len12, loss:-106.0149, fail, steps:80, opt steps:43, total reward:-23.7000, 0.5433235168457031 sec\n",
      "Episode 779, len10, loss:-93.3553, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5459320545196533 sec\n",
      "Episode 780, len12, loss:-118.2400, fail, steps:80, opt steps:45, total reward:-25.5000, 0.5277822017669678 sec\n",
      "Episode 781, len10, loss:-99.0903, fail, steps:80, opt steps:49, total reward:-25.4000, 0.5385534763336182 sec\n",
      "Episode 782, len8, loss:-64.7853, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5982227325439453 sec\n",
      "Episode 783, len12, loss:-95.1374, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5493535995483398 sec\n",
      "Episode 784, len12, loss:-100.1226, fail, steps:80, opt steps:39, total reward:-23.4000, 0.5412161350250244 sec\n",
      "Episode 785, len6, loss:-72.8037, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5479931831359863 sec\n",
      "Episode 786, len10, loss:-110.6145, fail, steps:80, opt steps:37, total reward:-25.4000, 0.540543794631958 sec\n",
      "Episode 787, len12, loss:-116.1692, fail, steps:80, opt steps:36, total reward:-24.7000, 0.5438880920410156 sec\n",
      "Episode 788, len12, loss:-110.1233, fail, steps:80, opt steps:77, total reward:-24.0000, 0.5491816997528076 sec\n",
      "Episode 789, len8, loss:-63.8691, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5488162040710449 sec\n",
      "Episode 790, len12, loss:-121.9749, fail, steps:38, opt steps:22, total reward:-22.1000, 0.27013444900512695 sec\n",
      "Episode 791, len8, loss:-79.0785, fail, steps:80, opt steps:36, total reward:-25.1000, 0.5113396644592285 sec\n",
      "Episode 792, len8, loss:-80.9251, fail, steps:80, opt steps:33, total reward:-24.1000, 0.5263912677764893 sec\n",
      "Episode 793, len8, loss:-76.4520, fail, steps:80, opt steps:22, total reward:-24.7000, 0.540510892868042 sec\n",
      "Episode 794, len12, loss:-104.9392, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5444693565368652 sec\n",
      "Episode 795, len8, loss:-73.9786, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5470077991485596 sec\n",
      "Episode 796, len10, loss:-94.4021, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5487875938415527 sec\n",
      "Episode 797, len10, loss:-116.9752, fail, steps:80, opt steps:33, total reward:-26.1000, 0.5357053279876709 sec\n",
      "Episode 798, len6, loss:-90.8786, fail, steps:80, opt steps:13, total reward:-25.1000, 0.534111738204956 sec\n",
      "Episode 799, len6, loss:-85.4134, fail, steps:80, opt steps:19, total reward:-24.1000, 0.5333526134490967 sec\n",
      "Episode 800, len10, loss:-111.6820, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5946729183197021 sec\n",
      "Episode 801, len10, loss:-105.0068, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5443580150604248 sec\n",
      "Episode 802, len6, loss:-84.9745, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5446245670318604 sec\n",
      "Episode 803, len10, loss:-105.8728, fail, steps:80, opt steps:31, total reward:-24.7000, 0.5450332164764404 sec\n",
      "Episode 804, len6, loss:-75.8472, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5484573841094971 sec\n",
      "Episode 805, len6, loss:-71.1370, fail, steps:80, opt steps:19, total reward:-22.4000, 0.5399026870727539 sec\n",
      "Episode 806, len12, loss:-115.4749, fail, steps:80, opt steps:57, total reward:-25.4000, 0.5396983623504639 sec\n",
      "Episode 807, len8, loss:-31.0821, fail, steps:0, opt steps:4, total reward:-10.0000, 0.02133631706237793 sec\n",
      "Episode 808, len8, loss:-100.8879, fail, steps:80, opt steps:24, total reward:-25.4000, 0.48307251930236816 sec\n",
      "Episode 809, len10, loss:-114.4758, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5203714370727539 sec\n",
      "Episode 810, len10, loss:-112.4395, fail, steps:80, opt steps:25, total reward:-25.4000, 0.527958869934082 sec\n",
      "Episode 811, len6, loss:-85.0993, fail, steps:80, opt steps:13, total reward:-24.7000, 0.536074161529541 sec\n",
      "Episode 812, len8, loss:-72.8470, fail, steps:80, opt steps:18, total reward:-22.7000, 0.5398497581481934 sec\n",
      "Episode 813, len12, loss:-107.2602, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5461108684539795 sec\n",
      "Episode 814, len6, loss:-77.8976, fail, steps:80, opt steps:11, total reward:-24.1000, 0.5346226692199707 sec\n",
      "Episode 815, len8, loss:-96.5448, fail, steps:80, opt steps:26, total reward:-25.4000, 0.589174747467041 sec\n",
      "Episode 816, len12, loss:-109.2584, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5480291843414307 sec\n",
      "Episode 817, len12, loss:-112.1696, fail, steps:80, opt steps:62, total reward:-24.7000, 0.5468626022338867 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 818, len8, loss:-87.1032, fail, steps:80, opt steps:26, total reward:-24.7000, 0.544471025466919 sec\n",
      "Episode 819, len12, loss:-120.3873, fail, steps:80, opt steps:49, total reward:-24.7000, 0.5459063053131104 sec\n",
      "Episode 820, len12, loss:-105.7656, fail, steps:80, opt steps:47, total reward:-23.7000, 0.5457053184509277 sec\n",
      "Episode 821, len8, loss:-83.9206, fail, steps:80, opt steps:12, total reward:-24.0000, 0.550361156463623 sec\n",
      "Episode 822, len12, loss:-122.2312, fail, steps:80, opt steps:62, total reward:-25.4000, 0.5444145202636719 sec\n",
      "Episode 823, len10, loss:-102.6939, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5494234561920166 sec\n",
      "Episode 824, len8, loss:-87.8757, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5504133701324463 sec\n",
      "Episode 825, len12, loss:-108.2127, fail, steps:30, opt steps:47, total reward:-19.7000, 0.21841192245483398 sec\n",
      "Episode 826, len12, loss:-106.3438, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5187654495239258 sec\n",
      "Episode 827, len10, loss:-95.5145, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5388267040252686 sec\n",
      "Episode 828, len6, loss:-70.0374, fail, steps:80, opt steps:20, total reward:-23.7000, 0.5392446517944336 sec\n",
      "Episode 829, len10, loss:-97.8617, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5451798439025879 sec\n",
      "Episode 830, len8, loss:-80.7981, fail, steps:80, opt steps:28, total reward:-25.4000, 0.5380029678344727 sec\n",
      "Episode 831, len12, loss:-106.0915, fail, steps:80, opt steps:62, total reward:-24.7000, 0.5432970523834229 sec\n",
      "Episode 832, len10, loss:-98.6537, fail, steps:80, opt steps:50, total reward:-24.4000, 0.5419549942016602 sec\n",
      "Episode 833, len8, loss:-83.8884, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5439860820770264 sec\n",
      "Episode 834, len6, loss:-79.1777, fail, steps:80, opt steps:16, total reward:-25.4000, 0.5959024429321289 sec\n",
      "Episode 835, len10, loss:-98.0679, fail, steps:80, opt steps:49, total reward:-23.4000, 0.5408079624176025 sec\n",
      "Episode 836, len8, loss:-76.6058, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5481338500976562 sec\n",
      "Episode 837, len10, loss:-98.5443, fail, steps:80, opt steps:42, total reward:-24.4000, 0.5394659042358398 sec\n",
      "Episode 838, len12, loss:-115.1434, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5456721782684326 sec\n",
      "Episode 839, len6, loss:-67.9090, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5483415126800537 sec\n",
      "Episode 840, len12, loss:-106.9674, fail, steps:80, opt steps:53, total reward:-24.1000, 0.5362589359283447 sec\n",
      "Episode 841, len6, loss:-59.9360, fail, steps:80, opt steps:14, total reward:-22.7000, 0.5448787212371826 sec\n",
      "Episode 842, len12, loss:-107.3269, fail, steps:80, opt steps:61, total reward:-24.4000, 0.5402250289916992 sec\n",
      "Episode 843, len10, loss:-103.9952, fail, steps:80, opt steps:40, total reward:-24.8000, 0.5310673713684082 sec\n",
      "Episode 844, len8, loss:-78.6304, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5426592826843262 sec\n",
      "Episode 845, len8, loss:-81.5390, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5493800640106201 sec\n",
      "Episode 846, len10, loss:-95.9486, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5442771911621094 sec\n",
      "Episode 847, len6, loss:-79.1830, fail, steps:80, opt steps:15, total reward:-25.1000, 0.5363864898681641 sec\n",
      "Episode 848, len10, loss:-94.3112, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5951194763183594 sec\n",
      "Episode 849, len12, loss:-102.3419, fail, steps:80, opt steps:29, total reward:-23.4000, 0.5412437915802002 sec\n",
      "Episode 850, len12, loss:-115.3820, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5450401306152344 sec\n",
      "Episode 851, len8, loss:-77.0759, fail, steps:80, opt steps:29, total reward:-24.4000, 0.5403249263763428 sec\n",
      "Episode 852, len12, loss:-101.7944, fail, steps:80, opt steps:29, total reward:-23.7000, 0.5442349910736084 sec\n",
      "Episode 853, len10, loss:-109.3022, fail, steps:80, opt steps:32, total reward:-25.4000, 0.5427069664001465 sec\n",
      "Episode 854, len6, loss:-66.6207, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5495967864990234 sec\n",
      "Episode 855, len10, loss:-93.3481, fail, steps:80, opt steps:36, total reward:-24.7000, 0.5451710224151611 sec\n",
      "Episode 856, len10, loss:-96.3908, fail, steps:80, opt steps:29, total reward:-24.1000, 0.536571741104126 sec\n",
      "Episode 857, len12, loss:-120.3609, fail, steps:80, opt steps:59, total reward:-25.8000, 0.532249927520752 sec\n",
      "Episode 858, len12, loss:-101.0549, fail, steps:80, opt steps:54, total reward:-24.7000, 0.5444076061248779 sec\n",
      "Episode 859, len8, loss:-70.4356, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5484588146209717 sec\n",
      "Episode 860, len10, loss:-100.6192, fail, steps:80, opt steps:38, total reward:-25.8000, 0.5320990085601807 sec\n",
      "Episode 861, len8, loss:-68.8166, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5490458011627197 sec\n",
      "Episode 862, len10, loss:-93.7111, fail, steps:80, opt steps:46, total reward:-23.7000, 0.597996711730957 sec\n",
      "Episode 863, len10, loss:-91.5246, fail, steps:80, opt steps:39, total reward:-23.7000, 0.547705888748169 sec\n",
      "Episode 864, len8, loss:-74.8621, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5454471111297607 sec\n",
      "Episode 865, len10, loss:-98.0086, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5459723472595215 sec\n",
      "Episode 866, len10, loss:-84.8296, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5501461029052734 sec\n",
      "Episode 867, len12, loss:-113.6658, fail, steps:80, opt steps:61, total reward:-25.4000, 0.5423109531402588 sec\n",
      "Episode 868, len10, loss:-95.4936, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5461483001708984 sec\n",
      "Episode 869, len12, loss:-103.5382, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5496621131896973 sec\n",
      "Episode 870, len10, loss:-95.9816, fail, steps:80, opt steps:44, total reward:-24.7000, 0.5446937084197998 sec\n",
      "Episode 871, len12, loss:-111.3060, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5468494892120361 sec\n",
      "Episode 872, len12, loss:-104.7978, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5498921871185303 sec\n",
      "Episode 873, len12, loss:-99.7179, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5503814220428467 sec\n",
      "Episode 874, len6, loss:-63.0776, fail, steps:80, opt steps:14, total reward:-24.4000, 0.5421566963195801 sec\n",
      "Episode 875, len8, loss:-76.2004, fail, steps:80, opt steps:12, total reward:-24.7000, 0.544302225112915 sec\n",
      "Episode 876, len6, loss:-66.0735, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5948464870452881 sec\n",
      "Episode 877, len12, loss:-108.7616, fail, steps:80, opt steps:49, total reward:-24.7000, 0.5458571910858154 sec\n",
      "Episode 878, len10, loss:-88.8686, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5501055717468262 sec\n",
      "Episode 879, len6, loss:-66.6302, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5468547344207764 sec\n",
      "Episode 880, len8, loss:-100.5032, fail, steps:80, opt steps:12, total reward:-26.8000, 0.5312440395355225 sec\n",
      "Episode 881, len10, loss:-98.8190, fail, steps:80, opt steps:23, total reward:-24.4000, 0.5378341674804688 sec\n",
      "Episode 882, len12, loss:-108.2542, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5487661361694336 sec\n",
      "Episode 883, len8, loss:-69.7596, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5483736991882324 sec\n",
      "Episode 884, len10, loss:-98.5503, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5431475639343262 sec\n",
      "Episode 885, len10, loss:-92.3693, fail, steps:80, opt steps:31, total reward:-24.7000, 0.5451908111572266 sec\n",
      "Episode 886, len8, loss:-74.1867, fail, steps:80, opt steps:22, total reward:-23.1000, 0.5353734493255615 sec\n",
      "Episode 887, len6, loss:-58.0808, fail, steps:80, opt steps:15, total reward:-22.7000, 0.542898416519165 sec\n",
      "Episode 888, len10, loss:-89.7251, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5488936901092529 sec\n",
      "Episode 889, len6, loss:-68.4310, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5494494438171387 sec\n",
      "Episode 890, len10, loss:-93.6559, fail, steps:80, opt steps:38, total reward:-24.0000, 0.601844310760498 sec\n",
      "Episode 891, len10, loss:-85.7274, fail, steps:80, opt steps:39, total reward:-22.7000, 0.5442163944244385 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 892, len6, loss:-58.4388, fail, steps:80, opt steps:13, total reward:-23.4000, 0.5408155918121338 sec\n",
      "Episode 893, len6, loss:-66.6684, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5490045547485352 sec\n",
      "Episode 894, len8, loss:-68.3333, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5486729145050049 sec\n",
      "Episode 895, len10, loss:-105.8215, fail, steps:80, opt steps:36, total reward:-26.1000, 0.5366313457489014 sec\n",
      "Episode 896, len10, loss:-85.5900, fail, steps:80, opt steps:31, total reward:-23.7000, 0.5431249141693115 sec\n",
      "Episode 897, len6, loss:-68.3654, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5429513454437256 sec\n",
      "Episode 898, len8, loss:-85.5181, fail, steps:80, opt steps:23, total reward:-25.1000, 0.5348975658416748 sec\n",
      "Episode 899, len8, loss:-80.5553, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5471923351287842 sec\n",
      "Episode 900, len6, loss:-60.9062, fail, steps:80, opt steps:19, total reward:-24.1000, 0.53493332862854 sec\n",
      "Episode 901, len8, loss:-77.7194, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5488576889038086 sec\n",
      "Episode 902, len10, loss:-91.8913, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5479631423950195 sec\n",
      "Episode 903, len10, loss:-85.8274, fail, steps:80, opt steps:30, total reward:-22.7000, 0.5444700717926025 sec\n",
      "Episode 904, len12, loss:-116.0117, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5501112937927246 sec\n",
      "Episode 905, len10, loss:-95.1931, fail, steps:80, opt steps:35, total reward:-24.7000, 0.5940439701080322 sec\n",
      "Episode 906, len8, loss:-80.5508, fail, steps:80, opt steps:4, total reward:-24.7000, 0.5437064170837402 sec\n",
      "Episode 907, len6, loss:-66.5324, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5441546440124512 sec\n",
      "Episode 908, len6, loss:-63.7548, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5484306812286377 sec\n",
      "Episode 909, len10, loss:-98.2466, fail, steps:80, opt steps:46, total reward:-24.7000, 0.5439517498016357 sec\n",
      "Episode 910, len12, loss:-105.7093, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5485007762908936 sec\n",
      "Episode 911, len6, loss:-68.1860, fail, steps:80, opt steps:5, total reward:-24.7000, 0.544609546661377 sec\n",
      "Episode 912, len12, loss:-116.6604, fail, steps:80, opt steps:48, total reward:-24.4000, 0.5410869121551514 sec\n",
      "Episode 913, len12, loss:-106.8761, fail, steps:80, opt steps:32, total reward:-24.4000, 0.5398595333099365 sec\n",
      "Episode 914, len8, loss:-76.9357, fail, steps:80, opt steps:24, total reward:-23.7000, 0.5441040992736816 sec\n",
      "Episode 915, len6, loss:-62.1046, fail, steps:80, opt steps:7, total reward:-23.4000, 0.5408923625946045 sec\n",
      "Episode 916, len10, loss:-93.0440, fail, steps:80, opt steps:45, total reward:-24.7000, 0.543694257736206 sec\n",
      "Episode 917, len12, loss:-118.0715, fail, steps:80, opt steps:41, total reward:-25.1000, 0.5368139743804932 sec\n",
      "Episode 918, len10, loss:-94.2183, fail, steps:80, opt steps:19, total reward:-24.1000, 0.5352635383605957 sec\n",
      "Episode 919, len10, loss:-98.6360, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5439963340759277 sec\n",
      "Episode 920, len12, loss:-104.0192, fail, steps:80, opt steps:44, total reward:-24.7000, 0.5421364307403564 sec\n",
      "Episode 921, len12, loss:-114.6569, fail, steps:80, opt steps:25, total reward:-25.1000, 0.5883049964904785 sec\n",
      "Episode 922, len8, loss:-31.5304, fail, steps:0, opt steps:7, total reward:-10.0000, 0.021481752395629883 sec\n",
      "Episode 923, len12, loss:-100.4603, fail, steps:80, opt steps:59, total reward:-23.4000, 0.4837768077850342 sec\n",
      "Episode 924, len8, loss:-66.5661, fail, steps:80, opt steps:29, total reward:-22.7000, 0.5192515850067139 sec\n",
      "Episode 925, len10, loss:-83.3254, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5349633693695068 sec\n",
      "Episode 926, len8, loss:-74.5866, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5389745235443115 sec\n",
      "Episode 927, len6, loss:-57.2515, fail, steps:80, opt steps:10, total reward:-23.4000, 0.5349018573760986 sec\n",
      "Episode 928, len12, loss:-115.3014, fail, steps:80, opt steps:60, total reward:-25.4000, 0.5346724987030029 sec\n",
      "Episode 929, len6, loss:-54.3997, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5445265769958496 sec\n",
      "Episode 930, len6, loss:-70.3707, fail, steps:80, opt steps:10, total reward:-24.7000, 0.5416998863220215 sec\n",
      "Episode 931, len8, loss:-85.5220, fail, steps:80, opt steps:21, total reward:-25.8000, 0.5297255516052246 sec\n",
      "Episode 932, len12, loss:-109.1668, fail, steps:80, opt steps:54, total reward:-24.7000, 0.5430376529693604 sec\n",
      "Episode 933, len12, loss:-102.8536, fail, steps:80, opt steps:56, total reward:-23.7000, 0.5430493354797363 sec\n",
      "Episode 934, len10, loss:-97.5242, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5429861545562744 sec\n",
      "Episode 935, len6, loss:-61.2238, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5474967956542969 sec\n",
      "Episode 936, len8, loss:-78.1897, fail, steps:80, opt steps:13, total reward:-24.4000, 0.5377271175384521 sec\n",
      "Episode 937, len10, loss:-95.4606, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5482001304626465 sec\n",
      "Episode 938, len8, loss:-64.6704, fail, steps:80, opt steps:25, total reward:-23.7000, 0.5994892120361328 sec\n",
      "Episode 939, len10, loss:-101.2243, fail, steps:80, opt steps:39, total reward:-25.4000, 0.539447546005249 sec\n",
      "Episode 940, len6, loss:-44.1401, fail, steps:80, opt steps:15, total reward:-22.7000, 0.5424203872680664 sec\n",
      "Episode 941, len6, loss:-58.9150, fail, steps:80, opt steps:20, total reward:-22.8000, 0.5299580097198486 sec\n",
      "Episode 942, len10, loss:-101.0094, fail, steps:80, opt steps:55, total reward:-24.8000, 0.5289850234985352 sec\n",
      "Episode 943, len6, loss:-56.8327, fail, steps:80, opt steps:21, total reward:-24.1000, 0.5332167148590088 sec\n",
      "Episode 944, len8, loss:-65.6861, fail, steps:80, opt steps:21, total reward:-22.7000, 0.5441794395446777 sec\n",
      "Episode 945, len12, loss:-106.4324, fail, steps:80, opt steps:47, total reward:-24.0000, 0.549128532409668 sec\n",
      "Episode 946, len10, loss:-86.0669, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5475854873657227 sec\n",
      "Episode 947, len10, loss:-86.4293, fail, steps:80, opt steps:30, total reward:-22.8000, 0.5294163227081299 sec\n",
      "Episode 948, len8, loss:-86.3557, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5415105819702148 sec\n",
      "Episode 949, len6, loss:-64.8880, fail, steps:80, opt steps:11, total reward:-24.1000, 0.5364599227905273 sec\n",
      "Episode 950, len10, loss:-94.8935, fail, steps:80, opt steps:21, total reward:-24.4000, 0.5385866165161133 sec\n",
      "Episode 951, len8, loss:-68.0154, fail, steps:80, opt steps:33, total reward:-22.1000, 0.5946652889251709 sec\n",
      "Episode 952, len10, loss:-97.4073, fail, steps:80, opt steps:44, total reward:-24.7000, 0.543677806854248 sec\n",
      "Episode 953, len10, loss:-76.7589, fail, steps:80, opt steps:53, total reward:-22.7000, 0.5435421466827393 sec\n",
      "Episode 954, len6, loss:-64.5116, fail, steps:80, opt steps:13, total reward:-25.4000, 0.5395007133483887 sec\n",
      "Episode 955, len10, loss:-84.0662, fail, steps:80, opt steps:38, total reward:-23.4000, 0.5390927791595459 sec\n",
      "Episode 956, len12, loss:-105.3023, fail, steps:80, opt steps:53, total reward:-24.4000, 0.5402581691741943 sec\n",
      "Episode 957, len10, loss:-82.1476, fail, steps:80, opt steps:9, total reward:-24.7000, 0.542900562286377 sec\n",
      "Episode 958, len12, loss:-105.2755, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5441124439239502 sec\n",
      "Episode 959, len6, loss:-56.0543, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5489466190338135 sec\n",
      "Episode 960, len8, loss:-67.2992, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5477843284606934 sec\n",
      "Episode 961, len12, loss:-103.9319, fail, steps:80, opt steps:40, total reward:-24.7000, 0.547008752822876 sec\n",
      "Episode 962, len12, loss:-101.7697, fail, steps:80, opt steps:34, total reward:-24.7000, 0.544384241104126 sec\n",
      "Episode 963, len10, loss:-108.0134, fail, steps:80, opt steps:30, total reward:-26.8000, 0.5305271148681641 sec\n",
      "Episode 964, len8, loss:-72.7034, fail, steps:80, opt steps:27, total reward:-23.4000, 0.538285493850708 sec\n",
      "Episode 965, len12, loss:-107.3692, fail, steps:80, opt steps:42, total reward:-23.7000, 0.6012005805969238 sec\n",
      "Episode 966, len12, loss:-111.4083, fail, steps:80, opt steps:44, total reward:-25.4000, 0.5400347709655762 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 967, len6, loss:-57.1914, fail, steps:80, opt steps:18, total reward:-22.1000, 0.5348026752471924 sec\n",
      "Episode 968, len6, loss:-65.9909, fail, steps:80, opt steps:13, total reward:-24.4000, 0.5392167568206787 sec\n",
      "Episode 969, len12, loss:-31.9046, fail, steps:0, opt steps:44, total reward:-10.0000, 0.02156686782836914 sec\n",
      "Episode 970, len6, loss:-46.0084, fail, steps:80, opt steps:19, total reward:-22.4000, 0.4824554920196533 sec\n",
      "Episode 971, len6, loss:-51.9785, fail, steps:80, opt steps:15, total reward:-22.7000, 0.5222318172454834 sec\n",
      "Episode 972, len6, loss:-57.4879, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5364627838134766 sec\n",
      "Episode 973, len6, loss:-64.6458, fail, steps:80, opt steps:8, total reward:-23.4000, 0.5298268795013428 sec\n",
      "Episode 974, len8, loss:-74.0789, fail, steps:80, opt steps:9, total reward:-24.7000, 0.539919376373291 sec\n",
      "Episode 975, len8, loss:-81.2126, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5390336513519287 sec\n",
      "Episode 976, len12, loss:-107.1065, fail, steps:80, opt steps:30, total reward:-24.4000, 0.5373058319091797 sec\n",
      "Episode 977, len10, loss:-91.6249, fail, steps:80, opt steps:33, total reward:-24.1000, 0.5328183174133301 sec\n",
      "Episode 978, len10, loss:-84.3600, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5469961166381836 sec\n",
      "Episode 979, len8, loss:-64.6431, fail, steps:80, opt steps:19, total reward:-24.4000, 0.5398283004760742 sec\n",
      "Episode 980, len6, loss:-57.0156, fail, steps:80, opt steps:18, total reward:-23.7000, 0.6010169982910156 sec\n",
      "Episode 981, len6, loss:-46.7116, fail, steps:80, opt steps:21, total reward:-22.1000, 0.5332810878753662 sec\n",
      "Episode 982, len10, loss:-94.5905, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5446305274963379 sec\n",
      "Episode 983, len8, loss:-76.4130, fail, steps:80, opt steps:18, total reward:-23.4000, 0.5393035411834717 sec\n",
      "Episode 984, len8, loss:-71.7319, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5449566841125488 sec\n",
      "Episode 985, len6, loss:-42.3505, fail, steps:80, opt steps:12, total reward:-21.5000, 0.5268254280090332 sec\n",
      "Episode 986, len6, loss:-50.5193, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5467982292175293 sec\n",
      "Episode 987, len6, loss:-60.6267, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5434503555297852 sec\n",
      "Episode 988, len10, loss:-86.4852, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5471782684326172 sec\n",
      "Episode 989, len12, loss:-116.5951, fail, steps:80, opt steps:55, total reward:-25.4000, 0.5407841205596924 sec\n",
      "Episode 990, len12, loss:-109.4035, fail, steps:80, opt steps:55, total reward:-24.7000, 0.543682336807251 sec\n",
      "Episode 991, len8, loss:-31.3061, fail, steps:0, opt steps:21, total reward:-10.0000, 0.021500825881958008 sec\n",
      "Episode 992, len10, loss:-90.1229, fail, steps:80, opt steps:35, total reward:-23.7000, 0.4881291389465332 sec\n",
      "Episode 993, len10, loss:-101.1564, fail, steps:80, opt steps:35, total reward:-25.4000, 0.5155460834503174 sec\n",
      "Episode 994, len12, loss:-103.7417, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5295422077178955 sec\n",
      "Episode 995, len8, loss:-73.1520, fail, steps:80, opt steps:34, total reward:-24.0000, 0.540224552154541 sec\n",
      "Episode 996, len10, loss:-89.9629, fail, steps:80, opt steps:17, total reward:-24.0000, 0.592937707901001 sec\n",
      "Episode 997, len12, loss:-120.9842, fail, steps:80, opt steps:68, total reward:-26.1000, 0.531085729598999 sec\n",
      "Episode 998, len12, loss:-107.7914, fail, steps:80, opt steps:59, total reward:-24.4000, 0.5370409488677979 sec\n",
      "Episode 999, len10, loss:-92.7140, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5461363792419434 sec\n",
      "Episode 1000, len6, loss:-61.4911, fail, steps:80, opt steps:7, total reward:-24.7000, 0.5437948703765869 sec\n",
      "Checkpoint saved at episode 1000 to /home/mcwave/code/autocode/datasets/rl_sort_transformer_easy/list6_12_transformer3_128_gamma07_step80_v3_merge_2_sorted/ckpt_1000_0.0020_28.49_vs_5.50.pth\n",
      "Learning rate = 0.000098\n",
      "Episode 1001, len6, loss:-54.3104, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5439732074737549 sec\n",
      "Episode 1002, len10, loss:-97.7679, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5478806495666504 sec\n",
      "Episode 1003, len6, loss:-55.8206, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5444009304046631 sec\n",
      "Episode 1004, len10, loss:-88.1533, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5494933128356934 sec\n",
      "Episode 1005, len6, loss:-46.9393, fail, steps:80, opt steps:21, total reward:-22.1000, 0.535024881362915 sec\n",
      "Episode 1006, len10, loss:-110.6981, fail, steps:80, opt steps:23, total reward:-25.1000, 0.534698486328125 sec\n",
      "Episode 1007, len6, loss:-60.8173, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5420627593994141 sec\n",
      "Episode 1008, len10, loss:-90.6832, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5483648777008057 sec\n",
      "Episode 1009, len10, loss:-32.0545, fail, steps:0, opt steps:32, total reward:-10.0000, 0.021794557571411133 sec\n",
      "Episode 1010, len8, loss:-86.9655, fail, steps:80, opt steps:14, total reward:-25.4000, 0.48278260231018066 sec\n",
      "Episode 1011, len10, loss:-93.8544, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5766394138336182 sec\n",
      "Episode 1012, len6, loss:-62.9358, fail, steps:80, opt steps:15, total reward:-24.4000, 0.5250828266143799 sec\n",
      "Episode 1013, len12, loss:-106.9960, fail, steps:80, opt steps:61, total reward:-24.7000, 0.5346994400024414 sec\n",
      "Episode 1014, len10, loss:-94.4605, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5419168472290039 sec\n",
      "Episode 1015, len12, loss:-100.5412, fail, steps:80, opt steps:50, total reward:-24.7000, 0.5405030250549316 sec\n",
      "Episode 1016, len8, loss:-73.1150, fail, steps:80, opt steps:16, total reward:-23.4000, 0.5361936092376709 sec\n",
      "Episode 1017, len12, loss:-105.0871, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5453333854675293 sec\n",
      "Episode 1018, len6, loss:-57.3067, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5476686954498291 sec\n",
      "Episode 1019, len8, loss:-77.0530, fail, steps:80, opt steps:22, total reward:-24.0000, 0.547797441482544 sec\n",
      "Episode 1020, len6, loss:-55.9653, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5440363883972168 sec\n",
      "Episode 1021, len6, loss:-53.9322, fail, steps:80, opt steps:16, total reward:-23.4000, 0.5396432876586914 sec\n",
      "Episode 1022, len8, loss:-80.4657, fail, steps:80, opt steps:18, total reward:-24.7000, 0.542011022567749 sec\n",
      "Episode 1023, len6, loss:-53.9476, fail, steps:80, opt steps:11, total reward:-23.1000, 0.5350494384765625 sec\n",
      "Episode 1024, len10, loss:-97.1746, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5423920154571533 sec\n",
      "Episode 1025, len8, loss:-76.2924, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5431599617004395 sec\n",
      "Episode 1026, len12, loss:-102.0711, fail, steps:80, opt steps:24, total reward:-23.7000, 0.5430023670196533 sec\n",
      "Episode 1027, len10, loss:-93.5308, fail, steps:80, opt steps:47, total reward:-24.0000, 0.6002569198608398 sec\n",
      "Episode 1028, len8, loss:-148.2303, fail, steps:59, opt steps:11, total reward:-29.1000, 0.4021334648132324 sec\n",
      "Episode 1029, len12, loss:-99.4028, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5345427989959717 sec\n",
      "Episode 1030, len10, loss:-98.7024, fail, steps:80, opt steps:30, total reward:-24.7000, 0.540485143661499 sec\n",
      "Episode 1031, len12, loss:-104.4160, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5458798408508301 sec\n",
      "Episode 1032, len8, loss:-78.3236, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5477943420410156 sec\n",
      "Episode 1033, len12, loss:-110.2072, fail, steps:80, opt steps:64, total reward:-24.7000, 0.542107105255127 sec\n",
      "Episode 1034, len8, loss:-79.7753, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5425755977630615 sec\n",
      "Episode 1035, len6, loss:-59.3049, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5474855899810791 sec\n",
      "Episode 1036, len8, loss:-82.0915, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5490274429321289 sec\n",
      "Episode 1037, len8, loss:-79.2548, fail, steps:80, opt steps:16, total reward:-25.4000, 0.5450470447540283 sec\n",
      "Episode 1038, len6, loss:-66.4843, fail, steps:80, opt steps:7, total reward:-24.7000, 0.5431301593780518 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1039, len12, loss:-116.0750, fail, steps:80, opt steps:44, total reward:-25.4000, 0.5415470600128174 sec\n",
      "Episode 1040, len6, loss:-59.1393, fail, steps:80, opt steps:10, total reward:-24.7000, 0.5438694953918457 sec\n",
      "Episode 1041, len6, loss:-62.9322, fail, steps:80, opt steps:11, total reward:-23.1000, 0.5339758396148682 sec\n",
      "Episode 1042, len12, loss:-107.6220, fail, steps:80, opt steps:60, total reward:-24.4000, 0.5382707118988037 sec\n",
      "Episode 1043, len12, loss:-106.3250, fail, steps:80, opt steps:49, total reward:-24.0000, 0.6000049114227295 sec\n",
      "Episode 1044, len8, loss:-89.2381, fail, steps:80, opt steps:27, total reward:-25.4000, 0.5391271114349365 sec\n",
      "Episode 1045, len8, loss:-77.4562, fail, steps:80, opt steps:26, total reward:-23.7000, 0.5439271926879883 sec\n",
      "Episode 1046, len10, loss:-95.9613, fail, steps:80, opt steps:54, total reward:-24.7000, 0.5479569435119629 sec\n",
      "Episode 1047, len12, loss:-108.8144, fail, steps:80, opt steps:48, total reward:-25.4000, 0.5395040512084961 sec\n",
      "Episode 1048, len6, loss:-68.1112, fail, steps:80, opt steps:20, total reward:-25.4000, 0.5400288105010986 sec\n",
      "Episode 1049, len10, loss:-100.9868, fail, steps:80, opt steps:38, total reward:-24.4000, 0.5391900539398193 sec\n",
      "Episode 1050, len8, loss:-131.1512, fail, steps:68, opt steps:19, total reward:-30.1000, 0.4650094509124756 sec\n",
      "Episode 1051, len8, loss:-79.5728, fail, steps:80, opt steps:23, total reward:-23.7000, 0.537970781326294 sec\n",
      "Episode 1052, len12, loss:-106.6506, fail, steps:80, opt steps:58, total reward:-24.4000, 0.536693811416626 sec\n",
      "Episode 1053, len10, loss:-99.4702, fail, steps:80, opt steps:46, total reward:-24.7000, 0.5418057441711426 sec\n",
      "Episode 1054, len10, loss:-101.9671, fail, steps:80, opt steps:50, total reward:-24.7000, 0.5426187515258789 sec\n",
      "Episode 1055, len8, loss:-77.9884, fail, steps:80, opt steps:13, total reward:-23.7000, 0.54225754737854 sec\n",
      "Episode 1056, len6, loss:-66.3205, fail, steps:80, opt steps:20, total reward:-25.4000, 0.5894021987915039 sec\n",
      "Episode 1057, len8, loss:-80.0361, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5482664108276367 sec\n",
      "Episode 1058, len10, loss:-93.1825, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5445778369903564 sec\n",
      "Episode 1059, len8, loss:-79.5815, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5494132041931152 sec\n",
      "Episode 1060, len12, loss:-98.8118, fail, steps:80, opt steps:66, total reward:-23.5000, 0.5289781093597412 sec\n",
      "Episode 1061, len12, loss:-100.2559, fail, steps:80, opt steps:35, total reward:-24.7000, 0.544090747833252 sec\n",
      "Episode 1062, len6, loss:-64.2405, fail, steps:80, opt steps:14, total reward:-24.4000, 0.5407540798187256 sec\n",
      "Episode 1063, len10, loss:-90.4823, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5487382411956787 sec\n",
      "Episode 1064, len10, loss:-101.1946, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5454213619232178 sec\n",
      "Episode 1065, len8, loss:-82.8623, fail, steps:80, opt steps:26, total reward:-24.7000, 0.545788049697876 sec\n",
      "Episode 1066, len12, loss:-96.9633, fail, steps:80, opt steps:33, total reward:-24.7000, 0.5454261302947998 sec\n",
      "Episode 1067, len12, loss:-100.8603, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5495116710662842 sec\n",
      "Episode 1068, len8, loss:-91.8859, fail, steps:80, opt steps:15, total reward:-25.4000, 0.5411756038665771 sec\n",
      "Episode 1069, len10, loss:-97.8502, fail, steps:80, opt steps:46, total reward:-24.0000, 0.548703670501709 sec\n",
      "Episode 1070, len8, loss:-91.7947, fail, steps:80, opt steps:21, total reward:-26.1000, 0.5374116897583008 sec\n",
      "Episode 1071, len8, loss:-71.7025, fail, steps:80, opt steps:29, total reward:-22.7000, 0.5450143814086914 sec\n",
      "Episode 1072, len10, loss:-117.4327, fail, steps:80, opt steps:25, total reward:-26.1000, 0.5855882167816162 sec\n",
      "Episode 1073, len6, loss:-68.1404, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5479145050048828 sec\n",
      "Episode 1074, len12, loss:-104.2531, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5501267910003662 sec\n",
      "Episode 1075, len10, loss:-102.7345, fail, steps:80, opt steps:39, total reward:-24.7000, 0.546616792678833 sec\n",
      "Episode 1076, len10, loss:-89.5593, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5499975681304932 sec\n",
      "Episode 1077, len8, loss:-80.4496, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5516870021820068 sec\n",
      "Episode 1078, len8, loss:-85.8901, fail, steps:80, opt steps:6, total reward:-25.4000, 0.5404586791992188 sec\n",
      "Episode 1079, len10, loss:-92.8912, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5501987934112549 sec\n",
      "Episode 1080, len10, loss:-96.9750, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5489828586578369 sec\n",
      "Episode 1081, len6, loss:-68.5625, fail, steps:80, opt steps:20, total reward:-24.4000, 0.5410647392272949 sec\n",
      "Episode 1082, len12, loss:-99.2966, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5509941577911377 sec\n",
      "Episode 1083, len8, loss:-86.5880, fail, steps:80, opt steps:4, total reward:-24.7000, 0.5458290576934814 sec\n",
      "Episode 1084, len12, loss:-104.8550, fail, steps:80, opt steps:49, total reward:-24.7000, 0.5452260971069336 sec\n",
      "Episode 1085, len10, loss:-94.5652, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5492613315582275 sec\n",
      "Episode 1086, len10, loss:-105.2536, fail, steps:80, opt steps:18, total reward:-24.7000, 0.545255184173584 sec\n",
      "Episode 1087, len10, loss:-112.5878, fail, steps:80, opt steps:43, total reward:-24.8000, 0.531123161315918 sec\n",
      "Episode 1088, len10, loss:-107.6132, fail, steps:80, opt steps:43, total reward:-25.1000, 0.5350558757781982 sec\n",
      "Episode 1089, len8, loss:-83.1469, fail, steps:80, opt steps:23, total reward:-24.4000, 0.5917458534240723 sec\n",
      "Episode 1090, len6, loss:-62.9420, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5483672618865967 sec\n",
      "Episode 1091, len6, loss:-65.3269, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5495619773864746 sec\n",
      "Episode 1092, len10, loss:-103.6919, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5496366024017334 sec\n",
      "Episode 1093, len10, loss:-104.3933, fail, steps:80, opt steps:29, total reward:-24.1000, 0.5372719764709473 sec\n",
      "Episode 1094, len8, loss:-91.5931, fail, steps:80, opt steps:29, total reward:-23.7000, 0.5436549186706543 sec\n",
      "Episode 1095, len10, loss:-93.4458, fail, steps:80, opt steps:43, total reward:-22.4000, 0.5394599437713623 sec\n",
      "Episode 1096, len8, loss:-97.6247, fail, steps:80, opt steps:12, total reward:-25.4000, 0.5406975746154785 sec\n",
      "Episode 1097, len8, loss:-87.3870, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5494675636291504 sec\n",
      "Episode 1098, len12, loss:-97.6205, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5499544143676758 sec\n",
      "Episode 1099, len8, loss:-89.9436, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5489401817321777 sec\n",
      "Episode 1100, len8, loss:-84.6584, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5483963489532471 sec\n",
      "Episode 1101, len8, loss:-84.7330, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5507631301879883 sec\n",
      "Episode 1102, len10, loss:-116.4652, fail, steps:80, opt steps:30, total reward:-25.4000, 0.5989935398101807 sec\n",
      "Episode 1103, len8, loss:-97.8638, fail, steps:80, opt steps:8, total reward:-24.0000, 0.548656702041626 sec\n",
      "Episode 1104, len8, loss:-86.7244, fail, steps:80, opt steps:31, total reward:-24.1000, 0.5360927581787109 sec\n",
      "Episode 1105, len6, loss:-70.8887, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5463378429412842 sec\n",
      "Episode 1106, len10, loss:-100.8011, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5500833988189697 sec\n",
      "Episode 1107, len8, loss:-90.6883, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5455129146575928 sec\n",
      "Episode 1108, len6, loss:-73.1732, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5496299266815186 sec\n",
      "Episode 1109, len8, loss:-84.4993, fail, steps:80, opt steps:17, total reward:-22.7000, 0.5468852519989014 sec\n",
      "Episode 1110, len12, loss:-104.8264, fail, steps:80, opt steps:42, total reward:-23.8000, 0.5328140258789062 sec\n",
      "Episode 1111, len8, loss:-90.5276, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5451815128326416 sec\n",
      "Episode 1112, len6, loss:-70.0402, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5484333038330078 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1113, len12, loss:-114.2555, fail, steps:80, opt steps:35, total reward:-26.1000, 0.5347859859466553 sec\n",
      "Episode 1114, len10, loss:-99.4293, fail, steps:80, opt steps:47, total reward:-22.8000, 0.5301122665405273 sec\n",
      "Episode 1115, len10, loss:-102.8983, fail, steps:80, opt steps:33, total reward:-24.7000, 0.5433793067932129 sec\n",
      "Episode 1116, len12, loss:-106.0619, fail, steps:80, opt steps:42, total reward:-24.4000, 0.5927436351776123 sec\n",
      "Episode 1117, len12, loss:-106.7198, fail, steps:80, opt steps:58, total reward:-24.7000, 0.5440661907196045 sec\n",
      "Episode 1118, len10, loss:-99.8010, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5491428375244141 sec\n",
      "Episode 1119, len12, loss:-97.9373, fail, steps:80, opt steps:54, total reward:-23.4000, 0.5398135185241699 sec\n",
      "Episode 1120, len6, loss:-77.9558, fail, steps:80, opt steps:13, total reward:-25.4000, 0.5402579307556152 sec\n",
      "Episode 1121, len10, loss:-97.0094, fail, steps:80, opt steps:32, total reward:-23.4000, 0.5397601127624512 sec\n",
      "Episode 1122, len12, loss:-112.7218, fail, steps:80, opt steps:37, total reward:-24.4000, 0.5385887622833252 sec\n",
      "Episode 1123, len6, loss:-68.9072, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5442771911621094 sec\n",
      "Episode 1124, len10, loss:-107.0151, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5477805137634277 sec\n",
      "Episode 1125, len8, loss:-79.8588, fail, steps:80, opt steps:29, total reward:-22.7000, 0.5449624061584473 sec\n",
      "Episode 1126, len12, loss:-99.1236, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5488688945770264 sec\n",
      "Episode 1127, len12, loss:-103.8802, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5501070022583008 sec\n",
      "Episode 1128, len10, loss:-100.2114, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5498607158660889 sec\n",
      "Episode 1129, len12, loss:-163.1406, fail, steps:67, opt steps:46, total reward:-31.5000, 0.4574556350708008 sec\n",
      "Episode 1130, len8, loss:-95.5932, fail, steps:80, opt steps:25, total reward:-25.1000, 0.5824034214019775 sec\n",
      "Episode 1131, len8, loss:-86.0599, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5455465316772461 sec\n",
      "Episode 1132, len8, loss:-92.5791, fail, steps:80, opt steps:18, total reward:-24.7000, 0.542128324508667 sec\n",
      "Episode 1133, len6, loss:-69.5700, fail, steps:80, opt steps:16, total reward:-24.0000, 0.547753095626831 sec\n",
      "Episode 1134, len6, loss:-72.4388, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5479719638824463 sec\n",
      "Episode 1135, len12, loss:-97.2047, fail, steps:80, opt steps:71, total reward:-24.0000, 0.5487968921661377 sec\n",
      "Episode 1136, len12, loss:-154.7552, fail, steps:61, opt steps:44, total reward:-29.0000, 0.4200265407562256 sec\n",
      "Episode 1137, len10, loss:-104.9462, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5320591926574707 sec\n",
      "Episode 1138, len12, loss:-104.1891, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5415909290313721 sec\n",
      "Episode 1139, len6, loss:-71.8523, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5436866283416748 sec\n",
      "Episode 1140, len8, loss:-91.3932, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5427749156951904 sec\n",
      "Episode 1141, len10, loss:-102.9278, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5471668243408203 sec\n",
      "Episode 1142, len6, loss:-71.5869, fail, steps:80, opt steps:10, total reward:-24.0000, 0.547234058380127 sec\n",
      "Episode 1143, len8, loss:-87.2571, fail, steps:80, opt steps:21, total reward:-24.4000, 0.5395240783691406 sec\n",
      "Episode 1144, len10, loss:-114.5161, fail, steps:80, opt steps:16, total reward:-25.4000, 0.5385639667510986 sec\n",
      "Episode 1145, len6, loss:-74.3164, fail, steps:80, opt steps:5, total reward:-23.4000, 0.53948974609375 sec\n",
      "Episode 1146, len12, loss:-105.1598, fail, steps:80, opt steps:73, total reward:-23.4000, 0.5958578586578369 sec\n",
      "Episode 1147, len10, loss:-101.4237, fail, steps:80, opt steps:31, total reward:-24.1000, 0.5355696678161621 sec\n",
      "Episode 1148, len10, loss:-108.9739, fail, steps:80, opt steps:28, total reward:-25.4000, 0.5393669605255127 sec\n",
      "Episode 1149, len10, loss:-99.3987, fail, steps:80, opt steps:26, total reward:-24.0000, 0.549832820892334 sec\n",
      "Episode 1150, len10, loss:-106.9373, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5444984436035156 sec\n",
      "Episode 1151, len6, loss:-71.0388, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5486223697662354 sec\n",
      "Episode 1152, len6, loss:-77.4386, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5437643527984619 sec\n",
      "Episode 1153, len12, loss:-97.1681, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5477437973022461 sec\n",
      "Episode 1154, len6, loss:-74.9939, fail, steps:80, opt steps:16, total reward:-24.7000, 0.544180154800415 sec\n",
      "Episode 1155, len6, loss:-72.4373, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5487277507781982 sec\n",
      "Episode 1156, len8, loss:-82.8416, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5486030578613281 sec\n",
      "Episode 1157, len10, loss:-102.1765, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5446019172668457 sec\n",
      "Episode 1158, len8, loss:-94.7677, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5450809001922607 sec\n",
      "Episode 1159, len10, loss:-96.6699, fail, steps:80, opt steps:8, total reward:-24.0000, 0.6062564849853516 sec\n",
      "Episode 1160, len6, loss:-73.7110, fail, steps:80, opt steps:11, total reward:-23.4000, 0.5405745506286621 sec\n",
      "Episode 1161, len6, loss:-69.2342, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5484628677368164 sec\n",
      "Episode 1162, len10, loss:-99.5208, fail, steps:80, opt steps:35, total reward:-24.7000, 0.5434021949768066 sec\n",
      "Episode 1163, len10, loss:-98.2759, fail, steps:80, opt steps:47, total reward:-23.7000, 0.5451123714447021 sec\n",
      "Episode 1164, len10, loss:-100.5674, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5486545562744141 sec\n",
      "Episode 1165, len12, loss:-103.2028, fail, steps:80, opt steps:57, total reward:-24.0000, 0.548328161239624 sec\n",
      "Episode 1166, len12, loss:-101.2358, fail, steps:80, opt steps:60, total reward:-24.0000, 0.549152135848999 sec\n",
      "Episode 1167, len10, loss:-100.2711, fail, steps:80, opt steps:44, total reward:-23.4000, 0.540215253829956 sec\n",
      "Episode 1168, len12, loss:-93.8955, fail, steps:80, opt steps:50, total reward:-23.1000, 0.5360264778137207 sec\n",
      "Episode 1169, len6, loss:-71.0598, fail, steps:80, opt steps:11, total reward:-23.4000, 0.5384783744812012 sec\n",
      "Episode 1170, len10, loss:-109.7376, fail, steps:80, opt steps:27, total reward:-25.4000, 0.5389204025268555 sec\n",
      "Episode 1171, len8, loss:-80.6599, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5424599647521973 sec\n",
      "Episode 1172, len10, loss:-101.0464, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5444941520690918 sec\n",
      "Episode 1173, len10, loss:-105.2168, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5968694686889648 sec\n",
      "Episode 1174, len12, loss:-92.6370, fail, steps:80, opt steps:23, total reward:-24.0000, 0.54925537109375 sec\n",
      "Episode 1175, len10, loss:-95.5329, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5490546226501465 sec\n",
      "Episode 1176, len10, loss:-88.1392, fail, steps:80, opt steps:43, total reward:-22.7000, 0.5444676876068115 sec\n",
      "Episode 1177, len10, loss:-92.7052, fail, steps:80, opt steps:30, total reward:-23.1000, 0.5349481105804443 sec\n",
      "Episode 1178, len10, loss:-96.2536, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5467953681945801 sec\n",
      "Episode 1179, len10, loss:-170.3377, fail, steps:75, opt steps:32, total reward:-33.9000, 0.508232831954956 sec\n",
      "Episode 1180, len10, loss:-102.2092, fail, steps:80, opt steps:11, total reward:-24.7000, 0.540839433670044 sec\n",
      "Episode 1181, len8, loss:-83.8544, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5424962043762207 sec\n",
      "Episode 1182, len12, loss:-108.2251, fail, steps:80, opt steps:69, total reward:-24.7000, 0.5440492630004883 sec\n",
      "Episode 1183, len8, loss:-90.5733, fail, steps:80, opt steps:12, total reward:-24.7000, 0.5436961650848389 sec\n",
      "Episode 1184, len6, loss:-62.7319, fail, steps:80, opt steps:18, total reward:-22.7000, 0.5431208610534668 sec\n",
      "Episode 1185, len10, loss:-96.3651, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5482974052429199 sec\n",
      "Episode 1186, len10, loss:-93.0604, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5485379695892334 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1187, len8, loss:-73.8020, fail, steps:80, opt steps:29, total reward:-23.7000, 0.5442202091217041 sec\n",
      "Episode 1188, len6, loss:-80.4356, fail, steps:80, opt steps:5, total reward:-25.4000, 0.5941758155822754 sec\n",
      "Episode 1189, len12, loss:-94.5817, fail, steps:80, opt steps:55, total reward:-23.4000, 0.5404694080352783 sec\n",
      "Episode 1190, len8, loss:-81.1713, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5416305065155029 sec\n",
      "Episode 1191, len8, loss:-70.6556, fail, steps:80, opt steps:33, total reward:-24.0000, 0.547745943069458 sec\n",
      "Episode 1192, len6, loss:-133.5878, fail, steps:57, opt steps:20, total reward:-27.8000, 0.39347290992736816 sec\n",
      "Episode 1193, len10, loss:-94.9247, fail, steps:80, opt steps:44, total reward:-23.7000, 0.5306885242462158 sec\n",
      "Episode 1194, len10, loss:-93.6000, fail, steps:80, opt steps:50, total reward:-23.4000, 0.5396592617034912 sec\n",
      "Episode 1195, len10, loss:-97.5806, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5456633567810059 sec\n",
      "Episode 1196, len12, loss:-101.0599, fail, steps:80, opt steps:55, total reward:-24.7000, 0.542313814163208 sec\n",
      "Episode 1197, len10, loss:-95.1092, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5488746166229248 sec\n",
      "Episode 1198, len6, loss:-72.5426, fail, steps:80, opt steps:21, total reward:-24.4000, 0.5392825603485107 sec\n",
      "Episode 1199, len8, loss:-96.3506, fail, steps:80, opt steps:21, total reward:-25.4000, 0.5384857654571533 sec\n",
      "Episode 1200, len8, loss:-76.4076, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5486986637115479 sec\n",
      "Episode 1201, len12, loss:-118.2020, fail, steps:80, opt steps:55, total reward:-24.4000, 0.5419676303863525 sec\n",
      "Episode 1202, len12, loss:-102.9982, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5506858825683594 sec\n",
      "Episode 1203, len12, loss:-95.2308, fail, steps:80, opt steps:58, total reward:-24.0000, 0.6018245220184326 sec\n",
      "Episode 1204, len6, loss:-56.3632, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5490593910217285 sec\n",
      "Episode 1205, len6, loss:-67.6866, fail, steps:80, opt steps:15, total reward:-23.7000, 0.5454282760620117 sec\n",
      "Episode 1206, len10, loss:-102.9812, fail, steps:80, opt steps:44, total reward:-25.4000, 0.5418820381164551 sec\n",
      "Episode 1207, len8, loss:-75.7848, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5445880889892578 sec\n",
      "Episode 1208, len6, loss:-62.1386, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5527877807617188 sec\n",
      "Episode 1209, len6, loss:-63.5388, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5494120121002197 sec\n",
      "Episode 1210, len8, loss:-128.2949, fail, steps:74, opt steps:33, total reward:-31.6000, 0.5013706684112549 sec\n",
      "Episode 1211, len6, loss:-54.2051, fail, steps:80, opt steps:13, total reward:-22.7000, 0.541032075881958 sec\n",
      "Episode 1212, len8, loss:-66.9207, fail, steps:80, opt steps:35, total reward:-23.4000, 0.5398263931274414 sec\n",
      "Episode 1213, len6, loss:-57.3932, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5479693412780762 sec\n",
      "Episode 1214, len12, loss:-104.2899, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5504941940307617 sec\n",
      "Episode 1215, len6, loss:-59.5241, fail, steps:80, opt steps:6, total reward:-22.7000, 0.5454225540161133 sec\n",
      "Episode 1216, len6, loss:-61.2015, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5501258373260498 sec\n",
      "Episode 1217, len10, loss:-97.9462, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5993914604187012 sec\n",
      "Episode 1218, len6, loss:-65.1125, fail, steps:80, opt steps:14, total reward:-24.4000, 0.5395915508270264 sec\n",
      "Episode 1219, len8, loss:-69.8304, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5435237884521484 sec\n",
      "Episode 1220, len8, loss:-82.9513, fail, steps:80, opt steps:29, total reward:-25.1000, 0.5380239486694336 sec\n",
      "Episode 1221, len6, loss:-54.5592, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5439682006835938 sec\n",
      "Episode 1222, len10, loss:-99.0114, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5518529415130615 sec\n",
      "Episode 1223, len12, loss:-104.9962, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5454790592193604 sec\n",
      "Episode 1224, len10, loss:-89.3653, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5500938892364502 sec\n",
      "Episode 1225, len8, loss:-75.6655, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5442655086517334 sec\n",
      "Episode 1226, len8, loss:-64.4245, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5459005832672119 sec\n",
      "Episode 1227, len12, loss:-101.6707, fail, steps:80, opt steps:59, total reward:-24.7000, 0.5454807281494141 sec\n",
      "Episode 1228, len10, loss:-84.3852, fail, steps:80, opt steps:28, total reward:-24.0000, 0.548445463180542 sec\n",
      "Episode 1229, len12, loss:-110.3788, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5500044822692871 sec\n",
      "Episode 1230, len12, loss:-98.1106, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5498161315917969 sec\n",
      "Episode 1231, len12, loss:-100.4412, fail, steps:80, opt steps:36, total reward:-24.0000, 0.6028249263763428 sec\n",
      "Episode 1232, len12, loss:-109.8943, fail, steps:80, opt steps:62, total reward:-24.7000, 0.5461716651916504 sec\n",
      "Episode 1233, len10, loss:-82.9655, fail, steps:80, opt steps:35, total reward:-23.4000, 0.5407009124755859 sec\n",
      "Episode 1234, len8, loss:-65.6986, fail, steps:80, opt steps:12, total reward:-24.0000, 0.548691987991333 sec\n",
      "Episode 1235, len12, loss:-98.9969, fail, steps:80, opt steps:63, total reward:-24.4000, 0.5417261123657227 sec\n",
      "Episode 1236, len8, loss:-58.8320, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5502796173095703 sec\n",
      "Episode 1237, len12, loss:-111.5317, fail, steps:80, opt steps:18, total reward:-26.1000, 0.5362858772277832 sec\n",
      "Episode 1238, len12, loss:-99.1394, fail, steps:80, opt steps:40, total reward:-24.7000, 0.5442378520965576 sec\n",
      "Episode 1239, len6, loss:-50.6100, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5442061424255371 sec\n",
      "Episode 1240, len12, loss:-90.4478, fail, steps:80, opt steps:70, total reward:-24.0000, 0.5487370491027832 sec\n",
      "Episode 1241, len10, loss:-78.0981, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5508131980895996 sec\n",
      "Episode 1242, len6, loss:-45.2417, fail, steps:80, opt steps:11, total reward:-22.7000, 0.5448133945465088 sec\n",
      "Episode 1243, len6, loss:-53.9679, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5447914600372314 sec\n",
      "Episode 1244, len6, loss:-57.0578, fail, steps:80, opt steps:21, total reward:-23.7000, 0.5428035259246826 sec\n",
      "Episode 1245, len10, loss:-34.2376, fail, steps:0, opt steps:27, total reward:-10.0000, 0.02172255516052246 sec\n",
      "Episode 1246, len10, loss:-93.3964, fail, steps:80, opt steps:44, total reward:-25.4000, 0.5360367298126221 sec\n",
      "Episode 1247, len12, loss:-95.9184, fail, steps:80, opt steps:66, total reward:-24.0000, 0.525515079498291 sec\n",
      "Episode 1248, len8, loss:-61.2783, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5338025093078613 sec\n",
      "Episode 1249, len8, loss:-70.1125, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5411891937255859 sec\n",
      "Episode 1250, len8, loss:-65.5748, fail, steps:80, opt steps:26, total reward:-23.7000, 0.5390243530273438 sec\n",
      "Episode 1251, len6, loss:-52.6881, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5453488826751709 sec\n",
      "Episode 1252, len8, loss:-78.7278, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5431900024414062 sec\n",
      "Episode 1253, len6, loss:-56.5244, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5475466251373291 sec\n",
      "Episode 1254, len10, loss:-83.5473, fail, steps:80, opt steps:35, total reward:-24.0000, 0.549058198928833 sec\n",
      "Episode 1255, len6, loss:-53.5807, fail, steps:80, opt steps:8, total reward:-22.7000, 0.543816328048706 sec\n",
      "Episode 1256, len8, loss:-56.3880, fail, steps:80, opt steps:28, total reward:-23.7000, 0.544175386428833 sec\n",
      "Episode 1257, len12, loss:-80.6848, fail, steps:80, opt steps:64, total reward:-22.4000, 0.540618896484375 sec\n",
      "Episode 1258, len12, loss:-95.0599, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5485358238220215 sec\n",
      "Episode 1259, len8, loss:-59.7247, fail, steps:80, opt steps:28, total reward:-23.4000, 0.5404584407806396 sec\n",
      "Episode 1260, len8, loss:-60.7076, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5985722541809082 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1261, len12, loss:-104.0695, fail, steps:80, opt steps:38, total reward:-25.4000, 0.5410571098327637 sec\n",
      "Episode 1262, len8, loss:-68.7199, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5456752777099609 sec\n",
      "Episode 1263, len6, loss:-51.6597, fail, steps:80, opt steps:8, total reward:-22.7000, 0.5428981781005859 sec\n",
      "Episode 1264, len8, loss:-68.4786, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5451140403747559 sec\n",
      "Episode 1265, len12, loss:-100.0654, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5491809844970703 sec\n",
      "Episode 1266, len10, loss:-87.0043, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5441746711730957 sec\n",
      "Episode 1267, len10, loss:-88.0589, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5486536026000977 sec\n",
      "Episode 1268, len10, loss:-84.0247, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5503089427947998 sec\n",
      "Episode 1269, len12, loss:-98.1736, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5506589412689209 sec\n",
      "Episode 1270, len8, loss:-62.9558, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5448136329650879 sec\n",
      "Episode 1271, len6, loss:-48.3940, fail, steps:80, opt steps:13, total reward:-22.4000, 0.5410616397857666 sec\n",
      "Episode 1272, len12, loss:-99.3573, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5489559173583984 sec\n",
      "Episode 1273, len10, loss:-98.6549, fail, steps:80, opt steps:19, total reward:-25.4000, 0.5415079593658447 sec\n",
      "Episode 1274, len8, loss:-62.5846, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5998609066009521 sec\n",
      "Episode 1275, len6, loss:-65.8464, fail, steps:80, opt steps:18, total reward:-24.7000, 0.544111967086792 sec\n",
      "Episode 1276, len12, loss:-97.1494, fail, steps:80, opt steps:22, total reward:-23.7000, 0.5457346439361572 sec\n",
      "Episode 1277, len6, loss:-58.0329, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5483560562133789 sec\n",
      "Episode 1278, len8, loss:-57.7400, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5501708984375 sec\n",
      "Episode 1279, len10, loss:-75.4579, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5497653484344482 sec\n",
      "Episode 1280, len8, loss:-66.8879, fail, steps:80, opt steps:26, total reward:-24.4000, 0.5419631004333496 sec\n",
      "Episode 1281, len10, loss:-82.1427, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5480458736419678 sec\n",
      "Episode 1282, len10, loss:-84.7551, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5494000911712646 sec\n",
      "Episode 1283, len10, loss:-96.4340, fail, steps:80, opt steps:36, total reward:-25.4000, 0.54136061668396 sec\n",
      "Episode 1284, len12, loss:-83.0360, fail, steps:80, opt steps:30, total reward:-22.7000, 0.5444130897521973 sec\n",
      "Episode 1285, len8, loss:-68.9594, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5449039936065674 sec\n",
      "Episode 1286, len10, loss:-91.3910, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5485084056854248 sec\n",
      "Episode 1287, len12, loss:-95.7056, fail, steps:80, opt steps:55, total reward:-22.7000, 0.5453038215637207 sec\n",
      "Episode 1288, len10, loss:-92.1141, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5436854362487793 sec\n",
      "Episode 1289, len10, loss:-96.3750, fail, steps:80, opt steps:29, total reward:-24.0000, 0.6009750366210938 sec\n",
      "Episode 1290, len8, loss:-67.2124, fail, steps:80, opt steps:22, total reward:-22.7000, 0.5444786548614502 sec\n",
      "Episode 1291, len10, loss:-90.1344, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5434253215789795 sec\n",
      "Episode 1292, len6, loss:-60.4469, fail, steps:80, opt steps:13, total reward:-23.7000, 0.5446922779083252 sec\n",
      "Episode 1293, len10, loss:-84.0953, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5488405227661133 sec\n",
      "Episode 1294, len6, loss:-75.2990, fail, steps:80, opt steps:3, total reward:-25.4000, 0.540457010269165 sec\n",
      "Episode 1295, len8, loss:-65.0210, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5477132797241211 sec\n",
      "Episode 1296, len12, loss:-101.4090, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5492475032806396 sec\n",
      "Episode 1297, len6, loss:-67.1176, fail, steps:80, opt steps:11, total reward:-24.1000, 0.5363707542419434 sec\n",
      "Episode 1298, len12, loss:-99.2355, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5483384132385254 sec\n",
      "Episode 1299, len8, loss:-67.9414, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5439867973327637 sec\n",
      "Episode 1300, len8, loss:-71.2076, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5453388690948486 sec\n",
      "Episode 1301, len12, loss:-95.2423, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5493011474609375 sec\n",
      "Episode 1302, len12, loss:-104.4205, fail, steps:80, opt steps:30, total reward:-24.7000, 0.544628381729126 sec\n",
      "Episode 1303, len8, loss:-61.9009, fail, steps:80, opt steps:32, total reward:-23.1000, 0.5368776321411133 sec\n",
      "Episode 1304, len10, loss:-94.0017, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5441303253173828 sec\n",
      "Episode 1305, len12, loss:-96.4438, fail, steps:80, opt steps:46, total reward:-24.7000, 0.5934584140777588 sec\n",
      "Episode 1306, len6, loss:-65.1514, fail, steps:80, opt steps:10, total reward:-23.4000, 0.5397529602050781 sec\n",
      "Episode 1307, len12, loss:-93.3333, fail, steps:80, opt steps:26, total reward:-24.0000, 0.548961877822876 sec\n",
      "Episode 1308, len8, loss:-67.4878, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5451362133026123 sec\n",
      "Episode 1309, len6, loss:-65.3196, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5491275787353516 sec\n",
      "Episode 1310, len12, loss:-96.6751, fail, steps:80, opt steps:48, total reward:-24.7000, 0.5460467338562012 sec\n",
      "Episode 1311, len12, loss:-105.6391, fail, steps:80, opt steps:59, total reward:-25.4000, 0.5410981178283691 sec\n",
      "Episode 1312, len12, loss:-95.2625, fail, steps:80, opt steps:69, total reward:-24.0000, 0.5487744808197021 sec\n",
      "Episode 1313, len12, loss:-84.9607, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5482416152954102 sec\n",
      "Episode 1314, len10, loss:-81.6907, fail, steps:80, opt steps:39, total reward:-24.0000, 0.549713134765625 sec\n",
      "Episode 1315, len6, loss:-62.5574, fail, steps:80, opt steps:10, total reward:-24.0000, 0.549541711807251 sec\n",
      "Episode 1316, len10, loss:-81.4361, fail, steps:80, opt steps:33, total reward:-23.7000, 0.5455279350280762 sec\n",
      "Episode 1317, len10, loss:-94.6191, fail, steps:80, opt steps:33, total reward:-24.7000, 0.5449471473693848 sec\n",
      "Episode 1318, len10, loss:-83.8887, fail, steps:80, opt steps:45, total reward:-23.7000, 0.5444743633270264 sec\n",
      "Episode 1319, len12, loss:-93.9532, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5490844249725342 sec\n",
      "Episode 1320, len8, loss:-70.9928, fail, steps:80, opt steps:19, total reward:-25.1000, 0.5372536182403564 sec\n",
      "Episode 1321, len6, loss:-59.0807, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5987353324890137 sec\n",
      "Episode 1322, len6, loss:-61.0858, fail, steps:80, opt steps:21, total reward:-23.7000, 0.5453310012817383 sec\n",
      "Episode 1323, len8, loss:-54.1970, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5497817993164062 sec\n",
      "Episode 1324, len8, loss:-67.3301, fail, steps:80, opt steps:28, total reward:-24.0000, 0.550119161605835 sec\n",
      "Episode 1325, len8, loss:-59.9679, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5457446575164795 sec\n",
      "Episode 1326, len8, loss:-47.9079, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5495586395263672 sec\n",
      "Episode 1327, len6, loss:-64.5174, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5488858222961426 sec\n",
      "Episode 1328, len12, loss:-92.9547, fail, steps:80, opt steps:36, total reward:-24.7000, 0.545424222946167 sec\n",
      "Episode 1329, len12, loss:-100.3578, fail, steps:80, opt steps:50, total reward:-24.7000, 0.5455045700073242 sec\n",
      "Episode 1330, len10, loss:-91.5356, fail, steps:80, opt steps:20, total reward:-25.4000, 0.5418744087219238 sec\n",
      "Episode 1331, len6, loss:-61.8710, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5492792129516602 sec\n",
      "Episode 1332, len10, loss:-87.8610, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5518479347229004 sec\n",
      "Episode 1333, len8, loss:-73.9305, fail, steps:80, opt steps:23, total reward:-25.4000, 0.5406525135040283 sec\n",
      "Episode 1334, len10, loss:-88.0845, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5986189842224121 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1335, len6, loss:-68.7783, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5442345142364502 sec\n",
      "Episode 1336, len8, loss:-61.8076, fail, steps:80, opt steps:24, total reward:-23.7000, 0.5445282459259033 sec\n",
      "Episode 1337, len12, loss:-103.7564, fail, steps:80, opt steps:76, total reward:-24.0000, 0.5487513542175293 sec\n",
      "Episode 1338, len8, loss:-69.0964, fail, steps:80, opt steps:27, total reward:-24.4000, 0.5413968563079834 sec\n",
      "Episode 1339, len10, loss:-93.1211, fail, steps:80, opt steps:20, total reward:-24.4000, 0.5419402122497559 sec\n",
      "Episode 1340, len12, loss:-105.0518, fail, steps:80, opt steps:65, total reward:-24.7000, 0.5434587001800537 sec\n",
      "Episode 1341, len10, loss:-83.6692, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5480930805206299 sec\n",
      "Episode 1342, len8, loss:-66.2174, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548154354095459 sec\n",
      "Episode 1343, len6, loss:-75.9843, fail, steps:80, opt steps:12, total reward:-25.4000, 0.5411214828491211 sec\n",
      "Episode 1344, len6, loss:-55.2242, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5481843948364258 sec\n",
      "Episode 1345, len12, loss:-98.2058, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5484673976898193 sec\n",
      "Episode 1346, len8, loss:-84.0176, fail, steps:80, opt steps:14, total reward:-25.4000, 0.5406954288482666 sec\n",
      "Episode 1347, len6, loss:-56.4896, fail, steps:80, opt steps:19, total reward:-23.7000, 0.5425631999969482 sec\n",
      "Episode 1348, len6, loss:-46.1409, fail, steps:80, opt steps:11, total reward:-22.7000, 0.6010708808898926 sec\n",
      "Episode 1349, len10, loss:-92.5067, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5487406253814697 sec\n",
      "Episode 1350, len12, loss:-104.6274, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5487070083618164 sec\n",
      "Episode 1351, len12, loss:-106.9698, fail, steps:80, opt steps:64, total reward:-23.7000, 0.5436241626739502 sec\n",
      "Episode 1352, len10, loss:-101.1597, fail, steps:80, opt steps:34, total reward:-24.7000, 0.5439910888671875 sec\n",
      "Episode 1353, len8, loss:-84.7718, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5442075729370117 sec\n",
      "Episode 1354, len6, loss:-61.0018, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5487565994262695 sec\n",
      "Episode 1355, len12, loss:-115.2192, fail, steps:80, opt steps:63, total reward:-25.4000, 0.5395591259002686 sec\n",
      "Episode 1356, len12, loss:-112.2852, fail, steps:80, opt steps:34, total reward:-25.4000, 0.5404136180877686 sec\n",
      "Episode 1357, len6, loss:-67.0102, fail, steps:80, opt steps:7, total reward:-24.4000, 0.5385837554931641 sec\n",
      "Episode 1358, len8, loss:-84.5805, fail, steps:80, opt steps:21, total reward:-25.4000, 0.5383000373840332 sec\n",
      "Episode 1359, len6, loss:-60.6178, fail, steps:80, opt steps:20, total reward:-23.7000, 0.5434169769287109 sec\n",
      "Episode 1360, len6, loss:-53.5079, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5478014945983887 sec\n",
      "Episode 1361, len8, loss:-71.3880, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5482118129730225 sec\n",
      "Episode 1362, len10, loss:-97.5266, fail, steps:80, opt steps:40, total reward:-24.0000, 0.6033010482788086 sec\n",
      "Episode 1363, len6, loss:-50.6591, fail, steps:80, opt steps:12, total reward:-23.4000, 0.5387623310089111 sec\n",
      "Episode 1364, len10, loss:-85.7720, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5492885112762451 sec\n",
      "Episode 1365, len12, loss:-98.6395, fail, steps:80, opt steps:34, total reward:-24.7000, 0.5434021949768066 sec\n",
      "Episode 1366, len12, loss:-98.6307, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5484607219696045 sec\n",
      "Episode 1367, len12, loss:-107.8819, fail, steps:80, opt steps:29, total reward:-24.4000, 0.5389769077301025 sec\n",
      "Episode 1368, len10, loss:-86.2189, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5499062538146973 sec\n",
      "Episode 1369, len12, loss:-102.7439, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5493521690368652 sec\n",
      "Episode 1370, len6, loss:-56.4082, fail, steps:80, opt steps:8, total reward:-22.7000, 0.5447900295257568 sec\n",
      "Episode 1371, len10, loss:-90.5327, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5502703189849854 sec\n",
      "Episode 1372, len10, loss:-102.9671, fail, steps:80, opt steps:45, total reward:-26.1000, 0.5366060733795166 sec\n",
      "Episode 1373, len12, loss:-97.2200, fail, steps:80, opt steps:38, total reward:-24.0000, 0.548504114151001 sec\n",
      "Episode 1374, len6, loss:-60.7257, fail, steps:80, opt steps:16, total reward:-24.4000, 0.5420362949371338 sec\n",
      "Episode 1375, len8, loss:-71.8163, fail, steps:80, opt steps:4, total reward:-24.7000, 0.5444245338439941 sec\n",
      "Episode 1376, len10, loss:-83.1737, fail, steps:80, opt steps:35, total reward:-22.7000, 0.597510814666748 sec\n",
      "Episode 1377, len8, loss:-80.7255, fail, steps:80, opt steps:8, total reward:-25.4000, 0.5406002998352051 sec\n",
      "Episode 1378, len12, loss:-104.4744, fail, steps:80, opt steps:42, total reward:-24.0000, 0.548407793045044 sec\n",
      "Episode 1379, len6, loss:-59.9175, fail, steps:80, opt steps:7, total reward:-24.0000, 0.548459529876709 sec\n",
      "Episode 1380, len6, loss:-61.7378, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5495538711547852 sec\n",
      "Episode 1381, len10, loss:-93.3568, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5495407581329346 sec\n",
      "Episode 1382, len10, loss:-89.9379, fail, steps:80, opt steps:38, total reward:-24.0000, 0.549475908279419 sec\n",
      "Episode 1383, len12, loss:-103.6788, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5498554706573486 sec\n",
      "Episode 1384, len8, loss:-70.4393, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5492546558380127 sec\n",
      "Episode 1385, len10, loss:-89.0857, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5501689910888672 sec\n",
      "Episode 1386, len12, loss:-97.8073, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5527567863464355 sec\n",
      "Episode 1387, len8, loss:-66.1764, fail, steps:80, opt steps:13, total reward:-23.4000, 0.5409772396087646 sec\n",
      "Episode 1388, len8, loss:-85.7605, fail, steps:80, opt steps:25, total reward:-25.4000, 0.5411441326141357 sec\n",
      "Episode 1389, len10, loss:-96.4168, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5504860877990723 sec\n",
      "Episode 1390, len12, loss:-100.3066, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5995278358459473 sec\n",
      "Episode 1391, len6, loss:-71.6967, fail, steps:80, opt steps:15, total reward:-25.1000, 0.5363116264343262 sec\n",
      "Episode 1392, len10, loss:-105.8467, fail, steps:80, opt steps:46, total reward:-25.4000, 0.5390341281890869 sec\n",
      "Episode 1393, len12, loss:-109.5652, fail, steps:80, opt steps:41, total reward:-25.4000, 0.5403175354003906 sec\n",
      "Episode 1394, len6, loss:-60.6892, fail, steps:80, opt steps:10, total reward:-22.7000, 0.5443646907806396 sec\n",
      "Episode 1395, len12, loss:-110.7241, fail, steps:80, opt steps:35, total reward:-24.7000, 0.5451071262359619 sec\n",
      "Episode 1396, len6, loss:-63.5734, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5446088314056396 sec\n",
      "Episode 1397, len8, loss:-69.3162, fail, steps:80, opt steps:32, total reward:-22.7000, 0.5453436374664307 sec\n",
      "Episode 1398, len12, loss:-107.8536, fail, steps:80, opt steps:58, total reward:-24.7000, 0.5467643737792969 sec\n",
      "Episode 1399, len10, loss:-94.7315, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5451154708862305 sec\n",
      "Episode 1400, len6, loss:-58.9579, fail, steps:80, opt steps:13, total reward:-24.4000, 0.5401666164398193 sec\n",
      "Episode 1401, len10, loss:-94.7150, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5471906661987305 sec\n",
      "Episode 1402, len8, loss:-70.1286, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5490195751190186 sec\n",
      "Episode 1403, len6, loss:-69.5255, fail, steps:80, opt steps:16, total reward:-24.1000, 0.5361309051513672 sec\n",
      "Episode 1404, len12, loss:-110.6665, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5472097396850586 sec\n",
      "Episode 1405, len6, loss:-57.9506, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5974886417388916 sec\n",
      "Episode 1406, len12, loss:-101.7568, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5486352443695068 sec\n",
      "Episode 1407, len12, loss:-107.3927, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5457563400268555 sec\n",
      "Episode 1408, len8, loss:-83.2353, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5446946620941162 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1409, len6, loss:-70.5881, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5437393188476562 sec\n",
      "Episode 1410, len12, loss:-102.1442, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5453534126281738 sec\n",
      "Episode 1411, len6, loss:-62.6434, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5486721992492676 sec\n",
      "Episode 1412, len12, loss:-107.1742, fail, steps:80, opt steps:69, total reward:-24.7000, 0.5457272529602051 sec\n",
      "Episode 1413, len10, loss:-96.4279, fail, steps:80, opt steps:22, total reward:-24.7000, 0.545598030090332 sec\n",
      "Episode 1414, len8, loss:-81.0916, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5474824905395508 sec\n",
      "Episode 1415, len12, loss:-109.7666, fail, steps:80, opt steps:31, total reward:-24.7000, 0.5444245338439941 sec\n",
      "Episode 1416, len10, loss:-83.8131, fail, steps:80, opt steps:45, total reward:-23.7000, 0.5442728996276855 sec\n",
      "Episode 1417, len12, loss:-107.9536, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5449409484863281 sec\n",
      "Episode 1418, len6, loss:-62.2699, fail, steps:80, opt steps:15, total reward:-24.7000, 0.545586347579956 sec\n",
      "Episode 1419, len10, loss:-87.9002, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5507118701934814 sec\n",
      "Episode 1420, len10, loss:-94.1465, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5482001304626465 sec\n",
      "Episode 1421, len8, loss:-69.5079, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5996851921081543 sec\n",
      "Episode 1422, len10, loss:-89.5359, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5503430366516113 sec\n",
      "Episode 1423, len10, loss:-94.4814, fail, steps:80, opt steps:37, total reward:-23.7000, 0.5457303524017334 sec\n",
      "Episode 1424, len8, loss:-87.0624, fail, steps:80, opt steps:11, total reward:-26.1000, 0.53818678855896 sec\n",
      "Episode 1425, len6, loss:-61.4920, fail, steps:80, opt steps:15, total reward:-23.7000, 0.5448672771453857 sec\n",
      "Episode 1426, len8, loss:-70.8029, fail, steps:80, opt steps:28, total reward:-24.0000, 0.549518346786499 sec\n",
      "Episode 1427, len6, loss:-71.5484, fail, steps:80, opt steps:11, total reward:-25.4000, 0.5408778190612793 sec\n",
      "Episode 1428, len12, loss:-111.3668, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5448727607727051 sec\n",
      "Episode 1429, len8, loss:-78.4547, fail, steps:80, opt steps:25, total reward:-24.7000, 0.543914794921875 sec\n",
      "Episode 1430, len10, loss:-95.8839, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5447568893432617 sec\n",
      "Episode 1431, len6, loss:-124.6310, fail, steps:76, opt steps:18, total reward:-33.5000, 0.5191116333007812 sec\n",
      "Episode 1432, len12, loss:-100.4957, fail, steps:80, opt steps:38, total reward:-23.7000, 0.5429224967956543 sec\n",
      "Episode 1433, len12, loss:-105.9199, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5493438243865967 sec\n",
      "Episode 1434, len8, loss:-73.4438, fail, steps:80, opt steps:18, total reward:-23.4000, 0.5411505699157715 sec\n",
      "Episode 1435, len8, loss:-73.4765, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5488936901092529 sec\n",
      "Episode 1436, len10, loss:-97.1632, fail, steps:80, opt steps:21, total reward:-25.4000, 0.5404548645019531 sec\n",
      "Episode 1437, len10, loss:-88.3981, fail, steps:80, opt steps:24, total reward:-23.1000, 0.5366060733795166 sec\n",
      "Episode 1438, len12, loss:-107.7741, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5984129905700684 sec\n",
      "Episode 1439, len12, loss:-104.0462, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5517964363098145 sec\n",
      "Episode 1440, len6, loss:-72.5816, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5461373329162598 sec\n",
      "Episode 1441, len12, loss:-109.8836, fail, steps:80, opt steps:45, total reward:-24.0000, 0.549081563949585 sec\n",
      "Episode 1442, len12, loss:-35.9047, fail, steps:0, opt steps:37, total reward:-10.0000, 0.021702051162719727 sec\n",
      "Episode 1443, len8, loss:-61.0147, fail, steps:80, opt steps:25, total reward:-22.7000, 0.48771071434020996 sec\n",
      "Episode 1444, len12, loss:-105.2463, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5247459411621094 sec\n",
      "Episode 1445, len8, loss:-81.7672, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5299191474914551 sec\n",
      "Episode 1446, len12, loss:-100.8348, fail, steps:80, opt steps:35, total reward:-23.7000, 0.5348975658416748 sec\n",
      "Episode 1447, len8, loss:-69.0793, fail, steps:80, opt steps:19, total reward:-24.0000, 0.54361891746521 sec\n",
      "Episode 1448, len12, loss:-108.0678, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5448741912841797 sec\n",
      "Episode 1449, len12, loss:-99.6374, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5444414615631104 sec\n",
      "Episode 1450, len12, loss:-103.3782, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5481677055358887 sec\n",
      "Episode 1451, len10, loss:-89.4402, fail, steps:80, opt steps:55, total reward:-22.7000, 0.5447323322296143 sec\n",
      "Episode 1452, len6, loss:-55.8171, fail, steps:80, opt steps:11, total reward:-24.0000, 0.6029524803161621 sec\n",
      "Episode 1453, len12, loss:-36.5130, fail, steps:0, opt steps:55, total reward:-10.0000, 0.022162437438964844 sec\n",
      "Episode 1454, len12, loss:-117.1026, fail, steps:80, opt steps:53, total reward:-24.7000, 0.4878573417663574 sec\n",
      "Episode 1455, len10, loss:-107.5042, fail, steps:80, opt steps:48, total reward:-25.4000, 0.5163733959197998 sec\n",
      "Episode 1456, len10, loss:-82.6923, fail, steps:80, opt steps:39, total reward:-22.7000, 0.5291709899902344 sec\n",
      "Episode 1457, len6, loss:-57.3472, fail, steps:80, opt steps:13, total reward:-23.7000, 0.5371580123901367 sec\n",
      "Episode 1458, len12, loss:-106.0474, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5444564819335938 sec\n",
      "Episode 1459, len12, loss:-104.4244, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5457272529602051 sec\n",
      "Episode 1460, len8, loss:-71.0531, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5464859008789062 sec\n",
      "Episode 1461, len8, loss:-72.2289, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5475590229034424 sec\n",
      "Episode 1462, len10, loss:-98.2511, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5441992282867432 sec\n",
      "Episode 1463, len12, loss:-100.0206, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5483288764953613 sec\n",
      "Episode 1464, len8, loss:-72.8357, fail, steps:80, opt steps:19, total reward:-24.1000, 0.5354604721069336 sec\n",
      "Episode 1465, len12, loss:-110.6319, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5436103343963623 sec\n",
      "Episode 1466, len8, loss:-82.7921, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5461888313293457 sec\n",
      "Episode 1467, len12, loss:-106.5533, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5968680381774902 sec\n",
      "Episode 1468, len10, loss:-89.3493, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5490505695343018 sec\n",
      "Episode 1469, len8, loss:-71.1432, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5483412742614746 sec\n",
      "Episode 1470, len8, loss:-67.4843, fail, steps:80, opt steps:25, total reward:-24.0000, 0.549910306930542 sec\n",
      "Episode 1471, len10, loss:-96.2322, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5459086894989014 sec\n",
      "Episode 1472, len8, loss:-76.9352, fail, steps:80, opt steps:13, total reward:-23.7000, 0.5446903705596924 sec\n",
      "Episode 1473, len8, loss:-75.5180, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5444695949554443 sec\n",
      "Episode 1474, len6, loss:-64.4052, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5489258766174316 sec\n",
      "Episode 1475, len12, loss:-99.6717, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5491225719451904 sec\n",
      "Episode 1476, len6, loss:-73.3833, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5453071594238281 sec\n",
      "Episode 1477, len8, loss:-60.5331, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5486540794372559 sec\n",
      "Episode 1478, len6, loss:-68.3027, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5503008365631104 sec\n",
      "Episode 1479, len8, loss:-52.7894, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5492134094238281 sec\n",
      "Episode 1480, len12, loss:-101.0087, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5496294498443604 sec\n",
      "Episode 1481, len8, loss:-36.1327, fail, steps:0, opt steps:24, total reward:-10.0000, 0.021806716918945312 sec\n",
      "Episode 1482, len10, loss:-95.6006, fail, steps:80, opt steps:41, total reward:-25.4000, 0.5340750217437744 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1483, len6, loss:-59.7674, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5229945182800293 sec\n",
      "Episode 1484, len6, loss:-63.9955, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5340213775634766 sec\n",
      "Episode 1485, len6, loss:-61.8251, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5388154983520508 sec\n",
      "Episode 1486, len12, loss:-97.8794, fail, steps:80, opt steps:59, total reward:-23.7000, 0.5398647785186768 sec\n",
      "Episode 1487, len12, loss:-107.3471, fail, steps:80, opt steps:44, total reward:-24.7000, 0.540496826171875 sec\n",
      "Episode 1488, len8, loss:-56.3663, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5475120544433594 sec\n",
      "Episode 1489, len6, loss:-60.4776, fail, steps:80, opt steps:18, total reward:-24.4000, 0.5391240119934082 sec\n",
      "Episode 1490, len6, loss:-67.7273, fail, steps:80, opt steps:8, total reward:-24.4000, 0.5379981994628906 sec\n",
      "Episode 1491, len8, loss:-61.9440, fail, steps:80, opt steps:24, total reward:-23.4000, 0.5372014045715332 sec\n",
      "Episode 1492, len12, loss:-97.4612, fail, steps:80, opt steps:68, total reward:-24.0000, 0.5461184978485107 sec\n",
      "Episode 1493, len10, loss:-81.8133, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5484189987182617 sec\n",
      "Episode 1494, len10, loss:-95.5232, fail, steps:80, opt steps:36, total reward:-25.4000, 0.5392594337463379 sec\n",
      "Episode 1495, len12, loss:-94.2135, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5476856231689453 sec\n",
      "Episode 1496, len12, loss:-94.7018, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5985150337219238 sec\n",
      "Episode 1497, len12, loss:-99.2177, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5480821132659912 sec\n",
      "Episode 1498, len8, loss:-49.1893, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5486366748809814 sec\n",
      "Episode 1499, len10, loss:-81.6185, fail, steps:80, opt steps:47, total reward:-24.7000, 0.5429959297180176 sec\n",
      "Episode 1500, len8, loss:-66.0263, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5429384708404541 sec\n",
      "Episode 1501, len8, loss:-66.3452, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5430855751037598 sec\n",
      "Episode 1502, len10, loss:-89.1740, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5480034351348877 sec\n",
      "Episode 1503, len6, loss:-58.4588, fail, steps:80, opt steps:11, total reward:-23.7000, 0.5438544750213623 sec\n",
      "Episode 1504, len6, loss:-59.1326, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5478551387786865 sec\n",
      "Episode 1505, len12, loss:-106.8195, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5444238185882568 sec\n",
      "Episode 1506, len6, loss:-64.4340, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5447895526885986 sec\n",
      "Episode 1507, len10, loss:-92.4100, fail, steps:80, opt steps:43, total reward:-24.7000, 0.5451292991638184 sec\n",
      "Episode 1508, len12, loss:-101.9785, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5476601123809814 sec\n",
      "Episode 1509, len12, loss:-95.9355, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5496914386749268 sec\n",
      "Episode 1510, len12, loss:-106.3670, fail, steps:80, opt steps:60, total reward:-24.8000, 0.5817108154296875 sec\n",
      "Episode 1511, len6, loss:-63.1501, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5484786033630371 sec\n",
      "Episode 1512, len6, loss:-51.4804, fail, steps:80, opt steps:15, total reward:-22.7000, 0.5438776016235352 sec\n",
      "Episode 1513, len8, loss:-62.7130, fail, steps:80, opt steps:28, total reward:-24.4000, 0.5412733554840088 sec\n",
      "Episode 1514, len12, loss:-99.6132, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5444395542144775 sec\n",
      "Episode 1515, len10, loss:-92.8659, fail, steps:80, opt steps:32, total reward:-24.4000, 0.5389471054077148 sec\n",
      "Episode 1516, len8, loss:-66.5869, fail, steps:80, opt steps:17, total reward:-23.7000, 0.5432851314544678 sec\n",
      "Episode 1517, len10, loss:-95.4669, fail, steps:80, opt steps:36, total reward:-24.7000, 0.543581485748291 sec\n",
      "Episode 1518, len6, loss:-76.9166, fail, steps:80, opt steps:7, total reward:-24.7000, 0.544053316116333 sec\n",
      "Episode 1519, len8, loss:-57.2542, fail, steps:80, opt steps:26, total reward:-24.0000, 0.547621488571167 sec\n",
      "Episode 1520, len10, loss:-81.7766, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5494635105133057 sec\n",
      "Episode 1521, len8, loss:-61.1751, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5492353439331055 sec\n",
      "Episode 1522, len10, loss:-93.4155, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5477428436279297 sec\n",
      "Episode 1523, len10, loss:-81.0319, fail, steps:80, opt steps:35, total reward:-22.7000, 0.5446851253509521 sec\n",
      "Episode 1524, len10, loss:-90.0790, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5495834350585938 sec\n",
      "Episode 1525, len10, loss:-91.4574, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5952589511871338 sec\n",
      "Episode 1526, len8, loss:-60.5054, fail, steps:80, opt steps:36, total reward:-24.7000, 0.543917179107666 sec\n",
      "Episode 1527, len6, loss:-73.4758, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5464076995849609 sec\n",
      "Episode 1528, len10, loss:-88.0982, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5501346588134766 sec\n",
      "Episode 1529, len10, loss:-83.7269, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5494670867919922 sec\n",
      "Episode 1530, len10, loss:-86.3718, fail, steps:80, opt steps:28, total reward:-24.0000, 0.550626277923584 sec\n",
      "Episode 1531, len10, loss:-97.9373, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5458540916442871 sec\n",
      "Episode 1532, len10, loss:-87.5864, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5489518642425537 sec\n",
      "Episode 1533, len10, loss:-82.0072, fail, steps:80, opt steps:41, total reward:-22.7000, 0.5453293323516846 sec\n",
      "Episode 1534, len6, loss:-70.8805, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5489029884338379 sec\n",
      "Episode 1535, len8, loss:-62.9580, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5526134967803955 sec\n",
      "Episode 1536, len12, loss:-93.4278, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5515737533569336 sec\n",
      "Episode 1537, len8, loss:-62.7322, fail, steps:80, opt steps:16, total reward:-24.4000, 0.5398859977722168 sec\n",
      "Episode 1538, len12, loss:-90.7735, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5491514205932617 sec\n",
      "Episode 1539, len12, loss:-111.5222, fail, steps:80, opt steps:61, total reward:-24.7000, 0.5446817874908447 sec\n",
      "Episode 1540, len10, loss:-74.5548, fail, steps:80, opt steps:34, total reward:-22.7000, 0.5431525707244873 sec\n",
      "Episode 1541, len12, loss:-102.0345, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5923962593078613 sec\n",
      "Episode 1542, len12, loss:-102.0868, fail, steps:80, opt steps:57, total reward:-25.4000, 0.5404949188232422 sec\n",
      "Episode 1543, len8, loss:-60.0134, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5431203842163086 sec\n",
      "Episode 1544, len6, loss:-36.8937, fail, steps:0, opt steps:3, total reward:-10.0000, 0.021753787994384766 sec\n",
      "Episode 1545, len8, loss:-88.1521, fail, steps:80, opt steps:24, total reward:-26.1000, 0.4792134761810303 sec\n",
      "Episode 1546, len10, loss:-85.1096, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5243782997131348 sec\n",
      "Episode 1547, len6, loss:-67.9795, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5342695713043213 sec\n",
      "Episode 1548, len12, loss:-97.5797, fail, steps:80, opt steps:39, total reward:-25.4000, 0.529801607131958 sec\n",
      "Episode 1549, len12, loss:-90.4095, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5430009365081787 sec\n",
      "Episode 1550, len12, loss:-97.5873, fail, steps:80, opt steps:31, total reward:-24.7000, 0.5392985343933105 sec\n",
      "Episode 1551, len12, loss:-102.0968, fail, steps:80, opt steps:67, total reward:-24.7000, 0.5399966239929199 sec\n",
      "Episode 1552, len8, loss:-58.0628, fail, steps:80, opt steps:11, total reward:-24.7000, 0.541128396987915 sec\n",
      "Episode 1553, len12, loss:-89.6819, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5482535362243652 sec\n",
      "Episode 1554, len10, loss:-84.8058, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5470366477966309 sec\n",
      "Episode 1555, len12, loss:-103.8497, fail, steps:80, opt steps:59, total reward:-24.7000, 0.542633056640625 sec\n",
      "Episode 1556, len12, loss:-92.9800, fail, steps:80, opt steps:55, total reward:-24.0000, 0.546576976776123 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1557, len12, loss:-102.1441, fail, steps:80, opt steps:60, total reward:-24.7000, 0.5442295074462891 sec\n",
      "Episode 1558, len10, loss:-90.9856, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5973389148712158 sec\n",
      "Episode 1559, len10, loss:-84.7873, fail, steps:80, opt steps:13, total reward:-24.0000, 0.546980619430542 sec\n",
      "Episode 1560, len8, loss:-60.7817, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5476295948028564 sec\n",
      "Episode 1561, len6, loss:-73.2981, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5474996566772461 sec\n",
      "Episode 1562, len8, loss:-55.6249, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5488355159759521 sec\n",
      "Episode 1563, len8, loss:-53.7373, fail, steps:80, opt steps:24, total reward:-24.0000, 0.548436164855957 sec\n",
      "Episode 1564, len8, loss:-57.8763, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5472605228424072 sec\n",
      "Episode 1565, len12, loss:-91.1276, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5487253665924072 sec\n",
      "Episode 1566, len6, loss:-71.7267, fail, steps:80, opt steps:16, total reward:-23.4000, 0.5387496948242188 sec\n",
      "Episode 1567, len10, loss:-82.6867, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5469026565551758 sec\n",
      "Episode 1568, len10, loss:-91.0419, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5475320816040039 sec\n",
      "Episode 1569, len10, loss:-82.8844, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5468389987945557 sec\n",
      "Episode 1570, len10, loss:-96.6646, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5442521572113037 sec\n",
      "Episode 1571, len6, loss:-81.5468, fail, steps:80, opt steps:13, total reward:-24.7000, 0.6024453639984131 sec\n",
      "Episode 1572, len6, loss:-6.4315, succeed, steps:38, opt steps:5, total reward:-10.8100, 0.2665102481842041 sec\n",
      "Episode 1573, len6, loss:-85.4754, fail, steps:80, opt steps:17, total reward:-25.4000, 0.5135624408721924 sec\n",
      "Episode 1574, len10, loss:-89.4521, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5357422828674316 sec\n",
      "Episode 1575, len6, loss:-75.3829, fail, steps:80, opt steps:13, total reward:-24.0000, 0.542036771774292 sec\n",
      "Episode 1576, len12, loss:-104.9381, fail, steps:80, opt steps:34, total reward:-23.7000, 0.5397334098815918 sec\n",
      "Episode 1577, len8, loss:-71.5953, fail, steps:80, opt steps:9, total reward:-24.0000, 0.545867919921875 sec\n",
      "Episode 1578, len12, loss:-97.7142, fail, steps:80, opt steps:57, total reward:-23.7000, 0.5430383682250977 sec\n",
      "Episode 1579, len10, loss:-91.8031, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5479404926300049 sec\n",
      "Episode 1580, len6, loss:-73.9052, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5481407642364502 sec\n",
      "Episode 1581, len8, loss:-67.1627, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5465688705444336 sec\n",
      "Episode 1582, len10, loss:-99.4037, fail, steps:80, opt steps:36, total reward:-24.7000, 0.5444700717926025 sec\n",
      "Episode 1583, len10, loss:-82.3460, fail, steps:80, opt steps:21, total reward:-23.7000, 0.5421185493469238 sec\n",
      "Episode 1584, len12, loss:-103.5690, fail, steps:80, opt steps:40, total reward:-23.7000, 0.5438907146453857 sec\n",
      "Episode 1585, len6, loss:-74.5477, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5482392311096191 sec\n",
      "Episode 1586, len12, loss:-108.7244, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5476851463317871 sec\n",
      "Episode 1587, len12, loss:-103.7599, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5496346950531006 sec\n",
      "Episode 1588, len6, loss:-78.6967, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5945854187011719 sec\n",
      "Episode 1589, len8, loss:-74.6425, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5488629341125488 sec\n",
      "Episode 1590, len6, loss:-72.7881, fail, steps:80, opt steps:13, total reward:-24.0000, 0.547553300857544 sec\n",
      "Episode 1591, len6, loss:-71.9503, fail, steps:80, opt steps:5, total reward:-23.4000, 0.5406057834625244 sec\n",
      "Episode 1592, len6, loss:-77.9783, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5437040328979492 sec\n",
      "Episode 1593, len8, loss:-67.6431, fail, steps:80, opt steps:9, total reward:-23.4000, 0.5395984649658203 sec\n",
      "Episode 1594, len6, loss:-73.1224, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5487926006317139 sec\n",
      "Episode 1595, len8, loss:-75.2937, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5470376014709473 sec\n",
      "Episode 1596, len10, loss:-96.0497, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5481536388397217 sec\n",
      "Episode 1597, len10, loss:-95.2814, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5490777492523193 sec\n",
      "Episode 1598, len12, loss:-105.7327, fail, steps:80, opt steps:42, total reward:-23.4000, 0.5415358543395996 sec\n",
      "Episode 1599, len12, loss:-105.1533, fail, steps:80, opt steps:51, total reward:-24.0000, 0.549100399017334 sec\n",
      "Episode 1600, len6, loss:-71.9830, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5497016906738281 sec\n",
      "Episode 1601, len6, loss:-72.8720, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5500321388244629 sec\n",
      "Episode 1602, len8, loss:-79.7982, fail, steps:80, opt steps:22, total reward:-23.7000, 0.5460643768310547 sec\n",
      "Episode 1603, len6, loss:-66.8072, fail, steps:80, opt steps:16, total reward:-22.7000, 0.5467514991760254 sec\n",
      "Episode 1604, len10, loss:-108.4796, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5954351425170898 sec\n",
      "Episode 1605, len6, loss:-71.1380, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5494258403778076 sec\n",
      "Episode 1606, len6, loss:-63.8973, fail, steps:80, opt steps:14, total reward:-22.7000, 0.5444388389587402 sec\n",
      "Episode 1607, len6, loss:-68.3343, fail, steps:80, opt steps:21, total reward:-23.4000, 0.5407819747924805 sec\n",
      "Episode 1608, len8, loss:-72.0536, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5442526340484619 sec\n",
      "Episode 1609, len8, loss:-76.5394, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5486414432525635 sec\n",
      "Episode 1610, len8, loss:-67.8627, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5480248928070068 sec\n",
      "Episode 1611, len10, loss:-91.6541, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5494556427001953 sec\n",
      "Episode 1612, len8, loss:-72.9735, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5489428043365479 sec\n",
      "Episode 1613, len10, loss:-90.0993, fail, steps:80, opt steps:36, total reward:-24.7000, 0.545529842376709 sec\n",
      "Episode 1614, len10, loss:-99.3433, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5444586277008057 sec\n",
      "Episode 1615, len12, loss:-99.3967, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5487444400787354 sec\n",
      "Episode 1616, len6, loss:-70.6706, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5454220771789551 sec\n",
      "Episode 1617, len8, loss:-73.7944, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5993921756744385 sec\n",
      "Episode 1618, len6, loss:-75.8390, fail, steps:80, opt steps:15, total reward:-24.7000, 0.543987512588501 sec\n",
      "Episode 1619, len10, loss:-92.8155, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5493950843811035 sec\n",
      "Episode 1620, len10, loss:-89.8630, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5464413166046143 sec\n",
      "Episode 1621, len12, loss:-101.8153, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5487961769104004 sec\n",
      "Episode 1622, len10, loss:-85.3202, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5487136840820312 sec\n",
      "Episode 1623, len8, loss:-69.8825, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5484466552734375 sec\n",
      "Episode 1624, len12, loss:-102.8748, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5507087707519531 sec\n",
      "Episode 1625, len12, loss:-113.2433, fail, steps:80, opt steps:55, total reward:-24.7000, 0.5447971820831299 sec\n",
      "Episode 1626, len12, loss:-102.2868, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5484714508056641 sec\n",
      "Episode 1627, len8, loss:-62.9005, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5486986637115479 sec\n",
      "Episode 1628, len10, loss:-99.4367, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5444433689117432 sec\n",
      "Episode 1629, len12, loss:-107.5171, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5504360198974609 sec\n",
      "Episode 1630, len6, loss:-77.9262, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5435659885406494 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1631, len10, loss:-91.1638, fail, steps:80, opt steps:30, total reward:-24.0000, 0.601006031036377 sec\n",
      "Episode 1632, len6, loss:-67.8234, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5495343208312988 sec\n",
      "Episode 1633, len6, loss:-73.6884, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5484218597412109 sec\n",
      "Episode 1634, len6, loss:-64.9159, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5497019290924072 sec\n",
      "Episode 1635, len8, loss:-75.6653, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5496692657470703 sec\n",
      "Episode 1636, len6, loss:-72.7053, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5499916076660156 sec\n",
      "Episode 1637, len6, loss:-73.7500, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5441915988922119 sec\n",
      "Episode 1638, len8, loss:-82.5446, fail, steps:80, opt steps:23, total reward:-24.4000, 0.5414988994598389 sec\n",
      "Episode 1639, len6, loss:-69.6741, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5466184616088867 sec\n",
      "Episode 1640, len6, loss:-61.4545, fail, steps:80, opt steps:16, total reward:-22.7000, 0.5436859130859375 sec\n",
      "Episode 1641, len10, loss:-38.4964, fail, steps:0, opt steps:25, total reward:-10.0000, 0.021780729293823242 sec\n",
      "Episode 1642, len6, loss:-67.2705, fail, steps:80, opt steps:13, total reward:-24.0000, 0.49109911918640137 sec\n",
      "Episode 1643, len6, loss:-72.8918, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5194439888000488 sec\n",
      "Episode 1644, len8, loss:-66.7201, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5285544395446777 sec\n",
      "Episode 1645, len8, loss:-67.3817, fail, steps:80, opt steps:16, total reward:-24.0000, 0.538994312286377 sec\n",
      "Episode 1646, len12, loss:-105.0989, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5981664657592773 sec\n",
      "Episode 1647, len6, loss:-71.1742, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5442194938659668 sec\n",
      "Episode 1648, len6, loss:-65.7553, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5420300960540771 sec\n",
      "Episode 1649, len12, loss:-108.6534, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5455954074859619 sec\n",
      "Episode 1650, len10, loss:-97.6061, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5480060577392578 sec\n",
      "Episode 1651, len10, loss:-92.0983, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5464491844177246 sec\n",
      "Episode 1652, len12, loss:-102.1844, fail, steps:80, opt steps:62, total reward:-23.7000, 0.5431458950042725 sec\n",
      "Episode 1653, len6, loss:-75.0444, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5429751873016357 sec\n",
      "Episode 1654, len6, loss:-73.1512, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5489003658294678 sec\n",
      "Episode 1655, len10, loss:-84.0872, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5477242469787598 sec\n",
      "Episode 1656, len10, loss:-114.9794, fail, steps:80, opt steps:51, total reward:-26.1000, 0.5361301898956299 sec\n",
      "Episode 1657, len12, loss:-111.0440, fail, steps:80, opt steps:41, total reward:-24.0000, 0.547482967376709 sec\n",
      "Episode 1658, len6, loss:-71.3118, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5434198379516602 sec\n",
      "Episode 1659, len8, loss:-66.8058, fail, steps:80, opt steps:4, total reward:-24.0000, 0.548053503036499 sec\n",
      "Episode 1660, len6, loss:-67.3471, fail, steps:80, opt steps:8, total reward:-24.0000, 0.597510814666748 sec\n",
      "Episode 1661, len12, loss:-109.5984, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5490331649780273 sec\n",
      "Episode 1662, len6, loss:-69.5362, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5475122928619385 sec\n",
      "Episode 1663, len8, loss:-61.2194, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5481607913970947 sec\n",
      "Episode 1664, len10, loss:-99.8537, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5440609455108643 sec\n",
      "Episode 1665, len10, loss:-91.5599, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5485656261444092 sec\n",
      "Episode 1666, len8, loss:-72.7227, fail, steps:80, opt steps:27, total reward:-24.0000, 0.548903226852417 sec\n",
      "Episode 1667, len12, loss:-104.9194, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5469024181365967 sec\n",
      "Episode 1668, len6, loss:-78.8929, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5440261363983154 sec\n",
      "Episode 1669, len8, loss:-63.6973, fail, steps:80, opt steps:30, total reward:-24.0000, 0.547877311706543 sec\n",
      "Episode 1670, len8, loss:-71.1349, fail, steps:80, opt steps:15, total reward:-24.0000, 0.547680139541626 sec\n",
      "Episode 1671, len6, loss:-64.7216, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5480320453643799 sec\n",
      "Episode 1672, len6, loss:-66.0616, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5478026866912842 sec\n",
      "Episode 1673, len10, loss:-92.6133, fail, steps:80, opt steps:34, total reward:-24.7000, 0.5439956188201904 sec\n",
      "Episode 1674, len8, loss:-69.9017, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5959382057189941 sec\n",
      "Episode 1675, len8, loss:-133.2160, fail, steps:70, opt steps:29, total reward:-31.7000, 0.47880125045776367 sec\n",
      "Episode 1676, len6, loss:-68.5505, fail, steps:80, opt steps:17, total reward:-23.4000, 0.5336587429046631 sec\n",
      "Episode 1677, len10, loss:-93.1669, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5462770462036133 sec\n",
      "Episode 1678, len12, loss:-118.1440, fail, steps:80, opt steps:10, total reward:-25.4000, 0.5387089252471924 sec\n",
      "Episode 1679, len8, loss:-68.6258, fail, steps:80, opt steps:23, total reward:-23.7000, 0.5426695346832275 sec\n",
      "Episode 1680, len10, loss:-90.6654, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5488395690917969 sec\n",
      "Episode 1681, len12, loss:-118.4892, fail, steps:80, opt steps:57, total reward:-24.7000, 0.5448410511016846 sec\n",
      "Episode 1682, len10, loss:-99.1142, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5496499538421631 sec\n",
      "Episode 1683, len6, loss:-68.0561, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5498232841491699 sec\n",
      "Episode 1684, len8, loss:-82.6302, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5438909530639648 sec\n",
      "Episode 1685, len8, loss:-78.7550, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5482709407806396 sec\n",
      "Episode 1686, len12, loss:-106.2961, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5494811534881592 sec\n",
      "Episode 1687, len6, loss:-74.7149, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5459771156311035 sec\n",
      "Episode 1688, len12, loss:-112.2866, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5989179611206055 sec\n",
      "Episode 1689, len6, loss:-66.4625, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5489802360534668 sec\n",
      "Episode 1690, len10, loss:-101.4296, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5495865345001221 sec\n",
      "Episode 1691, len6, loss:-60.3093, fail, steps:80, opt steps:13, total reward:-22.7000, 0.5455641746520996 sec\n",
      "Episode 1692, len8, loss:-133.7457, fail, steps:50, opt steps:19, total reward:-25.4000, 0.34393930435180664 sec\n",
      "Episode 1693, len12, loss:-101.7031, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5307068824768066 sec\n",
      "Episode 1694, len8, loss:-71.1332, fail, steps:80, opt steps:36, total reward:-23.7000, 0.5389010906219482 sec\n",
      "Episode 1695, len10, loss:-89.7592, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5447447299957275 sec\n",
      "Episode 1696, len10, loss:-93.2502, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5464873313903809 sec\n",
      "Episode 1697, len10, loss:-95.1147, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5459020137786865 sec\n",
      "Episode 1698, len6, loss:-69.4577, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5429775714874268 sec\n",
      "Episode 1699, len8, loss:-68.3185, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5480287075042725 sec\n",
      "Episode 1700, len8, loss:-76.9701, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5488309860229492 sec\n",
      "Episode 1701, len12, loss:-105.4131, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5485951900482178 sec\n",
      "Episode 1702, len10, loss:-100.2718, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5500454902648926 sec\n",
      "Episode 1703, len12, loss:-110.1648, fail, steps:80, opt steps:40, total reward:-24.0000, 0.6018743515014648 sec\n",
      "Episode 1704, len12, loss:-102.1762, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5496292114257812 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1705, len8, loss:-64.1256, fail, steps:80, opt steps:22, total reward:-22.7000, 0.5463123321533203 sec\n",
      "Episode 1706, len6, loss:-70.7858, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5486764907836914 sec\n",
      "Episode 1707, len10, loss:-92.9227, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5500152111053467 sec\n",
      "Episode 1708, len8, loss:-74.1685, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5494091510772705 sec\n",
      "Episode 1709, len10, loss:-101.6481, fail, steps:80, opt steps:53, total reward:-25.4000, 0.5408010482788086 sec\n",
      "Episode 1710, len12, loss:-114.0989, fail, steps:80, opt steps:43, total reward:-24.7000, 0.5436446666717529 sec\n",
      "Episode 1711, len6, loss:-71.9279, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5487022399902344 sec\n",
      "Episode 1712, len10, loss:-96.4179, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5491864681243896 sec\n",
      "Episode 1713, len6, loss:-79.7681, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5452446937561035 sec\n",
      "Episode 1714, len12, loss:-112.8113, fail, steps:80, opt steps:61, total reward:-24.7000, 0.545992374420166 sec\n",
      "Episode 1715, len8, loss:-76.6586, fail, steps:80, opt steps:34, total reward:-24.0000, 0.549518346786499 sec\n",
      "Episode 1716, len10, loss:-97.7213, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5504050254821777 sec\n",
      "Episode 1717, len6, loss:-74.3263, fail, steps:80, opt steps:13, total reward:-24.0000, 0.6014783382415771 sec\n",
      "Episode 1718, len12, loss:-39.1851, fail, steps:0, opt steps:37, total reward:-10.0000, 0.0221097469329834 sec\n",
      "Episode 1719, len8, loss:-79.4691, fail, steps:80, opt steps:21, total reward:-24.7000, 0.48796677589416504 sec\n",
      "Episode 1720, len10, loss:-102.4535, fail, steps:80, opt steps:30, total reward:-24.4000, 0.5168933868408203 sec\n",
      "Episode 1721, len10, loss:-95.5247, fail, steps:80, opt steps:54, total reward:-23.7000, 0.5322248935699463 sec\n",
      "Episode 1722, len8, loss:-91.6585, fail, steps:80, opt steps:14, total reward:-24.7000, 0.535233736038208 sec\n",
      "Episode 1723, len12, loss:-116.9265, fail, steps:80, opt steps:61, total reward:-24.7000, 0.5388362407684326 sec\n",
      "Episode 1724, len6, loss:-67.7751, fail, steps:80, opt steps:18, total reward:-22.7000, 0.5398716926574707 sec\n",
      "Episode 1725, len6, loss:-77.2562, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5468921661376953 sec\n",
      "Episode 1726, len10, loss:-95.6772, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5473840236663818 sec\n",
      "Episode 1727, len6, loss:-79.7410, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5427348613739014 sec\n",
      "Episode 1728, len12, loss:-120.5395, fail, steps:80, opt steps:42, total reward:-25.4000, 0.5395362377166748 sec\n",
      "Episode 1729, len10, loss:-86.6347, fail, steps:80, opt steps:35, total reward:-22.7000, 0.5432956218719482 sec\n",
      "Episode 1730, len12, loss:-109.2225, fail, steps:80, opt steps:49, total reward:-22.4000, 0.5405113697052002 sec\n",
      "Episode 1731, len10, loss:-99.2132, fail, steps:80, opt steps:32, total reward:-23.7000, 0.5439300537109375 sec\n",
      "Episode 1732, len12, loss:-112.6353, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5976755619049072 sec\n",
      "Episode 1733, len8, loss:-78.8199, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5491592884063721 sec\n",
      "Episode 1734, len10, loss:-90.4000, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5488121509552002 sec\n",
      "Episode 1735, len12, loss:-116.7594, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5445852279663086 sec\n",
      "Episode 1736, len6, loss:-74.0350, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5491712093353271 sec\n",
      "Episode 1737, len12, loss:-113.7855, fail, steps:80, opt steps:46, total reward:-24.4000, 0.5400798320770264 sec\n",
      "Episode 1738, len10, loss:-96.2318, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5432567596435547 sec\n",
      "Episode 1739, len10, loss:-95.8923, fail, steps:80, opt steps:37, total reward:-23.7000, 0.5441069602966309 sec\n",
      "Episode 1740, len6, loss:-70.6273, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5487461090087891 sec\n",
      "Episode 1741, len6, loss:-77.0044, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5488171577453613 sec\n",
      "Episode 1742, len8, loss:-69.8680, fail, steps:80, opt steps:12, total reward:-24.7000, 0.5454502105712891 sec\n",
      "Episode 1743, len10, loss:-92.6549, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5501549243927002 sec\n",
      "Episode 1744, len6, loss:-81.3996, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5459556579589844 sec\n",
      "Episode 1745, len6, loss:-72.4421, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5494320392608643 sec\n",
      "Episode 1746, len8, loss:-69.7608, fail, steps:80, opt steps:28, total reward:-23.7000, 0.5937926769256592 sec\n",
      "Episode 1747, len10, loss:-97.9838, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5493865013122559 sec\n",
      "Episode 1748, len8, loss:-76.8736, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5454602241516113 sec\n",
      "Episode 1749, len12, loss:-111.4265, fail, steps:80, opt steps:59, total reward:-24.7000, 0.5451564788818359 sec\n",
      "Episode 1750, len6, loss:-73.0528, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5488457679748535 sec\n",
      "Episode 1751, len6, loss:-74.8400, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5478761196136475 sec\n",
      "Episode 1752, len10, loss:-92.6419, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5490155220031738 sec\n",
      "Episode 1753, len6, loss:-76.1815, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5498058795928955 sec\n",
      "Episode 1754, len12, loss:-100.1964, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5495791435241699 sec\n",
      "Episode 1755, len8, loss:-56.3137, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5508570671081543 sec\n",
      "Episode 1756, len8, loss:-69.4823, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5454602241516113 sec\n",
      "Episode 1757, len10, loss:-82.7979, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5505080223083496 sec\n",
      "Episode 1758, len6, loss:-77.7793, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5444896221160889 sec\n",
      "Episode 1759, len8, loss:-64.5626, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5458288192749023 sec\n",
      "Episode 1760, len6, loss:-71.4733, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5975890159606934 sec\n",
      "Episode 1761, len10, loss:-88.1399, fail, steps:80, opt steps:33, total reward:-24.0000, 0.550159215927124 sec\n",
      "Episode 1762, len12, loss:-104.1034, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5500621795654297 sec\n",
      "Episode 1763, len8, loss:-65.4324, fail, steps:80, opt steps:9, total reward:-24.7000, 0.544633150100708 sec\n",
      "Episode 1764, len12, loss:-101.4205, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5486762523651123 sec\n",
      "Episode 1765, len12, loss:-100.8349, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5497462749481201 sec\n",
      "Episode 1766, len8, loss:-64.6835, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5489814281463623 sec\n",
      "Episode 1767, len12, loss:-101.1304, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5479907989501953 sec\n",
      "Episode 1768, len6, loss:-74.2441, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5478055477142334 sec\n",
      "Episode 1769, len12, loss:-92.6917, fail, steps:80, opt steps:59, total reward:-23.4000, 0.5414028167724609 sec\n",
      "Episode 1770, len10, loss:-87.4752, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5479927062988281 sec\n",
      "Episode 1771, len6, loss:-77.6466, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5470771789550781 sec\n",
      "Episode 1772, len12, loss:-93.6322, fail, steps:80, opt steps:41, total reward:-22.7000, 0.5437018871307373 sec\n",
      "Episode 1773, len10, loss:-84.2312, fail, steps:80, opt steps:40, total reward:-23.7000, 0.543851375579834 sec\n",
      "Episode 1774, len12, loss:-102.9721, fail, steps:80, opt steps:44, total reward:-23.7000, 0.5443792343139648 sec\n",
      "Episode 1775, len8, loss:-55.2326, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6005632877349854 sec\n",
      "Episode 1776, len8, loss:-74.1953, fail, steps:80, opt steps:21, total reward:-24.0000, 0.54799485206604 sec\n",
      "Episode 1777, len10, loss:-84.3077, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5482022762298584 sec\n",
      "Episode 1778, len10, loss:-83.0405, fail, steps:80, opt steps:27, total reward:-24.0000, 0.546872615814209 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1779, len8, loss:-57.7362, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5471532344818115 sec\n",
      "Episode 1780, len8, loss:-58.2696, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5482194423675537 sec\n",
      "Episode 1781, len12, loss:-99.6457, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5488724708557129 sec\n",
      "Episode 1782, len12, loss:-108.0538, fail, steps:80, opt steps:50, total reward:-24.7000, 0.5435519218444824 sec\n",
      "Episode 1783, len10, loss:-87.6995, fail, steps:80, opt steps:39, total reward:-24.0000, 0.548478364944458 sec\n",
      "Episode 1784, len8, loss:-65.1433, fail, steps:80, opt steps:23, total reward:-23.7000, 0.5438446998596191 sec\n",
      "Episode 1785, len6, loss:-71.3138, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5472512245178223 sec\n",
      "Episode 1786, len10, loss:-95.3503, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5435705184936523 sec\n",
      "Episode 1787, len12, loss:-97.7593, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5470843315124512 sec\n",
      "Episode 1788, len8, loss:-62.8015, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5475232601165771 sec\n",
      "Episode 1789, len8, loss:-62.6024, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5482034683227539 sec\n",
      "Episode 1790, len12, loss:-105.2456, fail, steps:80, opt steps:59, total reward:-24.4000, 0.5390517711639404 sec\n",
      "Episode 1791, len12, loss:-98.2530, fail, steps:80, opt steps:51, total reward:-24.0000, 0.6012787818908691 sec\n",
      "Episode 1792, len8, loss:-66.1836, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5443060398101807 sec\n",
      "Episode 1793, len10, loss:-93.9142, fail, steps:80, opt steps:35, total reward:-25.4000, 0.5375473499298096 sec\n",
      "Episode 1794, len6, loss:-77.0326, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5493345260620117 sec\n",
      "Episode 1795, len10, loss:-85.4724, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5475244522094727 sec\n",
      "Episode 1796, len12, loss:-102.7095, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5472147464752197 sec\n",
      "Episode 1797, len10, loss:-85.6545, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5472545623779297 sec\n",
      "Episode 1798, len12, loss:-94.1504, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5481960773468018 sec\n",
      "Episode 1799, len10, loss:-83.8619, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5480268001556396 sec\n",
      "Episode 1800, len12, loss:-101.1728, fail, steps:80, opt steps:45, total reward:-24.0000, 0.547217607498169 sec\n",
      "Episode 1801, len10, loss:-89.6153, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5445830821990967 sec\n",
      "Episode 1802, len8, loss:-59.5420, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5474545955657959 sec\n",
      "Episode 1803, len8, loss:-57.3981, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5485563278198242 sec\n",
      "Episode 1804, len6, loss:-78.4564, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5477077960968018 sec\n",
      "Episode 1805, len12, loss:-96.7742, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5475888252258301 sec\n",
      "Episode 1806, len8, loss:-68.4024, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5488986968994141 sec\n",
      "Episode 1807, len8, loss:-56.0527, fail, steps:80, opt steps:11, total reward:-24.0000, 0.6013975143432617 sec\n",
      "Episode 1808, len6, loss:-74.3443, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5470142364501953 sec\n",
      "Episode 1809, len10, loss:-87.7569, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5479998588562012 sec\n",
      "Episode 1810, len6, loss:-72.5094, fail, steps:80, opt steps:20, total reward:-24.0000, 0.547339677810669 sec\n",
      "Episode 1811, len6, loss:-71.7939, fail, steps:80, opt steps:17, total reward:-23.7000, 0.5426864624023438 sec\n",
      "Episode 1812, len6, loss:-72.3520, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5493512153625488 sec\n",
      "Episode 1813, len6, loss:-72.9289, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5482275485992432 sec\n",
      "Episode 1814, len12, loss:-99.0014, fail, steps:80, opt steps:75, total reward:-24.0000, 0.5493605136871338 sec\n",
      "Episode 1815, len8, loss:-65.4261, fail, steps:80, opt steps:27, total reward:-22.7000, 0.5446484088897705 sec\n",
      "Episode 1816, len10, loss:-83.9682, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5474941730499268 sec\n",
      "Episode 1817, len8, loss:-70.4469, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5471639633178711 sec\n",
      "Episode 1818, len6, loss:-66.9304, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5479047298431396 sec\n",
      "Episode 1819, len8, loss:-63.5028, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5485661029815674 sec\n",
      "Episode 1820, len12, loss:-91.3392, fail, steps:80, opt steps:60, total reward:-23.7000, 0.603905200958252 sec\n",
      "Episode 1821, len6, loss:-65.0363, fail, steps:80, opt steps:19, total reward:-22.7000, 0.5441596508026123 sec\n",
      "Episode 1822, len6, loss:-69.7480, fail, steps:80, opt steps:19, total reward:-22.4000, 0.5391747951507568 sec\n",
      "Episode 1823, len6, loss:-70.3195, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5479953289031982 sec\n",
      "Episode 1824, len6, loss:-71.3908, fail, steps:80, opt steps:10, total reward:-24.7000, 0.5429525375366211 sec\n",
      "Episode 1825, len12, loss:-101.8890, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5466320514678955 sec\n",
      "Episode 1826, len6, loss:-74.9229, fail, steps:80, opt steps:19, total reward:-24.4000, 0.538917064666748 sec\n",
      "Episode 1827, len12, loss:-90.8669, fail, steps:80, opt steps:29, total reward:-22.7000, 0.5426535606384277 sec\n",
      "Episode 1828, len10, loss:-89.0516, fail, steps:80, opt steps:46, total reward:-23.7000, 0.5426099300384521 sec\n",
      "Episode 1829, len8, loss:-70.3717, fail, steps:80, opt steps:35, total reward:-25.1000, 0.533719539642334 sec\n",
      "Episode 1830, len10, loss:-82.3679, fail, steps:80, opt steps:47, total reward:-22.7000, 0.5428080558776855 sec\n",
      "Episode 1831, len12, loss:-104.3913, fail, steps:80, opt steps:43, total reward:-24.7000, 0.5417180061340332 sec\n",
      "Episode 1832, len12, loss:-102.5816, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5477738380432129 sec\n",
      "Episode 1833, len10, loss:-93.5238, fail, steps:80, opt steps:44, total reward:-25.4000, 0.5400047302246094 sec\n",
      "Episode 1834, len6, loss:-66.5728, fail, steps:80, opt steps:15, total reward:-24.0000, 0.6019816398620605 sec\n",
      "Episode 1835, len8, loss:-59.5283, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5482339859008789 sec\n",
      "Episode 1836, len6, loss:-64.1474, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5483098030090332 sec\n",
      "Episode 1837, len8, loss:-69.6082, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5495090484619141 sec\n",
      "Episode 1838, len12, loss:-115.7808, fail, steps:80, opt steps:37, total reward:-25.1000, 0.5351467132568359 sec\n",
      "Episode 1839, len12, loss:-100.0301, fail, steps:80, opt steps:69, total reward:-24.0000, 0.5477921962738037 sec\n",
      "Episode 1840, len12, loss:-112.8059, fail, steps:80, opt steps:27, total reward:-24.4000, 0.539208173751831 sec\n",
      "Episode 1841, len12, loss:-102.6399, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5487830638885498 sec\n",
      "Episode 1842, len12, loss:-107.2204, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5506272315979004 sec\n",
      "Episode 1843, len6, loss:-61.5725, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5480067729949951 sec\n",
      "Episode 1844, len8, loss:-62.7522, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5476996898651123 sec\n",
      "Episode 1845, len6, loss:-68.7072, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5496714115142822 sec\n",
      "Episode 1846, len8, loss:-60.0359, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5498080253601074 sec\n",
      "Episode 1847, len10, loss:-89.2475, fail, steps:80, opt steps:41, total reward:-25.4000, 0.541018009185791 sec\n",
      "Episode 1848, len6, loss:-62.8512, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5999898910522461 sec\n",
      "Episode 1849, len8, loss:-64.2449, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5447635650634766 sec\n",
      "Episode 1850, len12, loss:-90.5095, fail, steps:80, opt steps:44, total reward:-24.7000, 0.5428376197814941 sec\n",
      "Episode 1851, len8, loss:-59.1011, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5498175621032715 sec\n",
      "Episode 1852, len12, loss:-92.8896, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5503878593444824 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1853, len8, loss:-55.1203, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5492146015167236 sec\n",
      "Episode 1854, len10, loss:-84.4993, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5446014404296875 sec\n",
      "Episode 1855, len12, loss:-102.7883, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5459675788879395 sec\n",
      "Episode 1856, len12, loss:-98.8471, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5485844612121582 sec\n",
      "Episode 1857, len8, loss:-61.1026, fail, steps:80, opt steps:31, total reward:-22.7000, 0.5463693141937256 sec\n",
      "Episode 1858, len10, loss:-37.0461, fail, steps:0, opt steps:31, total reward:-10.0000, 0.02189493179321289 sec\n",
      "Episode 1859, len8, loss:-55.9601, fail, steps:80, opt steps:18, total reward:-22.7000, 0.48793792724609375 sec\n",
      "Episode 1860, len10, loss:-74.0168, fail, steps:80, opt steps:28, total reward:-22.7000, 0.5247383117675781 sec\n",
      "Episode 1861, len8, loss:-63.9200, fail, steps:80, opt steps:22, total reward:-23.4000, 0.5258967876434326 sec\n",
      "Episode 1862, len10, loss:-79.4696, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5400922298431396 sec\n",
      "Episode 1863, len8, loss:-57.9563, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5922491550445557 sec\n",
      "Episode 1864, len8, loss:-61.1876, fail, steps:80, opt steps:24, total reward:-24.7000, 0.541431188583374 sec\n",
      "Episode 1865, len10, loss:-83.7487, fail, steps:80, opt steps:12, total reward:-24.0000, 0.548107385635376 sec\n",
      "Episode 1866, len12, loss:-97.3875, fail, steps:80, opt steps:42, total reward:-24.0000, 0.547173023223877 sec\n",
      "Episode 1867, len12, loss:-98.3265, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5475528240203857 sec\n",
      "Episode 1868, len8, loss:-61.6362, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5445177555084229 sec\n",
      "Episode 1869, len12, loss:-96.2921, fail, steps:80, opt steps:55, total reward:-23.4000, 0.5388760566711426 sec\n",
      "Episode 1870, len6, loss:-49.4740, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5461268424987793 sec\n",
      "Episode 1871, len12, loss:-97.7235, fail, steps:80, opt steps:57, total reward:-24.0000, 0.549048900604248 sec\n",
      "Episode 1872, len6, loss:-53.6616, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5498316287994385 sec\n",
      "Episode 1873, len12, loss:-92.5825, fail, steps:80, opt steps:71, total reward:-24.0000, 0.5488846302032471 sec\n",
      "Episode 1874, len6, loss:-49.5038, fail, steps:80, opt steps:3, total reward:-24.0000, 0.548943281173706 sec\n",
      "Episode 1875, len10, loss:-87.9125, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5451858043670654 sec\n",
      "Episode 1876, len8, loss:-55.4618, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5440707206726074 sec\n",
      "Episode 1877, len6, loss:-55.0422, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5979580879211426 sec\n",
      "Episode 1878, len6, loss:-59.6653, fail, steps:80, opt steps:10, total reward:-24.7000, 0.5455679893493652 sec\n",
      "Episode 1879, len12, loss:-99.6707, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5449066162109375 sec\n",
      "Episode 1880, len8, loss:-58.4821, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5449659824371338 sec\n",
      "Episode 1881, len12, loss:-102.6813, fail, steps:80, opt steps:50, total reward:-24.7000, 0.5440108776092529 sec\n",
      "Episode 1882, len6, loss:-63.0207, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5492689609527588 sec\n",
      "Episode 1883, len8, loss:-54.2241, fail, steps:80, opt steps:15, total reward:-23.7000, 0.5447533130645752 sec\n",
      "Episode 1884, len10, loss:-90.4735, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5479440689086914 sec\n",
      "Episode 1885, len6, loss:-75.9021, fail, steps:80, opt steps:6, total reward:-26.8000, 0.533430814743042 sec\n",
      "Episode 1886, len12, loss:-101.6539, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5441398620605469 sec\n",
      "Episode 1887, len8, loss:-69.1031, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5487184524536133 sec\n",
      "Episode 1888, len10, loss:-75.7791, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5492725372314453 sec\n",
      "Episode 1889, len12, loss:-106.0350, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5496623516082764 sec\n",
      "Episode 1890, len6, loss:-50.9238, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5488438606262207 sec\n",
      "Episode 1891, len8, loss:-57.8040, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5490491390228271 sec\n",
      "Episode 1892, len10, loss:-82.9707, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5980448722839355 sec\n",
      "Episode 1893, len12, loss:-101.3852, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5489323139190674 sec\n",
      "Episode 1894, len8, loss:-68.9644, fail, steps:80, opt steps:17, total reward:-24.0000, 0.550586462020874 sec\n",
      "Episode 1895, len8, loss:-59.8324, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5501351356506348 sec\n",
      "Episode 1896, len10, loss:-69.7663, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5485231876373291 sec\n",
      "Episode 1897, len12, loss:-99.7733, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5463309288024902 sec\n",
      "Episode 1898, len12, loss:-87.6323, fail, steps:80, opt steps:51, total reward:-23.7000, 0.5459098815917969 sec\n",
      "Episode 1899, len12, loss:-93.0387, fail, steps:80, opt steps:50, total reward:-24.0000, 0.549391508102417 sec\n",
      "Episode 1900, len10, loss:-77.1737, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5485730171203613 sec\n",
      "Episode 1901, len10, loss:-77.0298, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5500302314758301 sec\n",
      "Episode 1902, len6, loss:-49.2420, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5487112998962402 sec\n",
      "Episode 1903, len6, loss:-65.0671, fail, steps:80, opt steps:12, total reward:-24.7000, 0.543853759765625 sec\n",
      "Episode 1904, len12, loss:-92.7772, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5490849018096924 sec\n",
      "Episode 1905, len6, loss:-56.3915, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5501890182495117 sec\n",
      "Episode 1906, len6, loss:-54.7379, fail, steps:80, opt steps:5, total reward:-23.4000, 0.5406961441040039 sec\n",
      "Episode 1907, len12, loss:-109.7235, fail, steps:80, opt steps:56, total reward:-24.7000, 0.5437512397766113 sec\n",
      "Episode 1908, len12, loss:-95.3191, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5943450927734375 sec\n",
      "Episode 1909, len10, loss:-89.1123, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5446310043334961 sec\n",
      "Episode 1910, len10, loss:-79.9731, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5477421283721924 sec\n",
      "Episode 1911, len12, loss:-95.5201, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5495989322662354 sec\n",
      "Episode 1912, len12, loss:-101.3513, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5447609424591064 sec\n",
      "Episode 1913, len8, loss:-59.1188, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5497698783874512 sec\n",
      "Episode 1914, len8, loss:-62.0249, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5503723621368408 sec\n",
      "Episode 1915, len6, loss:-52.1831, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5498082637786865 sec\n",
      "Episode 1916, len6, loss:-65.0393, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5444540977478027 sec\n",
      "Episode 1917, len8, loss:-56.0466, fail, steps:80, opt steps:9, total reward:-24.7000, 0.5453276634216309 sec\n",
      "Episode 1918, len6, loss:-63.3779, fail, steps:80, opt steps:13, total reward:-24.4000, 0.539557933807373 sec\n",
      "Episode 1919, len8, loss:-60.0867, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5480194091796875 sec\n",
      "Episode 1920, len12, loss:-110.6225, fail, steps:80, opt steps:47, total reward:-24.7000, 0.5445046424865723 sec\n",
      "Episode 1921, len10, loss:-88.1760, fail, steps:80, opt steps:28, total reward:-22.7000, 0.5446224212646484 sec\n",
      "Episode 1922, len12, loss:-101.0808, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5464296340942383 sec\n",
      "Episode 1923, len12, loss:-100.0360, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5502877235412598 sec\n",
      "Episode 1924, len10, loss:-83.5579, fail, steps:80, opt steps:45, total reward:-24.0000, 0.599947452545166 sec\n",
      "Episode 1925, len6, loss:-57.1535, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5476562976837158 sec\n",
      "Episode 1926, len6, loss:-56.4580, fail, steps:80, opt steps:15, total reward:-23.7000, 0.5446035861968994 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1927, len8, loss:-66.2356, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5475020408630371 sec\n",
      "Episode 1928, len12, loss:-98.2454, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5474438667297363 sec\n",
      "Episode 1929, len8, loss:-58.2829, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5485754013061523 sec\n",
      "Episode 1930, len8, loss:-54.9307, fail, steps:80, opt steps:18, total reward:-23.4000, 0.5391619205474854 sec\n",
      "Episode 1931, len12, loss:-91.6682, fail, steps:80, opt steps:39, total reward:-24.4000, 0.5443451404571533 sec\n",
      "Episode 1932, len6, loss:-67.1242, fail, steps:80, opt steps:17, total reward:-24.0000, 0.546720027923584 sec\n",
      "Episode 1933, len8, loss:-60.4430, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5482156276702881 sec\n",
      "Episode 1934, len10, loss:-77.3345, fail, steps:80, opt steps:37, total reward:-22.7000, 0.5439763069152832 sec\n",
      "Episode 1935, len6, loss:-55.5224, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5474486351013184 sec\n",
      "Episode 1936, len10, loss:-89.2526, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5475203990936279 sec\n",
      "Episode 1937, len10, loss:-80.9321, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6089167594909668 sec\n",
      "Episode 1938, len6, loss:-55.8192, fail, steps:80, opt steps:15, total reward:-22.7000, 0.5441608428955078 sec\n",
      "Episode 1939, len12, loss:-108.8273, fail, steps:80, opt steps:58, total reward:-24.7000, 0.5432698726654053 sec\n",
      "Episode 1940, len12, loss:-98.0593, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5478003025054932 sec\n",
      "Episode 1941, len6, loss:-53.1473, fail, steps:80, opt steps:19, total reward:-22.7000, 0.5445950031280518 sec\n",
      "Episode 1942, len10, loss:-83.1652, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5485262870788574 sec\n",
      "Episode 1943, len8, loss:-63.6439, fail, steps:80, opt steps:18, total reward:-25.4000, 0.53879714012146 sec\n",
      "Episode 1944, len8, loss:-71.3283, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5479850769042969 sec\n",
      "Episode 1945, len6, loss:-60.3274, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5441529750823975 sec\n",
      "Episode 1946, len10, loss:-79.2132, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5484292507171631 sec\n",
      "Episode 1947, len8, loss:-61.2376, fail, steps:80, opt steps:15, total reward:-23.7000, 0.544262170791626 sec\n",
      "Episode 1948, len6, loss:-61.2256, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5433390140533447 sec\n",
      "Episode 1949, len6, loss:-60.9028, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5472958087921143 sec\n",
      "Episode 1950, len10, loss:-81.2731, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5476779937744141 sec\n",
      "Episode 1951, len6, loss:-59.0822, fail, steps:80, opt steps:15, total reward:-24.0000, 0.6057467460632324 sec\n",
      "Episode 1952, len12, loss:-90.2898, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5430009365081787 sec\n",
      "Episode 1953, len12, loss:-105.3563, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5490078926086426 sec\n",
      "Episode 1954, len6, loss:-69.7380, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5435898303985596 sec\n",
      "Episode 1955, len12, loss:-91.1543, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5496397018432617 sec\n",
      "Episode 1956, len6, loss:-63.4879, fail, steps:80, opt steps:10, total reward:-24.0000, 0.548675537109375 sec\n",
      "Episode 1957, len10, loss:-72.2554, fail, steps:80, opt steps:34, total reward:-23.7000, 0.5439398288726807 sec\n",
      "Episode 1958, len12, loss:-92.6856, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5478105545043945 sec\n",
      "Episode 1959, len6, loss:-64.4016, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5476229190826416 sec\n",
      "Episode 1960, len6, loss:-66.8745, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5481553077697754 sec\n",
      "Episode 1961, len8, loss:-42.6103, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5480246543884277 sec\n",
      "Episode 1962, len10, loss:-80.7682, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5486087799072266 sec\n",
      "Episode 1963, len12, loss:-104.1929, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5498213768005371 sec\n",
      "Episode 1964, len6, loss:-64.8860, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5484886169433594 sec\n",
      "Episode 1965, len6, loss:-75.8208, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5988333225250244 sec\n",
      "Episode 1966, len6, loss:-66.1422, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5488455295562744 sec\n",
      "Episode 1967, len12, loss:-101.4091, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5476367473602295 sec\n",
      "Episode 1968, len6, loss:-65.0339, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5480694770812988 sec\n",
      "Episode 1969, len12, loss:-99.3839, fail, steps:80, opt steps:56, total reward:-24.7000, 0.543597936630249 sec\n",
      "Episode 1970, len8, loss:-52.0375, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5445637702941895 sec\n",
      "Episode 1971, len8, loss:-53.1775, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5465273857116699 sec\n",
      "Episode 1972, len12, loss:-88.0402, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5487534999847412 sec\n",
      "Episode 1973, len6, loss:-38.3435, fail, steps:0, opt steps:11, total reward:-10.0000, 0.021709203720092773 sec\n",
      "Episode 1974, len12, loss:-87.4552, fail, steps:80, opt steps:26, total reward:-24.0000, 0.49162864685058594 sec\n",
      "Episode 1975, len8, loss:-50.0094, fail, steps:80, opt steps:23, total reward:-24.7000, 0.519507646560669 sec\n",
      "Episode 1976, len12, loss:-91.4957, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5333330631256104 sec\n",
      "Episode 1977, len12, loss:-96.0771, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5389671325683594 sec\n",
      "Episode 1978, len6, loss:-68.9836, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5442655086517334 sec\n",
      "Episode 1979, len6, loss:-72.9573, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5440371036529541 sec\n",
      "Episode 1980, len12, loss:-88.7027, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5989468097686768 sec\n",
      "Episode 1981, len6, loss:-76.0266, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5462954044342041 sec\n",
      "Episode 1982, len12, loss:-99.7870, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5469486713409424 sec\n",
      "Episode 1983, len8, loss:-53.8894, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5467748641967773 sec\n",
      "Episode 1984, len10, loss:-84.8986, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5466492176055908 sec\n",
      "Episode 1985, len6, loss:-70.8718, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5480432510375977 sec\n",
      "Episode 1986, len6, loss:-69.7347, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5478048324584961 sec\n",
      "Episode 1987, len6, loss:-74.6693, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5492322444915771 sec\n",
      "Episode 1988, len10, loss:-84.8060, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5439474582672119 sec\n",
      "Episode 1989, len12, loss:-92.3671, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5476455688476562 sec\n",
      "Episode 1990, len12, loss:-98.9922, fail, steps:80, opt steps:20, total reward:-23.7000, 0.5436475276947021 sec\n",
      "Episode 1991, len6, loss:-64.7132, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5482409000396729 sec\n",
      "Episode 1992, len12, loss:-101.2531, fail, steps:80, opt steps:45, total reward:-24.4000, 0.5390615463256836 sec\n",
      "Episode 1993, len12, loss:-102.8427, fail, steps:80, opt steps:22, total reward:-24.4000, 0.5380136966705322 sec\n",
      "Episode 1994, len12, loss:-100.8312, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5964705944061279 sec\n",
      "Episode 1995, len6, loss:-68.9108, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5487008094787598 sec\n",
      "Episode 1996, len12, loss:-101.5372, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5486156940460205 sec\n",
      "Episode 1997, len6, loss:-70.5816, fail, steps:80, opt steps:19, total reward:-24.0000, 0.547879695892334 sec\n",
      "Episode 1998, len10, loss:-83.2518, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5492753982543945 sec\n",
      "Episode 1999, len12, loss:-108.0285, fail, steps:80, opt steps:40, total reward:-24.7000, 0.544675350189209 sec\n",
      "Episode 2000, len10, loss:-86.4279, fail, steps:80, opt steps:40, total reward:-22.7000, 0.5452954769134521 sec\n",
      "Checkpoint saved at episode 2000 to /home/mcwave/code/autocode/datasets/rl_sort_transformer_easy/list6_12_transformer3_128_gamma07_step80_v3_merge_2_sorted/ckpt_2000_0.0010_31.66_vs_5.33.pth\n",
      "Learning rate = 0.000096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2001, len6, loss:-67.2203, fail, steps:80, opt steps:18, total reward:-24.0000, 0.54638671875 sec\n",
      "Episode 2002, len10, loss:-88.0114, fail, steps:80, opt steps:39, total reward:-24.4000, 0.5422942638397217 sec\n",
      "Episode 2003, len12, loss:-103.9073, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5488827228546143 sec\n",
      "Episode 2004, len6, loss:-79.5421, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5493831634521484 sec\n",
      "Episode 2005, len12, loss:-103.1753, fail, steps:80, opt steps:61, total reward:-24.0000, 0.549297571182251 sec\n",
      "Episode 2006, len8, loss:-65.7946, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5462038516998291 sec\n",
      "Episode 2007, len12, loss:-105.8750, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5491013526916504 sec\n",
      "Episode 2008, len12, loss:-99.9556, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5484375953674316 sec\n",
      "Episode 2009, len12, loss:-103.1675, fail, steps:80, opt steps:51, total reward:-24.7000, 0.5927801132202148 sec\n",
      "Episode 2010, len6, loss:-72.9470, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5481338500976562 sec\n",
      "Episode 2011, len10, loss:-73.7377, fail, steps:80, opt steps:29, total reward:-22.7000, 0.5451149940490723 sec\n",
      "Episode 2012, len12, loss:-99.8527, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5482635498046875 sec\n",
      "Episode 2013, len8, loss:-57.1423, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5482809543609619 sec\n",
      "Episode 2014, len12, loss:-94.5008, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5503640174865723 sec\n",
      "Episode 2015, len6, loss:-74.6390, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5483295917510986 sec\n",
      "Episode 2016, len12, loss:-94.9674, fail, steps:80, opt steps:53, total reward:-23.7000, 0.5454874038696289 sec\n",
      "Episode 2017, len10, loss:-80.9764, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5488119125366211 sec\n",
      "Episode 2018, len6, loss:-74.0396, fail, steps:80, opt steps:8, total reward:-24.0000, 0.551196813583374 sec\n",
      "Episode 2019, len10, loss:-82.9101, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5506563186645508 sec\n",
      "Episode 2020, len12, loss:-106.0856, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5455877780914307 sec\n",
      "Episode 2021, len10, loss:-78.0407, fail, steps:80, opt steps:43, total reward:-22.4000, 0.5425078868865967 sec\n",
      "Episode 2022, len8, loss:-65.4026, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5486326217651367 sec\n",
      "Episode 2023, len8, loss:-69.1766, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5508022308349609 sec\n",
      "Episode 2024, len12, loss:-97.3737, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5500931739807129 sec\n",
      "Episode 2025, len12, loss:-110.2334, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5450904369354248 sec\n",
      "Episode 2026, len8, loss:-77.8194, fail, steps:80, opt steps:33, total reward:-24.7000, 0.5968582630157471 sec\n",
      "Episode 2027, len10, loss:-89.1979, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5490860939025879 sec\n",
      "Episode 2028, len6, loss:-77.1754, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5490412712097168 sec\n",
      "Episode 2029, len12, loss:-104.3083, fail, steps:80, opt steps:57, total reward:-24.7000, 0.5446391105651855 sec\n",
      "Episode 2030, len10, loss:-94.2641, fail, steps:80, opt steps:23, total reward:-24.0000, 0.549285888671875 sec\n",
      "Episode 2031, len6, loss:-77.1442, fail, steps:80, opt steps:7, total reward:-25.4000, 0.5394539833068848 sec\n",
      "Episode 2032, len6, loss:-79.2701, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5452713966369629 sec\n",
      "Episode 2033, len10, loss:-93.6790, fail, steps:80, opt steps:34, total reward:-23.7000, 0.5435943603515625 sec\n",
      "Episode 2034, len12, loss:-113.5265, fail, steps:80, opt steps:37, total reward:-25.4000, 0.5405669212341309 sec\n",
      "Episode 2035, len6, loss:-68.0559, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5487582683563232 sec\n",
      "Episode 2036, len10, loss:-97.3097, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5462729930877686 sec\n",
      "Episode 2037, len6, loss:-79.1386, fail, steps:80, opt steps:15, total reward:-24.4000, 0.5392823219299316 sec\n",
      "Episode 2038, len12, loss:-110.5525, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5490508079528809 sec\n",
      "Episode 2039, len12, loss:-103.8332, fail, steps:80, opt steps:42, total reward:-24.0000, 0.6023867130279541 sec\n",
      "Episode 2040, len12, loss:-104.0675, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5496912002563477 sec\n",
      "Episode 2041, len6, loss:-73.3669, fail, steps:80, opt steps:18, total reward:-23.4000, 0.5424084663391113 sec\n",
      "Episode 2042, len8, loss:-78.4276, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5497841835021973 sec\n",
      "Episode 2043, len10, loss:-81.9654, fail, steps:80, opt steps:52, total reward:-22.7000, 0.5442898273468018 sec\n",
      "Episode 2044, len12, loss:-114.0349, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5487406253814697 sec\n",
      "Episode 2045, len6, loss:-73.1682, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5488088130950928 sec\n",
      "Episode 2046, len6, loss:-74.3610, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5487158298492432 sec\n",
      "Episode 2047, len10, loss:-99.1174, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5510075092315674 sec\n",
      "Episode 2048, len10, loss:-95.4993, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5486602783203125 sec\n",
      "Episode 2049, len6, loss:-75.8553, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5505719184875488 sec\n",
      "Episode 2050, len10, loss:-92.9850, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5496160984039307 sec\n",
      "Episode 2051, len6, loss:-80.3978, fail, steps:80, opt steps:15, total reward:-24.4000, 0.5422427654266357 sec\n",
      "Episode 2052, len12, loss:-110.0777, fail, steps:80, opt steps:49, total reward:-24.0000, 0.549534797668457 sec\n",
      "Episode 2053, len10, loss:-102.1702, fail, steps:80, opt steps:8, total reward:-24.7000, 0.596876859664917 sec\n",
      "Episode 2054, len10, loss:-94.9162, fail, steps:80, opt steps:28, total reward:-23.7000, 0.545773983001709 sec\n",
      "Episode 2055, len12, loss:-112.0721, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5509672164916992 sec\n",
      "Episode 2056, len8, loss:-73.8284, fail, steps:80, opt steps:33, total reward:-23.7000, 0.545435905456543 sec\n",
      "Episode 2057, len6, loss:-75.7834, fail, steps:80, opt steps:8, total reward:-24.0000, 0.549924373626709 sec\n",
      "Episode 2058, len6, loss:-68.8129, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5495891571044922 sec\n",
      "Episode 2059, len10, loss:-94.7151, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5500552654266357 sec\n",
      "Episode 2060, len10, loss:-84.2144, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5497825145721436 sec\n",
      "Episode 2061, len10, loss:-95.7747, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5494363307952881 sec\n",
      "Episode 2062, len6, loss:-72.7058, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5493819713592529 sec\n",
      "Episode 2063, len6, loss:-70.4343, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5498306751251221 sec\n",
      "Episode 2064, len8, loss:-63.3660, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5498178005218506 sec\n",
      "Episode 2065, len6, loss:-69.4376, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5502912998199463 sec\n",
      "Episode 2066, len10, loss:-97.4980, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5448267459869385 sec\n",
      "Episode 2067, len10, loss:-99.5831, fail, steps:80, opt steps:12, total reward:-24.7000, 0.5977048873901367 sec\n",
      "Episode 2068, len10, loss:-94.5891, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5453174114227295 sec\n",
      "Episode 2069, len6, loss:-71.7343, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5487353801727295 sec\n",
      "Episode 2070, len6, loss:-84.0896, fail, steps:80, opt steps:20, total reward:-25.4000, 0.5395052433013916 sec\n",
      "Episode 2071, len12, loss:-99.6713, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5487682819366455 sec\n",
      "Episode 2072, len12, loss:-104.0001, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5486643314361572 sec\n",
      "Episode 2073, len6, loss:-75.3390, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5487833023071289 sec\n",
      "Episode 2074, len8, loss:-76.7516, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5435705184936523 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2075, len8, loss:-75.9541, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5428953170776367 sec\n",
      "Episode 2076, len10, loss:-98.5693, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5470151901245117 sec\n",
      "Episode 2077, len8, loss:-71.6779, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5481319427490234 sec\n",
      "Episode 2078, len6, loss:-81.1013, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5443708896636963 sec\n",
      "Episode 2079, len8, loss:-73.4049, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5475878715515137 sec\n",
      "Episode 2080, len12, loss:-110.7427, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5492846965789795 sec\n",
      "Episode 2081, len6, loss:-76.5568, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5982856750488281 sec\n",
      "Episode 2082, len12, loss:-120.7658, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5452635288238525 sec\n",
      "Episode 2083, len8, loss:-73.3072, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5474851131439209 sec\n",
      "Episode 2084, len12, loss:-103.8132, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5487439632415771 sec\n",
      "Episode 2085, len10, loss:-96.6455, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5491499900817871 sec\n",
      "Episode 2086, len8, loss:-74.2983, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5484793186187744 sec\n",
      "Episode 2087, len8, loss:-80.8542, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5530116558074951 sec\n",
      "Episode 2088, len8, loss:-73.0137, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5488440990447998 sec\n",
      "Episode 2089, len12, loss:-111.9883, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5446553230285645 sec\n",
      "Episode 2090, len6, loss:-72.4879, fail, steps:80, opt steps:5, total reward:-24.0000, 0.548396110534668 sec\n",
      "Episode 2091, len10, loss:-108.1620, fail, steps:80, opt steps:23, total reward:-25.4000, 0.546830415725708 sec\n",
      "Episode 2092, len8, loss:-76.2964, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5498073101043701 sec\n",
      "Episode 2093, len10, loss:-90.3959, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5494930744171143 sec\n",
      "Episode 2094, len8, loss:-72.3372, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5486383438110352 sec\n",
      "Episode 2095, len12, loss:-107.3072, fail, steps:80, opt steps:43, total reward:-24.0000, 0.6002075672149658 sec\n",
      "Episode 2096, len8, loss:-64.4404, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5497841835021973 sec\n",
      "Episode 2097, len12, loss:-108.5207, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5520057678222656 sec\n",
      "Episode 2098, len8, loss:-70.8030, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5491335391998291 sec\n",
      "Episode 2099, len8, loss:-68.9204, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5497183799743652 sec\n",
      "Episode 2100, len12, loss:-104.2570, fail, steps:80, opt steps:40, total reward:-23.4000, 0.5441548824310303 sec\n",
      "Episode 2101, len12, loss:-102.1856, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5501046180725098 sec\n",
      "Episode 2102, len6, loss:-73.1341, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5483071804046631 sec\n",
      "Episode 2103, len10, loss:-92.2611, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5494458675384521 sec\n",
      "Episode 2104, len12, loss:-111.3276, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5524239540100098 sec\n",
      "Episode 2105, len8, loss:-68.0277, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5506300926208496 sec\n",
      "Episode 2106, len10, loss:-94.3879, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5502486228942871 sec\n",
      "Episode 2107, len10, loss:-109.2515, fail, steps:80, opt steps:39, total reward:-25.4000, 0.5409071445465088 sec\n",
      "Episode 2108, len12, loss:-118.1469, fail, steps:80, opt steps:51, total reward:-24.7000, 0.5450117588043213 sec\n",
      "Episode 2109, len12, loss:-113.0171, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5505988597869873 sec\n",
      "Episode 2110, len6, loss:-75.6338, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5994589328765869 sec\n",
      "Episode 2111, len8, loss:-73.4454, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5488443374633789 sec\n",
      "Episode 2112, len8, loss:-76.2301, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5433886051177979 sec\n",
      "Episode 2113, len6, loss:-85.7477, fail, steps:80, opt steps:13, total reward:-24.1000, 0.535947322845459 sec\n",
      "Episode 2114, len12, loss:-102.5778, fail, steps:80, opt steps:57, total reward:-24.0000, 0.549147367477417 sec\n",
      "Episode 2115, len8, loss:-75.0140, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5490720272064209 sec\n",
      "Episode 2116, len6, loss:-81.8696, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5469260215759277 sec\n",
      "Episode 2117, len8, loss:-78.1940, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5444374084472656 sec\n",
      "Episode 2118, len10, loss:-96.4520, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5490922927856445 sec\n",
      "Episode 2119, len10, loss:-92.1702, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5490882396697998 sec\n",
      "Episode 2120, len8, loss:-84.0273, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5496900081634521 sec\n",
      "Episode 2121, len8, loss:-72.0205, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5490555763244629 sec\n",
      "Episode 2122, len8, loss:-71.8549, fail, steps:80, opt steps:16, total reward:-24.0000, 0.549623966217041 sec\n",
      "Episode 2123, len12, loss:-111.4263, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5462253093719482 sec\n",
      "Episode 2124, len10, loss:-106.4532, fail, steps:80, opt steps:34, total reward:-24.7000, 0.5438451766967773 sec\n",
      "Episode 2125, len8, loss:-72.6634, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5508396625518799 sec\n",
      "Episode 2126, len10, loss:-90.9858, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5976500511169434 sec\n",
      "Episode 2127, len12, loss:-105.9237, fail, steps:80, opt steps:41, total reward:-24.0000, 0.549497127532959 sec\n",
      "Episode 2128, len6, loss:-77.3115, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5487895011901855 sec\n",
      "Episode 2129, len6, loss:-74.6914, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5486307144165039 sec\n",
      "Episode 2130, len12, loss:-111.8796, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5502679347991943 sec\n",
      "Episode 2131, len8, loss:-63.3616, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5491306781768799 sec\n",
      "Episode 2132, len8, loss:-70.1091, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5502200126647949 sec\n",
      "Episode 2133, len8, loss:-65.7719, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5447444915771484 sec\n",
      "Episode 2134, len6, loss:-79.4100, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5501575469970703 sec\n",
      "Episode 2135, len10, loss:-93.0202, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5514347553253174 sec\n",
      "Episode 2136, len10, loss:-92.0810, fail, steps:80, opt steps:33, total reward:-24.0000, 0.550318717956543 sec\n",
      "Episode 2137, len8, loss:-69.6254, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5497431755065918 sec\n",
      "Episode 2138, len10, loss:-80.2660, fail, steps:80, opt steps:24, total reward:-22.7000, 0.5470008850097656 sec\n",
      "Episode 2139, len12, loss:-106.0321, fail, steps:80, opt steps:36, total reward:-24.7000, 0.5467321872711182 sec\n",
      "Episode 2140, len12, loss:-105.3347, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5505154132843018 sec\n",
      "Episode 2141, len10, loss:-93.3166, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5508801937103271 sec\n",
      "Episode 2142, len8, loss:-60.7650, fail, steps:80, opt steps:27, total reward:-24.0000, 0.6012716293334961 sec\n",
      "Episode 2143, len8, loss:-56.7104, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5484311580657959 sec\n",
      "Episode 2144, len12, loss:-106.9409, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5491087436676025 sec\n",
      "Episode 2145, len10, loss:-98.9232, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5507419109344482 sec\n",
      "Episode 2146, len6, loss:-83.7022, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5436491966247559 sec\n",
      "Episode 2147, len12, loss:-123.9921, fail, steps:80, opt steps:66, total reward:-24.7000, 0.5445115566253662 sec\n",
      "Episode 2148, len8, loss:-66.4234, fail, steps:80, opt steps:21, total reward:-24.0000, 0.548691987991333 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2149, len6, loss:-78.0922, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5490562915802002 sec\n",
      "Episode 2150, len10, loss:-98.7761, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5516107082366943 sec\n",
      "Episode 2151, len10, loss:-102.3490, fail, steps:80, opt steps:33, total reward:-25.4000, 0.54018235206604 sec\n",
      "Episode 2152, len10, loss:-90.4457, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5486552715301514 sec\n",
      "Episode 2153, len6, loss:-82.0350, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5433626174926758 sec\n",
      "Episode 2154, len8, loss:-68.9413, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5498964786529541 sec\n",
      "Episode 2155, len6, loss:-77.5208, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6020622253417969 sec\n",
      "Episode 2156, len6, loss:-86.0860, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5453174114227295 sec\n",
      "Episode 2157, len6, loss:-85.2740, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5441820621490479 sec\n",
      "Episode 2158, len8, loss:-74.2072, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5453956127166748 sec\n",
      "Episode 2159, len10, loss:-94.0922, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5448853969573975 sec\n",
      "Episode 2160, len12, loss:-108.6330, fail, steps:80, opt steps:44, total reward:-25.4000, 0.5400364398956299 sec\n",
      "Episode 2161, len12, loss:-111.8755, fail, steps:80, opt steps:35, total reward:-24.7000, 0.5444400310516357 sec\n",
      "Episode 2162, len6, loss:-78.5408, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5474693775177002 sec\n",
      "Episode 2163, len12, loss:-100.6261, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5495390892028809 sec\n",
      "Episode 2164, len12, loss:-105.9237, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5494027137756348 sec\n",
      "Episode 2165, len12, loss:-100.0074, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5488500595092773 sec\n",
      "Episode 2166, len8, loss:-66.0700, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5455470085144043 sec\n",
      "Episode 2167, len6, loss:-82.2644, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5448439121246338 sec\n",
      "Episode 2168, len6, loss:-89.2567, fail, steps:80, opt steps:18, total reward:-24.4000, 0.5397849082946777 sec\n",
      "Episode 2169, len6, loss:-79.9850, fail, steps:80, opt steps:13, total reward:-24.0000, 0.601130485534668 sec\n",
      "Episode 2170, len8, loss:-70.8560, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5491173267364502 sec\n",
      "Episode 2171, len10, loss:-90.3879, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5482244491577148 sec\n",
      "Episode 2172, len6, loss:-77.3244, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5481491088867188 sec\n",
      "Episode 2173, len8, loss:-58.0975, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5489935874938965 sec\n",
      "Episode 2174, len12, loss:-100.7864, fail, steps:80, opt steps:53, total reward:-23.7000, 0.5463988780975342 sec\n",
      "Episode 2175, len12, loss:-101.6678, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5481710433959961 sec\n",
      "Episode 2176, len12, loss:-103.0900, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5490961074829102 sec\n",
      "Episode 2177, len8, loss:-69.3132, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5487303733825684 sec\n",
      "Episode 2178, len10, loss:-86.9941, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5494849681854248 sec\n",
      "Episode 2179, len12, loss:-106.1713, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5500171184539795 sec\n",
      "Episode 2180, len12, loss:-106.1164, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5492322444915771 sec\n",
      "Episode 2181, len6, loss:-77.6431, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5501613616943359 sec\n",
      "Episode 2182, len8, loss:-68.3019, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5498733520507812 sec\n",
      "Episode 2183, len6, loss:-81.1795, fail, steps:80, opt steps:15, total reward:-24.0000, 0.599921703338623 sec\n",
      "Episode 2184, len10, loss:-85.5435, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5474104881286621 sec\n",
      "Episode 2185, len8, loss:-64.6615, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5491902828216553 sec\n",
      "Episode 2186, len10, loss:-91.9658, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5493357181549072 sec\n",
      "Episode 2187, len6, loss:-76.2158, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5472989082336426 sec\n",
      "Episode 2188, len12, loss:-95.8551, fail, steps:80, opt steps:75, total reward:-24.0000, 0.5490930080413818 sec\n",
      "Episode 2189, len8, loss:-65.6502, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5451018810272217 sec\n",
      "Episode 2190, len12, loss:-103.2886, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5455517768859863 sec\n",
      "Episode 2191, len12, loss:-101.4583, fail, steps:80, opt steps:54, total reward:-24.7000, 0.5449888706207275 sec\n",
      "Episode 2192, len10, loss:-84.4774, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5492997169494629 sec\n",
      "Episode 2193, len12, loss:-96.0442, fail, steps:80, opt steps:51, total reward:-24.0000, 0.549461841583252 sec\n",
      "Episode 2194, len6, loss:-73.5267, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5507819652557373 sec\n",
      "Episode 2195, len6, loss:-76.3946, fail, steps:80, opt steps:21, total reward:-24.0000, 0.549619197845459 sec\n",
      "Episode 2196, len6, loss:-75.2883, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5500073432922363 sec\n",
      "Episode 2197, len8, loss:-59.1704, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5999088287353516 sec\n",
      "Episode 2198, len6, loss:-74.5346, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5497257709503174 sec\n",
      "Episode 2199, len6, loss:-75.5928, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5503530502319336 sec\n",
      "Episode 2200, len6, loss:-74.6385, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5489964485168457 sec\n",
      "Episode 2201, len6, loss:-79.9439, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5494575500488281 sec\n",
      "Episode 2202, len6, loss:-81.2643, fail, steps:80, opt steps:21, total reward:-24.4000, 0.5407943725585938 sec\n",
      "Episode 2203, len12, loss:-100.2416, fail, steps:80, opt steps:43, total reward:-24.0000, 0.549100399017334 sec\n",
      "Episode 2204, len12, loss:-110.2888, fail, steps:80, opt steps:50, total reward:-24.7000, 0.5455858707427979 sec\n",
      "Episode 2205, len10, loss:-78.8712, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5487780570983887 sec\n",
      "Episode 2206, len10, loss:-87.3358, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5499374866485596 sec\n",
      "Episode 2207, len10, loss:-82.1023, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5502378940582275 sec\n",
      "Episode 2208, len12, loss:-119.8379, fail, steps:80, opt steps:34, total reward:-25.4000, 0.5423765182495117 sec\n",
      "Episode 2209, len8, loss:-63.4286, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5457165241241455 sec\n",
      "Episode 2210, len6, loss:-85.9397, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5437614917755127 sec\n",
      "Episode 2211, len10, loss:-76.6949, fail, steps:80, opt steps:36, total reward:-24.0000, 0.6021213531494141 sec\n",
      "Episode 2212, len6, loss:-71.4663, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5505621433258057 sec\n",
      "Episode 2213, len12, loss:-98.6978, fail, steps:80, opt steps:74, total reward:-24.0000, 0.5508327484130859 sec\n",
      "Episode 2214, len6, loss:-77.4227, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5496516227722168 sec\n",
      "Episode 2215, len8, loss:-72.3200, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5439939498901367 sec\n",
      "Episode 2216, len8, loss:-61.9599, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5454616546630859 sec\n",
      "Episode 2217, len12, loss:-41.1029, fail, steps:0, opt steps:41, total reward:-10.0000, 0.02180027961730957 sec\n",
      "Episode 2218, len6, loss:-76.8567, fail, steps:80, opt steps:18, total reward:-24.0000, 0.492185115814209 sec\n",
      "Episode 2219, len8, loss:-65.8022, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5237197875976562 sec\n",
      "Episode 2220, len6, loss:-80.6623, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5295870304107666 sec\n",
      "Episode 2221, len12, loss:-94.5639, fail, steps:80, opt steps:51, total reward:-23.4000, 0.5309555530548096 sec\n",
      "Episode 2222, len12, loss:-104.0827, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5429253578186035 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2223, len12, loss:-109.2704, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5448365211486816 sec\n",
      "Episode 2224, len12, loss:-91.9177, fail, steps:80, opt steps:75, total reward:-24.0000, 0.547736644744873 sec\n",
      "Episode 2225, len8, loss:-59.9352, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5407812595367432 sec\n",
      "Episode 2226, len6, loss:-80.7481, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5421004295349121 sec\n",
      "Episode 2227, len12, loss:-96.2122, fail, steps:80, opt steps:63, total reward:-23.7000, 0.5917620658874512 sec\n",
      "Episode 2228, len10, loss:-80.3591, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5476984977722168 sec\n",
      "Episode 2229, len8, loss:-54.1793, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5477967262268066 sec\n",
      "Episode 2230, len10, loss:-84.1612, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5487973690032959 sec\n",
      "Episode 2231, len10, loss:-84.7447, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5474019050598145 sec\n",
      "Episode 2232, len12, loss:-103.0086, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5473248958587646 sec\n",
      "Episode 2233, len6, loss:-67.4755, fail, steps:80, opt steps:17, total reward:-22.7000, 0.5446064472198486 sec\n",
      "Episode 2234, len12, loss:-103.1563, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5485012531280518 sec\n",
      "Episode 2235, len10, loss:-91.9910, fail, steps:80, opt steps:31, total reward:-24.7000, 0.5448715686798096 sec\n",
      "Episode 2236, len6, loss:-83.1792, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5426592826843262 sec\n",
      "Episode 2237, len6, loss:-74.6671, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5476438999176025 sec\n",
      "Episode 2238, len8, loss:-50.1850, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5472688674926758 sec\n",
      "Episode 2239, len6, loss:-81.5301, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5429563522338867 sec\n",
      "Episode 2240, len10, loss:-88.7578, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5441508293151855 sec\n",
      "Episode 2241, len8, loss:-54.9316, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5483005046844482 sec\n",
      "Episode 2242, len6, loss:-78.1650, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5472385883331299 sec\n",
      "Episode 2243, len8, loss:-57.5561, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5963501930236816 sec\n",
      "Episode 2244, len10, loss:-91.2239, fail, steps:80, opt steps:36, total reward:-24.7000, 0.5435431003570557 sec\n",
      "Episode 2245, len8, loss:-65.0436, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5471410751342773 sec\n",
      "Episode 2246, len6, loss:-77.4608, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5473949909210205 sec\n",
      "Episode 2247, len10, loss:-89.3189, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5471832752227783 sec\n",
      "Episode 2248, len12, loss:-97.1694, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5495586395263672 sec\n",
      "Episode 2249, len10, loss:-94.2189, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5447351932525635 sec\n",
      "Episode 2250, len12, loss:-105.2900, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5487122535705566 sec\n",
      "Episode 2251, len10, loss:-85.0416, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5483536720275879 sec\n",
      "Episode 2252, len8, loss:-74.8745, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5445306301116943 sec\n",
      "Episode 2253, len8, loss:-65.7530, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5474514961242676 sec\n",
      "Episode 2254, len8, loss:-67.5972, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5498003959655762 sec\n",
      "Episode 2255, len10, loss:-106.4975, fail, steps:80, opt steps:19, total reward:-25.4000, 0.5414319038391113 sec\n",
      "Episode 2256, len6, loss:-77.6118, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5478217601776123 sec\n",
      "Episode 2257, len8, loss:-71.4541, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5475788116455078 sec\n",
      "Episode 2258, len12, loss:-113.2249, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5478339195251465 sec\n",
      "Episode 2259, len12, loss:-99.9565, fail, steps:80, opt steps:53, total reward:-24.0000, 0.6061985492706299 sec\n",
      "Episode 2260, len6, loss:-82.2810, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5437033176422119 sec\n",
      "Episode 2261, len8, loss:-58.6091, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5477304458618164 sec\n",
      "Episode 2262, len12, loss:-102.3524, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5493776798248291 sec\n",
      "Episode 2263, len8, loss:-66.3899, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5479381084442139 sec\n",
      "Episode 2264, len8, loss:-72.2162, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5435476303100586 sec\n",
      "Episode 2265, len6, loss:-73.5691, fail, steps:80, opt steps:21, total reward:-23.7000, 0.544959545135498 sec\n",
      "Episode 2266, len12, loss:-92.5696, fail, steps:80, opt steps:46, total reward:-22.7000, 0.5451829433441162 sec\n",
      "Episode 2267, len6, loss:-79.4994, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5434367656707764 sec\n",
      "Episode 2268, len12, loss:-92.2639, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5486915111541748 sec\n",
      "Episode 2269, len8, loss:-60.4525, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548206090927124 sec\n",
      "Episode 2270, len10, loss:-79.8031, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5490031242370605 sec\n",
      "Episode 2271, len6, loss:-75.8539, fail, steps:80, opt steps:13, total reward:-24.0000, 0.549389123916626 sec\n",
      "Episode 2272, len12, loss:-114.6519, fail, steps:80, opt steps:13, total reward:-24.7000, 0.603581428527832 sec\n",
      "Episode 2273, len12, loss:-115.7168, fail, steps:80, opt steps:43, total reward:-25.4000, 0.541609525680542 sec\n",
      "Episode 2274, len10, loss:-83.3458, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5492675304412842 sec\n",
      "Episode 2275, len10, loss:-96.9905, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5451927185058594 sec\n",
      "Episode 2276, len6, loss:-75.7336, fail, steps:80, opt steps:12, total reward:-24.0000, 0.549140453338623 sec\n",
      "Episode 2277, len6, loss:-74.6962, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5479130744934082 sec\n",
      "Episode 2278, len8, loss:-59.6890, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5481657981872559 sec\n",
      "Episode 2279, len6, loss:-71.4958, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5505235195159912 sec\n",
      "Episode 2280, len12, loss:-106.5734, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5488326549530029 sec\n",
      "Episode 2281, len10, loss:-86.4764, fail, steps:80, opt steps:37, total reward:-24.0000, 0.549574613571167 sec\n",
      "Episode 2282, len12, loss:-110.8647, fail, steps:80, opt steps:77, total reward:-24.0000, 0.54854416847229 sec\n",
      "Episode 2283, len8, loss:-68.3074, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5479447841644287 sec\n",
      "Episode 2284, len6, loss:1.7724, succeed, steps:10, opt steps:5, total reward:-2.4100, 0.0818793773651123 sec\n",
      "Episode 2285, len6, loss:-76.0556, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5035903453826904 sec\n",
      "Episode 2286, len6, loss:-72.5989, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5298795700073242 sec\n",
      "Episode 2287, len10, loss:-106.1886, fail, steps:80, opt steps:25, total reward:-25.4000, 0.5850739479064941 sec\n",
      "Episode 2288, len8, loss:-62.9733, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5408501625061035 sec\n",
      "Episode 2289, len10, loss:-93.2290, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5415668487548828 sec\n",
      "Episode 2290, len6, loss:-72.7492, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5452399253845215 sec\n",
      "Episode 2291, len10, loss:-89.3643, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5466344356536865 sec\n",
      "Episode 2292, len6, loss:-75.8377, fail, steps:80, opt steps:6, total reward:-24.0000, 0.549116849899292 sec\n",
      "Episode 2293, len8, loss:-67.2080, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5482585430145264 sec\n",
      "Episode 2294, len10, loss:-96.6869, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5481328964233398 sec\n",
      "Episode 2295, len12, loss:-102.1143, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5497207641601562 sec\n",
      "Episode 2296, len12, loss:-111.3916, fail, steps:80, opt steps:36, total reward:-24.4000, 0.5402753353118896 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2297, len10, loss:-94.9302, fail, steps:80, opt steps:53, total reward:-24.0000, 0.54795241355896 sec\n",
      "Episode 2298, len6, loss:-77.0682, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5475866794586182 sec\n",
      "Episode 2299, len12, loss:-109.8879, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5543918609619141 sec\n",
      "Episode 2300, len10, loss:-97.4911, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5501227378845215 sec\n",
      "Episode 2301, len6, loss:-78.0702, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5987372398376465 sec\n",
      "Episode 2302, len8, loss:-73.4426, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5502462387084961 sec\n",
      "Episode 2303, len6, loss:-75.9081, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5490500926971436 sec\n",
      "Episode 2304, len12, loss:-115.1897, fail, steps:80, opt steps:70, total reward:-24.7000, 0.5448093414306641 sec\n",
      "Episode 2305, len12, loss:-113.4236, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5502829551696777 sec\n",
      "Episode 2306, len10, loss:-101.8926, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5445795059204102 sec\n",
      "Episode 2307, len12, loss:-110.5092, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5481796264648438 sec\n",
      "Episode 2308, len8, loss:-86.0876, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5431201457977295 sec\n",
      "Episode 2309, len10, loss:-93.6098, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5501022338867188 sec\n",
      "Episode 2310, len8, loss:-81.9385, fail, steps:80, opt steps:32, total reward:-23.7000, 0.5452234745025635 sec\n",
      "Episode 2311, len12, loss:-106.0145, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5477354526519775 sec\n",
      "Episode 2312, len12, loss:-111.6784, fail, steps:80, opt steps:69, total reward:-23.7000, 0.5448789596557617 sec\n",
      "Episode 2313, len8, loss:-83.9698, fail, steps:80, opt steps:11, total reward:-24.0000, 0.548919677734375 sec\n",
      "Episode 2314, len6, loss:-74.1827, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5494461059570312 sec\n",
      "Episode 2315, len10, loss:-93.2718, fail, steps:80, opt steps:40, total reward:-24.0000, 0.6030383110046387 sec\n",
      "Episode 2316, len10, loss:-98.1284, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5492091178894043 sec\n",
      "Episode 2317, len6, loss:-82.2987, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5446650981903076 sec\n",
      "Episode 2318, len12, loss:-105.0411, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5481598377227783 sec\n",
      "Episode 2319, len6, loss:-80.7497, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5450809001922607 sec\n",
      "Episode 2320, len8, loss:-84.7012, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5485718250274658 sec\n",
      "Episode 2321, len8, loss:-79.9660, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5493063926696777 sec\n",
      "Episode 2322, len10, loss:-98.8651, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5477719306945801 sec\n",
      "Episode 2323, len12, loss:-112.7944, fail, steps:80, opt steps:35, total reward:-24.0000, 0.549189567565918 sec\n",
      "Episode 2324, len12, loss:-109.9733, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5494840145111084 sec\n",
      "Episode 2325, len8, loss:-76.7554, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5490398406982422 sec\n",
      "Episode 2326, len6, loss:-75.9504, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5479879379272461 sec\n",
      "Episode 2327, len12, loss:-104.9260, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5500490665435791 sec\n",
      "Episode 2328, len12, loss:-106.7063, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5502617359161377 sec\n",
      "Episode 2329, len12, loss:-108.0433, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5487680435180664 sec\n",
      "Episode 2330, len6, loss:-82.1224, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5941920280456543 sec\n",
      "Episode 2331, len6, loss:-78.7627, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5486733913421631 sec\n",
      "Episode 2332, len12, loss:-105.2692, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5485200881958008 sec\n",
      "Episode 2333, len10, loss:-102.9942, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5440421104431152 sec\n",
      "Episode 2334, len10, loss:-93.2003, fail, steps:80, opt steps:25, total reward:-24.0000, 0.547290563583374 sec\n",
      "Episode 2335, len10, loss:-90.0871, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5495688915252686 sec\n",
      "Episode 2336, len12, loss:-113.4352, fail, steps:80, opt steps:38, total reward:-24.7000, 0.546013355255127 sec\n",
      "Episode 2337, len12, loss:-106.6068, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5484795570373535 sec\n",
      "Episode 2338, len8, loss:-97.1840, fail, steps:80, opt steps:22, total reward:-25.4000, 0.5405290126800537 sec\n",
      "Episode 2339, len8, loss:-82.8037, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5490157604217529 sec\n",
      "Episode 2340, len8, loss:-73.3721, fail, steps:80, opt steps:29, total reward:-22.7000, 0.5434436798095703 sec\n",
      "Episode 2341, len12, loss:-114.1216, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5477137565612793 sec\n",
      "Episode 2342, len12, loss:-112.1385, fail, steps:80, opt steps:45, total reward:-23.7000, 0.5441501140594482 sec\n",
      "Episode 2343, len10, loss:-96.4052, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5492961406707764 sec\n",
      "Episode 2344, len6, loss:-80.0527, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5444643497467041 sec\n",
      "Episode 2345, len8, loss:-80.5230, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5482425689697266 sec\n",
      "Episode 2346, len8, loss:-88.1071, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5955727100372314 sec\n",
      "Episode 2347, len10, loss:-100.0237, fail, steps:80, opt steps:29, total reward:-24.0000, 0.54952073097229 sec\n",
      "Episode 2348, len8, loss:-76.3260, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5498628616333008 sec\n",
      "Episode 2349, len6, loss:-77.5893, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5494945049285889 sec\n",
      "Episode 2350, len10, loss:-97.9027, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5496246814727783 sec\n",
      "Episode 2351, len10, loss:-96.3620, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5493576526641846 sec\n",
      "Episode 2352, len12, loss:-116.0692, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5498580932617188 sec\n",
      "Episode 2353, len12, loss:-112.0530, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5488343238830566 sec\n",
      "Episode 2354, len8, loss:-81.2076, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5495271682739258 sec\n",
      "Episode 2355, len12, loss:-119.7367, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5490596294403076 sec\n",
      "Episode 2356, len6, loss:-71.2964, fail, steps:80, opt steps:16, total reward:-22.7000, 0.5449545383453369 sec\n",
      "Episode 2357, len8, loss:-84.1906, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5483217239379883 sec\n",
      "Episode 2358, len10, loss:-101.8337, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5491311550140381 sec\n",
      "Episode 2359, len8, loss:-86.8208, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5485742092132568 sec\n",
      "Episode 2360, len12, loss:-112.0923, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5489256381988525 sec\n",
      "Episode 2361, len12, loss:-117.9042, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5515923500061035 sec\n",
      "Episode 2362, len6, loss:-81.5649, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5991401672363281 sec\n",
      "Episode 2363, len8, loss:-93.6750, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5481827259063721 sec\n",
      "Episode 2364, len12, loss:-120.2475, fail, steps:80, opt steps:68, total reward:-24.7000, 0.5442419052124023 sec\n",
      "Episode 2365, len12, loss:-109.8881, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5481002330780029 sec\n",
      "Episode 2366, len6, loss:-88.9361, fail, steps:80, opt steps:10, total reward:-25.4000, 0.5388343334197998 sec\n",
      "Episode 2367, len12, loss:-113.2210, fail, steps:80, opt steps:29, total reward:-23.7000, 0.5439233779907227 sec\n",
      "Episode 2368, len6, loss:-75.8351, fail, steps:80, opt steps:15, total reward:-24.0000, 0.547792911529541 sec\n",
      "Episode 2369, len10, loss:-98.0456, fail, steps:80, opt steps:35, total reward:-24.0000, 0.548292875289917 sec\n",
      "Episode 2370, len6, loss:-86.5067, fail, steps:80, opt steps:5, total reward:-25.4000, 0.5403389930725098 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2371, len8, loss:-91.4290, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5470988750457764 sec\n",
      "Episode 2372, len6, loss:-75.1875, fail, steps:80, opt steps:19, total reward:-23.4000, 0.539313793182373 sec\n",
      "Episode 2373, len12, loss:-117.6098, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5485868453979492 sec\n",
      "Episode 2374, len8, loss:-86.1970, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5489921569824219 sec\n",
      "Episode 2375, len10, loss:-103.2587, fail, steps:80, opt steps:23, total reward:-24.0000, 0.6017417907714844 sec\n",
      "Episode 2376, len10, loss:-99.9400, fail, steps:80, opt steps:39, total reward:-24.0000, 0.548166036605835 sec\n",
      "Episode 2377, len10, loss:-110.7024, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5446934700012207 sec\n",
      "Episode 2378, len6, loss:-69.1429, fail, steps:80, opt steps:18, total reward:-22.7000, 0.5445537567138672 sec\n",
      "Episode 2379, len10, loss:-112.2030, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5429091453552246 sec\n",
      "Episode 2380, len10, loss:-96.8365, fail, steps:80, opt steps:43, total reward:-22.7000, 0.5436820983886719 sec\n",
      "Episode 2381, len6, loss:-78.2522, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5503613948822021 sec\n",
      "Episode 2382, len10, loss:-108.0444, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5492222309112549 sec\n",
      "Episode 2383, len8, loss:-90.1749, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5479123592376709 sec\n",
      "Episode 2384, len8, loss:-86.6405, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5479240417480469 sec\n",
      "Episode 2385, len8, loss:-86.4532, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5489785671234131 sec\n",
      "Episode 2386, len8, loss:-86.2716, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5502834320068359 sec\n",
      "Episode 2387, len10, loss:-104.8749, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5511503219604492 sec\n",
      "Episode 2388, len12, loss:-110.2645, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5512287616729736 sec\n",
      "Episode 2389, len6, loss:-71.4411, fail, steps:80, opt steps:13, total reward:-24.0000, 0.6018071174621582 sec\n",
      "Episode 2390, len6, loss:-77.2613, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5499043464660645 sec\n",
      "Episode 2391, len10, loss:-104.5790, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5499095916748047 sec\n",
      "Episode 2392, len10, loss:-112.7712, fail, steps:80, opt steps:46, total reward:-24.7000, 0.5456955432891846 sec\n",
      "Episode 2393, len10, loss:-100.6377, fail, steps:80, opt steps:20, total reward:-23.7000, 0.5461571216583252 sec\n",
      "Episode 2394, len10, loss:-103.5404, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5493707656860352 sec\n",
      "Episode 2395, len6, loss:-75.2533, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5502910614013672 sec\n",
      "Episode 2396, len10, loss:-100.3736, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5475070476531982 sec\n",
      "Episode 2397, len6, loss:-77.1781, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5493700504302979 sec\n",
      "Episode 2398, len6, loss:-72.9754, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5488646030426025 sec\n",
      "Episode 2399, len12, loss:-119.3154, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5500063896179199 sec\n",
      "Episode 2400, len10, loss:-104.0885, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5494451522827148 sec\n",
      "Episode 2401, len6, loss:-74.7736, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5504279136657715 sec\n",
      "Episode 2402, len12, loss:-116.5766, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5500848293304443 sec\n",
      "Episode 2403, len6, loss:-72.7179, fail, steps:80, opt steps:8, total reward:-24.0000, 0.6015710830688477 sec\n",
      "Episode 2404, len12, loss:-116.0718, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5493807792663574 sec\n",
      "Episode 2405, len8, loss:-84.6126, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5503251552581787 sec\n",
      "Episode 2406, len6, loss:-73.2635, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5476877689361572 sec\n",
      "Episode 2407, len10, loss:-106.8989, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5487492084503174 sec\n",
      "Episode 2408, len8, loss:-90.0996, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5497815608978271 sec\n",
      "Episode 2409, len10, loss:-108.0677, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5495543479919434 sec\n",
      "Episode 2410, len8, loss:-88.4186, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5494990348815918 sec\n",
      "Episode 2411, len12, loss:-119.4346, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5494086742401123 sec\n",
      "Episode 2412, len6, loss:-69.0809, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5491902828216553 sec\n",
      "Episode 2413, len6, loss:-63.9941, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5499424934387207 sec\n",
      "Episode 2414, len8, loss:-88.8528, fail, steps:80, opt steps:33, total reward:-24.0000, 0.550177812576294 sec\n",
      "Episode 2415, len8, loss:-91.5159, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5497891902923584 sec\n",
      "Episode 2416, len12, loss:-116.1707, fail, steps:80, opt steps:41, total reward:-24.7000, 0.546048641204834 sec\n",
      "Episode 2417, len10, loss:-106.0837, fail, steps:80, opt steps:33, total reward:-24.0000, 0.6011514663696289 sec\n",
      "Episode 2418, len10, loss:-106.3544, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5493097305297852 sec\n",
      "Episode 2419, len8, loss:-94.4603, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490832328796387 sec\n",
      "Episode 2420, len10, loss:-108.4071, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5504374504089355 sec\n",
      "Episode 2421, len6, loss:-72.4979, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5495731830596924 sec\n",
      "Episode 2422, len6, loss:-86.4072, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5445771217346191 sec\n",
      "Episode 2423, len12, loss:-120.0059, fail, steps:80, opt steps:49, total reward:-24.7000, 0.5445678234100342 sec\n",
      "Episode 2424, len8, loss:-87.4098, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5491230487823486 sec\n",
      "Episode 2425, len8, loss:-90.0872, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5489540100097656 sec\n",
      "Episode 2426, len12, loss:-131.5934, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5442376136779785 sec\n",
      "Episode 2427, len6, loss:-79.6986, fail, steps:80, opt steps:7, total reward:-24.7000, 0.5439586639404297 sec\n",
      "Episode 2428, len8, loss:-86.9767, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548367977142334 sec\n",
      "Episode 2429, len10, loss:-102.7768, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5490584373474121 sec\n",
      "Episode 2430, len8, loss:-92.2346, fail, steps:80, opt steps:23, total reward:-23.7000, 0.546959638595581 sec\n",
      "Episode 2431, len8, loss:-99.3715, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5966486930847168 sec\n",
      "Episode 2432, len8, loss:-93.8219, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5477464199066162 sec\n",
      "Episode 2433, len6, loss:-75.2225, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5500516891479492 sec\n",
      "Episode 2434, len6, loss:-75.0427, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5485937595367432 sec\n",
      "Episode 2435, len12, loss:-116.6426, fail, steps:80, opt steps:45, total reward:-24.0000, 0.548621416091919 sec\n",
      "Episode 2436, len6, loss:-82.2365, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5439324378967285 sec\n",
      "Episode 2437, len12, loss:-118.4541, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5478413105010986 sec\n",
      "Episode 2438, len12, loss:-111.2921, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5485439300537109 sec\n",
      "Episode 2439, len12, loss:-117.3088, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5483200550079346 sec\n",
      "Episode 2440, len10, loss:-107.3464, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5450184345245361 sec\n",
      "Episode 2441, len12, loss:-120.3550, fail, steps:80, opt steps:49, total reward:-24.7000, 0.5435731410980225 sec\n",
      "Episode 2442, len12, loss:-119.7387, fail, steps:80, opt steps:19, total reward:-24.0000, 0.552708625793457 sec\n",
      "Episode 2443, len6, loss:-74.3216, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5489287376403809 sec\n",
      "Episode 2444, len6, loss:-75.4001, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5483503341674805 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2445, len8, loss:-94.7805, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5474576950073242 sec\n",
      "Episode 2446, len6, loss:-73.8844, fail, steps:80, opt steps:11, total reward:-24.0000, 0.6026813983917236 sec\n",
      "Episode 2447, len12, loss:-119.5888, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5477659702301025 sec\n",
      "Episode 2448, len10, loss:-106.9685, fail, steps:80, opt steps:44, total reward:-24.7000, 0.5471622943878174 sec\n",
      "Episode 2449, len8, loss:-93.8783, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5484707355499268 sec\n",
      "Episode 2450, len8, loss:-95.5181, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5494720935821533 sec\n",
      "Episode 2451, len10, loss:-104.1173, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5485575199127197 sec\n",
      "Episode 2452, len12, loss:-117.1474, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5493571758270264 sec\n",
      "Episode 2453, len6, loss:-64.2117, fail, steps:80, opt steps:13, total reward:-22.7000, 0.5439903736114502 sec\n",
      "Episode 2454, len8, loss:-88.8720, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5482916831970215 sec\n",
      "Episode 2455, len10, loss:-103.2413, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5485460758209229 sec\n",
      "Episode 2456, len12, loss:-120.5846, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5486137866973877 sec\n",
      "Episode 2457, len8, loss:-84.8493, fail, steps:80, opt steps:20, total reward:-24.0000, 0.548382043838501 sec\n",
      "Episode 2458, len8, loss:-89.6697, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5442888736724854 sec\n",
      "Episode 2459, len10, loss:-101.3442, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5482664108276367 sec\n",
      "Episode 2460, len8, loss:-89.2377, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5487649440765381 sec\n",
      "Episode 2461, len6, loss:-73.0264, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5476973056793213 sec\n",
      "Episode 2462, len12, loss:-112.6181, fail, steps:80, opt steps:54, total reward:-24.0000, 0.6018788814544678 sec\n",
      "Episode 2463, len6, loss:-69.2917, fail, steps:80, opt steps:13, total reward:-24.0000, 0.549185037612915 sec\n",
      "Episode 2464, len6, loss:-70.0945, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5483975410461426 sec\n",
      "Episode 2465, len10, loss:-99.4777, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5493173599243164 sec\n",
      "Episode 2466, len6, loss:-75.9012, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5485525131225586 sec\n",
      "Episode 2467, len10, loss:-100.6349, fail, steps:80, opt steps:28, total reward:-24.4000, 0.5412116050720215 sec\n",
      "Episode 2468, len10, loss:-99.4604, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5476250648498535 sec\n",
      "Episode 2469, len10, loss:-103.7192, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5434448719024658 sec\n",
      "Episode 2470, len8, loss:-85.3757, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5451321601867676 sec\n",
      "Episode 2471, len12, loss:-110.9911, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5491976737976074 sec\n",
      "Episode 2472, len12, loss:-127.9920, fail, steps:80, opt steps:42, total reward:-26.1000, 0.5347518920898438 sec\n",
      "Episode 2473, len8, loss:-86.0528, fail, steps:80, opt steps:35, total reward:-24.0000, 0.546428918838501 sec\n",
      "Episode 2474, len12, loss:-111.4886, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5479402542114258 sec\n",
      "Episode 2475, len8, loss:-84.6600, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5489637851715088 sec\n",
      "Episode 2476, len12, loss:-114.7042, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5484828948974609 sec\n",
      "Episode 2477, len8, loss:-90.3481, fail, steps:80, opt steps:20, total reward:-24.0000, 0.547722578048706 sec\n",
      "Episode 2478, len10, loss:-100.7198, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5985047817230225 sec\n",
      "Episode 2479, len12, loss:-120.3061, fail, steps:80, opt steps:33, total reward:-24.7000, 0.5468132495880127 sec\n",
      "Episode 2480, len12, loss:-112.1873, fail, steps:80, opt steps:43, total reward:-23.7000, 0.5447325706481934 sec\n",
      "Episode 2481, len6, loss:-72.7465, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5482795238494873 sec\n",
      "Episode 2482, len6, loss:-70.3928, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5484857559204102 sec\n",
      "Episode 2483, len12, loss:-111.4423, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5501227378845215 sec\n",
      "Episode 2484, len12, loss:-112.4589, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5490026473999023 sec\n",
      "Episode 2485, len8, loss:-79.1481, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5482723712921143 sec\n",
      "Episode 2486, len10, loss:-112.4118, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5476768016815186 sec\n",
      "Episode 2487, len10, loss:-98.3812, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5489938259124756 sec\n",
      "Episode 2488, len10, loss:-102.4487, fail, steps:80, opt steps:33, total reward:-24.0000, 0.548283576965332 sec\n",
      "Episode 2489, len12, loss:-115.8159, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5479021072387695 sec\n",
      "Episode 2490, len12, loss:-114.0265, fail, steps:80, opt steps:46, total reward:-24.0000, 0.549375057220459 sec\n",
      "Episode 2491, len8, loss:-84.1610, fail, steps:80, opt steps:35, total reward:-24.0000, 0.6093339920043945 sec\n",
      "Episode 2492, len10, loss:-101.3235, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5493214130401611 sec\n",
      "Episode 2493, len12, loss:-119.3834, fail, steps:80, opt steps:23, total reward:-24.0000, 0.549879789352417 sec\n",
      "Episode 2494, len10, loss:-107.1995, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5441250801086426 sec\n",
      "Episode 2495, len12, loss:-119.9627, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5483551025390625 sec\n",
      "Episode 2496, len6, loss:-74.7922, fail, steps:80, opt steps:20, total reward:-24.0000, 0.547919750213623 sec\n",
      "Episode 2497, len8, loss:-94.1867, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5420966148376465 sec\n",
      "Episode 2498, len12, loss:-125.6878, fail, steps:16, opt steps:21, total reward:-15.5000, 0.1226661205291748 sec\n",
      "Episode 2499, len12, loss:-126.1284, fail, steps:80, opt steps:57, total reward:-24.7000, 0.5018494129180908 sec\n",
      "Episode 2500, len10, loss:-100.7184, fail, steps:80, opt steps:40, total reward:-23.4000, 0.522075891494751 sec\n",
      "Episode 2501, len12, loss:-120.6070, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5394506454467773 sec\n",
      "Episode 2502, len8, loss:-90.3026, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5413129329681396 sec\n",
      "Episode 2503, len10, loss:-102.6984, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5456559658050537 sec\n",
      "Episode 2504, len6, loss:-74.9659, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5458614826202393 sec\n",
      "Episode 2505, len12, loss:-114.2005, fail, steps:80, opt steps:24, total reward:-24.0000, 0.6040072441101074 sec\n",
      "Episode 2506, len8, loss:-87.9615, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5471234321594238 sec\n",
      "Episode 2507, len6, loss:-74.9212, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5473799705505371 sec\n",
      "Episode 2508, len10, loss:-105.6785, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5476312637329102 sec\n",
      "Episode 2509, len10, loss:-105.9168, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5466601848602295 sec\n",
      "Episode 2510, len8, loss:-85.4374, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5471220016479492 sec\n",
      "Episode 2511, len12, loss:-119.2170, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5487692356109619 sec\n",
      "Episode 2512, len10, loss:-103.3582, fail, steps:80, opt steps:16, total reward:-24.0000, 0.54842209815979 sec\n",
      "Episode 2513, len10, loss:-97.5322, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5469558238983154 sec\n",
      "Episode 2514, len6, loss:-83.1635, fail, steps:80, opt steps:5, total reward:-24.7000, 0.544032096862793 sec\n",
      "Episode 2515, len6, loss:-77.9302, fail, steps:80, opt steps:16, total reward:-23.7000, 0.5434746742248535 sec\n",
      "Episode 2516, len8, loss:-81.3743, fail, steps:80, opt steps:21, total reward:-24.0000, 0.547461986541748 sec\n",
      "Episode 2517, len6, loss:-77.0769, fail, steps:80, opt steps:10, total reward:-24.0000, 0.551832914352417 sec\n",
      "Episode 2518, len6, loss:-78.9105, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5491576194763184 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2519, len12, loss:-117.0038, fail, steps:80, opt steps:50, total reward:-24.0000, 0.6037044525146484 sec\n",
      "Episode 2520, len8, loss:-89.7064, fail, steps:80, opt steps:9, total reward:-24.7000, 0.5445337295532227 sec\n",
      "Episode 2521, len8, loss:-78.1429, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5480597019195557 sec\n",
      "Episode 2522, len6, loss:-79.3044, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5471467971801758 sec\n",
      "Episode 2523, len8, loss:-76.6187, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5482285022735596 sec\n",
      "Episode 2524, len12, loss:-112.8866, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5480010509490967 sec\n",
      "Episode 2525, len6, loss:-76.8647, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5471282005310059 sec\n",
      "Episode 2526, len12, loss:-108.5035, fail, steps:80, opt steps:39, total reward:-24.0000, 0.548485517501831 sec\n",
      "Episode 2527, len8, loss:-76.8993, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5467562675476074 sec\n",
      "Episode 2528, len10, loss:-99.1507, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5485525131225586 sec\n",
      "Episode 2529, len6, loss:-78.4700, fail, steps:80, opt steps:8, total reward:-24.0000, 0.549109935760498 sec\n",
      "Episode 2530, len10, loss:-109.3911, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5448851585388184 sec\n",
      "Episode 2531, len6, loss:-80.3884, fail, steps:80, opt steps:11, total reward:-24.0000, 0.549696683883667 sec\n",
      "Episode 2532, len10, loss:-99.7711, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5485296249389648 sec\n",
      "Episode 2533, len6, loss:-79.6507, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5988357067108154 sec\n",
      "Episode 2534, len6, loss:-75.9691, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5480215549468994 sec\n",
      "Episode 2535, len6, loss:-78.1305, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5479919910430908 sec\n",
      "Episode 2536, len8, loss:-64.1256, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5486586093902588 sec\n",
      "Episode 2537, len10, loss:-92.1386, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5489275455474854 sec\n",
      "Episode 2538, len6, loss:-73.6922, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5469679832458496 sec\n",
      "Episode 2539, len6, loss:-76.6444, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5479543209075928 sec\n",
      "Episode 2540, len12, loss:-108.0801, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5482449531555176 sec\n",
      "Episode 2541, len12, loss:-105.0300, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5479717254638672 sec\n",
      "Episode 2542, len10, loss:-99.2518, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5478885173797607 sec\n",
      "Episode 2543, len12, loss:-108.2842, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5497555732727051 sec\n",
      "Episode 2544, len6, loss:-82.4769, fail, steps:80, opt steps:10, total reward:-24.7000, 0.5438764095306396 sec\n",
      "Episode 2545, len8, loss:-77.1623, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5472812652587891 sec\n",
      "Episode 2546, len6, loss:-81.6836, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5475795269012451 sec\n",
      "Episode 2547, len6, loss:-76.0079, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5487961769104004 sec\n",
      "Episode 2548, len10, loss:-91.8338, fail, steps:80, opt steps:25, total reward:-24.0000, 0.6017684936523438 sec\n",
      "Episode 2549, len10, loss:-90.0959, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5477313995361328 sec\n",
      "Episode 2550, len12, loss:-108.7456, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5486979484558105 sec\n",
      "Episode 2551, len6, loss:-80.8119, fail, steps:80, opt steps:3, total reward:-24.4000, 0.5419967174530029 sec\n",
      "Episode 2552, len12, loss:-98.4591, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5484757423400879 sec\n",
      "Episode 2553, len12, loss:-99.6794, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5466659069061279 sec\n",
      "Episode 2554, len10, loss:-92.2335, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5480411052703857 sec\n",
      "Episode 2555, len6, loss:-76.1513, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5474941730499268 sec\n",
      "Episode 2556, len6, loss:-77.5134, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5511538982391357 sec\n",
      "Episode 2557, len8, loss:-61.3832, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5489490032196045 sec\n",
      "Episode 2558, len12, loss:-103.3622, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5483179092407227 sec\n",
      "Episode 2559, len8, loss:-68.4513, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5480732917785645 sec\n",
      "Episode 2560, len8, loss:-68.4176, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5425090789794922 sec\n",
      "Episode 2561, len6, loss:-76.5038, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5478329658508301 sec\n",
      "Episode 2562, len6, loss:-80.9545, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5430598258972168 sec\n",
      "Episode 2563, len6, loss:-75.6711, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5461435317993164 sec\n",
      "Episode 2564, len10, loss:-81.6006, fail, steps:80, opt steps:35, total reward:-24.0000, 0.6003401279449463 sec\n",
      "Episode 2565, len10, loss:-86.3425, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5495073795318604 sec\n",
      "Episode 2566, len8, loss:-66.5261, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5474090576171875 sec\n",
      "Episode 2567, len10, loss:-82.0023, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5469424724578857 sec\n",
      "Episode 2568, len10, loss:-85.4437, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5472264289855957 sec\n",
      "Episode 2569, len12, loss:-100.4719, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5489675998687744 sec\n",
      "Episode 2570, len12, loss:-102.1154, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5472664833068848 sec\n",
      "Episode 2571, len12, loss:-107.5154, fail, steps:80, opt steps:53, total reward:-24.7000, 0.5434751510620117 sec\n",
      "Episode 2572, len10, loss:-94.6291, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5478384494781494 sec\n",
      "Episode 2573, len10, loss:-93.7065, fail, steps:80, opt steps:36, total reward:-24.7000, 0.5444827079772949 sec\n",
      "Episode 2574, len12, loss:-105.0555, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5471751689910889 sec\n",
      "Episode 2575, len10, loss:-84.0192, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5473933219909668 sec\n",
      "Episode 2576, len12, loss:-105.3939, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5482175350189209 sec\n",
      "Episode 2577, len12, loss:-98.5957, fail, steps:80, opt steps:43, total reward:-24.0000, 0.546757698059082 sec\n",
      "Episode 2578, len12, loss:-106.7223, fail, steps:80, opt steps:65, total reward:-24.0000, 0.548445463180542 sec\n",
      "Episode 2579, len6, loss:-72.4509, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5479309558868408 sec\n",
      "Episode 2580, len6, loss:-72.8907, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5995218753814697 sec\n",
      "Episode 2581, len8, loss:-57.5854, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5485885143280029 sec\n",
      "Episode 2582, len12, loss:-107.8135, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5448493957519531 sec\n",
      "Episode 2583, len12, loss:-105.5164, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5478763580322266 sec\n",
      "Episode 2584, len8, loss:-61.9088, fail, steps:80, opt steps:27, total reward:-23.7000, 0.5438425540924072 sec\n",
      "Episode 2585, len8, loss:-63.7736, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5468294620513916 sec\n",
      "Episode 2586, len6, loss:-73.1782, fail, steps:80, opt steps:19, total reward:-23.4000, 0.5380141735076904 sec\n",
      "Episode 2587, len8, loss:-60.9211, fail, steps:80, opt steps:19, total reward:-24.0000, 0.549238920211792 sec\n",
      "Episode 2588, len10, loss:-78.9264, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5488274097442627 sec\n",
      "Episode 2589, len10, loss:-79.8866, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5486984252929688 sec\n",
      "Episode 2590, len8, loss:-71.3716, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5451817512512207 sec\n",
      "Episode 2591, len6, loss:-68.2591, fail, steps:80, opt steps:13, total reward:-23.7000, 0.5428709983825684 sec\n",
      "Episode 2592, len10, loss:-82.8558, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5483133792877197 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2593, len6, loss:-81.6449, fail, steps:80, opt steps:16, total reward:-24.0000, 0.6031582355499268 sec\n",
      "Episode 2594, len10, loss:-78.9796, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5489037036895752 sec\n",
      "Episode 2595, len8, loss:-55.1813, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5488362312316895 sec\n",
      "Episode 2596, len8, loss:-56.2389, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5502026081085205 sec\n",
      "Episode 2597, len6, loss:-74.9443, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5493998527526855 sec\n",
      "Episode 2598, len10, loss:-80.9834, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5504329204559326 sec\n",
      "Episode 2599, len8, loss:-65.8659, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5499527454376221 sec\n",
      "Episode 2600, len10, loss:-79.7611, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5484075546264648 sec\n",
      "Episode 2601, len10, loss:-74.7983, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5500197410583496 sec\n",
      "Episode 2602, len6, loss:-70.5866, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5486836433410645 sec\n",
      "Episode 2603, len12, loss:-81.7727, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5498294830322266 sec\n",
      "Episode 2604, len6, loss:-80.0621, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5483715534210205 sec\n",
      "Episode 2605, len6, loss:-75.8865, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5492453575134277 sec\n",
      "Episode 2606, len12, loss:-91.6041, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5496258735656738 sec\n",
      "Episode 2607, len10, loss:-78.9845, fail, steps:80, opt steps:27, total reward:-24.0000, 0.6038215160369873 sec\n",
      "Episode 2608, len10, loss:-74.8010, fail, steps:80, opt steps:34, total reward:-24.7000, 0.5458176136016846 sec\n",
      "Episode 2609, len6, loss:-73.7223, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5493037700653076 sec\n",
      "Episode 2610, len6, loss:-72.0730, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5499267578125 sec\n",
      "Episode 2611, len10, loss:-69.0662, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5500571727752686 sec\n",
      "Episode 2612, len8, loss:-43.9766, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5498566627502441 sec\n",
      "Episode 2613, len10, loss:-84.7927, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5449557304382324 sec\n",
      "Episode 2614, len6, loss:-71.4558, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5483949184417725 sec\n",
      "Episode 2615, len8, loss:-53.0087, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5508825778961182 sec\n",
      "Episode 2616, len6, loss:-82.6539, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5465238094329834 sec\n",
      "Episode 2617, len8, loss:-50.4620, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5448694229125977 sec\n",
      "Episode 2618, len10, loss:-73.7029, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5498809814453125 sec\n",
      "Episode 2619, len10, loss:-85.1952, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5496165752410889 sec\n",
      "Episode 2620, len8, loss:-53.0328, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5500450134277344 sec\n",
      "Episode 2621, len6, loss:-72.9216, fail, steps:80, opt steps:3, total reward:-24.0000, 0.6001741886138916 sec\n",
      "Episode 2622, len10, loss:-98.1490, fail, steps:80, opt steps:46, total reward:-24.7000, 0.5446774959564209 sec\n",
      "Episode 2623, len8, loss:-67.0938, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5492873191833496 sec\n",
      "Episode 2624, len10, loss:-79.5024, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5487017631530762 sec\n",
      "Episode 2625, len10, loss:-84.5576, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5500540733337402 sec\n",
      "Episode 2626, len8, loss:-60.4506, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5499513149261475 sec\n",
      "Episode 2627, len6, loss:-72.3645, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5508720874786377 sec\n",
      "Episode 2628, len8, loss:-53.8497, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5502822399139404 sec\n",
      "Episode 2629, len8, loss:-57.7898, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5451812744140625 sec\n",
      "Episode 2630, len6, loss:-77.7672, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5449800491333008 sec\n",
      "Episode 2631, len8, loss:-53.7401, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5493104457855225 sec\n",
      "Episode 2632, len10, loss:-77.9375, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5485203266143799 sec\n",
      "Episode 2633, len12, loss:-91.9655, fail, steps:80, opt steps:45, total reward:-24.0000, 0.548659086227417 sec\n",
      "Episode 2634, len12, loss:-99.9901, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5488648414611816 sec\n",
      "Episode 2635, len6, loss:-70.8564, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5990462303161621 sec\n",
      "Episode 2636, len6, loss:-69.1357, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5494756698608398 sec\n",
      "Episode 2637, len12, loss:-105.0958, fail, steps:80, opt steps:23, total reward:-24.0000, 0.54901123046875 sec\n",
      "Episode 2638, len12, loss:-103.4753, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5516011714935303 sec\n",
      "Episode 2639, len12, loss:-102.0530, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5521233081817627 sec\n",
      "Episode 2640, len12, loss:-122.6891, fail, steps:80, opt steps:44, total reward:-25.4000, 0.5413248538970947 sec\n",
      "Episode 2641, len10, loss:-90.5584, fail, steps:80, opt steps:29, total reward:-24.0000, 0.549445629119873 sec\n",
      "Episode 2642, len6, loss:-73.1913, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5489859580993652 sec\n",
      "Episode 2643, len12, loss:-114.7977, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5464046001434326 sec\n",
      "Episode 2644, len8, loss:-66.3852, fail, steps:80, opt steps:12, total reward:-24.7000, 0.5439293384552002 sec\n",
      "Episode 2645, len6, loss:-76.2076, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5469918251037598 sec\n",
      "Episode 2646, len6, loss:-78.8712, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5438408851623535 sec\n",
      "Episode 2647, len8, loss:-75.9098, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5495316982269287 sec\n",
      "Episode 2648, len6, loss:-74.1345, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5500507354736328 sec\n",
      "Episode 2649, len6, loss:-75.7831, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5971930027008057 sec\n",
      "Episode 2650, len6, loss:-73.6963, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5487890243530273 sec\n",
      "Episode 2651, len8, loss:-68.5252, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5515742301940918 sec\n",
      "Episode 2652, len10, loss:-94.1969, fail, steps:80, opt steps:39, total reward:-24.0000, 0.548957109451294 sec\n",
      "Episode 2653, len10, loss:-94.8388, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5490000247955322 sec\n",
      "Episode 2654, len10, loss:-89.1861, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5486774444580078 sec\n",
      "Episode 2655, len6, loss:-67.2998, fail, steps:80, opt steps:18, total reward:-22.7000, 0.5438535213470459 sec\n",
      "Episode 2656, len10, loss:-98.3374, fail, steps:80, opt steps:52, total reward:-24.7000, 0.5446608066558838 sec\n",
      "Episode 2657, len10, loss:-97.0067, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5445117950439453 sec\n",
      "Episode 2658, len6, loss:-74.1263, fail, steps:80, opt steps:13, total reward:-24.0000, 0.547492265701294 sec\n",
      "Episode 2659, len10, loss:-82.2903, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5490787029266357 sec\n",
      "Episode 2660, len12, loss:-105.1731, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5502264499664307 sec\n",
      "Episode 2661, len12, loss:-119.8840, fail, steps:80, opt steps:51, total reward:-24.7000, 0.5449182987213135 sec\n",
      "Episode 2662, len12, loss:-99.8587, fail, steps:80, opt steps:51, total reward:-22.7000, 0.5441248416900635 sec\n",
      "Episode 2663, len6, loss:-74.5614, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5479576587677002 sec\n",
      "Episode 2664, len8, loss:-67.6899, fail, steps:80, opt steps:16, total reward:-24.0000, 0.599362850189209 sec\n",
      "Episode 2665, len12, loss:-108.6054, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5487816333770752 sec\n",
      "Episode 2666, len12, loss:-110.6013, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5497028827667236 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2667, len10, loss:-87.1937, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5499694347381592 sec\n",
      "Episode 2668, len8, loss:-71.1497, fail, steps:80, opt steps:22, total reward:-24.7000, 0.545914888381958 sec\n",
      "Episode 2669, len10, loss:-90.2113, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5501489639282227 sec\n",
      "Episode 2670, len8, loss:-66.6209, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5453839302062988 sec\n",
      "Episode 2671, len6, loss:-71.4453, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5499329566955566 sec\n",
      "Episode 2672, len6, loss:-74.4292, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5500750541687012 sec\n",
      "Episode 2673, len10, loss:-94.7389, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5504858493804932 sec\n",
      "Episode 2674, len8, loss:-70.4059, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5443549156188965 sec\n",
      "Episode 2675, len6, loss:-69.5758, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5493819713592529 sec\n",
      "Episode 2676, len10, loss:-96.0495, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5485978126525879 sec\n",
      "Episode 2677, len8, loss:-75.6525, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5445084571838379 sec\n",
      "Episode 2678, len12, loss:-99.5881, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5498147010803223 sec\n",
      "Episode 2679, len8, loss:-72.1681, fail, steps:80, opt steps:34, total reward:-24.0000, 0.548689603805542 sec\n",
      "Episode 2680, len10, loss:-92.1846, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5982406139373779 sec\n",
      "Episode 2681, len10, loss:-93.6141, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5501418113708496 sec\n",
      "Episode 2682, len12, loss:-101.2500, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5500612258911133 sec\n",
      "Episode 2683, len8, loss:-65.0955, fail, steps:80, opt steps:18, total reward:-24.0000, 0.549053430557251 sec\n",
      "Episode 2684, len8, loss:-69.6340, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5484058856964111 sec\n",
      "Episode 2685, len10, loss:-88.4956, fail, steps:80, opt steps:27, total reward:-24.0000, 0.549565315246582 sec\n",
      "Episode 2686, len6, loss:-69.1382, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5492205619812012 sec\n",
      "Episode 2687, len6, loss:-76.0353, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5501449108123779 sec\n",
      "Episode 2688, len6, loss:-73.1719, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5504660606384277 sec\n",
      "Episode 2689, len8, loss:-76.2537, fail, steps:80, opt steps:7, total reward:-24.0000, 0.551311731338501 sec\n",
      "Episode 2690, len6, loss:-74.1610, fail, steps:80, opt steps:19, total reward:-24.0000, 0.549062967300415 sec\n",
      "Episode 2691, len8, loss:-78.7538, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5487926006317139 sec\n",
      "Episode 2692, len6, loss:-79.0784, fail, steps:80, opt steps:15, total reward:-24.7000, 0.546241283416748 sec\n",
      "Episode 2693, len12, loss:-111.8782, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5476915836334229 sec\n",
      "Episode 2694, len12, loss:-109.5438, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5501418113708496 sec\n",
      "Episode 2695, len6, loss:-74.7370, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5480318069458008 sec\n",
      "Episode 2696, len10, loss:-94.4163, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5999088287353516 sec\n",
      "Episode 2697, len8, loss:-75.9570, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5503058433532715 sec\n",
      "Episode 2698, len10, loss:-95.1987, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5516674518585205 sec\n",
      "Episode 2699, len6, loss:-66.9785, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5499372482299805 sec\n",
      "Episode 2700, len10, loss:-102.2303, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5501198768615723 sec\n",
      "Episode 2701, len6, loss:-73.3517, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5445034503936768 sec\n",
      "Episode 2702, len10, loss:-92.2927, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5497047901153564 sec\n",
      "Episode 2703, len10, loss:-93.8443, fail, steps:80, opt steps:32, total reward:-23.7000, 0.5461039543151855 sec\n",
      "Episode 2704, len8, loss:-80.9188, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5494422912597656 sec\n",
      "Episode 2705, len6, loss:-67.4254, fail, steps:80, opt steps:15, total reward:-24.0000, 0.549769401550293 sec\n",
      "Episode 2706, len8, loss:-72.0707, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5496425628662109 sec\n",
      "Episode 2707, len10, loss:-88.0770, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5495522022247314 sec\n",
      "Episode 2708, len12, loss:-104.9435, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5511698722839355 sec\n",
      "Episode 2709, len6, loss:-71.2624, fail, steps:80, opt steps:13, total reward:-24.0000, 0.6035373210906982 sec\n",
      "Episode 2710, len8, loss:-71.1876, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5501754283905029 sec\n",
      "Episode 2711, len10, loss:-97.1432, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5441622734069824 sec\n",
      "Episode 2712, len8, loss:-76.8388, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5500228404998779 sec\n",
      "Episode 2713, len10, loss:-89.7727, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5490610599517822 sec\n",
      "Episode 2714, len12, loss:-112.3657, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5493161678314209 sec\n",
      "Episode 2715, len6, loss:-61.6144, fail, steps:80, opt steps:17, total reward:-22.7000, 0.5447604656219482 sec\n",
      "Episode 2716, len12, loss:-108.2164, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5477466583251953 sec\n",
      "Episode 2717, len6, loss:-70.0222, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5455577373504639 sec\n",
      "Episode 2718, len8, loss:-86.2606, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5438601970672607 sec\n",
      "Episode 2719, len12, loss:-96.4942, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5494871139526367 sec\n",
      "Episode 2720, len10, loss:-88.4702, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5485281944274902 sec\n",
      "Episode 2721, len12, loss:-107.4334, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5502383708953857 sec\n",
      "Episode 2722, len10, loss:-85.9560, fail, steps:80, opt steps:43, total reward:-23.7000, 0.5461883544921875 sec\n",
      "Episode 2723, len10, loss:-88.5885, fail, steps:80, opt steps:44, total reward:-24.0000, 0.6004085540771484 sec\n",
      "Episode 2724, len6, loss:-64.0776, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5495774745941162 sec\n",
      "Episode 2725, len10, loss:-89.9406, fail, steps:80, opt steps:48, total reward:-24.7000, 0.5448482036590576 sec\n",
      "Episode 2726, len12, loss:-111.0795, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5445129871368408 sec\n",
      "Episode 2727, len8, loss:-69.0286, fail, steps:80, opt steps:30, total reward:-23.4000, 0.540722131729126 sec\n",
      "Episode 2728, len10, loss:-86.0999, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5482075214385986 sec\n",
      "Episode 2729, len12, loss:-99.7727, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5494544506072998 sec\n",
      "Episode 2730, len12, loss:-103.4412, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5493924617767334 sec\n",
      "Episode 2731, len6, loss:-62.7308, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5475714206695557 sec\n",
      "Episode 2732, len6, loss:-60.9768, fail, steps:80, opt steps:3, total reward:-24.0000, 0.550504207611084 sec\n",
      "Episode 2733, len6, loss:-74.3168, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5436275005340576 sec\n",
      "Episode 2734, len12, loss:-104.3466, fail, steps:80, opt steps:36, total reward:-23.7000, 0.5444977283477783 sec\n",
      "Episode 2735, len12, loss:-105.3081, fail, steps:80, opt steps:50, total reward:-24.0000, 0.554187536239624 sec\n",
      "Episode 2736, len10, loss:-89.2742, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5481736660003662 sec\n",
      "Episode 2737, len6, loss:-68.4030, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6016428470611572 sec\n",
      "Episode 2738, len6, loss:-80.7456, fail, steps:80, opt steps:6, total reward:-25.4000, 0.5404448509216309 sec\n",
      "Episode 2739, len12, loss:-104.1178, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5491693019866943 sec\n",
      "Episode 2740, len6, loss:-65.7663, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5502142906188965 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2741, len10, loss:-93.6158, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5489704608917236 sec\n",
      "Episode 2742, len10, loss:-92.0575, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5500426292419434 sec\n",
      "Episode 2743, len8, loss:-79.1742, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5495758056640625 sec\n",
      "Episode 2744, len10, loss:-98.0330, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5488686561584473 sec\n",
      "Episode 2745, len12, loss:-111.3956, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5461394786834717 sec\n",
      "Episode 2746, len12, loss:-100.0454, fail, steps:80, opt steps:59, total reward:-24.0000, 0.549309492111206 sec\n",
      "Episode 2747, len10, loss:-94.4885, fail, steps:80, opt steps:42, total reward:-24.0000, 0.549952507019043 sec\n",
      "Episode 2748, len6, loss:-65.7898, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5490007400512695 sec\n",
      "Episode 2749, len10, loss:-91.8029, fail, steps:80, opt steps:50, total reward:-24.0000, 0.549248218536377 sec\n",
      "Episode 2750, len12, loss:-101.9722, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5500531196594238 sec\n",
      "Episode 2751, len10, loss:-97.7325, fail, steps:80, opt steps:33, total reward:-24.0000, 0.6007654666900635 sec\n",
      "Episode 2752, len12, loss:-101.5891, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5492048263549805 sec\n",
      "Episode 2753, len10, loss:-96.8536, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5484986305236816 sec\n",
      "Episode 2754, len8, loss:-74.9630, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5506839752197266 sec\n",
      "Episode 2755, len8, loss:-75.3059, fail, steps:80, opt steps:18, total reward:-24.0000, 0.549652099609375 sec\n",
      "Episode 2756, len12, loss:-114.5744, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5458006858825684 sec\n",
      "Episode 2757, len10, loss:-92.1391, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5488958358764648 sec\n",
      "Episode 2758, len10, loss:-90.8162, fail, steps:80, opt steps:29, total reward:-24.0000, 0.548917293548584 sec\n",
      "Episode 2759, len10, loss:-94.1494, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5500550270080566 sec\n",
      "Episode 2760, len8, loss:-76.4317, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5520398616790771 sec\n",
      "Episode 2761, len8, loss:-79.2626, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5500435829162598 sec\n",
      "Episode 2762, len6, loss:-73.6276, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5450022220611572 sec\n",
      "Episode 2763, len12, loss:-107.6673, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5499453544616699 sec\n",
      "Episode 2764, len6, loss:-78.8584, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5462443828582764 sec\n",
      "Episode 2765, len12, loss:-106.3465, fail, steps:80, opt steps:47, total reward:-24.0000, 0.599541187286377 sec\n",
      "Episode 2766, len12, loss:-112.6020, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5502068996429443 sec\n",
      "Episode 2767, len12, loss:-112.0852, fail, steps:80, opt steps:48, total reward:-24.7000, 0.5450406074523926 sec\n",
      "Episode 2768, len8, loss:-79.4464, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5485665798187256 sec\n",
      "Episode 2769, len12, loss:-117.2402, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5488386154174805 sec\n",
      "Episode 2770, len12, loss:-109.8052, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5507664680480957 sec\n",
      "Episode 2771, len6, loss:-64.7845, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5490810871124268 sec\n",
      "Episode 2772, len6, loss:-63.8631, fail, steps:80, opt steps:12, total reward:-24.7000, 0.5455951690673828 sec\n",
      "Episode 2773, len12, loss:-111.3378, fail, steps:80, opt steps:57, total reward:-24.4000, 0.5407881736755371 sec\n",
      "Episode 2774, len12, loss:-106.5539, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5492568016052246 sec\n",
      "Episode 2775, len6, loss:-70.2327, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5472071170806885 sec\n",
      "Episode 2776, len12, loss:-103.1449, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5485639572143555 sec\n",
      "Episode 2777, len12, loss:-114.4926, fail, steps:80, opt steps:44, total reward:-24.7000, 0.5428836345672607 sec\n",
      "Episode 2778, len8, loss:-75.2719, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5423405170440674 sec\n",
      "Episode 2779, len12, loss:-105.6415, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5480852127075195 sec\n",
      "Episode 2780, len10, loss:-95.1293, fail, steps:80, opt steps:44, total reward:-24.0000, 0.6009228229522705 sec\n",
      "Episode 2781, len12, loss:-96.7693, fail, steps:80, opt steps:61, total reward:-22.4000, 0.5396358966827393 sec\n",
      "Episode 2782, len6, loss:-56.4714, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5460455417633057 sec\n",
      "Episode 2783, len6, loss:-60.7758, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5465874671936035 sec\n",
      "Episode 2784, len10, loss:-92.6173, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5476276874542236 sec\n",
      "Episode 2785, len6, loss:-63.1090, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5476891994476318 sec\n",
      "Episode 2786, len6, loss:-66.8787, fail, steps:80, opt steps:11, total reward:-23.7000, 0.5441453456878662 sec\n",
      "Episode 2787, len8, loss:-72.0479, fail, steps:80, opt steps:27, total reward:-24.0000, 0.548088788986206 sec\n",
      "Episode 2788, len8, loss:-73.5228, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5485563278198242 sec\n",
      "Episode 2789, len8, loss:-73.4327, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5435478687286377 sec\n",
      "Episode 2790, len10, loss:-87.8030, fail, steps:80, opt steps:46, total reward:-24.0000, 0.548166036605835 sec\n",
      "Episode 2791, len12, loss:-101.6934, fail, steps:80, opt steps:51, total reward:-24.0000, 0.547825813293457 sec\n",
      "Episode 2792, len8, loss:-71.1053, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5478432178497314 sec\n",
      "Episode 2793, len12, loss:-101.8558, fail, steps:80, opt steps:51, total reward:-24.0000, 0.549260139465332 sec\n",
      "Episode 2794, len10, loss:-87.7580, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5471987724304199 sec\n",
      "Episode 2795, len8, loss:-72.9323, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5484318733215332 sec\n",
      "Episode 2796, len10, loss:-91.6661, fail, steps:80, opt steps:32, total reward:-24.0000, 0.6015901565551758 sec\n",
      "Episode 2797, len10, loss:-96.8869, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5482709407806396 sec\n",
      "Episode 2798, len6, loss:-61.2780, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5478415489196777 sec\n",
      "Episode 2799, len10, loss:-94.3289, fail, steps:80, opt steps:31, total reward:-24.7000, 0.545586109161377 sec\n",
      "Episode 2800, len6, loss:-61.0098, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5481531620025635 sec\n",
      "Episode 2801, len10, loss:-82.1308, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5490396022796631 sec\n",
      "Episode 2802, len12, loss:-99.1883, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5478391647338867 sec\n",
      "Episode 2803, len12, loss:-103.7066, fail, steps:80, opt steps:59, total reward:-23.4000, 0.5394866466522217 sec\n",
      "Episode 2804, len8, loss:-70.1799, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5478434562683105 sec\n",
      "Episode 2805, len12, loss:-107.2883, fail, steps:80, opt steps:66, total reward:-24.7000, 0.5443615913391113 sec\n",
      "Episode 2806, len6, loss:-56.5781, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5475189685821533 sec\n",
      "Episode 2807, len8, loss:-64.4298, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5478997230529785 sec\n",
      "Episode 2808, len12, loss:-106.0704, fail, steps:80, opt steps:70, total reward:-24.0000, 0.5487771034240723 sec\n",
      "Episode 2809, len10, loss:-90.4183, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5476305484771729 sec\n",
      "Episode 2810, len10, loss:-92.9326, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5492644309997559 sec\n",
      "Episode 2811, len10, loss:-88.7441, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5478034019470215 sec\n",
      "Episode 2812, len8, loss:-76.1215, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5991625785827637 sec\n",
      "Episode 2813, len10, loss:-92.0928, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5476210117340088 sec\n",
      "Episode 2814, len10, loss:-87.9288, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5478973388671875 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2815, len10, loss:-86.5484, fail, steps:80, opt steps:33, total reward:-24.0000, 0.547835111618042 sec\n",
      "Episode 2816, len10, loss:-89.4688, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5470685958862305 sec\n",
      "Episode 2817, len10, loss:-88.0171, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5485689640045166 sec\n",
      "Episode 2818, len6, loss:-57.5713, fail, steps:80, opt steps:13, total reward:-22.7000, 0.5433177947998047 sec\n",
      "Episode 2819, len10, loss:-86.1221, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5486509799957275 sec\n",
      "Episode 2820, len10, loss:-86.7685, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5478620529174805 sec\n",
      "Episode 2821, len12, loss:-103.8475, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5493700504302979 sec\n",
      "Episode 2822, len8, loss:-119.3089, fail, steps:22, opt steps:22, total reward:-17.3000, 0.16239643096923828 sec\n",
      "Episode 2823, len6, loss:-81.2604, fail, steps:80, opt steps:17, total reward:-25.4000, 0.5042760372161865 sec\n",
      "Episode 2824, len10, loss:-79.6162, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5863120555877686 sec\n",
      "Episode 2825, len12, loss:-101.4547, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5395753383636475 sec\n",
      "Episode 2826, len8, loss:-73.4773, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5376718044281006 sec\n",
      "Episode 2827, len12, loss:-103.4922, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5466008186340332 sec\n",
      "Episode 2828, len12, loss:-96.8384, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5459127426147461 sec\n",
      "Episode 2829, len6, loss:-65.8467, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5475568771362305 sec\n",
      "Episode 2830, len12, loss:-97.9547, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5476748943328857 sec\n",
      "Episode 2831, len8, loss:-71.1588, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5458109378814697 sec\n",
      "Episode 2832, len8, loss:-70.4011, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5476751327514648 sec\n",
      "Episode 2833, len8, loss:-64.8888, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5486211776733398 sec\n",
      "Episode 2834, len6, loss:-65.0602, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5487408638000488 sec\n",
      "Episode 2835, len12, loss:-117.7844, fail, steps:80, opt steps:51, total reward:-24.7000, 0.5498499870300293 sec\n",
      "Episode 2836, len12, loss:-98.8064, fail, steps:80, opt steps:62, total reward:-23.7000, 0.5446975231170654 sec\n",
      "Episode 2837, len10, loss:-90.6201, fail, steps:80, opt steps:44, total reward:-24.7000, 0.5440192222595215 sec\n",
      "Episode 2838, len8, loss:-61.3878, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5991342067718506 sec\n",
      "Episode 2839, len6, loss:-69.2161, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5500946044921875 sec\n",
      "Episode 2840, len8, loss:-67.4039, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5485873222351074 sec\n",
      "Episode 2841, len12, loss:-103.2764, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5507199764251709 sec\n",
      "Episode 2842, len10, loss:-91.8914, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5484764575958252 sec\n",
      "Episode 2843, len12, loss:-102.4919, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5491111278533936 sec\n",
      "Episode 2844, len6, loss:-71.7118, fail, steps:80, opt steps:7, total reward:-24.0000, 0.548323392868042 sec\n",
      "Episode 2845, len10, loss:-93.7092, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5501198768615723 sec\n",
      "Episode 2846, len10, loss:-83.9514, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5498888492584229 sec\n",
      "Episode 2847, len8, loss:-67.2917, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5496377944946289 sec\n",
      "Episode 2848, len8, loss:-65.9001, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5502536296844482 sec\n",
      "Episode 2849, len6, loss:-70.4528, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5501284599304199 sec\n",
      "Episode 2850, len10, loss:-84.8053, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5501322746276855 sec\n",
      "Episode 2851, len12, loss:-99.9102, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5497264862060547 sec\n",
      "Episode 2852, len10, loss:-92.6843, fail, steps:80, opt steps:41, total reward:-24.0000, 0.6009814739227295 sec\n",
      "Episode 2853, len8, loss:-64.6314, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5492770671844482 sec\n",
      "Episode 2854, len12, loss:-102.5182, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5497949123382568 sec\n",
      "Episode 2855, len8, loss:-72.3719, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5493907928466797 sec\n",
      "Episode 2856, len10, loss:-92.3383, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5457053184509277 sec\n",
      "Episode 2857, len10, loss:-85.8786, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5486409664154053 sec\n",
      "Episode 2858, len12, loss:-99.9697, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5489211082458496 sec\n",
      "Episode 2859, len12, loss:-102.6566, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5498230457305908 sec\n",
      "Episode 2860, len8, loss:-69.4579, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5494711399078369 sec\n",
      "Episode 2861, len12, loss:-107.6973, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5462720394134521 sec\n",
      "Episode 2862, len6, loss:-67.5140, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5488364696502686 sec\n",
      "Episode 2863, len8, loss:-69.5031, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5503320693969727 sec\n",
      "Episode 2864, len6, loss:-61.1635, fail, steps:80, opt steps:13, total reward:-22.7000, 0.545769453048706 sec\n",
      "Episode 2865, len12, loss:-96.3030, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5501401424407959 sec\n",
      "Episode 2866, len10, loss:-86.9678, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5986356735229492 sec\n",
      "Episode 2867, len8, loss:-71.8441, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5495080947875977 sec\n",
      "Episode 2868, len8, loss:-76.2365, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5467820167541504 sec\n",
      "Episode 2869, len6, loss:-67.7270, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5477781295776367 sec\n",
      "Episode 2870, len10, loss:-85.4020, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5505771636962891 sec\n",
      "Episode 2871, len6, loss:-66.6099, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5496807098388672 sec\n",
      "Episode 2872, len12, loss:-108.9270, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5488817691802979 sec\n",
      "Episode 2873, len8, loss:-71.2440, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5500574111938477 sec\n",
      "Episode 2874, len12, loss:-99.0832, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5495612621307373 sec\n",
      "Episode 2875, len10, loss:-81.6988, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5504477024078369 sec\n",
      "Episode 2876, len10, loss:-87.8967, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5495336055755615 sec\n",
      "Episode 2877, len8, loss:-72.1694, fail, steps:80, opt steps:27, total reward:-23.7000, 0.5462226867675781 sec\n",
      "Episode 2878, len6, loss:-65.7041, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5498249530792236 sec\n",
      "Episode 2879, len6, loss:-73.9932, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5499358177185059 sec\n",
      "Episode 2880, len10, loss:-84.4650, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5479154586791992 sec\n",
      "Episode 2881, len12, loss:-101.8959, fail, steps:80, opt steps:39, total reward:-24.0000, 0.6034040451049805 sec\n",
      "Episode 2882, len6, loss:-71.3433, fail, steps:80, opt steps:6, total reward:-24.0000, 0.549652099609375 sec\n",
      "Episode 2883, len10, loss:-82.9176, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5488717555999756 sec\n",
      "Episode 2884, len10, loss:-90.5602, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5485818386077881 sec\n",
      "Episode 2885, len10, loss:-87.7559, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5481765270233154 sec\n",
      "Episode 2886, len12, loss:-112.4168, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5499086380004883 sec\n",
      "Episode 2887, len10, loss:-87.6724, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5494871139526367 sec\n",
      "Episode 2888, len6, loss:-71.6219, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5502066612243652 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2889, len12, loss:-107.4978, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5495185852050781 sec\n",
      "Episode 2890, len8, loss:-68.6843, fail, steps:80, opt steps:25, total reward:-23.7000, 0.5451548099517822 sec\n",
      "Episode 2891, len8, loss:-78.5138, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5440843105316162 sec\n",
      "Episode 2892, len8, loss:-77.3755, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5484378337860107 sec\n",
      "Episode 2893, len10, loss:-89.7442, fail, steps:80, opt steps:40, total reward:-24.7000, 0.5456523895263672 sec\n",
      "Episode 2894, len12, loss:-96.0015, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5488643646240234 sec\n",
      "Episode 2895, len8, loss:-64.9758, fail, steps:80, opt steps:33, total reward:-24.0000, 0.548229455947876 sec\n",
      "Episode 2896, len6, loss:-79.4884, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5434918403625488 sec\n",
      "Episode 2897, len8, loss:-74.0512, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5999312400817871 sec\n",
      "Episode 2898, len8, loss:-73.4762, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5435097217559814 sec\n",
      "Episode 2899, len6, loss:-66.6372, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5473818778991699 sec\n",
      "Episode 2900, len8, loss:-71.8064, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5492508411407471 sec\n",
      "Episode 2901, len10, loss:-85.2651, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5489237308502197 sec\n",
      "Episode 2902, len12, loss:-99.5390, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5488297939300537 sec\n",
      "Episode 2903, len10, loss:-99.8848, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5445132255554199 sec\n",
      "Episode 2904, len6, loss:-65.0644, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5464131832122803 sec\n",
      "Episode 2905, len6, loss:-67.8107, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5482487678527832 sec\n",
      "Episode 2906, len8, loss:-71.4413, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5473604202270508 sec\n",
      "Episode 2907, len6, loss:-63.0693, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5485601425170898 sec\n",
      "Episode 2908, len8, loss:-84.5732, fail, steps:80, opt steps:15, total reward:-25.4000, 0.5395896434783936 sec\n",
      "Episode 2909, len8, loss:-75.1148, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5471138954162598 sec\n",
      "Episode 2910, len10, loss:-81.0113, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5487070083618164 sec\n",
      "Episode 2911, len6, loss:-70.5466, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5469167232513428 sec\n",
      "Episode 2912, len12, loss:-104.3750, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5484087467193604 sec\n",
      "Episode 2913, len10, loss:-87.1101, fail, steps:80, opt steps:48, total reward:-24.0000, 0.6017649173736572 sec\n",
      "Episode 2914, len8, loss:-62.3980, fail, steps:80, opt steps:22, total reward:-23.7000, 0.5441348552703857 sec\n",
      "Episode 2915, len6, loss:-70.7946, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5482392311096191 sec\n",
      "Episode 2916, len8, loss:-75.9528, fail, steps:80, opt steps:22, total reward:-24.7000, 0.544811487197876 sec\n",
      "Episode 2917, len10, loss:-91.8891, fail, steps:80, opt steps:43, total reward:-23.4000, 0.5402522087097168 sec\n",
      "Episode 2918, len12, loss:-99.0471, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5477054119110107 sec\n",
      "Episode 2919, len8, loss:-79.4137, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5481607913970947 sec\n",
      "Episode 2920, len6, loss:-71.0350, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5477821826934814 sec\n",
      "Episode 2921, len12, loss:-101.5156, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5485453605651855 sec\n",
      "Episode 2922, len8, loss:-65.3041, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5491480827331543 sec\n",
      "Episode 2923, len10, loss:-85.2322, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5441603660583496 sec\n",
      "Episode 2924, len12, loss:-101.7478, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5478255748748779 sec\n",
      "Episode 2925, len6, loss:-72.5182, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485961437225342 sec\n",
      "Episode 2926, len8, loss:-67.8650, fail, steps:80, opt steps:15, total reward:-24.0000, 0.6015686988830566 sec\n",
      "Episode 2927, len12, loss:-98.8141, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5482783317565918 sec\n",
      "Episode 2928, len8, loss:-71.3655, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5489838123321533 sec\n",
      "Episode 2929, len8, loss:-63.3221, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5487790107727051 sec\n",
      "Episode 2930, len12, loss:-84.5909, fail, steps:80, opt steps:58, total reward:-22.7000, 0.5427439212799072 sec\n",
      "Episode 2931, len6, loss:-80.3516, fail, steps:80, opt steps:10, total reward:-24.7000, 0.5426783561706543 sec\n",
      "Episode 2932, len6, loss:-75.9726, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5420036315917969 sec\n",
      "Episode 2933, len8, loss:-70.0746, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5471737384796143 sec\n",
      "Episode 2934, len12, loss:-108.6707, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5437180995941162 sec\n",
      "Episode 2935, len10, loss:-82.9862, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5484623908996582 sec\n",
      "Episode 2936, len6, loss:-73.4908, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5429918766021729 sec\n",
      "Episode 2937, len10, loss:-79.9458, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5475928783416748 sec\n",
      "Episode 2938, len10, loss:-78.1146, fail, steps:80, opt steps:40, total reward:-23.4000, 0.5386531352996826 sec\n",
      "Episode 2939, len12, loss:-99.1389, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5465726852416992 sec\n",
      "Episode 2940, len10, loss:-78.8611, fail, steps:80, opt steps:42, total reward:-24.0000, 0.6048095226287842 sec\n",
      "Episode 2941, len6, loss:-70.8761, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5488057136535645 sec\n",
      "Episode 2942, len8, loss:-67.9065, fail, steps:80, opt steps:17, total reward:-24.0000, 0.548255443572998 sec\n",
      "Episode 2943, len6, loss:-69.4591, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5485575199127197 sec\n",
      "Episode 2944, len8, loss:-59.5163, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5468602180480957 sec\n",
      "Episode 2945, len12, loss:-92.2684, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5478677749633789 sec\n",
      "Episode 2946, len12, loss:-107.1483, fail, steps:80, opt steps:40, total reward:-24.7000, 0.5430395603179932 sec\n",
      "Episode 2947, len6, loss:-67.5377, fail, steps:80, opt steps:18, total reward:-24.0000, 0.54646897315979 sec\n",
      "Episode 2948, len6, loss:-65.8881, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5484294891357422 sec\n",
      "Episode 2949, len12, loss:-95.9564, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5480813980102539 sec\n",
      "Episode 2950, len8, loss:-63.2228, fail, steps:80, opt steps:6, total reward:-24.0000, 0.548241376876831 sec\n",
      "Episode 2951, len10, loss:-82.3748, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5487029552459717 sec\n",
      "Episode 2952, len6, loss:-70.4030, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5480146408081055 sec\n",
      "Episode 2953, len8, loss:-62.9111, fail, steps:80, opt steps:7, total reward:-24.0000, 0.554142951965332 sec\n",
      "Episode 2954, len12, loss:-92.1950, fail, steps:80, opt steps:54, total reward:-24.0000, 0.6052477359771729 sec\n",
      "Episode 2955, len8, loss:-67.5894, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5469183921813965 sec\n",
      "Episode 2956, len8, loss:-76.8503, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5432586669921875 sec\n",
      "Episode 2957, len12, loss:-101.5943, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5477890968322754 sec\n",
      "Episode 2958, len12, loss:-96.0394, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5479826927185059 sec\n",
      "Episode 2959, len8, loss:-69.4917, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5440845489501953 sec\n",
      "Episode 2960, len10, loss:-78.1440, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5471489429473877 sec\n",
      "Episode 2961, len12, loss:-95.3057, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5487730503082275 sec\n",
      "Episode 2962, len10, loss:-82.5209, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5530049800872803 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2963, len10, loss:-89.7336, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5478475093841553 sec\n",
      "Episode 2964, len10, loss:-80.2289, fail, steps:80, opt steps:22, total reward:-24.0000, 0.548213005065918 sec\n",
      "Episode 2965, len10, loss:-81.4114, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5487217903137207 sec\n",
      "Episode 2966, len12, loss:-98.7865, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5478754043579102 sec\n",
      "Episode 2967, len8, loss:-68.1717, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5495631694793701 sec\n",
      "Episode 2968, len10, loss:-84.9557, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5989274978637695 sec\n",
      "Episode 2969, len8, loss:-71.0880, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5484840869903564 sec\n",
      "Episode 2970, len10, loss:-86.4067, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5480020046234131 sec\n",
      "Episode 2971, len8, loss:-69.8538, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5484616756439209 sec\n",
      "Episode 2972, len12, loss:-108.0216, fail, steps:80, opt steps:62, total reward:-24.7000, 0.5456116199493408 sec\n",
      "Episode 2973, len10, loss:-88.0145, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5492489337921143 sec\n",
      "Episode 2974, len12, loss:-93.9862, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5478243827819824 sec\n",
      "Episode 2975, len10, loss:-87.0700, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5471477508544922 sec\n",
      "Episode 2976, len12, loss:-96.5006, fail, steps:80, opt steps:17, total reward:-23.4000, 0.5388495922088623 sec\n",
      "Episode 2977, len10, loss:-98.7707, fail, steps:80, opt steps:46, total reward:-24.7000, 0.5436599254608154 sec\n",
      "Episode 2978, len8, loss:-77.8661, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5475428104400635 sec\n",
      "Episode 2979, len12, loss:-98.4749, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5503921508789062 sec\n",
      "Episode 2980, len8, loss:-81.1186, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5490443706512451 sec\n",
      "Episode 2981, len8, loss:-83.4846, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5439839363098145 sec\n",
      "Episode 2982, len10, loss:-99.0609, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5960869789123535 sec\n",
      "Episode 2983, len12, loss:-103.1572, fail, steps:80, opt steps:73, total reward:-24.0000, 0.5491986274719238 sec\n",
      "Episode 2984, len10, loss:-92.6620, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5489647388458252 sec\n",
      "Episode 2985, len6, loss:-69.8331, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5502703189849854 sec\n",
      "Episode 2986, len6, loss:-70.2027, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5477170944213867 sec\n",
      "Episode 2987, len6, loss:-70.1214, fail, steps:80, opt steps:7, total reward:-24.0000, 0.550137996673584 sec\n",
      "Episode 2988, len6, loss:-81.1326, fail, steps:80, opt steps:8, total reward:-25.4000, 0.5405731201171875 sec\n",
      "Episode 2989, len10, loss:-94.0451, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5486347675323486 sec\n",
      "Episode 2990, len6, loss:-67.5882, fail, steps:80, opt steps:13, total reward:-22.7000, 0.5440921783447266 sec\n",
      "Episode 2991, len6, loss:-68.9615, fail, steps:80, opt steps:5, total reward:-24.0000, 0.549095630645752 sec\n",
      "Episode 2992, len12, loss:-103.5991, fail, steps:80, opt steps:54, total reward:-24.0000, 0.550473690032959 sec\n",
      "Episode 2993, len12, loss:-107.8620, fail, steps:80, opt steps:54, total reward:-24.0000, 0.549821138381958 sec\n",
      "Episode 2994, len10, loss:-101.0269, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5456783771514893 sec\n",
      "Episode 2995, len12, loss:-106.1719, fail, steps:80, opt steps:44, total reward:-24.0000, 0.551680326461792 sec\n",
      "Episode 2996, len8, loss:-79.2621, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5505766868591309 sec\n",
      "Episode 2997, len10, loss:-95.5685, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5985288619995117 sec\n",
      "Episode 2998, len6, loss:-67.8871, fail, steps:80, opt steps:21, total reward:-24.0000, 0.548018217086792 sec\n",
      "Episode 2999, len8, loss:-83.7850, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5451841354370117 sec\n",
      "Episode 3000, len6, loss:-66.7370, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5489301681518555 sec\n",
      "Checkpoint saved at episode 3000 to /home/mcwave/code/autocode/datasets/rl_sort_transformer_easy/list6_12_transformer3_128_gamma07_step80_v3_merge_2_sorted/ckpt_3000_0.0010_26.24_vs_5.25.pth\n",
      "Learning rate = 0.000094\n",
      "Episode 3001, len8, loss:-70.8939, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5481393337249756 sec\n",
      "Episode 3002, len6, loss:-72.0143, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5501139163970947 sec\n",
      "Episode 3003, len10, loss:-98.5458, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5510685443878174 sec\n",
      "Episode 3004, len10, loss:-100.0721, fail, steps:80, opt steps:32, total reward:-23.7000, 0.5464766025543213 sec\n",
      "Episode 3005, len12, loss:-106.0633, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5510623455047607 sec\n",
      "Episode 3006, len10, loss:-97.2861, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5490443706512451 sec\n",
      "Episode 3007, len10, loss:-94.5865, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5479063987731934 sec\n",
      "Episode 3008, len10, loss:-93.7911, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5509512424468994 sec\n",
      "Episode 3009, len12, loss:-106.9305, fail, steps:80, opt steps:55, total reward:-24.0000, 0.551006555557251 sec\n",
      "Episode 3010, len8, loss:-86.7329, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5437204837799072 sec\n",
      "Episode 3011, len6, loss:-75.8774, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5491535663604736 sec\n",
      "Episode 3012, len12, loss:-108.3738, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5493223667144775 sec\n",
      "Episode 3013, len6, loss:-62.0668, fail, steps:80, opt steps:19, total reward:-22.4000, 0.5899074077606201 sec\n",
      "Episode 3014, len10, loss:-94.6958, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5485482215881348 sec\n",
      "Episode 3015, len6, loss:-70.3512, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5484879016876221 sec\n",
      "Episode 3016, len6, loss:-68.9035, fail, steps:80, opt steps:17, total reward:-23.7000, 0.5458927154541016 sec\n",
      "Episode 3017, len10, loss:-95.2543, fail, steps:80, opt steps:30, total reward:-23.7000, 0.5437576770782471 sec\n",
      "Episode 3018, len8, loss:-81.5404, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5488173961639404 sec\n",
      "Episode 3019, len10, loss:-95.1150, fail, steps:80, opt steps:37, total reward:-24.0000, 0.550316333770752 sec\n",
      "Episode 3020, len10, loss:-99.6135, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5514469146728516 sec\n",
      "Episode 3021, len6, loss:-70.5236, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5502710342407227 sec\n",
      "Episode 3022, len12, loss:-111.0670, fail, steps:80, opt steps:54, total reward:-24.7000, 0.5442643165588379 sec\n",
      "Episode 3023, len6, loss:-79.4628, fail, steps:80, opt steps:14, total reward:-24.1000, 0.5356030464172363 sec\n",
      "Episode 3024, len12, loss:-104.2527, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5490281581878662 sec\n",
      "Episode 3025, len10, loss:-98.7278, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5489153861999512 sec\n",
      "Episode 3026, len12, loss:-109.1062, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5495383739471436 sec\n",
      "Episode 3027, len6, loss:-71.9644, fail, steps:80, opt steps:6, total reward:-24.0000, 0.6022241115570068 sec\n",
      "Episode 3028, len12, loss:-117.6411, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5453052520751953 sec\n",
      "Episode 3029, len6, loss:-67.3961, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5479652881622314 sec\n",
      "Episode 3030, len8, loss:-76.5860, fail, steps:80, opt steps:29, total reward:-22.7000, 0.5447165966033936 sec\n",
      "Episode 3031, len12, loss:-105.6212, fail, steps:80, opt steps:42, total reward:-24.0000, 0.550748348236084 sec\n",
      "Episode 3032, len10, loss:-100.2327, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5489883422851562 sec\n",
      "Episode 3033, len6, loss:-70.9282, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5489461421966553 sec\n",
      "Episode 3034, len12, loss:-99.8448, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5496115684509277 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3035, len12, loss:-106.8144, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5498418807983398 sec\n",
      "Episode 3036, len6, loss:-75.1243, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5444319248199463 sec\n",
      "Episode 3037, len10, loss:-101.7091, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5492305755615234 sec\n",
      "Episode 3038, len6, loss:-70.7467, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5487303733825684 sec\n",
      "Episode 3039, len10, loss:-96.8134, fail, steps:80, opt steps:34, total reward:-24.0000, 0.550652265548706 sec\n",
      "Episode 3040, len10, loss:-106.4166, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5506415367126465 sec\n",
      "Episode 3041, len12, loss:-115.7322, fail, steps:80, opt steps:46, total reward:-24.7000, 0.5977411270141602 sec\n",
      "Episode 3042, len8, loss:-83.0595, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5481100082397461 sec\n",
      "Episode 3043, len12, loss:-108.2464, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5494823455810547 sec\n",
      "Episode 3044, len10, loss:-91.5668, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5491251945495605 sec\n",
      "Episode 3045, len8, loss:-79.1645, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5486135482788086 sec\n",
      "Episode 3046, len8, loss:-92.2051, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5507214069366455 sec\n",
      "Episode 3047, len6, loss:-86.2717, fail, steps:80, opt steps:5, total reward:-26.1000, 0.5375144481658936 sec\n",
      "Episode 3048, len8, loss:-85.7206, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5488486289978027 sec\n",
      "Episode 3049, len10, loss:-107.7549, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5436453819274902 sec\n",
      "Episode 3050, len8, loss:-86.0856, fail, steps:80, opt steps:16, total reward:-24.0000, 0.548250675201416 sec\n",
      "Episode 3051, len8, loss:-75.5827, fail, steps:80, opt steps:30, total reward:-22.7000, 0.5460987091064453 sec\n",
      "Episode 3052, len10, loss:-100.1958, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5491974353790283 sec\n",
      "Episode 3053, len10, loss:-99.5227, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5491881370544434 sec\n",
      "Episode 3054, len12, loss:-111.6105, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5485677719116211 sec\n",
      "Episode 3055, len6, loss:-67.3031, fail, steps:80, opt steps:11, total reward:-24.0000, 0.599860668182373 sec\n",
      "Episode 3056, len8, loss:-84.8085, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5491101741790771 sec\n",
      "Episode 3057, len10, loss:-101.8845, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5493576526641846 sec\n",
      "Episode 3058, len10, loss:-97.1939, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5493793487548828 sec\n",
      "Episode 3059, len6, loss:-67.5921, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5494306087493896 sec\n",
      "Episode 3060, len12, loss:-101.9258, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5479633808135986 sec\n",
      "Episode 3061, len8, loss:-82.7798, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5493526458740234 sec\n",
      "Episode 3062, len6, loss:-69.4783, fail, steps:80, opt steps:10, total reward:-24.0000, 0.549720048904419 sec\n",
      "Episode 3063, len6, loss:-78.2221, fail, steps:80, opt steps:7, total reward:-24.7000, 0.5458312034606934 sec\n",
      "Episode 3064, len12, loss:-109.3517, fail, steps:80, opt steps:63, total reward:-24.0000, 0.548907995223999 sec\n",
      "Episode 3065, len6, loss:-71.3619, fail, steps:80, opt steps:11, total reward:-24.0000, 0.54903244972229 sec\n",
      "Episode 3066, len10, loss:-94.3759, fail, steps:80, opt steps:25, total reward:-23.4000, 0.5424830913543701 sec\n",
      "Episode 3067, len6, loss:-70.5842, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5454158782958984 sec\n",
      "Episode 3068, len12, loss:-106.6826, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5496408939361572 sec\n",
      "Episode 3069, len12, loss:-103.1599, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5995440483093262 sec\n",
      "Episode 3070, len6, loss:-70.5731, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5490596294403076 sec\n",
      "Episode 3071, len10, loss:-98.5799, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5494353771209717 sec\n",
      "Episode 3072, len6, loss:-66.9758, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5496370792388916 sec\n",
      "Episode 3073, len10, loss:-95.8970, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5498685836791992 sec\n",
      "Episode 3074, len6, loss:-67.7540, fail, steps:80, opt steps:18, total reward:-23.7000, 0.5464329719543457 sec\n",
      "Episode 3075, len10, loss:-104.3498, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5447871685028076 sec\n",
      "Episode 3076, len10, loss:-101.8336, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5490493774414062 sec\n",
      "Episode 3077, len6, loss:-68.8800, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5456385612487793 sec\n",
      "Episode 3078, len6, loss:-60.3912, fail, steps:80, opt steps:13, total reward:-24.0000, 0.549360990524292 sec\n",
      "Episode 3079, len12, loss:-100.8120, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5461969375610352 sec\n",
      "Episode 3080, len10, loss:-94.8816, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5492465496063232 sec\n",
      "Episode 3081, len10, loss:-98.0258, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5447976589202881 sec\n",
      "Episode 3082, len6, loss:-60.3569, fail, steps:80, opt steps:8, total reward:-24.0000, 0.54897141456604 sec\n",
      "Episode 3083, len12, loss:-102.6016, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5993831157684326 sec\n",
      "Episode 3084, len6, loss:-66.5472, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5458283424377441 sec\n",
      "Episode 3085, len6, loss:-60.1834, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5488414764404297 sec\n",
      "Episode 3086, len6, loss:-62.2869, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5486071109771729 sec\n",
      "Episode 3087, len10, loss:-97.7447, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5500218868255615 sec\n",
      "Episode 3088, len12, loss:-109.4913, fail, steps:80, opt steps:53, total reward:-24.7000, 0.5451052188873291 sec\n",
      "Episode 3089, len8, loss:-71.8880, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5494205951690674 sec\n",
      "Episode 3090, len12, loss:-97.0650, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5489256381988525 sec\n",
      "Episode 3091, len8, loss:-73.4758, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5504202842712402 sec\n",
      "Episode 3092, len8, loss:-82.1445, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5497455596923828 sec\n",
      "Episode 3093, len12, loss:-96.7009, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5491335391998291 sec\n",
      "Episode 3094, len10, loss:-101.3110, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5468590259552002 sec\n",
      "Episode 3095, len6, loss:-58.9058, fail, steps:80, opt steps:19, total reward:-23.4000, 0.5395863056182861 sec\n",
      "Episode 3096, len6, loss:-64.6511, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5484726428985596 sec\n",
      "Episode 3097, len10, loss:-97.9920, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5441486835479736 sec\n",
      "Episode 3098, len12, loss:-109.6771, fail, steps:80, opt steps:39, total reward:-24.7000, 0.594346284866333 sec\n",
      "Episode 3099, len12, loss:-107.6053, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5486557483673096 sec\n",
      "Episode 3100, len6, loss:-69.1811, fail, steps:80, opt steps:20, total reward:-24.0000, 0.548426628112793 sec\n",
      "Episode 3101, len6, loss:-68.2219, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5477325916290283 sec\n",
      "Episode 3102, len8, loss:-90.4911, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5437891483306885 sec\n",
      "Episode 3103, len8, loss:-85.3540, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5497288703918457 sec\n",
      "Episode 3104, len10, loss:-101.1888, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5437195301055908 sec\n",
      "Episode 3105, len6, loss:-67.1596, fail, steps:80, opt steps:12, total reward:-24.0000, 0.547137975692749 sec\n",
      "Episode 3106, len12, loss:-109.4312, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5490026473999023 sec\n",
      "Episode 3107, len12, loss:-114.0917, fail, steps:80, opt steps:41, total reward:-24.7000, 0.546295166015625 sec\n",
      "Episode 3108, len8, loss:-82.9454, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5494120121002197 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3109, len12, loss:-92.6237, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5492701530456543 sec\n",
      "Episode 3110, len12, loss:-98.4733, fail, steps:80, opt steps:73, total reward:-24.0000, 0.5498604774475098 sec\n",
      "Episode 3111, len10, loss:-91.8525, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5501430034637451 sec\n",
      "Episode 3112, len8, loss:-79.3116, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5495290756225586 sec\n",
      "Episode 3113, len6, loss:-66.1194, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5484175682067871 sec\n",
      "Episode 3114, len12, loss:-97.2692, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5996358394622803 sec\n",
      "Episode 3115, len6, loss:-65.3063, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5495967864990234 sec\n",
      "Episode 3116, len10, loss:-97.3718, fail, steps:80, opt steps:36, total reward:-24.7000, 0.5442640781402588 sec\n",
      "Episode 3117, len10, loss:-106.6184, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5448973178863525 sec\n",
      "Episode 3118, len8, loss:-80.9520, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5492455959320068 sec\n",
      "Episode 3119, len12, loss:-103.2394, fail, steps:80, opt steps:56, total reward:-24.7000, 0.5461828708648682 sec\n",
      "Episode 3120, len12, loss:-93.1048, fail, steps:80, opt steps:44, total reward:-24.0000, 0.549140214920044 sec\n",
      "Episode 3121, len6, loss:-64.1005, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5490262508392334 sec\n",
      "Episode 3122, len10, loss:-99.6316, fail, steps:80, opt steps:43, total reward:-24.7000, 0.5458929538726807 sec\n",
      "Episode 3123, len12, loss:-99.6720, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5443994998931885 sec\n",
      "Episode 3124, len8, loss:-91.3487, fail, steps:80, opt steps:25, total reward:-24.7000, 0.544675350189209 sec\n",
      "Episode 3125, len12, loss:-97.9128, fail, steps:80, opt steps:44, total reward:-23.7000, 0.5450615882873535 sec\n",
      "Episode 3126, len6, loss:-66.5510, fail, steps:80, opt steps:18, total reward:-24.0000, 0.548830509185791 sec\n",
      "Episode 3127, len8, loss:-77.4448, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5488018989562988 sec\n",
      "Episode 3128, len8, loss:-69.2831, fail, steps:80, opt steps:17, total reward:-22.7000, 0.544548749923706 sec\n",
      "Episode 3129, len8, loss:-76.1174, fail, steps:80, opt steps:21, total reward:-23.7000, 0.5441815853118896 sec\n",
      "Episode 3130, len6, loss:-72.5978, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5939040184020996 sec\n",
      "Episode 3131, len8, loss:-85.5965, fail, steps:80, opt steps:7, total reward:-24.7000, 0.5434372425079346 sec\n",
      "Episode 3132, len10, loss:-89.7523, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5487847328186035 sec\n",
      "Episode 3133, len8, loss:-89.5678, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5456199645996094 sec\n",
      "Episode 3134, len8, loss:-78.1538, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5495026111602783 sec\n",
      "Episode 3135, len8, loss:-75.6069, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5490071773529053 sec\n",
      "Episode 3136, len8, loss:-76.6501, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5491039752960205 sec\n",
      "Episode 3137, len6, loss:-65.5180, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5487427711486816 sec\n",
      "Episode 3138, len6, loss:-69.1735, fail, steps:80, opt steps:15, total reward:-24.0000, 0.549264669418335 sec\n",
      "Episode 3139, len12, loss:-93.4406, fail, steps:80, opt steps:78, total reward:-24.0000, 0.5509417057037354 sec\n",
      "Episode 3140, len8, loss:-81.8546, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485811233520508 sec\n",
      "Episode 3141, len10, loss:-103.4790, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5440566539764404 sec\n",
      "Episode 3142, len8, loss:-84.8479, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5486118793487549 sec\n",
      "Episode 3143, len6, loss:-75.2975, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5993061065673828 sec\n",
      "Episode 3144, len12, loss:-95.7431, fail, steps:80, opt steps:28, total reward:-24.0000, 0.549220085144043 sec\n",
      "Episode 3145, len8, loss:-88.0515, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5443112850189209 sec\n",
      "Episode 3146, len6, loss:-66.9656, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5495169162750244 sec\n",
      "Episode 3147, len12, loss:-103.7243, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5468003749847412 sec\n",
      "Episode 3148, len8, loss:-80.4081, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5488359928131104 sec\n",
      "Episode 3149, len6, loss:-68.1173, fail, steps:80, opt steps:16, total reward:-23.7000, 0.5447201728820801 sec\n",
      "Episode 3150, len10, loss:-105.6337, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5495452880859375 sec\n",
      "Episode 3151, len8, loss:-84.5808, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5458853244781494 sec\n",
      "Episode 3152, len10, loss:-97.6537, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5485050678253174 sec\n",
      "Episode 3153, len8, loss:-83.1909, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5490198135375977 sec\n",
      "Episode 3154, len12, loss:-107.1683, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5488672256469727 sec\n",
      "Episode 3155, len8, loss:-43.5665, fail, steps:0, opt steps:20, total reward:-10.0000, 0.021740436553955078 sec\n",
      "Episode 3156, len6, loss:-60.9563, fail, steps:80, opt steps:15, total reward:-23.7000, 0.48702192306518555 sec\n",
      "Episode 3157, len10, loss:-89.9401, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5241055488586426 sec\n",
      "Episode 3158, len6, loss:-67.2226, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5864927768707275 sec\n",
      "Episode 3159, len8, loss:-79.1078, fail, steps:80, opt steps:27, total reward:-24.0000, 0.540369987487793 sec\n",
      "Episode 3160, len12, loss:-106.9435, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5427732467651367 sec\n",
      "Episode 3161, len12, loss:-104.1275, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5445940494537354 sec\n",
      "Episode 3162, len12, loss:-103.1134, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5475728511810303 sec\n",
      "Episode 3163, len8, loss:-80.2032, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5469505786895752 sec\n",
      "Episode 3164, len12, loss:-103.5860, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5494897365570068 sec\n",
      "Episode 3165, len8, loss:-83.7696, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5484480857849121 sec\n",
      "Episode 3166, len8, loss:-74.6005, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5493457317352295 sec\n",
      "Episode 3167, len12, loss:-100.1098, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5499303340911865 sec\n",
      "Episode 3168, len12, loss:-100.3972, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5494139194488525 sec\n",
      "Episode 3169, len12, loss:-113.3101, fail, steps:80, opt steps:53, total reward:-24.7000, 0.5444240570068359 sec\n",
      "Episode 3170, len12, loss:-97.5837, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5493080615997314 sec\n",
      "Episode 3171, len8, loss:-83.7134, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5489726066589355 sec\n",
      "Episode 3172, len6, loss:-61.3333, fail, steps:80, opt steps:7, total reward:-24.0000, 0.606175422668457 sec\n",
      "Episode 3173, len12, loss:-101.2792, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5486063957214355 sec\n",
      "Episode 3174, len6, loss:-63.9256, fail, steps:80, opt steps:19, total reward:-24.0000, 0.550222635269165 sec\n",
      "Episode 3175, len6, loss:-66.7805, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5490696430206299 sec\n",
      "Episode 3176, len8, loss:-70.4522, fail, steps:80, opt steps:19, total reward:-24.0000, 0.549297571182251 sec\n",
      "Episode 3177, len6, loss:-63.8831, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5480329990386963 sec\n",
      "Episode 3178, len8, loss:-77.1251, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5490968227386475 sec\n",
      "Episode 3179, len8, loss:-81.2575, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5483126640319824 sec\n",
      "Episode 3180, len8, loss:-86.3099, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5440778732299805 sec\n",
      "Episode 3181, len8, loss:-80.8501, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5494194030761719 sec\n",
      "Episode 3182, len10, loss:-96.8884, fail, steps:80, opt steps:33, total reward:-24.7000, 0.544893741607666 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3183, len12, loss:-100.2806, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5496139526367188 sec\n",
      "Episode 3184, len8, loss:-74.9043, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5496728420257568 sec\n",
      "Episode 3185, len6, loss:-65.8034, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5481219291687012 sec\n",
      "Episode 3186, len6, loss:-66.0747, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5978765487670898 sec\n",
      "Episode 3187, len10, loss:-93.2174, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5479404926300049 sec\n",
      "Episode 3188, len8, loss:-79.3224, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5484127998352051 sec\n",
      "Episode 3189, len10, loss:-90.7861, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5495326519012451 sec\n",
      "Episode 3190, len10, loss:-88.4989, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5487875938415527 sec\n",
      "Episode 3191, len12, loss:-100.4657, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5497362613677979 sec\n",
      "Episode 3192, len12, loss:-93.9877, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5487914085388184 sec\n",
      "Episode 3193, len8, loss:-75.3212, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5463628768920898 sec\n",
      "Episode 3194, len10, loss:-91.4841, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5481734275817871 sec\n",
      "Episode 3195, len12, loss:-91.0086, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5480072498321533 sec\n",
      "Episode 3196, len8, loss:-78.7498, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5441079139709473 sec\n",
      "Episode 3197, len8, loss:-78.5038, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5493373870849609 sec\n",
      "Episode 3198, len12, loss:-99.0968, fail, steps:80, opt steps:45, total reward:-24.0000, 0.549098014831543 sec\n",
      "Episode 3199, len12, loss:-96.6859, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5484459400177002 sec\n",
      "Episode 3200, len10, loss:-84.5436, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5975124835968018 sec\n",
      "Episode 3201, len8, loss:-79.4710, fail, steps:80, opt steps:23, total reward:-24.7000, 0.545435905456543 sec\n",
      "Episode 3202, len8, loss:-69.4275, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5477886199951172 sec\n",
      "Episode 3203, len10, loss:-97.4096, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5433714389801025 sec\n",
      "Episode 3204, len8, loss:-72.1554, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5484318733215332 sec\n",
      "Episode 3205, len10, loss:-97.9042, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5480046272277832 sec\n",
      "Episode 3206, len10, loss:-88.0446, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5470106601715088 sec\n",
      "Episode 3207, len12, loss:-90.8960, fail, steps:80, opt steps:52, total reward:-24.0000, 0.548525333404541 sec\n",
      "Episode 3208, len8, loss:-79.2930, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5432701110839844 sec\n",
      "Episode 3209, len6, loss:-53.5351, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5483760833740234 sec\n",
      "Episode 3210, len12, loss:-95.0684, fail, steps:80, opt steps:75, total reward:-24.0000, 0.5483787059783936 sec\n",
      "Episode 3211, len10, loss:-96.5670, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5496807098388672 sec\n",
      "Episode 3212, len8, loss:-77.1006, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5432872772216797 sec\n",
      "Episode 3213, len12, loss:-87.7963, fail, steps:80, opt steps:73, total reward:-24.0000, 0.5479719638824463 sec\n",
      "Episode 3214, len10, loss:-92.2073, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5484073162078857 sec\n",
      "Episode 3215, len6, loss:-59.7484, fail, steps:80, opt steps:13, total reward:-24.0000, 0.597297191619873 sec\n",
      "Episode 3216, len10, loss:-92.1685, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5490322113037109 sec\n",
      "Episode 3217, len6, loss:-68.8628, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5435581207275391 sec\n",
      "Episode 3218, len10, loss:-92.8728, fail, steps:80, opt steps:22, total reward:-24.0000, 0.547111988067627 sec\n",
      "Episode 3219, len10, loss:-85.0116, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5473208427429199 sec\n",
      "Episode 3220, len10, loss:-87.7043, fail, steps:80, opt steps:39, total reward:-24.0000, 0.548945426940918 sec\n",
      "Episode 3221, len12, loss:-99.3337, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5485565662384033 sec\n",
      "Episode 3222, len6, loss:-66.1907, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5480115413665771 sec\n",
      "Episode 3223, len6, loss:-62.7346, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5493452548980713 sec\n",
      "Episode 3224, len8, loss:-77.6037, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5489585399627686 sec\n",
      "Episode 3225, len12, loss:-91.5471, fail, steps:80, opt steps:51, total reward:-24.0000, 0.547996997833252 sec\n",
      "Episode 3226, len12, loss:-94.3188, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5501241683959961 sec\n",
      "Episode 3227, len8, loss:-67.6323, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5500352382659912 sec\n",
      "Episode 3228, len12, loss:-105.4133, fail, steps:80, opt steps:39, total reward:-24.7000, 0.545513391494751 sec\n",
      "Episode 3229, len8, loss:-70.9222, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5475883483886719 sec\n",
      "Episode 3230, len8, loss:-73.9440, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5491056442260742 sec\n",
      "Episode 3231, len12, loss:-95.5403, fail, steps:80, opt steps:63, total reward:-23.7000, 0.5948441028594971 sec\n",
      "Episode 3232, len10, loss:-84.4696, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5474655628204346 sec\n",
      "Episode 3233, len6, loss:-61.3210, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5431551933288574 sec\n",
      "Episode 3234, len8, loss:-69.2563, fail, steps:80, opt steps:29, total reward:-23.4000, 0.5385646820068359 sec\n",
      "Episode 3235, len6, loss:-64.8535, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5431225299835205 sec\n",
      "Episode 3236, len6, loss:-55.9796, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5468862056732178 sec\n",
      "Episode 3237, len6, loss:-55.3601, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5485639572143555 sec\n",
      "Episode 3238, len8, loss:-69.6900, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5486423969268799 sec\n",
      "Episode 3239, len6, loss:-61.8332, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5474481582641602 sec\n",
      "Episode 3240, len12, loss:-106.3708, fail, steps:80, opt steps:52, total reward:-24.7000, 0.5438499450683594 sec\n",
      "Episode 3241, len6, loss:-59.5124, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5471727848052979 sec\n",
      "Episode 3242, len8, loss:-69.2875, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5476906299591064 sec\n",
      "Episode 3243, len6, loss:-50.4445, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5491945743560791 sec\n",
      "Episode 3244, len10, loss:-83.8762, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5482721328735352 sec\n",
      "Episode 3245, len6, loss:-52.7032, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5486946105957031 sec\n",
      "Episode 3246, len12, loss:-96.6335, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5441408157348633 sec\n",
      "Episode 3247, len10, loss:-87.7567, fail, steps:80, opt steps:29, total reward:-24.0000, 0.6025180816650391 sec\n",
      "Episode 3248, len12, loss:-94.3730, fail, steps:80, opt steps:26, total reward:-23.7000, 0.5440092086791992 sec\n",
      "Episode 3249, len8, loss:-72.6626, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5443565845489502 sec\n",
      "Episode 3250, len12, loss:-92.5846, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5491704940795898 sec\n",
      "Episode 3251, len12, loss:-89.2083, fail, steps:80, opt steps:45, total reward:-24.0000, 0.547095775604248 sec\n",
      "Episode 3252, len8, loss:-63.5547, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5487513542175293 sec\n",
      "Episode 3253, len6, loss:-50.5859, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5492966175079346 sec\n",
      "Episode 3254, len12, loss:-84.2858, fail, steps:80, opt steps:58, total reward:-22.7000, 0.544219970703125 sec\n",
      "Episode 3255, len12, loss:-87.9759, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5474469661712646 sec\n",
      "Episode 3256, len12, loss:-91.6240, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5505630970001221 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3257, len12, loss:-106.3108, fail, steps:80, opt steps:35, total reward:-24.7000, 0.5443220138549805 sec\n",
      "Episode 3258, len6, loss:-49.5688, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5472619533538818 sec\n",
      "Episode 3259, len10, loss:-94.7020, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5492501258850098 sec\n",
      "Episode 3260, len6, loss:-53.0375, fail, steps:80, opt steps:10, total reward:-24.0000, 0.6072003841400146 sec\n",
      "Episode 3261, len6, loss:-47.0812, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5484039783477783 sec\n",
      "Episode 3262, len8, loss:-69.3298, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5498545169830322 sec\n",
      "Episode 3263, len10, loss:-85.2468, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5492329597473145 sec\n",
      "Episode 3264, len10, loss:-87.5486, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5490989685058594 sec\n",
      "Episode 3265, len12, loss:-106.0386, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5484204292297363 sec\n",
      "Episode 3266, len6, loss:-51.0105, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5498120784759521 sec\n",
      "Episode 3267, len8, loss:-63.4513, fail, steps:80, opt steps:35, total reward:-24.0000, 0.549156904220581 sec\n",
      "Episode 3268, len10, loss:-85.3274, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5493350028991699 sec\n",
      "Episode 3269, len12, loss:-92.8238, fail, steps:80, opt steps:35, total reward:-23.7000, 0.5453355312347412 sec\n",
      "Episode 3270, len8, loss:-66.2324, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5479311943054199 sec\n",
      "Episode 3271, len12, loss:-93.4378, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5479090213775635 sec\n",
      "Episode 3272, len12, loss:-93.3101, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5495851039886475 sec\n",
      "Episode 3273, len6, loss:-54.8986, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5477035045623779 sec\n",
      "Episode 3274, len6, loss:-52.0454, fail, steps:80, opt steps:20, total reward:-24.0000, 0.6049671173095703 sec\n",
      "Episode 3275, len10, loss:-85.3815, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5484793186187744 sec\n",
      "Episode 3276, len6, loss:-47.7375, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5496699810028076 sec\n",
      "Episode 3277, len6, loss:-52.4246, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5485591888427734 sec\n",
      "Episode 3278, len10, loss:-99.4802, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5444726943969727 sec\n",
      "Episode 3279, len8, loss:-76.3252, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5449366569519043 sec\n",
      "Episode 3280, len6, loss:-54.6493, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5476412773132324 sec\n",
      "Episode 3281, len6, loss:-50.6761, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5487518310546875 sec\n",
      "Episode 3282, len10, loss:-82.6432, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5471501350402832 sec\n",
      "Episode 3283, len6, loss:-54.4626, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490467548370361 sec\n",
      "Episode 3284, len8, loss:-69.3817, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5481915473937988 sec\n",
      "Episode 3285, len10, loss:-100.8473, fail, steps:80, opt steps:34, total reward:-24.7000, 0.5445706844329834 sec\n",
      "Episode 3286, len12, loss:-84.3892, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5488345623016357 sec\n",
      "Episode 3287, len8, loss:-65.4864, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5495736598968506 sec\n",
      "Episode 3288, len6, loss:-62.5497, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5995683670043945 sec\n",
      "Episode 3289, len12, loss:-90.9029, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5493767261505127 sec\n",
      "Episode 3290, len10, loss:-87.7517, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5494930744171143 sec\n",
      "Episode 3291, len10, loss:-93.0149, fail, steps:80, opt steps:30, total reward:-24.0000, 0.548316478729248 sec\n",
      "Episode 3292, len12, loss:-92.1634, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5496418476104736 sec\n",
      "Episode 3293, len12, loss:-94.9911, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5493791103363037 sec\n",
      "Episode 3294, len8, loss:-73.4214, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5484838485717773 sec\n",
      "Episode 3295, len10, loss:-91.3204, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5474755764007568 sec\n",
      "Episode 3296, len6, loss:-57.2065, fail, steps:80, opt steps:21, total reward:-24.0000, 0.547508716583252 sec\n",
      "Episode 3297, len10, loss:-95.0981, fail, steps:80, opt steps:47, total reward:-24.7000, 0.5436375141143799 sec\n",
      "Episode 3298, len8, loss:-65.6476, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5490832328796387 sec\n",
      "Episode 3299, len12, loss:-93.4669, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5484139919281006 sec\n",
      "Episode 3300, len6, loss:-55.8773, fail, steps:80, opt steps:17, total reward:-24.0000, 0.548459529876709 sec\n",
      "Episode 3301, len10, loss:-89.6366, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5481967926025391 sec\n",
      "Episode 3302, len10, loss:-95.0811, fail, steps:80, opt steps:44, total reward:-24.7000, 0.5967741012573242 sec\n",
      "Episode 3303, len12, loss:-100.7145, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5486249923706055 sec\n",
      "Episode 3304, len8, loss:-74.2094, fail, steps:80, opt steps:15, total reward:-24.0000, 0.549654483795166 sec\n",
      "Episode 3305, len10, loss:-87.1790, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5469217300415039 sec\n",
      "Episode 3306, len10, loss:-93.2609, fail, steps:80, opt steps:40, total reward:-24.0000, 0.548569917678833 sec\n",
      "Episode 3307, len10, loss:-76.8685, fail, steps:80, opt steps:34, total reward:-22.7000, 0.5446653366088867 sec\n",
      "Episode 3308, len10, loss:-96.7112, fail, steps:80, opt steps:35, total reward:-24.7000, 0.5431711673736572 sec\n",
      "Episode 3309, len6, loss:-56.1272, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5478239059448242 sec\n",
      "Episode 3310, len10, loss:-82.3967, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5471658706665039 sec\n",
      "Episode 3311, len8, loss:-72.2864, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5493674278259277 sec\n",
      "Episode 3312, len8, loss:-68.6297, fail, steps:80, opt steps:12, total reward:-22.7000, 0.5436573028564453 sec\n",
      "Episode 3313, len10, loss:-89.9715, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5477023124694824 sec\n",
      "Episode 3314, len10, loss:-91.6564, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5488598346710205 sec\n",
      "Episode 3315, len10, loss:-87.9678, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548515796661377 sec\n",
      "Episode 3316, len12, loss:-92.5754, fail, steps:80, opt steps:65, total reward:-24.0000, 0.6021604537963867 sec\n",
      "Episode 3317, len10, loss:-89.0437, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5490231513977051 sec\n",
      "Episode 3318, len8, loss:-70.2527, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5492045879364014 sec\n",
      "Episode 3319, len10, loss:-86.7317, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5483443737030029 sec\n",
      "Episode 3320, len10, loss:-96.7170, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5442965030670166 sec\n",
      "Episode 3321, len6, loss:-71.6241, fail, steps:80, opt steps:15, total reward:-24.4000, 0.539494514465332 sec\n",
      "Episode 3322, len8, loss:-75.6355, fail, steps:80, opt steps:30, total reward:-24.0000, 0.547722339630127 sec\n",
      "Episode 3323, len6, loss:-61.5690, fail, steps:80, opt steps:15, total reward:-23.4000, 0.5399844646453857 sec\n",
      "Episode 3324, len12, loss:-97.5821, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5483479499816895 sec\n",
      "Episode 3325, len12, loss:-97.5012, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5493466854095459 sec\n",
      "Episode 3326, len6, loss:-58.8266, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5477557182312012 sec\n",
      "Episode 3327, len12, loss:-98.2274, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5479726791381836 sec\n",
      "Episode 3328, len10, loss:-89.6863, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5476043224334717 sec\n",
      "Episode 3329, len12, loss:-96.5066, fail, steps:80, opt steps:59, total reward:-24.0000, 0.547339916229248 sec\n",
      "Episode 3330, len10, loss:-94.4840, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5490152835845947 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3331, len12, loss:-97.7557, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5985171794891357 sec\n",
      "Episode 3332, len6, loss:-59.0380, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5481138229370117 sec\n",
      "Episode 3333, len8, loss:-70.6288, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5470592975616455 sec\n",
      "Episode 3334, len12, loss:-96.5958, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5477960109710693 sec\n",
      "Episode 3335, len10, loss:-90.4936, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5480740070343018 sec\n",
      "Episode 3336, len10, loss:-91.7419, fail, steps:80, opt steps:27, total reward:-23.7000, 0.5442256927490234 sec\n",
      "Episode 3337, len10, loss:-106.8206, fail, steps:80, opt steps:36, total reward:-25.4000, 0.5392613410949707 sec\n",
      "Episode 3338, len6, loss:-57.5213, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5480892658233643 sec\n",
      "Episode 3339, len8, loss:-79.1361, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5474147796630859 sec\n",
      "Episode 3340, len8, loss:-63.5819, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5491712093353271 sec\n",
      "Episode 3341, len8, loss:-77.2257, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5493457317352295 sec\n",
      "Episode 3342, len6, loss:-65.1255, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5478401184082031 sec\n",
      "Episode 3343, len6, loss:-60.4874, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5485057830810547 sec\n",
      "Episode 3344, len12, loss:-92.9236, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5484459400177002 sec\n",
      "Episode 3345, len8, loss:-75.4443, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5489072799682617 sec\n",
      "Episode 3346, len8, loss:-72.7580, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5477919578552246 sec\n",
      "Episode 3347, len6, loss:-63.4753, fail, steps:80, opt steps:13, total reward:-23.7000, 0.5955772399902344 sec\n",
      "Episode 3348, len10, loss:-89.0302, fail, steps:80, opt steps:21, total reward:-22.7000, 0.5438861846923828 sec\n",
      "Episode 3349, len12, loss:-98.1457, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5437400341033936 sec\n",
      "Episode 3350, len6, loss:-63.4083, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5466876029968262 sec\n",
      "Episode 3351, len12, loss:-95.6266, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5505161285400391 sec\n",
      "Episode 3352, len12, loss:-107.8638, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5489668846130371 sec\n",
      "Episode 3353, len8, loss:-73.9745, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5488743782043457 sec\n",
      "Episode 3354, len6, loss:-66.6031, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5441009998321533 sec\n",
      "Episode 3355, len8, loss:-76.6165, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5476968288421631 sec\n",
      "Episode 3356, len12, loss:-92.2460, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5485885143280029 sec\n",
      "Episode 3357, len8, loss:-81.3047, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5473830699920654 sec\n",
      "Episode 3358, len8, loss:-78.8037, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5484776496887207 sec\n",
      "Episode 3359, len6, loss:-62.8635, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5479371547698975 sec\n",
      "Episode 3360, len10, loss:-95.0339, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5489516258239746 sec\n",
      "Episode 3361, len12, loss:-113.1125, fail, steps:80, opt steps:48, total reward:-24.7000, 0.5430455207824707 sec\n",
      "Episode 3362, len6, loss:-61.0024, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5487053394317627 sec\n",
      "Episode 3363, len8, loss:-66.7507, fail, steps:80, opt steps:26, total reward:-24.0000, 0.6029047966003418 sec\n",
      "Episode 3364, len12, loss:-91.7778, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5482468605041504 sec\n",
      "Episode 3365, len8, loss:-78.1000, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5493690967559814 sec\n",
      "Episode 3366, len12, loss:-101.6554, fail, steps:80, opt steps:48, total reward:-24.0000, 0.548938512802124 sec\n",
      "Episode 3367, len6, loss:-65.3872, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5518186092376709 sec\n",
      "Episode 3368, len12, loss:-96.6719, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5492122173309326 sec\n",
      "Episode 3369, len8, loss:-75.7441, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5439438819885254 sec\n",
      "Episode 3370, len10, loss:-85.8878, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5481350421905518 sec\n",
      "Episode 3371, len6, loss:-62.4524, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5490415096282959 sec\n",
      "Episode 3372, len6, loss:-70.9805, fail, steps:80, opt steps:14, total reward:-24.4000, 0.539682149887085 sec\n",
      "Episode 3373, len8, loss:-77.5477, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5480515956878662 sec\n",
      "Episode 3374, len8, loss:-79.3610, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5426621437072754 sec\n",
      "Episode 3375, len10, loss:-91.9662, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5495712757110596 sec\n",
      "Episode 3376, len8, loss:-79.7161, fail, steps:80, opt steps:26, total reward:-24.0000, 0.6040229797363281 sec\n",
      "Episode 3377, len8, loss:-73.2600, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5505232810974121 sec\n",
      "Episode 3378, len10, loss:-98.1786, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5489223003387451 sec\n",
      "Episode 3379, len10, loss:-89.9658, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5493009090423584 sec\n",
      "Episode 3380, len8, loss:-76.9467, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5487062931060791 sec\n",
      "Episode 3381, len8, loss:-77.9078, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5490493774414062 sec\n",
      "Episode 3382, len10, loss:-91.2785, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5480613708496094 sec\n",
      "Episode 3383, len6, loss:-71.6606, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5483298301696777 sec\n",
      "Episode 3384, len12, loss:-109.9241, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5485708713531494 sec\n",
      "Episode 3385, len12, loss:-106.2902, fail, steps:80, opt steps:40, total reward:-24.0000, 0.548943281173706 sec\n",
      "Episode 3386, len12, loss:-101.0845, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5493118762969971 sec\n",
      "Episode 3387, len10, loss:-92.4775, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5505321025848389 sec\n",
      "Episode 3388, len10, loss:-93.0735, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5489351749420166 sec\n",
      "Episode 3389, len8, loss:-84.5657, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5443148612976074 sec\n",
      "Episode 3390, len8, loss:-77.6355, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6044886112213135 sec\n",
      "Episode 3391, len8, loss:-83.8878, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5444657802581787 sec\n",
      "Episode 3392, len6, loss:-64.4196, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5478768348693848 sec\n",
      "Episode 3393, len10, loss:-103.0429, fail, steps:80, opt steps:40, total reward:-24.7000, 0.5452876091003418 sec\n",
      "Episode 3394, len12, loss:-101.1335, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5490455627441406 sec\n",
      "Episode 3395, len10, loss:-86.6451, fail, steps:80, opt steps:26, total reward:-22.7000, 0.5448489189147949 sec\n",
      "Episode 3396, len10, loss:-95.1707, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5489840507507324 sec\n",
      "Episode 3397, len12, loss:-103.6012, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5509078502655029 sec\n",
      "Episode 3398, len6, loss:-66.3624, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5485389232635498 sec\n",
      "Episode 3399, len6, loss:-69.5351, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5485267639160156 sec\n",
      "Episode 3400, len12, loss:-99.5823, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5498480796813965 sec\n",
      "Episode 3401, len10, loss:-97.5851, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5499114990234375 sec\n",
      "Episode 3402, len6, loss:-73.5706, fail, steps:80, opt steps:15, total reward:-24.0000, 0.550572395324707 sec\n",
      "Episode 3403, len10, loss:-97.4044, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5491373538970947 sec\n",
      "Episode 3404, len12, loss:-100.3692, fail, steps:80, opt steps:49, total reward:-24.0000, 0.6009314060211182 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3405, len10, loss:-93.9858, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5502641201019287 sec\n",
      "Episode 3406, len6, loss:-72.2440, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5489580631256104 sec\n",
      "Episode 3407, len12, loss:-107.6470, fail, steps:80, opt steps:33, total reward:-24.7000, 0.5464844703674316 sec\n",
      "Episode 3408, len8, loss:-84.1193, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5440640449523926 sec\n",
      "Episode 3409, len10, loss:-97.7537, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5487017631530762 sec\n",
      "Episode 3410, len6, loss:-80.8496, fail, steps:80, opt steps:7, total reward:-24.7000, 0.5444827079772949 sec\n",
      "Episode 3411, len8, loss:-82.7860, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5482974052429199 sec\n",
      "Episode 3412, len10, loss:-99.9902, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5437147617340088 sec\n",
      "Episode 3413, len6, loss:-64.3940, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5489249229431152 sec\n",
      "Episode 3414, len10, loss:-96.4357, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5485696792602539 sec\n",
      "Episode 3415, len12, loss:-110.8230, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5504908561706543 sec\n",
      "Episode 3416, len6, loss:-68.5512, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5501875877380371 sec\n",
      "Episode 3417, len8, loss:-71.3624, fail, steps:80, opt steps:26, total reward:-24.0000, 0.549612283706665 sec\n",
      "Episode 3418, len6, loss:-64.7300, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5994861125946045 sec\n",
      "Episode 3419, len8, loss:-73.9048, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5502159595489502 sec\n",
      "Episode 3420, len6, loss:-72.2255, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5489263534545898 sec\n",
      "Episode 3421, len8, loss:-69.0904, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5475382804870605 sec\n",
      "Episode 3422, len10, loss:-89.3932, fail, steps:80, opt steps:22, total reward:-24.0000, 0.550349235534668 sec\n",
      "Episode 3423, len10, loss:-88.4954, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5494377613067627 sec\n",
      "Episode 3424, len6, loss:-64.9266, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5497188568115234 sec\n",
      "Episode 3425, len8, loss:-82.1274, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5442466735839844 sec\n",
      "Episode 3426, len12, loss:-94.6889, fail, steps:80, opt steps:54, total reward:-22.7000, 0.543881893157959 sec\n",
      "Episode 3427, len12, loss:-96.1895, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5495800971984863 sec\n",
      "Episode 3428, len6, loss:-64.7946, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5506129264831543 sec\n",
      "Episode 3429, len10, loss:-92.9674, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5449738502502441 sec\n",
      "Episode 3430, len6, loss:-64.7401, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5483627319335938 sec\n",
      "Episode 3431, len12, loss:-96.6089, fail, steps:80, opt steps:70, total reward:-23.7000, 0.5457465648651123 sec\n",
      "Episode 3432, len8, loss:-77.6522, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5979940891265869 sec\n",
      "Episode 3433, len12, loss:-104.4192, fail, steps:80, opt steps:37, total reward:-24.0000, 0.549267053604126 sec\n",
      "Episode 3434, len10, loss:-88.0803, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5496909618377686 sec\n",
      "Episode 3435, len6, loss:-67.7011, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5501019954681396 sec\n",
      "Episode 3436, len12, loss:-102.1087, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5486564636230469 sec\n",
      "Episode 3437, len8, loss:-76.0624, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5488169193267822 sec\n",
      "Episode 3438, len8, loss:-75.9005, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5501112937927246 sec\n",
      "Episode 3439, len10, loss:-90.8298, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5492403507232666 sec\n",
      "Episode 3440, len10, loss:-90.4554, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5482583045959473 sec\n",
      "Episode 3441, len10, loss:-86.8980, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5503494739532471 sec\n",
      "Episode 3442, len12, loss:-104.9977, fail, steps:80, opt steps:71, total reward:-24.0000, 0.5487234592437744 sec\n",
      "Episode 3443, len8, loss:-67.9808, fail, steps:80, opt steps:31, total reward:-22.7000, 0.5448377132415771 sec\n",
      "Episode 3444, len12, loss:-105.7177, fail, steps:80, opt steps:57, total reward:-24.7000, 0.5445294380187988 sec\n",
      "Episode 3445, len8, loss:-73.6188, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5484578609466553 sec\n",
      "Episode 3446, len10, loss:-90.0495, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5489110946655273 sec\n",
      "Episode 3447, len12, loss:-104.2612, fail, steps:80, opt steps:44, total reward:-24.7000, 0.5944411754608154 sec\n",
      "Episode 3448, len6, loss:-75.3160, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5435221195220947 sec\n",
      "Episode 3449, len6, loss:-62.4725, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5475654602050781 sec\n",
      "Episode 3450, len12, loss:-104.9173, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5494363307952881 sec\n",
      "Episode 3451, len12, loss:-98.3006, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5492727756500244 sec\n",
      "Episode 3452, len12, loss:-98.0132, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5500359535217285 sec\n",
      "Episode 3453, len6, loss:-56.8825, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5490295886993408 sec\n",
      "Episode 3454, len8, loss:-72.8265, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5485005378723145 sec\n",
      "Episode 3455, len8, loss:-66.5001, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5498600006103516 sec\n",
      "Episode 3456, len8, loss:-73.7315, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5486760139465332 sec\n",
      "Episode 3457, len6, loss:-57.5395, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5487871170043945 sec\n",
      "Episode 3458, len6, loss:-51.5759, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5483846664428711 sec\n",
      "Episode 3459, len12, loss:-102.7362, fail, steps:80, opt steps:47, total reward:-25.4000, 0.5399398803710938 sec\n",
      "Episode 3460, len10, loss:-83.1613, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5496022701263428 sec\n",
      "Episode 3461, len6, loss:-61.1398, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5480344295501709 sec\n",
      "Episode 3462, len12, loss:-93.8733, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5487539768218994 sec\n",
      "Episode 3463, len10, loss:-83.2675, fail, steps:80, opt steps:33, total reward:-24.7000, 0.5949311256408691 sec\n",
      "Episode 3464, len8, loss:-75.5634, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5489368438720703 sec\n",
      "Episode 3465, len10, loss:-87.3810, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5485963821411133 sec\n",
      "Episode 3466, len6, loss:-60.9619, fail, steps:80, opt steps:5, total reward:-24.0000, 0.548839807510376 sec\n",
      "Episode 3467, len10, loss:-88.4803, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5492362976074219 sec\n",
      "Episode 3468, len10, loss:-86.7100, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5493192672729492 sec\n",
      "Episode 3469, len10, loss:-81.9570, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5485312938690186 sec\n",
      "Episode 3470, len12, loss:-90.7366, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490615367889404 sec\n",
      "Episode 3471, len10, loss:-79.9503, fail, steps:80, opt steps:50, total reward:-24.0000, 0.548370361328125 sec\n",
      "Episode 3472, len6, loss:-63.7375, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5490882396697998 sec\n",
      "Episode 3473, len10, loss:-83.6374, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5487537384033203 sec\n",
      "Episode 3474, len8, loss:-71.9483, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5445911884307861 sec\n",
      "Episode 3475, len12, loss:-96.9175, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5504486560821533 sec\n",
      "Episode 3476, len6, loss:-57.7291, fail, steps:80, opt steps:11, total reward:-23.4000, 0.5401625633239746 sec\n",
      "Episode 3477, len6, loss:-66.7817, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5472548007965088 sec\n",
      "Episode 3478, len12, loss:-97.1424, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5492563247680664 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3479, len6, loss:-64.4515, fail, steps:80, opt steps:11, total reward:-24.0000, 0.598505973815918 sec\n",
      "Episode 3480, len12, loss:-92.9771, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5477287769317627 sec\n",
      "Episode 3481, len10, loss:-80.1177, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5501787662506104 sec\n",
      "Episode 3482, len12, loss:-96.0765, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5487000942230225 sec\n",
      "Episode 3483, len10, loss:-79.7464, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5494413375854492 sec\n",
      "Episode 3484, len6, loss:-65.4346, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490632057189941 sec\n",
      "Episode 3485, len12, loss:-99.2219, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5501847267150879 sec\n",
      "Episode 3486, len6, loss:-66.3820, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5438899993896484 sec\n",
      "Episode 3487, len8, loss:-75.8010, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5490777492523193 sec\n",
      "Episode 3488, len10, loss:-86.8589, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5513029098510742 sec\n",
      "Episode 3489, len8, loss:-73.3144, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5488667488098145 sec\n",
      "Episode 3490, len8, loss:-74.3504, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5487651824951172 sec\n",
      "Episode 3491, len6, loss:-67.1946, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5444378852844238 sec\n",
      "Episode 3492, len12, loss:-94.8102, fail, steps:80, opt steps:42, total reward:-24.0000, 0.6044859886169434 sec\n",
      "Episode 3493, len8, loss:-76.8640, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5501415729522705 sec\n",
      "Episode 3494, len8, loss:-70.3606, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5496480464935303 sec\n",
      "Episode 3495, len12, loss:-93.1380, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5494363307952881 sec\n",
      "Episode 3496, len6, loss:-62.0057, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5499663352966309 sec\n",
      "Episode 3497, len8, loss:-77.0252, fail, steps:80, opt steps:7, total reward:-24.0000, 0.54939866065979 sec\n",
      "Episode 3498, len6, loss:-59.3739, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5496160984039307 sec\n",
      "Episode 3499, len6, loss:-58.5363, fail, steps:80, opt steps:3, total reward:-24.0000, 0.549297571182251 sec\n",
      "Episode 3500, len8, loss:-70.6166, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5487914085388184 sec\n",
      "Episode 3501, len8, loss:-71.4928, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5493118762969971 sec\n",
      "Episode 3502, len12, loss:-97.3600, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5506932735443115 sec\n",
      "Episode 3503, len12, loss:-93.8864, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5505132675170898 sec\n",
      "Episode 3504, len12, loss:-99.0716, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5494730472564697 sec\n",
      "Episode 3505, len12, loss:-97.2994, fail, steps:80, opt steps:57, total reward:-24.0000, 0.549349308013916 sec\n",
      "Episode 3506, len12, loss:-102.8443, fail, steps:80, opt steps:52, total reward:-24.0000, 0.6018729209899902 sec\n",
      "Episode 3507, len10, loss:-96.8876, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5459401607513428 sec\n",
      "Episode 3508, len8, loss:-74.7313, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5506136417388916 sec\n",
      "Episode 3509, len12, loss:-101.6527, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5486688613891602 sec\n",
      "Episode 3510, len6, loss:-60.6627, fail, steps:80, opt steps:10, total reward:-24.7000, 0.5454087257385254 sec\n",
      "Episode 3511, len10, loss:-85.9062, fail, steps:80, opt steps:21, total reward:-24.7000, 0.544123649597168 sec\n",
      "Episode 3512, len12, loss:-92.1131, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5487039089202881 sec\n",
      "Episode 3513, len8, loss:-74.5495, fail, steps:80, opt steps:30, total reward:-24.0000, 0.548668384552002 sec\n",
      "Episode 3514, len12, loss:-90.1697, fail, steps:80, opt steps:58, total reward:-22.7000, 0.5454046726226807 sec\n",
      "Episode 3515, len10, loss:-80.6467, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5487425327301025 sec\n",
      "Episode 3516, len8, loss:-73.2824, fail, steps:80, opt steps:24, total reward:-24.0000, 0.548722505569458 sec\n",
      "Episode 3517, len6, loss:-62.1674, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5496513843536377 sec\n",
      "Episode 3518, len12, loss:-99.2134, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5498476028442383 sec\n",
      "Episode 3519, len10, loss:-90.8419, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5487689971923828 sec\n",
      "Episode 3520, len12, loss:-82.6518, fail, steps:80, opt steps:52, total reward:-22.7000, 0.6015868186950684 sec\n",
      "Episode 3521, len6, loss:-56.0445, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5471315383911133 sec\n",
      "Episode 3522, len6, loss:-64.7094, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5477063655853271 sec\n",
      "Episode 3523, len8, loss:-76.8134, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5477967262268066 sec\n",
      "Episode 3524, len8, loss:-68.3393, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5478858947753906 sec\n",
      "Episode 3525, len12, loss:-100.9436, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5486307144165039 sec\n",
      "Episode 3526, len8, loss:-73.6972, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5474345684051514 sec\n",
      "Episode 3527, len12, loss:-97.0771, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5469033718109131 sec\n",
      "Episode 3528, len12, loss:-94.9393, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5488870143890381 sec\n",
      "Episode 3529, len10, loss:-82.6238, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5474498271942139 sec\n",
      "Episode 3530, len6, loss:-56.0496, fail, steps:80, opt steps:21, total reward:-24.0000, 0.548649787902832 sec\n",
      "Episode 3531, len8, loss:-73.1149, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5488176345825195 sec\n",
      "Episode 3532, len6, loss:-53.4850, fail, steps:80, opt steps:18, total reward:-24.0000, 0.548438549041748 sec\n",
      "Episode 3533, len8, loss:-73.0644, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5474522113800049 sec\n",
      "Episode 3534, len8, loss:-79.2992, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5969827175140381 sec\n",
      "Episode 3535, len10, loss:-89.5515, fail, steps:80, opt steps:31, total reward:-24.7000, 0.5423543453216553 sec\n",
      "Episode 3536, len12, loss:-103.4365, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5435619354248047 sec\n",
      "Episode 3537, len8, loss:-76.1158, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5461080074310303 sec\n",
      "Episode 3538, len6, loss:-60.3928, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5465648174285889 sec\n",
      "Episode 3539, len8, loss:-70.0707, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5468869209289551 sec\n",
      "Episode 3540, len10, loss:-83.3865, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5478763580322266 sec\n",
      "Episode 3541, len6, loss:-55.5695, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5478723049163818 sec\n",
      "Episode 3542, len8, loss:-75.2717, fail, steps:80, opt steps:29, total reward:-24.7000, 0.542670726776123 sec\n",
      "Episode 3543, len6, loss:-61.7597, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5480227470397949 sec\n",
      "Episode 3544, len10, loss:-85.1999, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5483758449554443 sec\n",
      "Episode 3545, len10, loss:-89.3198, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5473842620849609 sec\n",
      "Episode 3546, len6, loss:-49.3318, fail, steps:80, opt steps:7, total reward:-22.7000, 0.5427215099334717 sec\n",
      "Episode 3547, len10, loss:-86.6479, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5480988025665283 sec\n",
      "Episode 3548, len10, loss:-92.6950, fail, steps:80, opt steps:50, total reward:-24.0000, 0.6014106273651123 sec\n",
      "Episode 3549, len10, loss:-83.4991, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5465631484985352 sec\n",
      "Episode 3550, len8, loss:-77.5762, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5418198108673096 sec\n",
      "Episode 3551, len8, loss:-71.8408, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5471127033233643 sec\n",
      "Episode 3552, len8, loss:-77.1126, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5471580028533936 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3553, len12, loss:-99.0484, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5465891361236572 sec\n",
      "Episode 3554, len12, loss:-91.4219, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5470077991485596 sec\n",
      "Episode 3555, len10, loss:-87.3081, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5473051071166992 sec\n",
      "Episode 3556, len10, loss:-91.7734, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5475723743438721 sec\n",
      "Episode 3557, len10, loss:-84.2744, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5486111640930176 sec\n",
      "Episode 3558, len12, loss:-90.6550, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5481202602386475 sec\n",
      "Episode 3559, len6, loss:-60.4610, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5483837127685547 sec\n",
      "Episode 3560, len8, loss:-76.5443, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5470137596130371 sec\n",
      "Episode 3561, len8, loss:-79.8439, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5481870174407959 sec\n",
      "Episode 3562, len8, loss:-73.3236, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5468485355377197 sec\n",
      "Episode 3563, len12, loss:-92.5484, fail, steps:80, opt steps:31, total reward:-24.0000, 0.6000134944915771 sec\n",
      "Episode 3564, len6, loss:-62.3574, fail, steps:80, opt steps:21, total reward:-24.7000, 0.543959379196167 sec\n",
      "Episode 3565, len10, loss:-87.4556, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5433182716369629 sec\n",
      "Episode 3566, len10, loss:-83.1043, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5467493534088135 sec\n",
      "Episode 3567, len8, loss:-85.4638, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5422861576080322 sec\n",
      "Episode 3568, len8, loss:-77.1536, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5441961288452148 sec\n",
      "Episode 3569, len8, loss:-78.9453, fail, steps:80, opt steps:33, total reward:-24.7000, 0.5429823398590088 sec\n",
      "Episode 3570, len10, loss:-83.7241, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5483276844024658 sec\n",
      "Episode 3571, len10, loss:-86.9005, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5472099781036377 sec\n",
      "Episode 3572, len6, loss:-64.6468, fail, steps:80, opt steps:21, total reward:-24.0000, 0.548443078994751 sec\n",
      "Episode 3573, len8, loss:-68.8917, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5469906330108643 sec\n",
      "Episode 3574, len12, loss:-95.1643, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5475351810455322 sec\n",
      "Episode 3575, len10, loss:-86.6561, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5479364395141602 sec\n",
      "Episode 3576, len6, loss:-55.3324, fail, steps:80, opt steps:13, total reward:-24.7000, 0.544365406036377 sec\n",
      "Episode 3577, len6, loss:-58.1586, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5464978218078613 sec\n",
      "Episode 3578, len10, loss:-78.7007, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5474631786346436 sec\n",
      "Episode 3579, len8, loss:-79.1152, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5994069576263428 sec\n",
      "Episode 3580, len6, loss:-56.4343, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5475113391876221 sec\n",
      "Episode 3581, len6, loss:-61.1022, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5470187664031982 sec\n",
      "Episode 3582, len6, loss:-55.5899, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5478131771087646 sec\n",
      "Episode 3583, len8, loss:-68.9875, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5493166446685791 sec\n",
      "Episode 3584, len8, loss:-74.9137, fail, steps:80, opt steps:23, total reward:-24.7000, 0.543189287185669 sec\n",
      "Episode 3585, len12, loss:-94.5432, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5486934185028076 sec\n",
      "Episode 3586, len8, loss:-73.5103, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5467720031738281 sec\n",
      "Episode 3587, len8, loss:-72.7402, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5469801425933838 sec\n",
      "Episode 3588, len6, loss:-64.2228, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5431418418884277 sec\n",
      "Episode 3589, len8, loss:-76.5663, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5469176769256592 sec\n",
      "Episode 3590, len10, loss:-88.9926, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5482330322265625 sec\n",
      "Episode 3591, len10, loss:-83.4098, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5480382442474365 sec\n",
      "Episode 3592, len12, loss:-97.0602, fail, steps:80, opt steps:44, total reward:-24.7000, 0.5435993671417236 sec\n",
      "Episode 3593, len8, loss:-72.9415, fail, steps:80, opt steps:18, total reward:-24.0000, 0.547623872756958 sec\n",
      "Episode 3594, len6, loss:-54.9649, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5482933521270752 sec\n",
      "Episode 3595, len8, loss:-68.1829, fail, steps:80, opt steps:26, total reward:-24.0000, 0.598578929901123 sec\n",
      "Episode 3596, len12, loss:-91.7154, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5478518009185791 sec\n",
      "Episode 3597, len8, loss:-69.0786, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5474092960357666 sec\n",
      "Episode 3598, len12, loss:-99.9012, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5481653213500977 sec\n",
      "Episode 3599, len10, loss:-80.3390, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5489652156829834 sec\n",
      "Episode 3600, len12, loss:-90.0461, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5495078563690186 sec\n",
      "Episode 3601, len6, loss:-58.9294, fail, steps:80, opt steps:3, total reward:-24.0000, 0.54762864112854 sec\n",
      "Episode 3602, len10, loss:-89.6058, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5468728542327881 sec\n",
      "Episode 3603, len6, loss:-61.1092, fail, steps:80, opt steps:21, total reward:-24.0000, 0.547795295715332 sec\n",
      "Episode 3604, len6, loss:-61.9112, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5480861663818359 sec\n",
      "Episode 3605, len10, loss:-98.2896, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5428299903869629 sec\n",
      "Episode 3606, len6, loss:-65.7567, fail, steps:80, opt steps:13, total reward:-24.7000, 0.543511152267456 sec\n",
      "Episode 3607, len8, loss:-73.9383, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5574276447296143 sec\n",
      "Episode 3608, len10, loss:-85.4125, fail, steps:80, opt steps:35, total reward:-24.0000, 0.6032342910766602 sec\n",
      "Episode 3609, len6, loss:-58.5499, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5476770401000977 sec\n",
      "Episode 3610, len10, loss:-87.8031, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5472588539123535 sec\n",
      "Episode 3611, len6, loss:-63.3370, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5473225116729736 sec\n",
      "Episode 3612, len10, loss:-86.3892, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5484716892242432 sec\n",
      "Episode 3613, len12, loss:-98.9685, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5485038757324219 sec\n",
      "Episode 3614, len12, loss:-93.1028, fail, steps:80, opt steps:57, total reward:-24.0000, 0.547478199005127 sec\n",
      "Episode 3615, len8, loss:-74.2168, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5473387241363525 sec\n",
      "Episode 3616, len8, loss:-73.9244, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5473155975341797 sec\n",
      "Episode 3617, len8, loss:-70.7884, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5463302135467529 sec\n",
      "Episode 3618, len10, loss:-82.8742, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5477719306945801 sec\n",
      "Episode 3619, len8, loss:-68.4225, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5480763912200928 sec\n",
      "Episode 3620, len12, loss:-103.0859, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5433540344238281 sec\n",
      "Episode 3621, len10, loss:-80.8832, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5476830005645752 sec\n",
      "Episode 3622, len6, loss:-55.8209, fail, steps:80, opt steps:15, total reward:-24.0000, 0.6037518978118896 sec\n",
      "Episode 3623, len12, loss:-98.3238, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5478420257568359 sec\n",
      "Episode 3624, len12, loss:-101.5206, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5468780994415283 sec\n",
      "Episode 3625, len10, loss:-86.3764, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5477273464202881 sec\n",
      "Episode 3626, len6, loss:-60.3838, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5477683544158936 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3627, len8, loss:-69.7233, fail, steps:80, opt steps:6, total reward:-24.0000, 0.548142671585083 sec\n",
      "Episode 3628, len8, loss:-74.9329, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5477216243743896 sec\n",
      "Episode 3629, len6, loss:-49.6402, fail, steps:80, opt steps:20, total reward:-22.7000, 0.5438628196716309 sec\n",
      "Episode 3630, len10, loss:-84.3274, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5483214855194092 sec\n",
      "Episode 3631, len10, loss:-83.5664, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5479130744934082 sec\n",
      "Episode 3632, len8, loss:-74.2299, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5472462177276611 sec\n",
      "Episode 3633, len8, loss:-76.2064, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5488402843475342 sec\n",
      "Episode 3634, len10, loss:-86.7244, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5451078414916992 sec\n",
      "Episode 3635, len12, loss:-92.4716, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5481758117675781 sec\n",
      "Episode 3636, len8, loss:-70.6576, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5996296405792236 sec\n",
      "Episode 3637, len10, loss:-96.0185, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5481421947479248 sec\n",
      "Episode 3638, len10, loss:-83.1790, fail, steps:80, opt steps:42, total reward:-24.0000, 0.54776930809021 sec\n",
      "Episode 3639, len6, loss:-64.9743, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5478668212890625 sec\n",
      "Episode 3640, len10, loss:-86.0047, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5478744506835938 sec\n",
      "Episode 3641, len10, loss:-84.9865, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5475656986236572 sec\n",
      "Episode 3642, len10, loss:-91.0833, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5489144325256348 sec\n",
      "Episode 3643, len6, loss:-62.4334, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5477414131164551 sec\n",
      "Episode 3644, len8, loss:-77.0378, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5480129718780518 sec\n",
      "Episode 3645, len10, loss:-87.5828, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5479393005371094 sec\n",
      "Episode 3646, len8, loss:-74.4599, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5475893020629883 sec\n",
      "Episode 3647, len6, loss:-60.6998, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5491898059844971 sec\n",
      "Episode 3648, len10, loss:-82.1989, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5487484931945801 sec\n",
      "Episode 3649, len10, loss:-86.0037, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5452163219451904 sec\n",
      "Episode 3650, len12, loss:-93.5657, fail, steps:80, opt steps:47, total reward:-24.0000, 0.600104808807373 sec\n",
      "Episode 3651, len12, loss:-95.6743, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5480451583862305 sec\n",
      "Episode 3652, len12, loss:-90.4213, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5478687286376953 sec\n",
      "Episode 3653, len12, loss:-99.1917, fail, steps:80, opt steps:39, total reward:-24.7000, 0.544055700302124 sec\n",
      "Episode 3654, len8, loss:-74.0459, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5482485294342041 sec\n",
      "Episode 3655, len6, loss:-63.5632, fail, steps:80, opt steps:11, total reward:-24.7000, 0.542701005935669 sec\n",
      "Episode 3656, len8, loss:-78.7211, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5460567474365234 sec\n",
      "Episode 3657, len8, loss:-67.9967, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5465972423553467 sec\n",
      "Episode 3658, len12, loss:-90.0634, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5484094619750977 sec\n",
      "Episode 3659, len8, loss:-72.1096, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5484335422515869 sec\n",
      "Episode 3660, len8, loss:-73.8604, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5476105213165283 sec\n",
      "Episode 3661, len12, loss:-91.6370, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5488581657409668 sec\n",
      "Episode 3662, len6, loss:-50.3689, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5467500686645508 sec\n",
      "Episode 3663, len6, loss:-56.0737, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5477392673492432 sec\n",
      "Episode 3664, len10, loss:-83.2340, fail, steps:80, opt steps:47, total reward:-24.7000, 0.5959572792053223 sec\n",
      "Episode 3665, len10, loss:-81.3594, fail, steps:80, opt steps:33, total reward:-24.0000, 0.547173261642456 sec\n",
      "Episode 3666, len6, loss:-50.5406, fail, steps:80, opt steps:6, total reward:-24.0000, 0.548398494720459 sec\n",
      "Episode 3667, len10, loss:-78.2433, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5476222038269043 sec\n",
      "Episode 3668, len6, loss:-59.3051, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5479316711425781 sec\n",
      "Episode 3669, len8, loss:-61.2259, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5483968257904053 sec\n",
      "Episode 3670, len12, loss:-93.7970, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5477616786956787 sec\n",
      "Episode 3671, len8, loss:-74.5453, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5475709438323975 sec\n",
      "Episode 3672, len10, loss:-81.7636, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5480325222015381 sec\n",
      "Episode 3673, len12, loss:-91.4875, fail, steps:80, opt steps:36, total reward:-24.7000, 0.543999433517456 sec\n",
      "Episode 3674, len10, loss:-75.5458, fail, steps:80, opt steps:33, total reward:-23.7000, 0.5441269874572754 sec\n",
      "Episode 3675, len8, loss:-75.0027, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5424449443817139 sec\n",
      "Episode 3676, len8, loss:-73.3767, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5475654602050781 sec\n",
      "Episode 3677, len6, loss:-55.3758, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5480973720550537 sec\n",
      "Episode 3678, len10, loss:-81.7032, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5475599765777588 sec\n",
      "Episode 3679, len8, loss:-65.7963, fail, steps:80, opt steps:27, total reward:-24.0000, 0.6021897792816162 sec\n",
      "Episode 3680, len8, loss:-68.4962, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5481612682342529 sec\n",
      "Episode 3681, len6, loss:-57.3465, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485308170318604 sec\n",
      "Episode 3682, len8, loss:-68.2285, fail, steps:80, opt steps:17, total reward:-24.0000, 0.547299861907959 sec\n",
      "Episode 3683, len6, loss:-55.8027, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5477907657623291 sec\n",
      "Episode 3684, len12, loss:-92.1168, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5488314628601074 sec\n",
      "Episode 3685, len8, loss:-65.2079, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5483224391937256 sec\n",
      "Episode 3686, len6, loss:-63.8966, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5451672077178955 sec\n",
      "Episode 3687, len10, loss:-80.4045, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5485444068908691 sec\n",
      "Episode 3688, len12, loss:-98.0425, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5492508411407471 sec\n",
      "Episode 3689, len8, loss:-68.6871, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5474057197570801 sec\n",
      "Episode 3690, len12, loss:-89.4513, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5480127334594727 sec\n",
      "Episode 3691, len6, loss:-57.6952, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5479557514190674 sec\n",
      "Episode 3692, len6, loss:-49.2016, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5482280254364014 sec\n",
      "Episode 3693, len10, loss:-82.3423, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5478241443634033 sec\n",
      "Episode 3694, len10, loss:-76.6453, fail, steps:80, opt steps:49, total reward:-24.0000, 0.548673152923584 sec\n",
      "Episode 3695, len12, loss:-98.0355, fail, steps:80, opt steps:47, total reward:-24.7000, 0.5989086627960205 sec\n",
      "Episode 3696, len6, loss:-60.1278, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5469207763671875 sec\n",
      "Episode 3697, len12, loss:-82.4842, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5467977523803711 sec\n",
      "Episode 3698, len10, loss:-87.5418, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5478537082672119 sec\n",
      "Episode 3699, len10, loss:-70.3367, fail, steps:80, opt steps:20, total reward:-22.7000, 0.5430247783660889 sec\n",
      "Episode 3700, len6, loss:-56.0757, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5478212833404541 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3701, len6, loss:-51.2484, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5468709468841553 sec\n",
      "Episode 3702, len12, loss:-91.0344, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5489540100097656 sec\n",
      "Episode 3703, len12, loss:-98.3301, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5480043888092041 sec\n",
      "Episode 3704, len8, loss:-75.3488, fail, steps:80, opt steps:33, total reward:-24.7000, 0.5426540374755859 sec\n",
      "Episode 3705, len8, loss:-65.9431, fail, steps:80, opt steps:23, total reward:-24.0000, 0.547100305557251 sec\n",
      "Episode 3706, len8, loss:-70.2643, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5439143180847168 sec\n",
      "Episode 3707, len8, loss:-66.4119, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5462989807128906 sec\n",
      "Episode 3708, len6, loss:-46.8910, fail, steps:80, opt steps:18, total reward:-22.7000, 0.5421836376190186 sec\n",
      "Episode 3709, len12, loss:-100.2153, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5470759868621826 sec\n",
      "Episode 3710, len8, loss:-69.8961, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5468387603759766 sec\n",
      "Episode 3711, len12, loss:-100.0509, fail, steps:80, opt steps:43, total reward:-24.0000, 0.6001007556915283 sec\n",
      "Episode 3712, len6, loss:-57.9464, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5484085083007812 sec\n",
      "Episode 3713, len6, loss:-56.7976, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5472891330718994 sec\n",
      "Episode 3714, len10, loss:-88.3447, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5440139770507812 sec\n",
      "Episode 3715, len10, loss:-83.3719, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5468487739562988 sec\n",
      "Episode 3716, len6, loss:-64.2413, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5442142486572266 sec\n",
      "Episode 3717, len6, loss:-60.8251, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5485386848449707 sec\n",
      "Episode 3718, len10, loss:-72.1704, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5472722053527832 sec\n",
      "Episode 3719, len12, loss:-101.5555, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5487375259399414 sec\n",
      "Episode 3720, len10, loss:-86.6025, fail, steps:80, opt steps:31, total reward:-24.7000, 0.5432353019714355 sec\n",
      "Episode 3721, len10, loss:-85.8645, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5466718673706055 sec\n",
      "Episode 3722, len6, loss:-65.3378, fail, steps:80, opt steps:15, total reward:-24.7000, 0.54414963722229 sec\n",
      "Episode 3723, len6, loss:-62.8182, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5470705032348633 sec\n",
      "Episode 3724, len6, loss:-63.4366, fail, steps:80, opt steps:3, total reward:-24.0000, 0.6012628078460693 sec\n",
      "Episode 3725, len6, loss:-61.4457, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5493068695068359 sec\n",
      "Episode 3726, len8, loss:-72.3811, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5468077659606934 sec\n",
      "Episode 3727, len10, loss:-88.0289, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5496988296508789 sec\n",
      "Episode 3728, len8, loss:-68.8761, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5486023426055908 sec\n",
      "Episode 3729, len12, loss:-99.2621, fail, steps:80, opt steps:36, total reward:-24.7000, 0.5431101322174072 sec\n",
      "Episode 3730, len6, loss:-61.7994, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5470356941223145 sec\n",
      "Episode 3731, len12, loss:-90.7553, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5477781295776367 sec\n",
      "Episode 3732, len6, loss:-60.6509, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5469636917114258 sec\n",
      "Episode 3733, len8, loss:-78.6892, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5468707084655762 sec\n",
      "Episode 3734, len6, loss:-56.2982, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5467886924743652 sec\n",
      "Episode 3735, len8, loss:-75.4714, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5472030639648438 sec\n",
      "Episode 3736, len10, loss:-79.0781, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5479967594146729 sec\n",
      "Episode 3737, len8, loss:-76.4684, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5426590442657471 sec\n",
      "Episode 3738, len6, loss:-58.1336, fail, steps:80, opt steps:11, total reward:-24.0000, 0.6003143787384033 sec\n",
      "Episode 3739, len8, loss:-73.5245, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5467379093170166 sec\n",
      "Episode 3740, len10, loss:-89.0430, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5478789806365967 sec\n",
      "Episode 3741, len12, loss:-106.9960, fail, steps:80, opt steps:49, total reward:-24.7000, 0.5433354377746582 sec\n",
      "Episode 3742, len8, loss:-70.3682, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5479485988616943 sec\n",
      "Episode 3743, len6, loss:-56.2172, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5473859310150146 sec\n",
      "Episode 3744, len6, loss:-62.9679, fail, steps:80, opt steps:21, total reward:-23.4000, 0.537269115447998 sec\n",
      "Episode 3745, len8, loss:-71.8426, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5455939769744873 sec\n",
      "Episode 3746, len12, loss:-95.9703, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5446474552154541 sec\n",
      "Episode 3747, len12, loss:-90.4542, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5464932918548584 sec\n",
      "Episode 3748, len8, loss:-69.6158, fail, steps:80, opt steps:34, total reward:-24.0000, 0.546330451965332 sec\n",
      "Episode 3749, len6, loss:-69.5665, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5434231758117676 sec\n",
      "Episode 3750, len10, loss:-90.1254, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5431289672851562 sec\n",
      "Episode 3751, len6, loss:-59.4024, fail, steps:80, opt steps:12, total reward:-23.7000, 0.5435614585876465 sec\n",
      "Episode 3752, len10, loss:-90.1946, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5991189479827881 sec\n",
      "Episode 3753, len6, loss:-60.9142, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5478510856628418 sec\n",
      "Episode 3754, len12, loss:-93.0081, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5473730564117432 sec\n",
      "Episode 3755, len8, loss:-76.6569, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5476198196411133 sec\n",
      "Episode 3756, len6, loss:-63.5071, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5480101108551025 sec\n",
      "Episode 3757, len6, loss:-59.6375, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5477654933929443 sec\n",
      "Episode 3758, len12, loss:-97.5097, fail, steps:80, opt steps:41, total reward:-24.0000, 0.54892897605896 sec\n",
      "Episode 3759, len6, loss:-68.1288, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5467615127563477 sec\n",
      "Episode 3760, len10, loss:-86.8189, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5492663383483887 sec\n",
      "Episode 3761, len6, loss:-64.2013, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5485100746154785 sec\n",
      "Episode 3762, len8, loss:-80.0204, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5486719608306885 sec\n",
      "Episode 3763, len12, loss:-106.2343, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5439846515655518 sec\n",
      "Episode 3764, len8, loss:-74.2254, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5494017601013184 sec\n",
      "Episode 3765, len8, loss:-71.1853, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5484583377838135 sec\n",
      "Episode 3766, len6, loss:-60.2681, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5980470180511475 sec\n",
      "Episode 3767, len10, loss:-95.9282, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5493853092193604 sec\n",
      "Episode 3768, len12, loss:-96.8303, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5506100654602051 sec\n",
      "Episode 3769, len8, loss:-78.1109, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5502076148986816 sec\n",
      "Episode 3770, len10, loss:-86.9853, fail, steps:80, opt steps:31, total reward:-24.7000, 0.5445742607116699 sec\n",
      "Episode 3771, len8, loss:-78.7048, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5484774112701416 sec\n",
      "Episode 3772, len6, loss:-69.1254, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5490317344665527 sec\n",
      "Episode 3773, len10, loss:-90.2402, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5483243465423584 sec\n",
      "Episode 3774, len12, loss:-106.5170, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5493395328521729 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3775, len8, loss:-67.4551, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5494656562805176 sec\n",
      "Episode 3776, len6, loss:-70.7419, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5451276302337646 sec\n",
      "Episode 3777, len6, loss:-61.1104, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5484466552734375 sec\n",
      "Episode 3778, len6, loss:-62.3489, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5488178730010986 sec\n",
      "Episode 3779, len10, loss:-96.4189, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5495326519012451 sec\n",
      "Episode 3780, len8, loss:-79.1714, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5977606773376465 sec\n",
      "Episode 3781, len10, loss:-88.0399, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5493025779724121 sec\n",
      "Episode 3782, len6, loss:-60.5102, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5488526821136475 sec\n",
      "Episode 3783, len12, loss:-102.9444, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5479662418365479 sec\n",
      "Episode 3784, len12, loss:-103.0767, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5494656562805176 sec\n",
      "Episode 3785, len10, loss:-86.2969, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5503571033477783 sec\n",
      "Episode 3786, len8, loss:-76.1378, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5487966537475586 sec\n",
      "Episode 3787, len8, loss:-72.5872, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5496318340301514 sec\n",
      "Episode 3788, len6, loss:-67.8278, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5500710010528564 sec\n",
      "Episode 3789, len8, loss:-78.2930, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5487103462219238 sec\n",
      "Episode 3790, len12, loss:-99.8809, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5505697727203369 sec\n",
      "Episode 3791, len6, loss:-60.8750, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5508084297180176 sec\n",
      "Episode 3792, len12, loss:-96.3406, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5496821403503418 sec\n",
      "Episode 3793, len12, loss:-97.6900, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5496044158935547 sec\n",
      "Episode 3794, len6, loss:-60.6820, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5490758419036865 sec\n",
      "Episode 3795, len12, loss:-97.4967, fail, steps:80, opt steps:45, total reward:-24.0000, 0.598320722579956 sec\n",
      "Episode 3796, len10, loss:-86.1442, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5495014190673828 sec\n",
      "Episode 3797, len12, loss:-96.2605, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5495355129241943 sec\n",
      "Episode 3798, len6, loss:-60.8633, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5488386154174805 sec\n",
      "Episode 3799, len10, loss:-87.3148, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5485978126525879 sec\n",
      "Episode 3800, len6, loss:-66.2840, fail, steps:80, opt steps:3, total reward:-24.0000, 0.549485445022583 sec\n",
      "Episode 3801, len10, loss:-91.8384, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5488243103027344 sec\n",
      "Episode 3802, len8, loss:-75.6510, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5488724708557129 sec\n",
      "Episode 3803, len12, loss:-109.6366, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5456163883209229 sec\n",
      "Episode 3804, len10, loss:-84.2425, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5506141185760498 sec\n",
      "Episode 3805, len10, loss:-100.6590, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5489411354064941 sec\n",
      "Episode 3806, len8, loss:-74.4382, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5489590167999268 sec\n",
      "Episode 3807, len12, loss:-103.4126, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5496296882629395 sec\n",
      "Episode 3808, len6, loss:-64.7963, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5495364665985107 sec\n",
      "Episode 3809, len10, loss:-94.7808, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5489873886108398 sec\n",
      "Episode 3810, len6, loss:-64.4384, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5488109588623047 sec\n",
      "Episode 3811, len10, loss:-91.2551, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5980124473571777 sec\n",
      "Episode 3812, len8, loss:-72.6526, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5488529205322266 sec\n",
      "Episode 3813, len10, loss:-85.5153, fail, steps:80, opt steps:33, total reward:-24.0000, 0.54888916015625 sec\n",
      "Episode 3814, len10, loss:-85.2891, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5495035648345947 sec\n",
      "Episode 3815, len10, loss:-89.2185, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5497725009918213 sec\n",
      "Episode 3816, len6, loss:-65.4615, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5495493412017822 sec\n",
      "Episode 3817, len8, loss:-74.0213, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5500094890594482 sec\n",
      "Episode 3818, len8, loss:-76.8400, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5502982139587402 sec\n",
      "Episode 3819, len10, loss:-93.9151, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5488576889038086 sec\n",
      "Episode 3820, len10, loss:-85.5104, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5486247539520264 sec\n",
      "Episode 3821, len10, loss:-89.7545, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5498778820037842 sec\n",
      "Episode 3822, len6, loss:-67.2738, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5505366325378418 sec\n",
      "Episode 3823, len12, loss:-94.0948, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5492608547210693 sec\n",
      "Episode 3824, len12, loss:-99.4480, fail, steps:80, opt steps:41, total reward:-24.0000, 0.548583984375 sec\n",
      "Episode 3825, len6, loss:-66.0755, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5533766746520996 sec\n",
      "Episode 3826, len8, loss:-73.0101, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5501642227172852 sec\n",
      "Episode 3827, len6, loss:-58.6413, fail, steps:80, opt steps:21, total reward:-24.0000, 0.6007664203643799 sec\n",
      "Episode 3828, len12, loss:-102.6305, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5495843887329102 sec\n",
      "Episode 3829, len10, loss:-109.2224, fail, steps:80, opt steps:43, total reward:-24.7000, 0.5440938472747803 sec\n",
      "Episode 3830, len12, loss:-97.5064, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5481090545654297 sec\n",
      "Episode 3831, len10, loss:-94.1655, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5498287677764893 sec\n",
      "Episode 3832, len8, loss:-78.2208, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5497171878814697 sec\n",
      "Episode 3833, len8, loss:-84.9595, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548715353012085 sec\n",
      "Episode 3834, len12, loss:-105.7709, fail, steps:80, opt steps:56, total reward:-24.7000, 0.544600248336792 sec\n",
      "Episode 3835, len6, loss:-63.0361, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5496485233306885 sec\n",
      "Episode 3836, len6, loss:-62.4431, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5495762825012207 sec\n",
      "Episode 3837, len6, loss:-63.4336, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5495138168334961 sec\n",
      "Episode 3838, len6, loss:-65.6216, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5481677055358887 sec\n",
      "Episode 3839, len12, loss:-102.3678, fail, steps:80, opt steps:70, total reward:-24.0000, 0.5502820014953613 sec\n",
      "Episode 3840, len10, loss:-92.3671, fail, steps:80, opt steps:16, total reward:-24.0000, 0.6033623218536377 sec\n",
      "Episode 3841, len10, loss:-88.8728, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5506613254547119 sec\n",
      "Episode 3842, len8, loss:-73.7330, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5493791103363037 sec\n",
      "Episode 3843, len10, loss:-87.9701, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5500712394714355 sec\n",
      "Episode 3844, len12, loss:-98.4321, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5504779815673828 sec\n",
      "Episode 3845, len6, loss:-75.0381, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5446772575378418 sec\n",
      "Episode 3846, len10, loss:-93.5456, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5488688945770264 sec\n",
      "Episode 3847, len12, loss:-117.8805, fail, steps:80, opt steps:56, total reward:-25.4000, 0.5404245853424072 sec\n",
      "Episode 3848, len6, loss:-66.1733, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5481832027435303 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3849, len12, loss:-100.4968, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5479121208190918 sec\n",
      "Episode 3850, len8, loss:-82.8640, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5504660606384277 sec\n",
      "Episode 3851, len6, loss:-70.3326, fail, steps:80, opt steps:5, total reward:-24.7000, 0.544914960861206 sec\n",
      "Episode 3852, len10, loss:-92.3184, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5489718914031982 sec\n",
      "Episode 3853, len10, loss:-90.7231, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5492351055145264 sec\n",
      "Episode 3854, len10, loss:-92.3122, fail, steps:80, opt steps:40, total reward:-24.0000, 0.6025309562683105 sec\n",
      "Episode 3855, len8, loss:-79.7797, fail, steps:80, opt steps:16, total reward:-24.0000, 0.549302339553833 sec\n",
      "Episode 3856, len10, loss:-94.6289, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5496904850006104 sec\n",
      "Episode 3857, len12, loss:-97.8917, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5493950843811035 sec\n",
      "Episode 3858, len12, loss:-108.1835, fail, steps:80, opt steps:40, total reward:-24.7000, 0.5446832180023193 sec\n",
      "Episode 3859, len10, loss:-89.7292, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5522341728210449 sec\n",
      "Episode 3860, len8, loss:-82.8806, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5447251796722412 sec\n",
      "Episode 3861, len12, loss:-109.7363, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5444355010986328 sec\n",
      "Episode 3862, len10, loss:-103.2766, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5489792823791504 sec\n",
      "Episode 3863, len6, loss:-67.2786, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5489060878753662 sec\n",
      "Episode 3864, len10, loss:-92.6161, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5497820377349854 sec\n",
      "Episode 3865, len6, loss:-69.4797, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5501575469970703 sec\n",
      "Episode 3866, len6, loss:-66.7390, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5498237609863281 sec\n",
      "Episode 3867, len6, loss:-69.2200, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5486302375793457 sec\n",
      "Episode 3868, len10, loss:-87.2571, fail, steps:80, opt steps:23, total reward:-24.0000, 0.6018757820129395 sec\n",
      "Episode 3869, len6, loss:-63.6599, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5491147041320801 sec\n",
      "Episode 3870, len10, loss:-92.7063, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5494027137756348 sec\n",
      "Episode 3871, len10, loss:-89.1852, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5497827529907227 sec\n",
      "Episode 3872, len12, loss:-104.4673, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5500032901763916 sec\n",
      "Episode 3873, len8, loss:-76.6712, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5496015548706055 sec\n",
      "Episode 3874, len10, loss:-99.1482, fail, steps:80, opt steps:25, total reward:-24.7000, 0.546522855758667 sec\n",
      "Episode 3875, len12, loss:-95.7159, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5477867126464844 sec\n",
      "Episode 3876, len8, loss:-82.8403, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5464742183685303 sec\n",
      "Episode 3877, len10, loss:-94.0993, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5467751026153564 sec\n",
      "Episode 3878, len10, loss:-91.0692, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5489561557769775 sec\n",
      "Episode 3879, len8, loss:-77.6703, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5468146800994873 sec\n",
      "Episode 3880, len10, loss:-85.3909, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5483818054199219 sec\n",
      "Episode 3881, len12, loss:-101.0293, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5499396324157715 sec\n",
      "Episode 3882, len12, loss:-104.3339, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5988481044769287 sec\n",
      "Episode 3883, len10, loss:-102.3992, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5456321239471436 sec\n",
      "Episode 3884, len10, loss:-88.0212, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5497024059295654 sec\n",
      "Episode 3885, len10, loss:-93.1053, fail, steps:80, opt steps:35, total reward:-24.4000, 0.5400331020355225 sec\n",
      "Episode 3886, len12, loss:-104.3146, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5480585098266602 sec\n",
      "Episode 3887, len10, loss:-87.7873, fail, steps:80, opt steps:51, total reward:-22.7000, 0.5459733009338379 sec\n",
      "Episode 3888, len12, loss:-102.7948, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5506243705749512 sec\n",
      "Episode 3889, len8, loss:-80.3857, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5481371879577637 sec\n",
      "Episode 3890, len12, loss:-100.7950, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5498690605163574 sec\n",
      "Episode 3891, len12, loss:-100.5537, fail, steps:80, opt steps:71, total reward:-24.0000, 0.5511336326599121 sec\n",
      "Episode 3892, len12, loss:-94.3013, fail, steps:80, opt steps:35, total reward:-22.7000, 0.5451290607452393 sec\n",
      "Episode 3893, len10, loss:-95.0741, fail, steps:80, opt steps:17, total reward:-24.0000, 0.548743486404419 sec\n",
      "Episode 3894, len10, loss:-94.9965, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5498454570770264 sec\n",
      "Episode 3895, len8, loss:-87.8473, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5446724891662598 sec\n",
      "Episode 3896, len8, loss:-81.8894, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5993607044219971 sec\n",
      "Episode 3897, len12, loss:-107.0830, fail, steps:80, opt steps:39, total reward:-24.0000, 0.549229621887207 sec\n",
      "Episode 3898, len10, loss:-92.9726, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5488376617431641 sec\n",
      "Episode 3899, len10, loss:-93.6858, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5491964817047119 sec\n",
      "Episode 3900, len10, loss:-91.1879, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5485560894012451 sec\n",
      "Episode 3901, len8, loss:-79.6460, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5497968196868896 sec\n",
      "Episode 3902, len12, loss:-108.5359, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5479915142059326 sec\n",
      "Episode 3903, len8, loss:-79.5825, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5482921600341797 sec\n",
      "Episode 3904, len12, loss:-98.7748, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5475277900695801 sec\n",
      "Episode 3905, len8, loss:-74.9173, fail, steps:80, opt steps:33, total reward:-24.0000, 0.547661542892456 sec\n",
      "Episode 3906, len10, loss:-90.9558, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5470335483551025 sec\n",
      "Episode 3907, len6, loss:-66.5164, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5473551750183105 sec\n",
      "Episode 3908, len10, loss:-97.3689, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5480613708496094 sec\n",
      "Episode 3909, len10, loss:-83.9255, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5481600761413574 sec\n",
      "Episode 3910, len6, loss:-67.0549, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5464136600494385 sec\n",
      "Episode 3911, len10, loss:-94.1965, fail, steps:80, opt steps:30, total reward:-24.0000, 0.602104663848877 sec\n",
      "Episode 3912, len12, loss:-108.9440, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5490314960479736 sec\n",
      "Episode 3913, len12, loss:-94.7374, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5481212139129639 sec\n",
      "Episode 3914, len6, loss:-59.8175, fail, steps:80, opt steps:18, total reward:-22.7000, 0.5436413288116455 sec\n",
      "Episode 3915, len8, loss:-74.9970, fail, steps:80, opt steps:6, total reward:-24.0000, 0.546971321105957 sec\n",
      "Episode 3916, len6, loss:-68.0587, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5496389865875244 sec\n",
      "Episode 3917, len12, loss:-113.1257, fail, steps:80, opt steps:44, total reward:-24.7000, 0.5464355945587158 sec\n",
      "Episode 3918, len8, loss:-85.5613, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5484058856964111 sec\n",
      "Episode 3919, len8, loss:-76.6889, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5497250556945801 sec\n",
      "Episode 3920, len12, loss:-107.1482, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5498089790344238 sec\n",
      "Episode 3921, len10, loss:-93.6833, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5497629642486572 sec\n",
      "Episode 3922, len6, loss:-65.2684, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5493285655975342 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3923, len12, loss:-97.4715, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5494661331176758 sec\n",
      "Episode 3924, len6, loss:-71.7663, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5442957878112793 sec\n",
      "Episode 3925, len12, loss:-104.1940, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5493960380554199 sec\n",
      "Episode 3926, len6, loss:-67.1308, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5483064651489258 sec\n",
      "Episode 3927, len10, loss:-90.1618, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5982315540313721 sec\n",
      "Episode 3928, len6, loss:-64.0935, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5485472679138184 sec\n",
      "Episode 3929, len6, loss:-65.5871, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5471243858337402 sec\n",
      "Episode 3930, len10, loss:-86.8646, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5492451190948486 sec\n",
      "Episode 3931, len6, loss:-64.8835, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5481970310211182 sec\n",
      "Episode 3932, len8, loss:-81.1838, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5485906600952148 sec\n",
      "Episode 3933, len10, loss:-95.5114, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5488214492797852 sec\n",
      "Episode 3934, len8, loss:-77.2136, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5486969947814941 sec\n",
      "Episode 3935, len8, loss:-71.0975, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5476133823394775 sec\n",
      "Episode 3936, len10, loss:-97.6558, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5503244400024414 sec\n",
      "Episode 3937, len6, loss:-69.1642, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5494480133056641 sec\n",
      "Episode 3938, len12, loss:-98.0717, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5491909980773926 sec\n",
      "Episode 3939, len6, loss:-68.4188, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5491883754730225 sec\n",
      "Episode 3940, len6, loss:-70.8454, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5497374534606934 sec\n",
      "Episode 3941, len12, loss:-100.8554, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5489256381988525 sec\n",
      "Episode 3942, len6, loss:-71.7239, fail, steps:80, opt steps:8, total reward:-24.0000, 0.548558235168457 sec\n",
      "Episode 3943, len6, loss:-68.1202, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5993673801422119 sec\n",
      "Episode 3944, len10, loss:-93.5638, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5498075485229492 sec\n",
      "Episode 3945, len12, loss:-92.7765, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5516049861907959 sec\n",
      "Episode 3946, len6, loss:-71.5770, fail, steps:80, opt steps:18, total reward:-23.7000, 0.5441079139709473 sec\n",
      "Episode 3947, len12, loss:-106.9471, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5440456867218018 sec\n",
      "Episode 3948, len8, loss:-81.0929, fail, steps:80, opt steps:19, total reward:-24.0000, 0.547938346862793 sec\n",
      "Episode 3949, len6, loss:-67.3134, fail, steps:80, opt steps:20, total reward:-24.0000, 0.548325777053833 sec\n",
      "Episode 3950, len12, loss:-109.0524, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5444397926330566 sec\n",
      "Episode 3951, len10, loss:-91.2170, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5478217601776123 sec\n",
      "Episode 3952, len10, loss:-90.8644, fail, steps:80, opt steps:36, total reward:-23.7000, 0.5456373691558838 sec\n",
      "Episode 3953, len6, loss:-67.2600, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5493900775909424 sec\n",
      "Episode 3954, len6, loss:-68.2463, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5492134094238281 sec\n",
      "Episode 3955, len12, loss:-104.3917, fail, steps:80, opt steps:45, total reward:-24.0000, 0.548844575881958 sec\n",
      "Episode 3956, len8, loss:-82.2305, fail, steps:80, opt steps:25, total reward:-24.0000, 0.6017229557037354 sec\n",
      "Episode 3957, len6, loss:-64.0313, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5481550693511963 sec\n",
      "Episode 3958, len10, loss:-91.9737, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5481059551239014 sec\n",
      "Episode 3959, len6, loss:-65.1882, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5496289730072021 sec\n",
      "Episode 3960, len10, loss:-87.4321, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5486464500427246 sec\n",
      "Episode 3961, len10, loss:-92.1988, fail, steps:80, opt steps:22, total reward:-24.0000, 0.549102783203125 sec\n",
      "Episode 3962, len10, loss:-96.5730, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5482327938079834 sec\n",
      "Episode 3963, len12, loss:-107.2217, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5478894710540771 sec\n",
      "Episode 3964, len10, loss:-105.3374, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5435566902160645 sec\n",
      "Episode 3965, len6, loss:-65.3778, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5478599071502686 sec\n",
      "Episode 3966, len8, loss:-78.7129, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5490241050720215 sec\n",
      "Episode 3967, len10, loss:-86.2680, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5500941276550293 sec\n",
      "Episode 3968, len8, loss:-76.2920, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5501930713653564 sec\n",
      "Episode 3969, len8, loss:-84.4989, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5491676330566406 sec\n",
      "Episode 3970, len10, loss:-90.2309, fail, steps:80, opt steps:46, total reward:-24.0000, 0.602069616317749 sec\n",
      "Episode 3971, len6, loss:-66.1494, fail, steps:80, opt steps:7, total reward:-24.0000, 0.548276424407959 sec\n",
      "Episode 3972, len10, loss:-99.4092, fail, steps:80, opt steps:54, total reward:-24.7000, 0.5467243194580078 sec\n",
      "Episode 3973, len8, loss:-75.1171, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5488286018371582 sec\n",
      "Episode 3974, len6, loss:-70.2000, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5486383438110352 sec\n",
      "Episode 3975, len8, loss:-75.8780, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5497980117797852 sec\n",
      "Episode 3976, len6, loss:-64.4289, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5480163097381592 sec\n",
      "Episode 3977, len8, loss:-82.8676, fail, steps:80, opt steps:19, total reward:-23.7000, 0.5457108020782471 sec\n",
      "Episode 3978, len6, loss:-67.6722, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5496466159820557 sec\n",
      "Episode 3979, len6, loss:-65.8540, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5487852096557617 sec\n",
      "Episode 3980, len8, loss:-82.1939, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5487649440765381 sec\n",
      "Episode 3981, len8, loss:-73.9752, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5494301319122314 sec\n",
      "Episode 3982, len8, loss:-77.1870, fail, steps:80, opt steps:7, total reward:-24.0000, 0.551628828048706 sec\n",
      "Episode 3983, len8, loss:-86.7150, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5438089370727539 sec\n",
      "Episode 3984, len12, loss:-101.8580, fail, steps:80, opt steps:45, total reward:-24.0000, 0.603844404220581 sec\n",
      "Episode 3985, len10, loss:-92.4365, fail, steps:80, opt steps:43, total reward:-24.0000, 0.549004316329956 sec\n",
      "Episode 3986, len8, loss:-74.1861, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5490097999572754 sec\n",
      "Episode 3987, len12, loss:-97.9050, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5477118492126465 sec\n",
      "Episode 3988, len6, loss:-70.7405, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5483601093292236 sec\n",
      "Episode 3989, len12, loss:-99.8422, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5475420951843262 sec\n",
      "Episode 3990, len8, loss:-76.1508, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5486838817596436 sec\n",
      "Episode 3991, len6, loss:-60.6546, fail, steps:80, opt steps:13, total reward:-22.7000, 0.5467226505279541 sec\n",
      "Episode 3992, len12, loss:-107.3359, fail, steps:80, opt steps:34, total reward:-24.7000, 0.5439140796661377 sec\n",
      "Episode 3993, len8, loss:-80.7266, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5480794906616211 sec\n",
      "Episode 3994, len12, loss:-99.3971, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5476655960083008 sec\n",
      "Episode 3995, len12, loss:-103.1043, fail, steps:80, opt steps:43, total reward:-24.7000, 0.5450763702392578 sec\n",
      "Episode 3996, len10, loss:-90.6182, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5490140914916992 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3997, len12, loss:-109.1915, fail, steps:80, opt steps:61, total reward:-24.7000, 0.543959379196167 sec\n",
      "Episode 3998, len8, loss:-83.4677, fail, steps:80, opt steps:27, total reward:-24.0000, 0.6020674705505371 sec\n",
      "Episode 3999, len8, loss:-79.9271, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5497763156890869 sec\n",
      "Episode 4000, len6, loss:-65.3431, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5490024089813232 sec\n",
      "Checkpoint saved at episode 4000 to /home/mcwave/code/autocode/datasets/rl_sort_transformer_easy/list6_12_transformer3_128_gamma07_step80_v3_merge_2_sorted/ckpt_4000_0.0000_26.24_vs_5.25.pth\n",
      "Learning rate = 0.000092\n",
      "Episode 4001, len6, loss:-65.6763, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5454859733581543 sec\n",
      "Episode 4002, len10, loss:-92.3449, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5476508140563965 sec\n",
      "Episode 4003, len10, loss:-96.0647, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5472073554992676 sec\n",
      "Episode 4004, len6, loss:-68.8970, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5479567050933838 sec\n",
      "Episode 4005, len10, loss:-90.3831, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5491549968719482 sec\n",
      "Episode 4006, len8, loss:-76.9780, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5480661392211914 sec\n",
      "Episode 4007, len12, loss:-99.7942, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5478441715240479 sec\n",
      "Episode 4008, len10, loss:-90.7252, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5484943389892578 sec\n",
      "Episode 4009, len8, loss:-81.8943, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5489320755004883 sec\n",
      "Episode 4010, len6, loss:-62.0601, fail, steps:80, opt steps:11, total reward:-24.0000, 0.549177885055542 sec\n",
      "Episode 4011, len10, loss:-96.6294, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5487120151519775 sec\n",
      "Episode 4012, len12, loss:-107.3126, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5970540046691895 sec\n",
      "Episode 4013, len12, loss:-97.5376, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5467214584350586 sec\n",
      "Episode 4014, len8, loss:-78.0786, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5471107959747314 sec\n",
      "Episode 4015, len8, loss:-80.7341, fail, steps:80, opt steps:13, total reward:-24.0000, 0.547170877456665 sec\n",
      "Episode 4016, len12, loss:-102.6355, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5471823215484619 sec\n",
      "Episode 4017, len10, loss:-93.9722, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5475955009460449 sec\n",
      "Episode 4018, len12, loss:-103.5643, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5488841533660889 sec\n",
      "Episode 4019, len12, loss:-102.8171, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5479021072387695 sec\n",
      "Episode 4020, len8, loss:-80.4294, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5490834712982178 sec\n",
      "Episode 4021, len10, loss:-98.0771, fail, steps:80, opt steps:23, total reward:-24.0000, 0.548546552658081 sec\n",
      "Episode 4022, len6, loss:-61.2877, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5582888126373291 sec\n",
      "Episode 4023, len8, loss:-85.1207, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5484864711761475 sec\n",
      "Episode 4024, len12, loss:-99.3503, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5492856502532959 sec\n",
      "Episode 4025, len6, loss:-66.4829, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5491659641265869 sec\n",
      "Episode 4026, len8, loss:-82.1853, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5455658435821533 sec\n",
      "Episode 4027, len10, loss:-96.3296, fail, steps:80, opt steps:41, total reward:-24.0000, 0.548762321472168 sec\n",
      "Episode 4028, len8, loss:-81.8827, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5993070602416992 sec\n",
      "Episode 4029, len6, loss:-54.7398, fail, steps:80, opt steps:19, total reward:-22.7000, 0.5438878536224365 sec\n",
      "Episode 4030, len6, loss:-70.4836, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5444707870483398 sec\n",
      "Episode 4031, len8, loss:-78.9334, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5480828285217285 sec\n",
      "Episode 4032, len12, loss:-98.1430, fail, steps:80, opt steps:39, total reward:-24.0000, 0.54878830909729 sec\n",
      "Episode 4033, len12, loss:-103.5794, fail, steps:80, opt steps:39, total reward:-24.0000, 0.55098557472229 sec\n",
      "Episode 4034, len10, loss:-91.2939, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5483114719390869 sec\n",
      "Episode 4035, len12, loss:-104.7255, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5494813919067383 sec\n",
      "Episode 4036, len10, loss:-97.5749, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5490975379943848 sec\n",
      "Episode 4037, len10, loss:-165.0117, fail, steps:42, opt steps:24, total reward:-23.3000, 0.29644227027893066 sec\n",
      "Episode 4038, len8, loss:-77.4842, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5263481140136719 sec\n",
      "Episode 4039, len6, loss:-64.7355, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5393030643463135 sec\n",
      "Episode 4040, len10, loss:-89.9378, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5954627990722656 sec\n",
      "Episode 4041, len6, loss:-64.7230, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5460097789764404 sec\n",
      "Episode 4042, len8, loss:-79.5405, fail, steps:80, opt steps:31, total reward:-24.0000, 0.546504020690918 sec\n",
      "Episode 4043, len8, loss:-77.2714, fail, steps:80, opt steps:23, total reward:-23.7000, 0.5501515865325928 sec\n",
      "Episode 4044, len8, loss:-71.5137, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5461647510528564 sec\n",
      "Episode 4045, len8, loss:-74.6640, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5484092235565186 sec\n",
      "Episode 4046, len8, loss:-79.1227, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5498254299163818 sec\n",
      "Episode 4047, len6, loss:-66.0672, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5477066040039062 sec\n",
      "Episode 4048, len12, loss:-105.9474, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5491995811462402 sec\n",
      "Episode 4049, len10, loss:-82.8638, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5488927364349365 sec\n",
      "Episode 4050, len10, loss:-93.3424, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5502347946166992 sec\n",
      "Episode 4051, len6, loss:-59.3567, fail, steps:80, opt steps:7, total reward:-22.7000, 0.5445482730865479 sec\n",
      "Episode 4052, len8, loss:-80.3306, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5458881855010986 sec\n",
      "Episode 4053, len12, loss:-98.1689, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5492782592773438 sec\n",
      "Episode 4054, len10, loss:-87.4927, fail, steps:80, opt steps:26, total reward:-24.0000, 0.6016271114349365 sec\n",
      "Episode 4055, len8, loss:-78.4000, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5531141757965088 sec\n",
      "Episode 4056, len6, loss:-64.4259, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5492744445800781 sec\n",
      "Episode 4057, len8, loss:-75.2341, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5479257106781006 sec\n",
      "Episode 4058, len10, loss:-91.4575, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5468659400939941 sec\n",
      "Episode 4059, len8, loss:-75.1142, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5475597381591797 sec\n",
      "Episode 4060, len8, loss:-73.6577, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5473229885101318 sec\n",
      "Episode 4061, len6, loss:-60.3596, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5467779636383057 sec\n",
      "Episode 4062, len12, loss:-108.1148, fail, steps:80, opt steps:43, total reward:-24.0000, 0.548424482345581 sec\n",
      "Episode 4063, len8, loss:-75.4154, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5479254722595215 sec\n",
      "Episode 4064, len6, loss:-67.0295, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5490081310272217 sec\n",
      "Episode 4065, len6, loss:-61.5656, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5468699932098389 sec\n",
      "Episode 4066, len10, loss:-89.4452, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5487337112426758 sec\n",
      "Episode 4067, len10, loss:-90.9708, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5477888584136963 sec\n",
      "Episode 4068, len6, loss:-69.6779, fail, steps:80, opt steps:11, total reward:-24.0000, 0.6061701774597168 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4069, len12, loss:-102.1739, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5490295886993408 sec\n",
      "Episode 4070, len8, loss:-77.3453, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5495390892028809 sec\n",
      "Episode 4071, len8, loss:-77.0785, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5476834774017334 sec\n",
      "Episode 4072, len12, loss:-100.9654, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5488824844360352 sec\n",
      "Episode 4073, len12, loss:-102.2848, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5484998226165771 sec\n",
      "Episode 4074, len6, loss:-63.1756, fail, steps:80, opt steps:17, total reward:-24.0000, 0.547553539276123 sec\n",
      "Episode 4075, len10, loss:-86.8410, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5475499629974365 sec\n",
      "Episode 4076, len10, loss:-84.9646, fail, steps:80, opt steps:31, total reward:-22.7000, 0.5440571308135986 sec\n",
      "Episode 4077, len8, loss:-88.6509, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5442848205566406 sec\n",
      "Episode 4078, len12, loss:-105.5898, fail, steps:80, opt steps:59, total reward:-24.0000, 0.548142671585083 sec\n",
      "Episode 4079, len8, loss:-75.7850, fail, steps:80, opt steps:11, total reward:-24.0000, 0.546044111251831 sec\n",
      "Episode 4080, len10, loss:-84.9532, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5478954315185547 sec\n",
      "Episode 4081, len8, loss:-77.2509, fail, steps:80, opt steps:17, total reward:-24.0000, 0.546201229095459 sec\n",
      "Episode 4082, len12, loss:-102.0317, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5483565330505371 sec\n",
      "Episode 4083, len8, loss:-85.1260, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5977773666381836 sec\n",
      "Episode 4084, len10, loss:-90.6614, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5483183860778809 sec\n",
      "Episode 4085, len6, loss:-65.2109, fail, steps:80, opt steps:13, total reward:-24.0000, 0.546048641204834 sec\n",
      "Episode 4086, len6, loss:-66.0967, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5482897758483887 sec\n",
      "Episode 4087, len10, loss:-94.7929, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5479686260223389 sec\n",
      "Episode 4088, len6, loss:-64.2595, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5475456714630127 sec\n",
      "Episode 4089, len8, loss:-74.1571, fail, steps:80, opt steps:11, total reward:-24.0000, 0.548323392868042 sec\n",
      "Episode 4090, len10, loss:-85.4804, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5490760803222656 sec\n",
      "Episode 4091, len8, loss:-72.2008, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5482614040374756 sec\n",
      "Episode 4092, len6, loss:-58.9552, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5475802421569824 sec\n",
      "Episode 4093, len12, loss:-102.6045, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5487890243530273 sec\n",
      "Episode 4094, len6, loss:-63.2236, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5481421947479248 sec\n",
      "Episode 4095, len12, loss:-98.5435, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5473558902740479 sec\n",
      "Episode 4096, len6, loss:-61.4577, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5475866794586182 sec\n",
      "Episode 4097, len10, loss:-86.5140, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5469367504119873 sec\n",
      "Episode 4098, len6, loss:-62.9731, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5480334758758545 sec\n",
      "Episode 4099, len8, loss:-79.6382, fail, steps:80, opt steps:11, total reward:-24.0000, 0.6014957427978516 sec\n",
      "Episode 4100, len8, loss:-74.7386, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5471453666687012 sec\n",
      "Episode 4101, len12, loss:-98.4475, fail, steps:80, opt steps:50, total reward:-24.7000, 0.5432822704315186 sec\n",
      "Episode 4102, len12, loss:-94.4695, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5481181144714355 sec\n",
      "Episode 4103, len12, loss:-99.2762, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5480012893676758 sec\n",
      "Episode 4104, len12, loss:-100.4643, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5492963790893555 sec\n",
      "Episode 4105, len8, loss:-72.2683, fail, steps:80, opt steps:23, total reward:-24.0000, 0.548011064529419 sec\n",
      "Episode 4106, len12, loss:-104.6631, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5510861873626709 sec\n",
      "Episode 4107, len10, loss:-86.0416, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5492424964904785 sec\n",
      "Episode 4108, len6, loss:-63.6063, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5498511791229248 sec\n",
      "Episode 4109, len12, loss:-94.8079, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5495495796203613 sec\n",
      "Episode 4110, len6, loss:-67.4592, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5494160652160645 sec\n",
      "Episode 4111, len12, loss:-100.2026, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5485453605651855 sec\n",
      "Episode 4112, len8, loss:-70.0771, fail, steps:80, opt steps:31, total reward:-24.0000, 0.549576997756958 sec\n",
      "Episode 4113, len6, loss:-61.7278, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5489592552185059 sec\n",
      "Episode 4114, len12, loss:-97.1163, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5497603416442871 sec\n",
      "Episode 4115, len10, loss:-82.3097, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5994875431060791 sec\n",
      "Episode 4116, len6, loss:-60.8644, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5499327182769775 sec\n",
      "Episode 4117, len10, loss:-83.2120, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5488808155059814 sec\n",
      "Episode 4118, len10, loss:-87.5683, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5495617389678955 sec\n",
      "Episode 4119, len10, loss:-83.8724, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5493721961975098 sec\n",
      "Episode 4120, len6, loss:-62.7523, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5493183135986328 sec\n",
      "Episode 4121, len12, loss:-108.2332, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5459322929382324 sec\n",
      "Episode 4122, len12, loss:-98.7463, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5494236946105957 sec\n",
      "Episode 4123, len8, loss:-71.2445, fail, steps:80, opt steps:6, total reward:-24.0000, 0.548741340637207 sec\n",
      "Episode 4124, len12, loss:-97.6895, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5494844913482666 sec\n",
      "Episode 4125, len12, loss:-104.6157, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5487523078918457 sec\n",
      "Episode 4126, len6, loss:-63.9182, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5481059551239014 sec\n",
      "Episode 4127, len10, loss:-95.5092, fail, steps:80, opt steps:43, total reward:-24.0000, 0.549152135848999 sec\n",
      "Episode 4128, len12, loss:-96.7422, fail, steps:80, opt steps:40, total reward:-24.0000, 0.6038291454315186 sec\n",
      "Episode 4129, len6, loss:-63.3873, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5492992401123047 sec\n",
      "Episode 4130, len10, loss:-96.3866, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5529859066009521 sec\n",
      "Episode 4131, len8, loss:-76.8777, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5490076541900635 sec\n",
      "Episode 4132, len12, loss:-99.4906, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5505967140197754 sec\n",
      "Episode 4133, len10, loss:-87.0892, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5484654903411865 sec\n",
      "Episode 4134, len12, loss:-98.7109, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5502386093139648 sec\n",
      "Episode 4135, len8, loss:-70.3283, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490949153900146 sec\n",
      "Episode 4136, len6, loss:-55.9272, fail, steps:80, opt steps:18, total reward:-22.7000, 0.5441172122955322 sec\n",
      "Episode 4137, len12, loss:-106.5410, fail, steps:80, opt steps:56, total reward:-24.0000, 0.549767255783081 sec\n",
      "Episode 4138, len10, loss:-84.9982, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5496559143066406 sec\n",
      "Episode 4139, len6, loss:-69.5790, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5437705516815186 sec\n",
      "Episode 4140, len10, loss:-86.3635, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5499007701873779 sec\n",
      "Episode 4141, len8, loss:-68.0992, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5494081974029541 sec\n",
      "Episode 4142, len12, loss:-94.6815, fail, steps:80, opt steps:43, total reward:-24.0000, 0.6068079471588135 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4143, len12, loss:-106.1100, fail, steps:80, opt steps:56, total reward:-24.7000, 0.5447685718536377 sec\n",
      "Episode 4144, len8, loss:-72.4201, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5496430397033691 sec\n",
      "Episode 4145, len8, loss:-72.2672, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5497620105743408 sec\n",
      "Episode 4146, len12, loss:-103.3480, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5499587059020996 sec\n",
      "Episode 4147, len8, loss:-65.1488, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5487959384918213 sec\n",
      "Episode 4148, len12, loss:-97.4177, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5498001575469971 sec\n",
      "Episode 4149, len6, loss:-58.4730, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5484893321990967 sec\n",
      "Episode 4150, len6, loss:-65.8232, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5502190589904785 sec\n",
      "Episode 4151, len12, loss:-80.6580, fail, steps:80, opt steps:59, total reward:-22.7000, 0.5448763370513916 sec\n",
      "Episode 4152, len6, loss:-57.0170, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5484013557434082 sec\n",
      "Episode 4153, len10, loss:-75.7234, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5492651462554932 sec\n",
      "Episode 4154, len10, loss:-75.3026, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5491881370544434 sec\n",
      "Episode 4155, len8, loss:-73.5263, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5488855838775635 sec\n",
      "Episode 4156, len6, loss:-55.7388, fail, steps:80, opt steps:12, total reward:-24.0000, 0.6024973392486572 sec\n",
      "Episode 4157, len8, loss:-66.9587, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5511372089385986 sec\n",
      "Episode 4158, len12, loss:-98.9288, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5494470596313477 sec\n",
      "Episode 4159, len6, loss:-61.6937, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5496029853820801 sec\n",
      "Episode 4160, len12, loss:-92.7272, fail, steps:80, opt steps:69, total reward:-24.0000, 0.5493001937866211 sec\n",
      "Episode 4161, len6, loss:-60.1940, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5482339859008789 sec\n",
      "Episode 4162, len6, loss:-62.4029, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5492522716522217 sec\n",
      "Episode 4163, len12, loss:-96.4585, fail, steps:80, opt steps:29, total reward:-24.0000, 0.550473690032959 sec\n",
      "Episode 4164, len10, loss:-88.6477, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5497751235961914 sec\n",
      "Episode 4165, len10, loss:-86.8080, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5495209693908691 sec\n",
      "Episode 4166, len6, loss:-64.3037, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5499050617218018 sec\n",
      "Episode 4167, len10, loss:-89.4205, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5505688190460205 sec\n",
      "Episode 4168, len12, loss:-103.6101, fail, steps:80, opt steps:22, total reward:-24.0000, 0.549950361251831 sec\n",
      "Episode 4169, len10, loss:-88.8336, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5501902103424072 sec\n",
      "Episode 4170, len12, loss:-99.9845, fail, steps:80, opt steps:42, total reward:-24.0000, 0.6000819206237793 sec\n",
      "Episode 4171, len12, loss:-88.2820, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5504889488220215 sec\n",
      "Episode 4172, len10, loss:-87.8971, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5490462779998779 sec\n",
      "Episode 4173, len10, loss:-86.8586, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5493762493133545 sec\n",
      "Episode 4174, len8, loss:-77.8743, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5480031967163086 sec\n",
      "Episode 4175, len6, loss:-63.5859, fail, steps:80, opt steps:17, total reward:-24.0000, 0.548736572265625 sec\n",
      "Episode 4176, len8, loss:-69.8495, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5485751628875732 sec\n",
      "Episode 4177, len10, loss:-87.9008, fail, steps:80, opt steps:31, total reward:-24.0000, 0.552323579788208 sec\n",
      "Episode 4178, len10, loss:-83.1524, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5483794212341309 sec\n",
      "Episode 4179, len6, loss:-63.3058, fail, steps:80, opt steps:13, total reward:-24.0000, 0.548797607421875 sec\n",
      "Episode 4180, len10, loss:-90.7716, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5483014583587646 sec\n",
      "Episode 4181, len10, loss:-87.2237, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5487017631530762 sec\n",
      "Episode 4182, len12, loss:-111.8815, fail, steps:80, opt steps:78, total reward:-24.0000, 0.5487666130065918 sec\n",
      "Episode 4183, len6, loss:-65.6694, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5484409332275391 sec\n",
      "Episode 4184, len10, loss:-85.6892, fail, steps:80, opt steps:37, total reward:-24.0000, 0.6000521183013916 sec\n",
      "Episode 4185, len6, loss:-62.0633, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5500273704528809 sec\n",
      "Episode 4186, len6, loss:-74.3571, fail, steps:80, opt steps:5, total reward:-25.4000, 0.5412282943725586 sec\n",
      "Episode 4187, len6, loss:-58.3742, fail, steps:80, opt steps:19, total reward:-24.0000, 0.547907829284668 sec\n",
      "Episode 4188, len12, loss:-90.6755, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5505616664886475 sec\n",
      "Episode 4189, len10, loss:-83.8284, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5483849048614502 sec\n",
      "Episode 4190, len10, loss:-82.9721, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5492401123046875 sec\n",
      "Episode 4191, len6, loss:-58.2684, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5495913028717041 sec\n",
      "Episode 4192, len8, loss:-74.2940, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5500838756561279 sec\n",
      "Episode 4193, len12, loss:-91.8627, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5489838123321533 sec\n",
      "Episode 4194, len6, loss:-63.4638, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5501291751861572 sec\n",
      "Episode 4195, len12, loss:-101.9295, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5501854419708252 sec\n",
      "Episode 4196, len6, loss:-65.1609, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5522575378417969 sec\n",
      "Episode 4197, len10, loss:-85.6526, fail, steps:80, opt steps:39, total reward:-24.0000, 0.548900842666626 sec\n",
      "Episode 4198, len12, loss:-111.0806, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5481710433959961 sec\n",
      "Episode 4199, len8, loss:-69.8004, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5980350971221924 sec\n",
      "Episode 4200, len10, loss:-93.8273, fail, steps:80, opt steps:26, total reward:-24.0000, 0.549077033996582 sec\n",
      "Episode 4201, len8, loss:-74.9915, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5497281551361084 sec\n",
      "Episode 4202, len10, loss:-90.9796, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5488686561584473 sec\n",
      "Episode 4203, len12, loss:-101.0469, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5486025810241699 sec\n",
      "Episode 4204, len8, loss:-71.0046, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5483131408691406 sec\n",
      "Episode 4205, len10, loss:-93.3945, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5492899417877197 sec\n",
      "Episode 4206, len12, loss:-102.7570, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5500257015228271 sec\n",
      "Episode 4207, len10, loss:-92.1116, fail, steps:80, opt steps:24, total reward:-24.0000, 0.549790620803833 sec\n",
      "Episode 4208, len10, loss:-86.3155, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5492284297943115 sec\n",
      "Episode 4209, len10, loss:-81.6171, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5499529838562012 sec\n",
      "Episode 4210, len6, loss:-69.0659, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5487267971038818 sec\n",
      "Episode 4211, len8, loss:-75.6464, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5488464832305908 sec\n",
      "Episode 4212, len12, loss:-105.1033, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5448756217956543 sec\n",
      "Episode 4213, len12, loss:-101.5099, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5494153499603271 sec\n",
      "Episode 4214, len12, loss:-107.6129, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5463178157806396 sec\n",
      "Episode 4215, len6, loss:-63.7058, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5981833934783936 sec\n",
      "Episode 4216, len6, loss:-58.2234, fail, steps:80, opt steps:10, total reward:-22.7000, 0.5435450077056885 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4217, len12, loss:-100.4818, fail, steps:80, opt steps:41, total reward:-24.0000, 0.548872709274292 sec\n",
      "Episode 4218, len8, loss:-76.6903, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5476179122924805 sec\n",
      "Episode 4219, len12, loss:-94.4754, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5491673946380615 sec\n",
      "Episode 4220, len12, loss:-92.9617, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5495555400848389 sec\n",
      "Episode 4221, len8, loss:-77.7596, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5488834381103516 sec\n",
      "Episode 4222, len10, loss:-90.7394, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5460653305053711 sec\n",
      "Episode 4223, len12, loss:-103.1285, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5540051460266113 sec\n",
      "Episode 4224, len10, loss:-87.1646, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5535266399383545 sec\n",
      "Episode 4225, len6, loss:-68.6786, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5481317043304443 sec\n",
      "Episode 4226, len10, loss:-83.8550, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5480046272277832 sec\n",
      "Episode 4227, len10, loss:-82.4541, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5476021766662598 sec\n",
      "Episode 4228, len12, loss:-100.7395, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5491187572479248 sec\n",
      "Episode 4229, len10, loss:-88.0934, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5489187240600586 sec\n",
      "Episode 4230, len12, loss:-86.3370, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5491533279418945 sec\n",
      "Episode 4231, len12, loss:-100.3990, fail, steps:80, opt steps:58, total reward:-24.0000, 0.6034777164459229 sec\n",
      "Episode 4232, len8, loss:-79.8472, fail, steps:80, opt steps:19, total reward:-24.7000, 0.543745756149292 sec\n",
      "Episode 4233, len8, loss:-118.7753, fail, steps:23, opt steps:27, total reward:-17.6000, 0.16869902610778809 sec\n",
      "Episode 4234, len8, loss:-77.6637, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5122339725494385 sec\n",
      "Episode 4235, len12, loss:-110.1040, fail, steps:80, opt steps:35, total reward:-24.7000, 0.5302228927612305 sec\n",
      "Episode 4236, len12, loss:-102.2248, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5419423580169678 sec\n",
      "Episode 4237, len6, loss:-65.7139, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5421497821807861 sec\n",
      "Episode 4238, len6, loss:-59.1077, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5447020530700684 sec\n",
      "Episode 4239, len12, loss:-96.3884, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5457401275634766 sec\n",
      "Episode 4240, len6, loss:-65.5775, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5466620922088623 sec\n",
      "Episode 4241, len12, loss:-92.2665, fail, steps:80, opt steps:44, total reward:-24.0000, 0.546166181564331 sec\n",
      "Episode 4242, len6, loss:-68.3644, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5474903583526611 sec\n",
      "Episode 4243, len8, loss:-79.3486, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5427169799804688 sec\n",
      "Episode 4244, len6, loss:-56.6809, fail, steps:80, opt steps:10, total reward:-24.0000, 0.6039550304412842 sec\n",
      "Episode 4245, len10, loss:-87.3128, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5483143329620361 sec\n",
      "Episode 4246, len12, loss:-95.0923, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5473747253417969 sec\n",
      "Episode 4247, len8, loss:-72.2197, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5485672950744629 sec\n",
      "Episode 4248, len10, loss:-80.8198, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5465257167816162 sec\n",
      "Episode 4249, len10, loss:-79.5010, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5476405620574951 sec\n",
      "Episode 4250, len8, loss:-79.6486, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5476508140563965 sec\n",
      "Episode 4251, len12, loss:-94.1361, fail, steps:80, opt steps:31, total reward:-24.0000, 0.548983097076416 sec\n",
      "Episode 4252, len10, loss:-90.7322, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5437657833099365 sec\n",
      "Episode 4253, len8, loss:-77.3334, fail, steps:80, opt steps:29, total reward:-24.0000, 0.548170804977417 sec\n",
      "Episode 4254, len10, loss:-84.1600, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5490169525146484 sec\n",
      "Episode 4255, len8, loss:-70.9987, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5484557151794434 sec\n",
      "Episode 4256, len8, loss:-67.4110, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5467381477355957 sec\n",
      "Episode 4257, len10, loss:-77.4033, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5473504066467285 sec\n",
      "Episode 4258, len8, loss:-66.8710, fail, steps:80, opt steps:32, total reward:-24.0000, 0.6029634475708008 sec\n",
      "Episode 4259, len10, loss:-82.1035, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5483155250549316 sec\n",
      "Episode 4260, len12, loss:-89.7899, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5482707023620605 sec\n",
      "Episode 4261, len10, loss:-97.4039, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5515968799591064 sec\n",
      "Episode 4262, len8, loss:-71.3483, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5485384464263916 sec\n",
      "Episode 4263, len10, loss:-84.6460, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5470855236053467 sec\n",
      "Episode 4264, len10, loss:-85.4239, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5489683151245117 sec\n",
      "Episode 4265, len10, loss:-91.4582, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5471653938293457 sec\n",
      "Episode 4266, len8, loss:-72.0195, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5484869480133057 sec\n",
      "Episode 4267, len12, loss:-102.9871, fail, steps:80, opt steps:43, total reward:-24.7000, 0.5428867340087891 sec\n",
      "Episode 4268, len12, loss:-98.6431, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5487303733825684 sec\n",
      "Episode 4269, len12, loss:-98.1168, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5495297908782959 sec\n",
      "Episode 4270, len12, loss:-103.9996, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5484755039215088 sec\n",
      "Episode 4271, len8, loss:-68.2258, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5475773811340332 sec\n",
      "Episode 4272, len12, loss:-94.3728, fail, steps:80, opt steps:34, total reward:-24.0000, 0.6030604839324951 sec\n",
      "Episode 4273, len12, loss:-90.0181, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5491831302642822 sec\n",
      "Episode 4274, len8, loss:-73.0521, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5474686622619629 sec\n",
      "Episode 4275, len12, loss:-95.0542, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5479602813720703 sec\n",
      "Episode 4276, len12, loss:-101.5484, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5473718643188477 sec\n",
      "Episode 4277, len12, loss:-94.7572, fail, steps:80, opt steps:59, total reward:-22.7000, 0.5422163009643555 sec\n",
      "Episode 4278, len6, loss:-62.4492, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5471017360687256 sec\n",
      "Episode 4279, len8, loss:-70.2875, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5472640991210938 sec\n",
      "Episode 4280, len6, loss:-66.8907, fail, steps:80, opt steps:12, total reward:-24.0000, 0.547670841217041 sec\n",
      "Episode 4281, len10, loss:-97.1630, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5478651523590088 sec\n",
      "Episode 4282, len8, loss:-64.9330, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5493655204772949 sec\n",
      "Episode 4283, len6, loss:-61.7207, fail, steps:80, opt steps:21, total reward:-24.0000, 0.548241376876831 sec\n",
      "Episode 4284, len6, loss:-64.6212, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5476534366607666 sec\n",
      "Episode 4285, len10, loss:-89.5733, fail, steps:80, opt steps:22, total reward:-23.7000, 0.5435314178466797 sec\n",
      "Episode 4286, len10, loss:-85.7720, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5478470325469971 sec\n",
      "Episode 4287, len6, loss:-63.9173, fail, steps:80, opt steps:5, total reward:-24.0000, 0.6010465621948242 sec\n",
      "Episode 4288, len6, loss:-61.8766, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5474646091461182 sec\n",
      "Episode 4289, len8, loss:-74.8355, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5482933521270752 sec\n",
      "Episode 4290, len6, loss:-70.8791, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5495500564575195 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4291, len8, loss:-72.1804, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5478930473327637 sec\n",
      "Episode 4292, len10, loss:-85.6935, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5491769313812256 sec\n",
      "Episode 4293, len10, loss:-81.2534, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5489249229431152 sec\n",
      "Episode 4294, len12, loss:-97.8211, fail, steps:80, opt steps:63, total reward:-24.7000, 0.5440208911895752 sec\n",
      "Episode 4295, len8, loss:-71.8516, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5475099086761475 sec\n",
      "Episode 4296, len6, loss:-53.5678, fail, steps:80, opt steps:6, total reward:-22.7000, 0.5446155071258545 sec\n",
      "Episode 4297, len6, loss:-62.7489, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5466787815093994 sec\n",
      "Episode 4298, len8, loss:-72.2457, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5485844612121582 sec\n",
      "Episode 4299, len6, loss:-69.5800, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5449578762054443 sec\n",
      "Episode 4300, len12, loss:-87.2054, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5484232902526855 sec\n",
      "Episode 4301, len10, loss:-81.5531, fail, steps:80, opt steps:27, total reward:-24.0000, 0.548051118850708 sec\n",
      "Episode 4302, len6, loss:-59.0677, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5474214553833008 sec\n",
      "Episode 4303, len6, loss:-61.0536, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5986404418945312 sec\n",
      "Episode 4304, len12, loss:-89.3237, fail, steps:80, opt steps:50, total reward:-22.7000, 0.5436084270477295 sec\n",
      "Episode 4305, len6, loss:-67.8481, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5482282638549805 sec\n",
      "Episode 4306, len12, loss:-94.3686, fail, steps:80, opt steps:49, total reward:-24.0000, 0.548729658126831 sec\n",
      "Episode 4307, len6, loss:-57.9979, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5465712547302246 sec\n",
      "Episode 4308, len6, loss:-57.8191, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5478558540344238 sec\n",
      "Episode 4309, len10, loss:-81.5689, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5488495826721191 sec\n",
      "Episode 4310, len10, loss:-88.8798, fail, steps:80, opt steps:27, total reward:-24.0000, 0.549072265625 sec\n",
      "Episode 4311, len8, loss:-66.5550, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5482985973358154 sec\n",
      "Episode 4312, len6, loss:-61.3938, fail, steps:80, opt steps:11, total reward:-24.0000, 0.548093318939209 sec\n",
      "Episode 4313, len8, loss:-77.2134, fail, steps:80, opt steps:35, total reward:-24.7000, 0.5439441204071045 sec\n",
      "Episode 4314, len8, loss:-77.4348, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5477242469787598 sec\n",
      "Episode 4315, len8, loss:-68.7417, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5471901893615723 sec\n",
      "Episode 4316, len10, loss:-87.4968, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5487632751464844 sec\n",
      "Episode 4317, len12, loss:-96.5467, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5468597412109375 sec\n",
      "Episode 4318, len12, loss:-94.2376, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5495033264160156 sec\n",
      "Episode 4319, len8, loss:-68.5812, fail, steps:80, opt steps:12, total reward:-24.0000, 0.600928783416748 sec\n",
      "Episode 4320, len12, loss:-94.3450, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5502572059631348 sec\n",
      "Episode 4321, len8, loss:-69.1623, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5491721630096436 sec\n",
      "Episode 4322, len6, loss:-60.0393, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5484585762023926 sec\n",
      "Episode 4323, len12, loss:-100.3604, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5490195751190186 sec\n",
      "Episode 4324, len8, loss:-70.3463, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5480422973632812 sec\n",
      "Episode 4325, len8, loss:-70.9598, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5470468997955322 sec\n",
      "Episode 4326, len10, loss:-84.7810, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5479433536529541 sec\n",
      "Episode 4327, len10, loss:-88.0348, fail, steps:80, opt steps:20, total reward:-24.0000, 0.54852294921875 sec\n",
      "Episode 4328, len6, loss:-60.1957, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5494093894958496 sec\n",
      "Episode 4329, len10, loss:-82.8795, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5487143993377686 sec\n",
      "Episode 4330, len10, loss:-93.7945, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5461289882659912 sec\n",
      "Episode 4331, len6, loss:-64.0831, fail, steps:80, opt steps:7, total reward:-24.7000, 0.5458276271820068 sec\n",
      "Episode 4332, len8, loss:-71.6754, fail, steps:80, opt steps:15, total reward:-24.0000, 0.604642391204834 sec\n",
      "Episode 4333, len6, loss:-52.9191, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5483453273773193 sec\n",
      "Episode 4334, len6, loss:-58.6592, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5499756336212158 sec\n",
      "Episode 4335, len10, loss:-78.7730, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5500578880310059 sec\n",
      "Episode 4336, len10, loss:-86.8457, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5482003688812256 sec\n",
      "Episode 4337, len12, loss:-100.2567, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5501589775085449 sec\n",
      "Episode 4338, len6, loss:-52.7940, fail, steps:80, opt steps:17, total reward:-22.7000, 0.5457704067230225 sec\n",
      "Episode 4339, len10, loss:-89.4486, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5485246181488037 sec\n",
      "Episode 4340, len6, loss:-63.8124, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5494775772094727 sec\n",
      "Episode 4341, len6, loss:-63.1016, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5489025115966797 sec\n",
      "Episode 4342, len10, loss:-80.2275, fail, steps:80, opt steps:33, total reward:-22.7000, 0.5454254150390625 sec\n",
      "Episode 4343, len12, loss:-108.7361, fail, steps:80, opt steps:36, total reward:-24.7000, 0.5443437099456787 sec\n",
      "Episode 4344, len10, loss:-91.9817, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5497596263885498 sec\n",
      "Episode 4345, len6, loss:-51.9424, fail, steps:80, opt steps:18, total reward:-22.7000, 0.5467057228088379 sec\n",
      "Episode 4346, len10, loss:-87.9417, fail, steps:80, opt steps:28, total reward:-24.0000, 0.60172438621521 sec\n",
      "Episode 4347, len10, loss:-96.5192, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5442414283752441 sec\n",
      "Episode 4348, len6, loss:-63.7178, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5450854301452637 sec\n",
      "Episode 4349, len12, loss:-95.9099, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5498175621032715 sec\n",
      "Episode 4350, len12, loss:-100.9564, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5506682395935059 sec\n",
      "Episode 4351, len12, loss:-99.2204, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5485312938690186 sec\n",
      "Episode 4352, len6, loss:-68.4060, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5490376949310303 sec\n",
      "Episode 4353, len8, loss:-74.9123, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5497510433197021 sec\n",
      "Episode 4354, len8, loss:-71.6290, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5486900806427002 sec\n",
      "Episode 4355, len10, loss:-94.2748, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5490436553955078 sec\n",
      "Episode 4356, len10, loss:-86.2271, fail, steps:80, opt steps:10, total reward:-24.0000, 0.550330400466919 sec\n",
      "Episode 4357, len10, loss:-85.0919, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5487453937530518 sec\n",
      "Episode 4358, len10, loss:-90.7310, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5490987300872803 sec\n",
      "Episode 4359, len12, loss:-90.8274, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5504260063171387 sec\n",
      "Episode 4360, len12, loss:-98.5988, fail, steps:80, opt steps:53, total reward:-24.0000, 0.6016252040863037 sec\n",
      "Episode 4361, len12, loss:-99.0886, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5491881370544434 sec\n",
      "Episode 4362, len8, loss:-70.8764, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5495777130126953 sec\n",
      "Episode 4363, len12, loss:-90.3846, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5512790679931641 sec\n",
      "Episode 4364, len12, loss:-87.3797, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5483477115631104 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4365, len8, loss:-72.8447, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5494205951690674 sec\n",
      "Episode 4366, len8, loss:-67.7733, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5483870506286621 sec\n",
      "Episode 4367, len10, loss:-80.5697, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5488314628601074 sec\n",
      "Episode 4368, len10, loss:-77.3223, fail, steps:80, opt steps:31, total reward:-23.7000, 0.5448410511016846 sec\n",
      "Episode 4369, len8, loss:-68.5264, fail, steps:80, opt steps:4, total reward:-24.0000, 0.54888916015625 sec\n",
      "Episode 4370, len10, loss:-81.6014, fail, steps:80, opt steps:33, total reward:-23.7000, 0.5451087951660156 sec\n",
      "Episode 4371, len10, loss:-82.6581, fail, steps:80, opt steps:25, total reward:-24.0000, 0.549358606338501 sec\n",
      "Episode 4372, len6, loss:-55.6878, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5506165027618408 sec\n",
      "Episode 4373, len10, loss:-81.9040, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5494420528411865 sec\n",
      "Episode 4374, len6, loss:-54.3057, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5984711647033691 sec\n",
      "Episode 4375, len6, loss:-51.1419, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5493946075439453 sec\n",
      "Episode 4376, len8, loss:-71.4752, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5495314598083496 sec\n",
      "Episode 4377, len6, loss:-57.6074, fail, steps:80, opt steps:20, total reward:-24.7000, 0.5449512004852295 sec\n",
      "Episode 4378, len8, loss:-70.1952, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5493357181549072 sec\n",
      "Episode 4379, len10, loss:-77.2339, fail, steps:80, opt steps:55, total reward:-23.7000, 0.5436441898345947 sec\n",
      "Episode 4380, len10, loss:-83.8110, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5492880344390869 sec\n",
      "Episode 4381, len8, loss:-62.4395, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5496304035186768 sec\n",
      "Episode 4382, len12, loss:-94.4245, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5490336418151855 sec\n",
      "Episode 4383, len8, loss:-64.9647, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5495383739471436 sec\n",
      "Episode 4384, len8, loss:-65.2879, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5492887496948242 sec\n",
      "Episode 4385, len12, loss:-93.2816, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5458841323852539 sec\n",
      "Episode 4386, len12, loss:-91.9861, fail, steps:80, opt steps:42, total reward:-24.0000, 0.548738956451416 sec\n",
      "Episode 4387, len8, loss:-61.8781, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5495548248291016 sec\n",
      "Episode 4388, len8, loss:-65.8740, fail, steps:80, opt steps:23, total reward:-24.0000, 0.6002321243286133 sec\n",
      "Episode 4389, len6, loss:-56.7251, fail, steps:80, opt steps:14, total reward:-24.0000, 0.547966718673706 sec\n",
      "Episode 4390, len12, loss:-87.7378, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5500757694244385 sec\n",
      "Episode 4391, len8, loss:-55.0278, fail, steps:80, opt steps:26, total reward:-24.0000, 0.548924446105957 sec\n",
      "Episode 4392, len12, loss:-81.4234, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5489499568939209 sec\n",
      "Episode 4393, len10, loss:-82.1813, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5480201244354248 sec\n",
      "Episode 4394, len6, loss:-54.6751, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5505819320678711 sec\n",
      "Episode 4395, len6, loss:-51.9940, fail, steps:80, opt steps:11, total reward:-22.7000, 0.5454518795013428 sec\n",
      "Episode 4396, len10, loss:-87.0832, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5483136177062988 sec\n",
      "Episode 4397, len6, loss:-55.1774, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5497102737426758 sec\n",
      "Episode 4398, len10, loss:-78.4866, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5488662719726562 sec\n",
      "Episode 4399, len12, loss:-83.1379, fail, steps:80, opt steps:64, total reward:-22.7000, 0.5821328163146973 sec\n",
      "Episode 4400, len12, loss:-83.8433, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5506775379180908 sec\n",
      "Episode 4401, len12, loss:-92.8939, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5505871772766113 sec\n",
      "Episode 4402, len6, loss:-57.3276, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5449950695037842 sec\n",
      "Episode 4403, len12, loss:-96.6483, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5977573394775391 sec\n",
      "Episode 4404, len8, loss:-67.6234, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5497775077819824 sec\n",
      "Episode 4405, len8, loss:-64.3500, fail, steps:80, opt steps:12, total reward:-24.0000, 0.547938346862793 sec\n",
      "Episode 4406, len6, loss:-60.8244, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5447144508361816 sec\n",
      "Episode 4407, len6, loss:-57.4030, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5494921207427979 sec\n",
      "Episode 4408, len8, loss:-71.4740, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5490550994873047 sec\n",
      "Episode 4409, len10, loss:-81.3117, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5504472255706787 sec\n",
      "Episode 4410, len6, loss:-52.6048, fail, steps:80, opt steps:10, total reward:-24.0000, 0.550342321395874 sec\n",
      "Episode 4411, len12, loss:-92.6314, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5501394271850586 sec\n",
      "Episode 4412, len8, loss:-68.0432, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5495030879974365 sec\n",
      "Episode 4413, len10, loss:-76.8995, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5494673252105713 sec\n",
      "Episode 4414, len6, loss:-56.9785, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5490767955780029 sec\n",
      "Episode 4415, len6, loss:-56.4283, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5483145713806152 sec\n",
      "Episode 4416, len12, loss:-93.2800, fail, steps:80, opt steps:71, total reward:-24.0000, 0.5493152141571045 sec\n",
      "Episode 4417, len8, loss:-58.0962, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5494954586029053 sec\n",
      "Episode 4418, len10, loss:-81.2884, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5502002239227295 sec\n",
      "Episode 4419, len12, loss:-89.7599, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5994007587432861 sec\n",
      "Episode 4420, len10, loss:-83.3767, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5493624210357666 sec\n",
      "Episode 4421, len8, loss:-60.0802, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5491666793823242 sec\n",
      "Episode 4422, len12, loss:-87.0852, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5493464469909668 sec\n",
      "Episode 4423, len10, loss:-77.8618, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5491883754730225 sec\n",
      "Episode 4424, len6, loss:-52.6434, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5494785308837891 sec\n",
      "Episode 4425, len6, loss:-56.8363, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5488734245300293 sec\n",
      "Episode 4426, len6, loss:-51.6275, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5490226745605469 sec\n",
      "Episode 4427, len6, loss:-54.6259, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5485994815826416 sec\n",
      "Episode 4428, len8, loss:-68.1459, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5488252639770508 sec\n",
      "Episode 4429, len6, loss:-51.0925, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5485138893127441 sec\n",
      "Episode 4430, len10, loss:-85.3057, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5498788356781006 sec\n",
      "Episode 4431, len10, loss:-74.5987, fail, steps:80, opt steps:41, total reward:-23.7000, 0.5442943572998047 sec\n",
      "Episode 4432, len12, loss:-92.2564, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5494663715362549 sec\n",
      "Episode 4433, len12, loss:-83.3520, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5484864711761475 sec\n",
      "Episode 4434, len12, loss:-80.5166, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5498867034912109 sec\n",
      "Episode 4435, len6, loss:-51.8577, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5992324352264404 sec\n",
      "Episode 4436, len12, loss:-87.6426, fail, steps:80, opt steps:64, total reward:-24.0000, 0.550722599029541 sec\n",
      "Episode 4437, len12, loss:-100.6461, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5489394664764404 sec\n",
      "Episode 4438, len12, loss:-87.3414, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5496840476989746 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4439, len12, loss:-87.5240, fail, steps:80, opt steps:72, total reward:-24.0000, 0.5504894256591797 sec\n",
      "Episode 4440, len12, loss:-93.8669, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5507030487060547 sec\n",
      "Episode 4441, len6, loss:-52.1311, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5497066974639893 sec\n",
      "Episode 4442, len6, loss:-55.1819, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5489153861999512 sec\n",
      "Episode 4443, len6, loss:-54.9635, fail, steps:80, opt steps:6, total reward:-24.0000, 0.54905104637146 sec\n",
      "Episode 4444, len6, loss:-57.7259, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485126972198486 sec\n",
      "Episode 4445, len12, loss:-84.7108, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5493640899658203 sec\n",
      "Episode 4446, len10, loss:-74.1910, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5507855415344238 sec\n",
      "Episode 4447, len8, loss:-68.4332, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5497286319732666 sec\n",
      "Episode 4448, len10, loss:-77.2091, fail, steps:80, opt steps:29, total reward:-24.0000, 0.6028003692626953 sec\n",
      "Episode 4449, len10, loss:-74.4727, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5484650135040283 sec\n",
      "Episode 4450, len8, loss:-61.1183, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5513710975646973 sec\n",
      "Episode 4451, len6, loss:-56.4515, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5487229824066162 sec\n",
      "Episode 4452, len12, loss:-97.0954, fail, steps:80, opt steps:50, total reward:-24.0000, 0.549933671951294 sec\n",
      "Episode 4453, len6, loss:-54.5405, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5492382049560547 sec\n",
      "Episode 4454, len6, loss:-55.2965, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5478897094726562 sec\n",
      "Episode 4455, len8, loss:-67.3465, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5497848987579346 sec\n",
      "Episode 4456, len12, loss:-88.4554, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5507898330688477 sec\n",
      "Episode 4457, len10, loss:-83.3486, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5501251220703125 sec\n",
      "Episode 4458, len8, loss:-70.6174, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5482628345489502 sec\n",
      "Episode 4459, len10, loss:-93.9159, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5501906871795654 sec\n",
      "Episode 4460, len12, loss:-88.6663, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5519602298736572 sec\n",
      "Episode 4461, len12, loss:-87.3697, fail, steps:80, opt steps:52, total reward:-24.0000, 0.551361083984375 sec\n",
      "Episode 4462, len6, loss:-62.9143, fail, steps:80, opt steps:18, total reward:-24.0000, 0.6015596389770508 sec\n",
      "Episode 4463, len10, loss:-85.9287, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5504758358001709 sec\n",
      "Episode 4464, len6, loss:-59.7456, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5448267459869385 sec\n",
      "Episode 4465, len12, loss:-101.4950, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5486431121826172 sec\n",
      "Episode 4466, len8, loss:-77.8543, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5477080345153809 sec\n",
      "Episode 4467, len6, loss:-60.4849, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5486276149749756 sec\n",
      "Episode 4468, len6, loss:-57.1272, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5484151840209961 sec\n",
      "Episode 4469, len10, loss:-85.8230, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5497515201568604 sec\n",
      "Episode 4470, len8, loss:-69.9823, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5495386123657227 sec\n",
      "Episode 4471, len8, loss:-70.6281, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5491905212402344 sec\n",
      "Episode 4472, len12, loss:-96.6380, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5495975017547607 sec\n",
      "Episode 4473, len8, loss:-63.4831, fail, steps:80, opt steps:23, total reward:-22.7000, 0.5449559688568115 sec\n",
      "Episode 4474, len6, loss:-63.3582, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5482089519500732 sec\n",
      "Episode 4475, len6, loss:-58.0845, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5494496822357178 sec\n",
      "Episode 4476, len10, loss:-79.8093, fail, steps:80, opt steps:43, total reward:-24.0000, 0.6011233329772949 sec\n",
      "Episode 4477, len12, loss:-92.0932, fail, steps:80, opt steps:71, total reward:-24.0000, 0.5500764846801758 sec\n",
      "Episode 4478, len10, loss:-84.5154, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5556769371032715 sec\n",
      "Episode 4479, len6, loss:-58.5761, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5485434532165527 sec\n",
      "Episode 4480, len12, loss:-98.5548, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5482809543609619 sec\n",
      "Episode 4481, len12, loss:-95.9681, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5489082336425781 sec\n",
      "Episode 4482, len10, loss:-85.2089, fail, steps:80, opt steps:26, total reward:-24.0000, 0.54844069480896 sec\n",
      "Episode 4483, len10, loss:-91.3110, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5483846664428711 sec\n",
      "Episode 4484, len6, loss:-65.1123, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5507907867431641 sec\n",
      "Episode 4485, len12, loss:-99.1891, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5492348670959473 sec\n",
      "Episode 4486, len6, loss:-59.4872, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5501432418823242 sec\n",
      "Episode 4487, len12, loss:-100.5542, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5497689247131348 sec\n",
      "Episode 4488, len6, loss:-63.4422, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5490827560424805 sec\n",
      "Episode 4489, len6, loss:-64.1513, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5499241352081299 sec\n",
      "Episode 4490, len6, loss:-60.1249, fail, steps:80, opt steps:8, total reward:-24.0000, 0.6005871295928955 sec\n",
      "Episode 4491, len10, loss:-85.1976, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5453197956085205 sec\n",
      "Episode 4492, len12, loss:-104.4805, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5485780239105225 sec\n",
      "Episode 4493, len10, loss:-88.7230, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5492696762084961 sec\n",
      "Episode 4494, len10, loss:-98.3578, fail, steps:80, opt steps:29, total reward:-24.0000, 0.549501895904541 sec\n",
      "Episode 4495, len10, loss:-82.2554, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5489199161529541 sec\n",
      "Episode 4496, len12, loss:-98.9131, fail, steps:80, opt steps:67, total reward:-24.7000, 0.5461533069610596 sec\n",
      "Episode 4497, len6, loss:-63.7630, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5490171909332275 sec\n",
      "Episode 4498, len12, loss:-99.9816, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5512645244598389 sec\n",
      "Episode 4499, len8, loss:-71.2410, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5494160652160645 sec\n",
      "Episode 4500, len6, loss:-62.4377, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5518901348114014 sec\n",
      "Episode 4501, len6, loss:-64.8338, fail, steps:80, opt steps:13, total reward:-24.0000, 0.548621654510498 sec\n",
      "Episode 4502, len6, loss:-57.2759, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5497653484344482 sec\n",
      "Episode 4503, len6, loss:-60.1016, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5481171607971191 sec\n",
      "Episode 4504, len12, loss:-85.0370, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5998594760894775 sec\n",
      "Episode 4505, len8, loss:-76.8207, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5492429733276367 sec\n",
      "Episode 4506, len12, loss:-91.4857, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5500612258911133 sec\n",
      "Episode 4507, len8, loss:-75.6623, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5489282608032227 sec\n",
      "Episode 4508, len10, loss:-94.4976, fail, steps:80, opt steps:24, total reward:-24.7000, 0.545792818069458 sec\n",
      "Episode 4509, len10, loss:-83.1394, fail, steps:80, opt steps:43, total reward:-23.7000, 0.5447921752929688 sec\n",
      "Episode 4510, len12, loss:-100.6598, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5490596294403076 sec\n",
      "Episode 4511, len8, loss:-65.1392, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5496237277984619 sec\n",
      "Episode 4512, len10, loss:-80.7745, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5522265434265137 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4513, len6, loss:-52.4541, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5495624542236328 sec\n",
      "Episode 4514, len12, loss:-88.8004, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5502874851226807 sec\n",
      "Episode 4515, len6, loss:-60.8230, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5491917133331299 sec\n",
      "Episode 4516, len12, loss:-91.2735, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5497434139251709 sec\n",
      "Episode 4517, len12, loss:-98.3188, fail, steps:80, opt steps:44, total reward:-24.7000, 0.5453975200653076 sec\n",
      "Episode 4518, len12, loss:-96.6461, fail, steps:80, opt steps:53, total reward:-24.0000, 0.549933671951294 sec\n",
      "Episode 4519, len10, loss:-80.6939, fail, steps:80, opt steps:20, total reward:-24.0000, 0.599158763885498 sec\n",
      "Episode 4520, len12, loss:-90.8659, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5492398738861084 sec\n",
      "Episode 4521, len8, loss:-65.0065, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5487082004547119 sec\n",
      "Episode 4522, len6, loss:-54.3221, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5507588386535645 sec\n",
      "Episode 4523, len8, loss:-66.2830, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5497524738311768 sec\n",
      "Episode 4524, len6, loss:-54.8236, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5481235980987549 sec\n",
      "Episode 4525, len6, loss:-59.1506, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5494282245635986 sec\n",
      "Episode 4526, len6, loss:-56.3025, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5520327091217041 sec\n",
      "Episode 4527, len10, loss:-80.0719, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5495569705963135 sec\n",
      "Episode 4528, len6, loss:-66.4046, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5451300144195557 sec\n",
      "Episode 4529, len12, loss:-98.0533, fail, steps:80, opt steps:31, total reward:-24.0000, 0.549687385559082 sec\n",
      "Episode 4530, len12, loss:-98.2418, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5496430397033691 sec\n",
      "Episode 4531, len10, loss:-84.3804, fail, steps:80, opt steps:43, total reward:-24.0000, 0.548506498336792 sec\n",
      "Episode 4532, len10, loss:-90.0722, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5488865375518799 sec\n",
      "Episode 4533, len10, loss:-82.1739, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5489912033081055 sec\n",
      "Episode 4534, len6, loss:-57.6458, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5497002601623535 sec\n",
      "Episode 4535, len10, loss:-80.8327, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5980570316314697 sec\n",
      "Episode 4536, len8, loss:-69.9203, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5487656593322754 sec\n",
      "Episode 4537, len10, loss:-89.6332, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5501053333282471 sec\n",
      "Episode 4538, len8, loss:-66.0209, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5484251976013184 sec\n",
      "Episode 4539, len10, loss:-83.0538, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5484201908111572 sec\n",
      "Episode 4540, len12, loss:-100.5412, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5485508441925049 sec\n",
      "Episode 4541, len12, loss:-94.7069, fail, steps:80, opt steps:73, total reward:-24.0000, 0.5489492416381836 sec\n",
      "Episode 4542, len10, loss:-89.9360, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5494718551635742 sec\n",
      "Episode 4543, len10, loss:-83.5742, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5486667156219482 sec\n",
      "Episode 4544, len10, loss:-87.7794, fail, steps:80, opt steps:28, total reward:-24.0000, 0.550349235534668 sec\n",
      "Episode 4545, len8, loss:-78.4660, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5493626594543457 sec\n",
      "Episode 4546, len12, loss:-98.6800, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5495209693908691 sec\n",
      "Episode 4547, len6, loss:-65.9251, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5492992401123047 sec\n",
      "Episode 4548, len10, loss:-96.5938, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5501320362091064 sec\n",
      "Episode 4549, len8, loss:-73.0510, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5493888854980469 sec\n",
      "Episode 4550, len8, loss:-77.8691, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5500636100769043 sec\n",
      "Episode 4551, len8, loss:-82.7969, fail, steps:80, opt steps:15, total reward:-24.0000, 0.599520206451416 sec\n",
      "Episode 4552, len6, loss:-66.9443, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5485823154449463 sec\n",
      "Episode 4553, len10, loss:-90.2240, fail, steps:80, opt steps:33, total reward:-23.7000, 0.5467360019683838 sec\n",
      "Episode 4554, len12, loss:-102.0335, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5484962463378906 sec\n",
      "Episode 4555, len12, loss:-101.2296, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5501606464385986 sec\n",
      "Episode 4556, len6, loss:-61.8561, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5501925945281982 sec\n",
      "Episode 4557, len12, loss:-99.9320, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5487213134765625 sec\n",
      "Episode 4558, len12, loss:-98.1814, fail, steps:80, opt steps:48, total reward:-23.7000, 0.5455424785614014 sec\n",
      "Episode 4559, len10, loss:-93.1585, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5494449138641357 sec\n",
      "Episode 4560, len6, loss:-63.6801, fail, steps:80, opt steps:13, total reward:-24.0000, 0.548377513885498 sec\n",
      "Episode 4561, len6, loss:-68.5252, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5492920875549316 sec\n",
      "Episode 4562, len6, loss:-62.9078, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5505526065826416 sec\n",
      "Episode 4563, len6, loss:-65.4312, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5492091178894043 sec\n",
      "Episode 4564, len10, loss:-103.1666, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5990819931030273 sec\n",
      "Episode 4565, len12, loss:-95.8157, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5480358600616455 sec\n",
      "Episode 4566, len6, loss:-59.4739, fail, steps:80, opt steps:19, total reward:-24.0000, 0.549687385559082 sec\n",
      "Episode 4567, len10, loss:-93.6615, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5490727424621582 sec\n",
      "Episode 4568, len6, loss:-70.5483, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5486938953399658 sec\n",
      "Episode 4569, len6, loss:-68.4024, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5482409000396729 sec\n",
      "Episode 4570, len6, loss:-65.4203, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5505211353302002 sec\n",
      "Episode 4571, len8, loss:-79.7048, fail, steps:80, opt steps:4, total reward:-24.0000, 0.549494743347168 sec\n",
      "Episode 4572, len6, loss:-70.4000, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5484409332275391 sec\n",
      "Episode 4573, len10, loss:-87.4274, fail, steps:80, opt steps:42, total reward:-23.7000, 0.5454707145690918 sec\n",
      "Episode 4574, len8, loss:-84.5804, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5445597171783447 sec\n",
      "Episode 4575, len6, loss:-66.9437, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5480232238769531 sec\n",
      "Episode 4576, len8, loss:-81.5680, fail, steps:80, opt steps:8, total reward:-24.0000, 0.549079179763794 sec\n",
      "Episode 4577, len10, loss:-95.4271, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5504899024963379 sec\n",
      "Episode 4578, len6, loss:-75.7726, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5978081226348877 sec\n",
      "Episode 4579, len6, loss:-61.7027, fail, steps:80, opt steps:8, total reward:-24.0000, 0.547309160232544 sec\n",
      "Episode 4580, len10, loss:-98.7977, fail, steps:80, opt steps:46, total reward:-24.7000, 0.5450417995452881 sec\n",
      "Episode 4581, len6, loss:-64.0523, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5478198528289795 sec\n",
      "Episode 4582, len12, loss:-104.3567, fail, steps:80, opt steps:52, total reward:-24.0000, 0.549936056137085 sec\n",
      "Episode 4583, len8, loss:-76.7671, fail, steps:80, opt steps:33, total reward:-24.0000, 0.549018383026123 sec\n",
      "Episode 4584, len10, loss:-96.5046, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5483272075653076 sec\n",
      "Episode 4585, len8, loss:-84.5646, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5461130142211914 sec\n",
      "Episode 4586, len6, loss:-63.4719, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5507481098175049 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4587, len8, loss:-76.2259, fail, steps:80, opt steps:16, total reward:-23.7000, 0.5447757244110107 sec\n",
      "Episode 4588, len8, loss:-83.3949, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5482742786407471 sec\n",
      "Episode 4589, len10, loss:-98.3283, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5497093200683594 sec\n",
      "Episode 4590, len8, loss:-80.6221, fail, steps:80, opt steps:13, total reward:-24.0000, 0.549487829208374 sec\n",
      "Episode 4591, len6, loss:-65.9841, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5495054721832275 sec\n",
      "Episode 4592, len8, loss:-73.5294, fail, steps:80, opt steps:8, total reward:-24.0000, 0.600407600402832 sec\n",
      "Episode 4593, len8, loss:-78.7507, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5492665767669678 sec\n",
      "Episode 4594, len8, loss:-80.0201, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5493505001068115 sec\n",
      "Episode 4595, len8, loss:-79.4836, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5483481884002686 sec\n",
      "Episode 4596, len12, loss:-101.4912, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5494875907897949 sec\n",
      "Episode 4597, len10, loss:-97.2269, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5491728782653809 sec\n",
      "Episode 4598, len10, loss:-93.4272, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5501258373260498 sec\n",
      "Episode 4599, len10, loss:-92.1355, fail, steps:80, opt steps:38, total reward:-24.0000, 0.548628568649292 sec\n",
      "Episode 4600, len6, loss:-71.5574, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5498833656311035 sec\n",
      "Episode 4601, len8, loss:-82.6302, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5497140884399414 sec\n",
      "Episode 4602, len12, loss:-99.9342, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5504090785980225 sec\n",
      "Episode 4603, len10, loss:-89.0475, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5511600971221924 sec\n",
      "Episode 4604, len8, loss:-76.4464, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5504486560821533 sec\n",
      "Episode 4605, len6, loss:-61.5528, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5497853755950928 sec\n",
      "Episode 4606, len10, loss:-95.4094, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5999445915222168 sec\n",
      "Episode 4607, len10, loss:-91.2081, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5496139526367188 sec\n",
      "Episode 4608, len6, loss:-67.6069, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5481736660003662 sec\n",
      "Episode 4609, len6, loss:-68.4455, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5491344928741455 sec\n",
      "Episode 4610, len10, loss:-98.9356, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5460629463195801 sec\n",
      "Episode 4611, len12, loss:-106.4620, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5494532585144043 sec\n",
      "Episode 4612, len10, loss:-104.5210, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5494520664215088 sec\n",
      "Episode 4613, len8, loss:-93.3569, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5445413589477539 sec\n",
      "Episode 4614, len8, loss:-78.3251, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5489475727081299 sec\n",
      "Episode 4615, len10, loss:-99.3239, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5487468242645264 sec\n",
      "Episode 4616, len10, loss:-93.6166, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5497312545776367 sec\n",
      "Episode 4617, len10, loss:-92.3590, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5493326187133789 sec\n",
      "Episode 4618, len10, loss:-90.6089, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5511400699615479 sec\n",
      "Episode 4619, len6, loss:-62.6922, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5488486289978027 sec\n",
      "Episode 4620, len12, loss:-106.5979, fail, steps:80, opt steps:49, total reward:-24.0000, 0.6000795364379883 sec\n",
      "Episode 4621, len6, loss:-67.7393, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5503950119018555 sec\n",
      "Episode 4622, len6, loss:-65.9551, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5493934154510498 sec\n",
      "Episode 4623, len8, loss:-81.9267, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5486834049224854 sec\n",
      "Episode 4624, len10, loss:-93.6454, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5503158569335938 sec\n",
      "Episode 4625, len12, loss:-103.2940, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5486040115356445 sec\n",
      "Episode 4626, len8, loss:-81.9931, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5488932132720947 sec\n",
      "Episode 4627, len6, loss:-64.7760, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5487749576568604 sec\n",
      "Episode 4628, len10, loss:-93.2460, fail, steps:80, opt steps:18, total reward:-24.0000, 0.550126314163208 sec\n",
      "Episode 4629, len10, loss:-93.8068, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5497019290924072 sec\n",
      "Episode 4630, len6, loss:-66.7041, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5493061542510986 sec\n",
      "Episode 4631, len12, loss:-104.2022, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5489935874938965 sec\n",
      "Episode 4632, len12, loss:-108.9612, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5479302406311035 sec\n",
      "Episode 4633, len12, loss:-107.8722, fail, steps:80, opt steps:75, total reward:-24.0000, 0.548346996307373 sec\n",
      "Episode 4634, len10, loss:-91.8315, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5498239994049072 sec\n",
      "Episode 4635, len8, loss:-81.5355, fail, steps:80, opt steps:23, total reward:-24.0000, 0.599104642868042 sec\n",
      "Episode 4636, len8, loss:-83.9225, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5505602359771729 sec\n",
      "Episode 4637, len10, loss:-95.1074, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5496077537536621 sec\n",
      "Episode 4638, len12, loss:-108.1299, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5494825839996338 sec\n",
      "Episode 4639, len8, loss:-87.1076, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5481052398681641 sec\n",
      "Episode 4640, len12, loss:-107.0484, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5488944053649902 sec\n",
      "Episode 4641, len12, loss:-106.5649, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5498430728912354 sec\n",
      "Episode 4642, len8, loss:-79.2185, fail, steps:80, opt steps:14, total reward:-24.0000, 0.549429178237915 sec\n",
      "Episode 4643, len6, loss:-68.4022, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5496070384979248 sec\n",
      "Episode 4644, len12, loss:-104.9706, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5494570732116699 sec\n",
      "Episode 4645, len6, loss:-64.0854, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5480890274047852 sec\n",
      "Episode 4646, len8, loss:-87.9637, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5503332614898682 sec\n",
      "Episode 4647, len6, loss:-76.9697, fail, steps:80, opt steps:7, total reward:-24.7000, 0.5436325073242188 sec\n",
      "Episode 4648, len8, loss:-78.2988, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5492827892303467 sec\n",
      "Episode 4649, len10, loss:-90.9401, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5490331649780273 sec\n",
      "Episode 4650, len6, loss:-61.2936, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5490295886993408 sec\n",
      "Episode 4651, len8, loss:-77.9010, fail, steps:80, opt steps:33, total reward:-24.0000, 0.6023004055023193 sec\n",
      "Episode 4652, len6, loss:-62.6765, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5493113994598389 sec\n",
      "Episode 4653, len12, loss:-100.1594, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5490870475769043 sec\n",
      "Episode 4654, len12, loss:-103.8991, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5496554374694824 sec\n",
      "Episode 4655, len10, loss:-91.5947, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5496466159820557 sec\n",
      "Episode 4656, len10, loss:-90.8149, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5492143630981445 sec\n",
      "Episode 4657, len12, loss:-114.4408, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5477695465087891 sec\n",
      "Episode 4658, len8, loss:-76.0129, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5503134727478027 sec\n",
      "Episode 4659, len6, loss:-60.8709, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5499885082244873 sec\n",
      "Episode 4660, len6, loss:-64.7174, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5496678352355957 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4661, len12, loss:-104.5907, fail, steps:80, opt steps:67, total reward:-23.7000, 0.5459432601928711 sec\n",
      "Episode 4662, len8, loss:-81.7284, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5489859580993652 sec\n",
      "Episode 4663, len10, loss:-90.7638, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5501420497894287 sec\n",
      "Episode 4664, len6, loss:-60.5081, fail, steps:80, opt steps:19, total reward:-24.0000, 0.549760103225708 sec\n",
      "Episode 4665, len10, loss:-90.3197, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5503575801849365 sec\n",
      "Episode 4666, len6, loss:-57.8503, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5503203868865967 sec\n",
      "Episode 4667, len6, loss:-57.9131, fail, steps:80, opt steps:11, total reward:-24.0000, 0.6011157035827637 sec\n",
      "Episode 4668, len12, loss:-96.8766, fail, steps:80, opt steps:44, total reward:-24.0000, 0.54996657371521 sec\n",
      "Episode 4669, len10, loss:-90.6894, fail, steps:80, opt steps:38, total reward:-24.0000, 0.549375057220459 sec\n",
      "Episode 4670, len10, loss:-94.7106, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5483360290527344 sec\n",
      "Episode 4671, len6, loss:-68.3156, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5492148399353027 sec\n",
      "Episode 4672, len6, loss:-62.0221, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5496952533721924 sec\n",
      "Episode 4673, len8, loss:-77.7059, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5495357513427734 sec\n",
      "Episode 4674, len8, loss:-77.8906, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5490837097167969 sec\n",
      "Episode 4675, len12, loss:-103.8863, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5504016876220703 sec\n",
      "Episode 4676, len10, loss:-93.9802, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5486888885498047 sec\n",
      "Episode 4677, len10, loss:-93.4879, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5496695041656494 sec\n",
      "Episode 4678, len10, loss:-87.1015, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5503096580505371 sec\n",
      "Episode 4679, len12, loss:-106.7284, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5508160591125488 sec\n",
      "Episode 4680, len12, loss:-97.5163, fail, steps:80, opt steps:53, total reward:-24.0000, 0.6035799980163574 sec\n",
      "Episode 4681, len6, loss:-60.9418, fail, steps:80, opt steps:21, total reward:-24.0000, 0.547865629196167 sec\n",
      "Episode 4682, len10, loss:-91.5034, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5486793518066406 sec\n",
      "Episode 4683, len10, loss:-90.0197, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5465829372406006 sec\n",
      "Episode 4684, len12, loss:-97.3773, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5471673011779785 sec\n",
      "Episode 4685, len12, loss:-110.8726, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5477101802825928 sec\n",
      "Episode 4686, len10, loss:-93.0168, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5497205257415771 sec\n",
      "Episode 4687, len10, loss:-85.9472, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5491917133331299 sec\n",
      "Episode 4688, len12, loss:-109.5432, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5493021011352539 sec\n",
      "Episode 4689, len8, loss:-84.3350, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5439386367797852 sec\n",
      "Episode 4690, len6, loss:-64.8461, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5437994003295898 sec\n",
      "Episode 4691, len10, loss:-89.6199, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5483651161193848 sec\n",
      "Episode 4692, len6, loss:-69.5543, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5486512184143066 sec\n",
      "Episode 4693, len10, loss:-89.8622, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5486898422241211 sec\n",
      "Episode 4694, len10, loss:-88.2600, fail, steps:80, opt steps:40, total reward:-24.0000, 0.6017515659332275 sec\n",
      "Episode 4695, len12, loss:-99.9498, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5571126937866211 sec\n",
      "Episode 4696, len8, loss:-74.2803, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5498039722442627 sec\n",
      "Episode 4697, len12, loss:-96.2357, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5482759475708008 sec\n",
      "Episode 4698, len12, loss:-95.5108, fail, steps:80, opt steps:53, total reward:-24.0000, 0.549565315246582 sec\n",
      "Episode 4699, len8, loss:-76.9146, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5478501319885254 sec\n",
      "Episode 4700, len6, loss:-66.2565, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5480010509490967 sec\n",
      "Episode 4701, len6, loss:-62.3172, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5488531589508057 sec\n",
      "Episode 4702, len8, loss:-71.7020, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5493943691253662 sec\n",
      "Episode 4703, len12, loss:-105.9511, fail, steps:80, opt steps:33, total reward:-24.0000, 0.548912525177002 sec\n",
      "Episode 4704, len10, loss:-90.7653, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5480616092681885 sec\n",
      "Episode 4705, len10, loss:-94.3322, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5487334728240967 sec\n",
      "Episode 4706, len10, loss:-95.5955, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5493283271789551 sec\n",
      "Episode 4707, len12, loss:-103.3431, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5500757694244385 sec\n",
      "Episode 4708, len10, loss:-93.0073, fail, steps:80, opt steps:29, total reward:-24.0000, 0.6007821559906006 sec\n",
      "Episode 4709, len10, loss:-105.3452, fail, steps:80, opt steps:32, total reward:-25.4000, 0.5392374992370605 sec\n",
      "Episode 4710, len10, loss:-91.6209, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5435123443603516 sec\n",
      "Episode 4711, len6, loss:-62.6604, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5475943088531494 sec\n",
      "Episode 4712, len12, loss:-104.6030, fail, steps:80, opt steps:61, total reward:-23.7000, 0.5463137626647949 sec\n",
      "Episode 4713, len6, loss:-61.3005, fail, steps:80, opt steps:20, total reward:-24.0000, 0.548149585723877 sec\n",
      "Episode 4714, len6, loss:-60.2064, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5498409271240234 sec\n",
      "Episode 4715, len12, loss:-98.9575, fail, steps:80, opt steps:39, total reward:-24.0000, 0.548659086227417 sec\n",
      "Episode 4716, len12, loss:-102.2241, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5491213798522949 sec\n",
      "Episode 4717, len12, loss:-105.9724, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5489625930786133 sec\n",
      "Episode 4718, len8, loss:-65.1358, fail, steps:80, opt steps:16, total reward:-22.7000, 0.5468518733978271 sec\n",
      "Episode 4719, len12, loss:-106.7047, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5483176708221436 sec\n",
      "Episode 4720, len8, loss:-82.6347, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5488626956939697 sec\n",
      "Episode 4721, len8, loss:-82.1498, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5497620105743408 sec\n",
      "Episode 4722, len6, loss:-65.7340, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5996589660644531 sec\n",
      "Episode 4723, len12, loss:-99.2831, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5477330684661865 sec\n",
      "Episode 4724, len12, loss:-123.2482, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5445444583892822 sec\n",
      "Episode 4725, len6, loss:-53.2855, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5478646755218506 sec\n",
      "Episode 4726, len12, loss:-97.6175, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5496270656585693 sec\n",
      "Episode 4727, len8, loss:-77.1908, fail, steps:80, opt steps:19, total reward:-24.0000, 0.547060489654541 sec\n",
      "Episode 4728, len8, loss:-78.6201, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5500481128692627 sec\n",
      "Episode 4729, len10, loss:-93.4299, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5488827228546143 sec\n",
      "Episode 4730, len12, loss:-98.6213, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5491771697998047 sec\n",
      "Episode 4731, len6, loss:-60.6446, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5497598648071289 sec\n",
      "Episode 4732, len6, loss:-60.8946, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5486505031585693 sec\n",
      "Episode 4733, len6, loss:-61.9225, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5484845638275146 sec\n",
      "Episode 4734, len8, loss:-75.8377, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5506393909454346 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4735, len12, loss:-103.6508, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5497958660125732 sec\n",
      "Episode 4736, len8, loss:-75.7752, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5994753837585449 sec\n",
      "Episode 4737, len10, loss:-93.3503, fail, steps:80, opt steps:48, total reward:-24.7000, 0.545229434967041 sec\n",
      "Episode 4738, len12, loss:-100.3287, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5488831996917725 sec\n",
      "Episode 4739, len6, loss:-63.9355, fail, steps:80, opt steps:17, total reward:-24.0000, 0.549342155456543 sec\n",
      "Episode 4740, len12, loss:-108.8795, fail, steps:80, opt steps:53, total reward:-24.0000, 0.548154354095459 sec\n",
      "Episode 4741, len8, loss:-80.7264, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5483729839324951 sec\n",
      "Episode 4742, len10, loss:-86.9080, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5489940643310547 sec\n",
      "Episode 4743, len10, loss:-97.9339, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5496392250061035 sec\n",
      "Episode 4744, len12, loss:-96.6436, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5502886772155762 sec\n",
      "Episode 4745, len12, loss:-105.3718, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5493345260620117 sec\n",
      "Episode 4746, len12, loss:-103.3745, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5494587421417236 sec\n",
      "Episode 4747, len8, loss:-74.0740, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5509631633758545 sec\n",
      "Episode 4748, len10, loss:-88.6975, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5491294860839844 sec\n",
      "Episode 4749, len8, loss:-72.1281, fail, steps:80, opt steps:21, total reward:-24.0000, 0.548647403717041 sec\n",
      "Episode 4750, len12, loss:-100.8600, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5500471591949463 sec\n",
      "Episode 4751, len10, loss:-87.4355, fail, steps:80, opt steps:31, total reward:-24.0000, 0.59979248046875 sec\n",
      "Episode 4752, len8, loss:-74.1253, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5478973388671875 sec\n",
      "Episode 4753, len10, loss:-92.5552, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5496339797973633 sec\n",
      "Episode 4754, len10, loss:-89.2984, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5493924617767334 sec\n",
      "Episode 4755, len10, loss:-87.4310, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5489203929901123 sec\n",
      "Episode 4756, len8, loss:-75.2808, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5495684146881104 sec\n",
      "Episode 4757, len8, loss:-81.3979, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5488178730010986 sec\n",
      "Episode 4758, len10, loss:-89.8490, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5487806797027588 sec\n",
      "Episode 4759, len8, loss:-82.0034, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5488312244415283 sec\n",
      "Episode 4760, len12, loss:-108.1472, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5498437881469727 sec\n",
      "Episode 4761, len8, loss:-81.7410, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5507698059082031 sec\n",
      "Episode 4762, len10, loss:-90.8613, fail, steps:80, opt steps:24, total reward:-24.0000, 0.549370288848877 sec\n",
      "Episode 4763, len8, loss:-77.9823, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5475268363952637 sec\n",
      "Episode 4764, len10, loss:-90.1703, fail, steps:80, opt steps:31, total reward:-24.0000, 0.549976110458374 sec\n",
      "Episode 4765, len6, loss:-57.7370, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5500190258026123 sec\n",
      "Episode 4766, len10, loss:-80.8546, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5500705242156982 sec\n",
      "Episode 4767, len10, loss:-90.8393, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5993392467498779 sec\n",
      "Episode 4768, len8, loss:-74.0647, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5493588447570801 sec\n",
      "Episode 4769, len12, loss:-94.9542, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5482537746429443 sec\n",
      "Episode 4770, len10, loss:-96.4054, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5501599311828613 sec\n",
      "Episode 4771, len8, loss:-77.9122, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5484535694122314 sec\n",
      "Episode 4772, len12, loss:-101.8179, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5489389896392822 sec\n",
      "Episode 4773, len6, loss:-57.5340, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5482895374298096 sec\n",
      "Episode 4774, len6, loss:-56.4404, fail, steps:80, opt steps:12, total reward:-23.7000, 0.543877124786377 sec\n",
      "Episode 4775, len8, loss:-79.9718, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5474355220794678 sec\n",
      "Episode 4776, len6, loss:-58.1852, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5480105876922607 sec\n",
      "Episode 4777, len10, loss:-85.9992, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5490546226501465 sec\n",
      "Episode 4778, len10, loss:-87.7238, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5496182441711426 sec\n",
      "Episode 4779, len8, loss:-77.7752, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5490562915802002 sec\n",
      "Episode 4780, len12, loss:-103.4682, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5497572422027588 sec\n",
      "Episode 4781, len10, loss:-86.2568, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5482931137084961 sec\n",
      "Episode 4782, len12, loss:-86.6752, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5488495826721191 sec\n",
      "Episode 4783, len10, loss:-91.0687, fail, steps:80, opt steps:40, total reward:-24.0000, 0.6001479625701904 sec\n",
      "Episode 4784, len6, loss:-57.9625, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5491790771484375 sec\n",
      "Episode 4785, len6, loss:-56.3519, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5492382049560547 sec\n",
      "Episode 4786, len6, loss:-51.8356, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5494787693023682 sec\n",
      "Episode 4787, len12, loss:-91.1022, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5495538711547852 sec\n",
      "Episode 4788, len10, loss:-87.7384, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5513944625854492 sec\n",
      "Episode 4789, len12, loss:-103.1202, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5452430248260498 sec\n",
      "Episode 4790, len10, loss:-86.2405, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5475790500640869 sec\n",
      "Episode 4791, len12, loss:-97.1686, fail, steps:80, opt steps:77, total reward:-24.0000, 0.5489306449890137 sec\n",
      "Episode 4792, len10, loss:-83.3252, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5499842166900635 sec\n",
      "Episode 4793, len12, loss:-95.5900, fail, steps:80, opt steps:42, total reward:-24.0000, 0.549907922744751 sec\n",
      "Episode 4794, len8, loss:-65.8656, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5504748821258545 sec\n",
      "Episode 4795, len10, loss:-93.7621, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5478737354278564 sec\n",
      "Episode 4796, len12, loss:-95.6509, fail, steps:80, opt steps:56, total reward:-24.0000, 0.6034018993377686 sec\n",
      "Episode 4797, len10, loss:-85.3954, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5491609573364258 sec\n",
      "Episode 4798, len8, loss:-71.8144, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5499148368835449 sec\n",
      "Episode 4799, len6, loss:-60.0112, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5505335330963135 sec\n",
      "Episode 4800, len10, loss:-85.7003, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5506999492645264 sec\n",
      "Episode 4801, len6, loss:-58.7193, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5519921779632568 sec\n",
      "Episode 4802, len10, loss:-93.0724, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5492498874664307 sec\n",
      "Episode 4803, len12, loss:-100.6301, fail, steps:80, opt steps:24, total reward:-24.0000, 0.549386739730835 sec\n",
      "Episode 4804, len6, loss:-61.5972, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5502040386199951 sec\n",
      "Episode 4805, len6, loss:-60.0903, fail, steps:80, opt steps:12, total reward:-24.0000, 0.552656888961792 sec\n",
      "Episode 4806, len10, loss:-90.8682, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5506153106689453 sec\n",
      "Episode 4807, len10, loss:-88.5066, fail, steps:80, opt steps:35, total reward:-24.0000, 0.553938627243042 sec\n",
      "Episode 4808, len6, loss:-54.4830, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5502748489379883 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4809, len8, loss:-75.5295, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5478687286376953 sec\n",
      "Episode 4810, len6, loss:-54.3435, fail, steps:80, opt steps:12, total reward:-24.0000, 0.6012849807739258 sec\n",
      "Episode 4811, len10, loss:-84.6278, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5489151477813721 sec\n",
      "Episode 4812, len10, loss:-82.9167, fail, steps:80, opt steps:46, total reward:-24.0000, 0.551588773727417 sec\n",
      "Episode 4813, len12, loss:-97.2504, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5493013858795166 sec\n",
      "Episode 4814, len10, loss:-89.9517, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5492720603942871 sec\n",
      "Episode 4815, len8, loss:-67.3119, fail, steps:80, opt steps:30, total reward:-24.0000, 0.55076003074646 sec\n",
      "Episode 4816, len6, loss:-53.1329, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5509328842163086 sec\n",
      "Episode 4817, len6, loss:-59.0610, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5487241744995117 sec\n",
      "Episode 4818, len12, loss:-100.6759, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5481224060058594 sec\n",
      "Episode 4819, len12, loss:-103.5140, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5447909832000732 sec\n",
      "Episode 4820, len8, loss:-69.5978, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5480618476867676 sec\n",
      "Episode 4821, len6, loss:-51.8467, fail, steps:80, opt steps:17, total reward:-23.7000, 0.5454959869384766 sec\n",
      "Episode 4822, len12, loss:-96.7058, fail, steps:80, opt steps:50, total reward:-24.7000, 0.5446157455444336 sec\n",
      "Episode 4823, len12, loss:-95.9794, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5478506088256836 sec\n",
      "Episode 4824, len8, loss:-61.8402, fail, steps:80, opt steps:24, total reward:-24.0000, 0.6001102924346924 sec\n",
      "Episode 4825, len8, loss:-60.2524, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5493607521057129 sec\n",
      "Episode 4826, len8, loss:-65.2646, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5505044460296631 sec\n",
      "Episode 4827, len12, loss:-89.4256, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5502610206604004 sec\n",
      "Episode 4828, len10, loss:-71.7658, fail, steps:80, opt steps:43, total reward:-23.7000, 0.542255163192749 sec\n",
      "Episode 4829, len8, loss:-63.8678, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5500757694244385 sec\n",
      "Episode 4830, len10, loss:-79.9661, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5444037914276123 sec\n",
      "Episode 4831, len6, loss:-51.8253, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5481410026550293 sec\n",
      "Episode 4832, len8, loss:-66.3929, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5488166809082031 sec\n",
      "Episode 4833, len12, loss:-105.1862, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5443863868713379 sec\n",
      "Episode 4834, len10, loss:-76.4207, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5504279136657715 sec\n",
      "Episode 4835, len8, loss:-66.8135, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5497243404388428 sec\n",
      "Episode 4836, len6, loss:-44.7307, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5496470928192139 sec\n",
      "Episode 4837, len10, loss:-84.5748, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5501682758331299 sec\n",
      "Episode 4838, len10, loss:-81.5109, fail, steps:80, opt steps:22, total reward:-24.0000, 0.6051232814788818 sec\n",
      "Episode 4839, len6, loss:-58.6212, fail, steps:80, opt steps:5, total reward:-24.0000, 0.548696756362915 sec\n",
      "Episode 4840, len8, loss:-62.3532, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5477805137634277 sec\n",
      "Episode 4841, len12, loss:-97.4434, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5489375591278076 sec\n",
      "Episode 4842, len6, loss:-56.2656, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5494372844696045 sec\n",
      "Episode 4843, len12, loss:-102.6327, fail, steps:80, opt steps:49, total reward:-24.7000, 0.5460867881774902 sec\n",
      "Episode 4844, len12, loss:-91.3998, fail, steps:80, opt steps:40, total reward:-24.7000, 0.545173168182373 sec\n",
      "Episode 4845, len12, loss:-85.2738, fail, steps:80, opt steps:58, total reward:-24.0000, 0.551518440246582 sec\n",
      "Episode 4846, len6, loss:-46.6571, fail, steps:0, opt steps:19, total reward:-10.0000, 0.022066831588745117 sec\n",
      "Episode 4847, len10, loss:-77.8262, fail, steps:80, opt steps:5, total reward:-24.0000, 0.49122190475463867 sec\n",
      "Episode 4848, len6, loss:-43.6768, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5236802101135254 sec\n",
      "Episode 4849, len10, loss:-68.2123, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5345206260681152 sec\n",
      "Episode 4850, len8, loss:-63.8484, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5402536392211914 sec\n",
      "Episode 4851, len12, loss:-90.8729, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5434267520904541 sec\n",
      "Episode 4852, len12, loss:-94.8647, fail, steps:80, opt steps:70, total reward:-24.0000, 0.5469825267791748 sec\n",
      "Episode 4853, len8, loss:-59.3740, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5958600044250488 sec\n",
      "Episode 4854, len8, loss:-63.6485, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5483658313751221 sec\n",
      "Episode 4855, len6, loss:-42.6947, fail, steps:80, opt steps:16, total reward:-24.0000, 0.547321081161499 sec\n",
      "Episode 4856, len8, loss:-58.1048, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5475013256072998 sec\n",
      "Episode 4857, len12, loss:-78.0465, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5481915473937988 sec\n",
      "Episode 4858, len8, loss:-63.1844, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5473856925964355 sec\n",
      "Episode 4859, len6, loss:-46.0602, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5498383045196533 sec\n",
      "Episode 4860, len8, loss:-63.9284, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5489342212677002 sec\n",
      "Episode 4861, len12, loss:-87.9371, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5501580238342285 sec\n",
      "Episode 4862, len8, loss:-53.7200, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5504903793334961 sec\n",
      "Episode 4863, len8, loss:-59.4028, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5488111972808838 sec\n",
      "Episode 4864, len10, loss:-71.8526, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5484607219696045 sec\n",
      "Episode 4865, len10, loss:-68.1265, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5494279861450195 sec\n",
      "Episode 4866, len10, loss:-67.6172, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5451040267944336 sec\n",
      "Episode 4867, len12, loss:-88.8959, fail, steps:80, opt steps:45, total reward:-23.7000, 0.5442464351654053 sec\n",
      "Episode 4868, len12, loss:-72.4068, fail, steps:80, opt steps:57, total reward:-24.0000, 0.6012258529663086 sec\n",
      "Episode 4869, len10, loss:-71.0691, fail, steps:80, opt steps:37, total reward:-24.0000, 0.548619270324707 sec\n",
      "Episode 4870, len6, loss:-48.4364, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5491659641265869 sec\n",
      "Episode 4871, len10, loss:-58.5262, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5508971214294434 sec\n",
      "Episode 4872, len10, loss:-69.4473, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5483341217041016 sec\n",
      "Episode 4873, len12, loss:-79.7946, fail, steps:80, opt steps:68, total reward:-24.0000, 0.5482556819915771 sec\n",
      "Episode 4874, len8, loss:-59.6559, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5482401847839355 sec\n",
      "Episode 4875, len10, loss:-68.8522, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5524425506591797 sec\n",
      "Episode 4876, len10, loss:-75.6792, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5491423606872559 sec\n",
      "Episode 4877, len10, loss:-68.1075, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5510754585266113 sec\n",
      "Episode 4878, len6, loss:-42.0661, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5512580871582031 sec\n",
      "Episode 4879, len8, loss:-60.7643, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5503067970275879 sec\n",
      "Episode 4880, len8, loss:-53.4354, fail, steps:80, opt steps:15, total reward:-24.0000, 0.547468900680542 sec\n",
      "Episode 4881, len12, loss:-82.4572, fail, steps:80, opt steps:57, total reward:-24.7000, 0.5451827049255371 sec\n",
      "Episode 4882, len12, loss:-86.3858, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5485177040100098 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4883, len10, loss:-65.9622, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5479414463043213 sec\n",
      "Episode 4884, len6, loss:-48.2279, fail, steps:80, opt steps:5, total reward:-24.0000, 0.6016731262207031 sec\n",
      "Episode 4885, len8, loss:-52.4065, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5502755641937256 sec\n",
      "Episode 4886, len8, loss:-69.2800, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5497195720672607 sec\n",
      "Episode 4887, len10, loss:-74.1257, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5499260425567627 sec\n",
      "Episode 4888, len6, loss:-49.0588, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5487575531005859 sec\n",
      "Episode 4889, len12, loss:-82.1138, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5503988265991211 sec\n",
      "Episode 4890, len8, loss:-53.4511, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5484251976013184 sec\n",
      "Episode 4891, len12, loss:-81.2936, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5503582954406738 sec\n",
      "Episode 4892, len10, loss:-74.7094, fail, steps:80, opt steps:34, total reward:-24.0000, 0.549558162689209 sec\n",
      "Episode 4893, len8, loss:-68.9174, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5503227710723877 sec\n",
      "Episode 4894, len10, loss:-67.2468, fail, steps:80, opt steps:46, total reward:-24.0000, 0.548835039138794 sec\n",
      "Episode 4895, len6, loss:-47.8543, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5497398376464844 sec\n",
      "Episode 4896, len10, loss:-71.5445, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5503203868865967 sec\n",
      "Episode 4897, len8, loss:-56.8300, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5481142997741699 sec\n",
      "Episode 4898, len6, loss:-46.6278, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5483443737030029 sec\n",
      "Episode 4899, len12, loss:-79.5544, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5505847930908203 sec\n",
      "Episode 4900, len10, loss:-75.2051, fail, steps:80, opt steps:25, total reward:-24.0000, 0.6046719551086426 sec\n",
      "Episode 4901, len10, loss:-70.0031, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5503067970275879 sec\n",
      "Episode 4902, len12, loss:-75.7257, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5499718189239502 sec\n",
      "Episode 4903, len10, loss:-61.2470, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5731227397918701 sec\n",
      "Episode 4904, len6, loss:-46.2787, fail, steps:80, opt steps:13, total reward:-22.7000, 0.5462436676025391 sec\n",
      "Episode 4905, len8, loss:-42.8215, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5488853454589844 sec\n",
      "Episode 4906, len10, loss:-70.6586, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5494577884674072 sec\n",
      "Episode 4907, len10, loss:-66.2266, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5495755672454834 sec\n",
      "Episode 4908, len6, loss:-46.0982, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5479953289031982 sec\n",
      "Episode 4909, len12, loss:-73.6035, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5507609844207764 sec\n",
      "Episode 4910, len10, loss:-74.9130, fail, steps:80, opt steps:52, total reward:-24.7000, 0.5451400279998779 sec\n",
      "Episode 4911, len8, loss:-53.9788, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5504496097564697 sec\n",
      "Episode 4912, len10, loss:-58.4263, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5495457649230957 sec\n",
      "Episode 4913, len10, loss:-59.8765, fail, steps:80, opt steps:35, total reward:-24.0000, 0.6084685325622559 sec\n",
      "Episode 4914, len6, loss:-46.1718, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5532312393188477 sec\n",
      "Episode 4915, len12, loss:-72.4140, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5484237670898438 sec\n",
      "Episode 4916, len8, loss:-50.0548, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5494654178619385 sec\n",
      "Episode 4917, len10, loss:-77.2165, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5496106147766113 sec\n",
      "Episode 4918, len6, loss:-45.3516, fail, steps:80, opt steps:15, total reward:-23.7000, 0.5453891754150391 sec\n",
      "Episode 4919, len6, loss:-56.3380, fail, steps:80, opt steps:15, total reward:-23.7000, 0.5443763732910156 sec\n",
      "Episode 4920, len8, loss:-51.6785, fail, steps:80, opt steps:25, total reward:-24.0000, 0.547353982925415 sec\n",
      "Episode 4921, len10, loss:-65.3199, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5483953952789307 sec\n",
      "Episode 4922, len6, loss:-47.8643, fail, steps:80, opt steps:13, total reward:-24.0000, 0.548466682434082 sec\n",
      "Episode 4923, len6, loss:-52.8327, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5480968952178955 sec\n",
      "Episode 4924, len8, loss:-60.6056, fail, steps:80, opt steps:22, total reward:-24.0000, 0.549072265625 sec\n",
      "Episode 4925, len6, loss:-49.2764, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5501871109008789 sec\n",
      "Episode 4926, len12, loss:-80.2944, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5497758388519287 sec\n",
      "Episode 4927, len8, loss:-55.3243, fail, steps:80, opt steps:7, total reward:-24.0000, 0.6006135940551758 sec\n",
      "Episode 4928, len6, loss:-45.7078, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5499155521392822 sec\n",
      "Episode 4929, len10, loss:-64.1518, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5492684841156006 sec\n",
      "Episode 4930, len10, loss:-58.2990, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5503566265106201 sec\n",
      "Episode 4931, len6, loss:-51.1307, fail, steps:80, opt steps:15, total reward:-23.7000, 0.5439703464508057 sec\n",
      "Episode 4932, len8, loss:-52.6427, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5488381385803223 sec\n",
      "Episode 4933, len8, loss:-50.0078, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5496170520782471 sec\n",
      "Episode 4934, len12, loss:-78.6629, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5493941307067871 sec\n",
      "Episode 4935, len8, loss:-44.5854, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5478980541229248 sec\n",
      "Episode 4936, len8, loss:-33.8985, fail, steps:80, opt steps:28, total reward:-22.7000, 0.5450499057769775 sec\n",
      "Episode 4937, len10, loss:-65.4310, fail, steps:80, opt steps:47, total reward:-24.0000, 0.548323392868042 sec\n",
      "Episode 4938, len12, loss:-72.8956, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5490336418151855 sec\n",
      "Episode 4939, len8, loss:-55.2369, fail, steps:80, opt steps:27, total reward:-24.0000, 0.550731897354126 sec\n",
      "Episode 4940, len10, loss:-62.3441, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5456924438476562 sec\n",
      "Episode 4941, len6, loss:-52.4823, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5997648239135742 sec\n",
      "Episode 4942, len8, loss:-54.8052, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5488429069519043 sec\n",
      "Episode 4943, len12, loss:-85.6717, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5496487617492676 sec\n",
      "Episode 4944, len10, loss:-61.6429, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5499508380889893 sec\n",
      "Episode 4945, len6, loss:-55.7175, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5498268604278564 sec\n",
      "Episode 4946, len6, loss:-43.6493, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5497860908508301 sec\n",
      "Episode 4947, len10, loss:-59.9851, fail, steps:80, opt steps:36, total reward:-24.0000, 0.54827880859375 sec\n",
      "Episode 4948, len10, loss:-55.0941, fail, steps:80, opt steps:31, total reward:-22.7000, 0.5441784858703613 sec\n",
      "Episode 4949, len6, loss:-43.2771, fail, steps:80, opt steps:5, total reward:-24.0000, 0.549358606338501 sec\n",
      "Episode 4950, len10, loss:-55.3931, fail, steps:80, opt steps:28, total reward:-23.7000, 0.5435185432434082 sec\n",
      "Episode 4951, len12, loss:-60.2335, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5503268241882324 sec\n",
      "Episode 4952, len8, loss:-47.5416, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5504391193389893 sec\n",
      "Episode 4953, len6, loss:-45.2714, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5494606494903564 sec\n",
      "Episode 4954, len10, loss:-57.5457, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5500228404998779 sec\n",
      "Episode 4955, len6, loss:-41.9936, fail, steps:80, opt steps:13, total reward:-24.0000, 0.599672794342041 sec\n",
      "Episode 4956, len6, loss:-40.8381, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5496056079864502 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4957, len10, loss:-61.2763, fail, steps:80, opt steps:40, total reward:-23.7000, 0.5472831726074219 sec\n",
      "Episode 4958, len6, loss:-44.6521, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5501172542572021 sec\n",
      "Episode 4959, len6, loss:-49.0052, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5498297214508057 sec\n",
      "Episode 4960, len8, loss:-56.4303, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5483381748199463 sec\n",
      "Episode 4961, len6, loss:-47.0352, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5487456321716309 sec\n",
      "Episode 4962, len8, loss:-41.6430, fail, steps:80, opt steps:15, total reward:-24.0000, 0.550945520401001 sec\n",
      "Episode 4963, len10, loss:-64.2163, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5488283634185791 sec\n",
      "Episode 4964, len8, loss:-46.5834, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5503683090209961 sec\n",
      "Episode 4965, len12, loss:-77.1670, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5501453876495361 sec\n",
      "Episode 4966, len8, loss:-44.8637, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5487778186798096 sec\n",
      "Episode 4967, len12, loss:-71.5232, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5501229763031006 sec\n",
      "Episode 4968, len10, loss:-67.8570, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5500631332397461 sec\n",
      "Episode 4969, len6, loss:-51.3768, fail, steps:80, opt steps:18, total reward:-24.0000, 0.6009011268615723 sec\n",
      "Episode 4970, len10, loss:-61.2258, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5510754585266113 sec\n",
      "Episode 4971, len8, loss:-44.6412, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5482733249664307 sec\n",
      "Episode 4972, len6, loss:-44.7054, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5495433807373047 sec\n",
      "Episode 4973, len8, loss:-51.3019, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5473747253417969 sec\n",
      "Episode 4974, len12, loss:-69.0419, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5479543209075928 sec\n",
      "Episode 4975, len6, loss:-47.9056, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5488893985748291 sec\n",
      "Episode 4976, len10, loss:-70.6601, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5447635650634766 sec\n",
      "Episode 4977, len12, loss:-73.2579, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5486586093902588 sec\n",
      "Episode 4978, len8, loss:-55.0807, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5499448776245117 sec\n",
      "Episode 4979, len6, loss:-49.7369, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5508716106414795 sec\n",
      "Episode 4980, len8, loss:-55.3257, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5452775955200195 sec\n",
      "Episode 4981, len8, loss:-56.3964, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5489158630371094 sec\n",
      "Episode 4982, len10, loss:-62.4560, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5483560562133789 sec\n",
      "Episode 4983, len10, loss:-61.4847, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5485262870788574 sec\n",
      "Episode 4984, len10, loss:-63.1035, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5991365909576416 sec\n",
      "Episode 4985, len8, loss:-42.8882, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5505082607269287 sec\n",
      "Episode 4986, len6, loss:-41.0673, fail, steps:80, opt steps:14, total reward:-22.7000, 0.5443284511566162 sec\n",
      "Episode 4987, len8, loss:-38.6335, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5474104881286621 sec\n",
      "Episode 4988, len6, loss:-40.7711, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5469698905944824 sec\n",
      "Episode 4989, len6, loss:-39.9652, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5478100776672363 sec\n",
      "Episode 4990, len12, loss:-80.0640, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5509688854217529 sec\n",
      "Episode 4991, len6, loss:-42.8346, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5478994846343994 sec\n",
      "Episode 4992, len10, loss:-65.6944, fail, steps:80, opt steps:33, total reward:-24.0000, 0.549858570098877 sec\n",
      "Episode 4993, len12, loss:-60.2032, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5488193035125732 sec\n",
      "Episode 4994, len8, loss:-52.2903, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5502891540527344 sec\n",
      "Episode 4995, len12, loss:-66.8405, fail, steps:80, opt steps:55, total reward:-22.4000, 0.5407764911651611 sec\n",
      "Episode 4996, len12, loss:-66.6232, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5476272106170654 sec\n",
      "Episode 4997, len8, loss:-45.7300, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5488629341125488 sec\n",
      "Episode 4998, len6, loss:-40.7694, fail, steps:80, opt steps:3, total reward:-24.0000, 0.547588586807251 sec\n",
      "Episode 4999, len12, loss:-79.5489, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5503494739532471 sec\n",
      "Episode 5000, len6, loss:-44.1802, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5985441207885742 sec\n",
      "Checkpoint saved at episode 5000 to /home/mcwave/code/autocode/datasets/rl_sort_transformer_easy/list6_12_transformer3_128_gamma07_step80_v3_merge_2_sorted/ckpt_5000_0.0000_26.24_vs_5.25.pth\n",
      "Learning rate = 0.000090\n",
      "Episode 5001, len8, loss:-44.3540, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5462367534637451 sec\n",
      "Episode 5002, len8, loss:-36.4240, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5487844944000244 sec\n",
      "Episode 5003, len12, loss:-74.1589, fail, steps:80, opt steps:27, total reward:-24.0000, 0.549534797668457 sec\n",
      "Episode 5004, len12, loss:-68.4780, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5515439510345459 sec\n",
      "Episode 5005, len6, loss:-45.7094, fail, steps:80, opt steps:15, total reward:-24.0000, 0.548292875289917 sec\n",
      "Episode 5006, len6, loss:-41.4866, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5500833988189697 sec\n",
      "Episode 5007, len10, loss:-57.5023, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5495576858520508 sec\n",
      "Episode 5008, len10, loss:-62.8185, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5451846122741699 sec\n",
      "Episode 5009, len10, loss:-59.4945, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5485291481018066 sec\n",
      "Episode 5010, len12, loss:-69.9008, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5509133338928223 sec\n",
      "Episode 5011, len12, loss:-57.8078, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5495190620422363 sec\n",
      "Episode 5012, len12, loss:-63.2737, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5488598346710205 sec\n",
      "Episode 5013, len6, loss:-47.5520, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5497639179229736 sec\n",
      "Episode 5014, len6, loss:-43.4741, fail, steps:80, opt steps:19, total reward:-24.0000, 0.6026856899261475 sec\n",
      "Episode 5015, len12, loss:-66.3721, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5478777885437012 sec\n",
      "Episode 5016, len8, loss:-41.4574, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5504400730133057 sec\n",
      "Episode 5017, len8, loss:-53.1839, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5453667640686035 sec\n",
      "Episode 5018, len8, loss:-45.5337, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5483386516571045 sec\n",
      "Episode 5019, len6, loss:-46.9717, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5506365299224854 sec\n",
      "Episode 5020, len12, loss:-77.8798, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5446946620941162 sec\n",
      "Episode 5021, len6, loss:-48.4229, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5492892265319824 sec\n",
      "Episode 5022, len8, loss:-51.8471, fail, steps:80, opt steps:4, total reward:-24.0000, 0.548255443572998 sec\n",
      "Episode 5023, len8, loss:-43.5014, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5495047569274902 sec\n",
      "Episode 5024, len12, loss:-78.5399, fail, steps:80, opt steps:50, total reward:-24.7000, 0.5438919067382812 sec\n",
      "Episode 5025, len12, loss:-77.4144, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5499372482299805 sec\n",
      "Episode 5026, len12, loss:-69.7218, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5490331649780273 sec\n",
      "Episode 5027, len6, loss:-46.0693, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5487899780273438 sec\n",
      "Episode 5028, len8, loss:-53.3662, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5985994338989258 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5029, len10, loss:-62.5616, fail, steps:80, opt steps:34, total reward:-24.0000, 0.549081563949585 sec\n",
      "Episode 5030, len10, loss:-63.7431, fail, steps:80, opt steps:32, total reward:-24.0000, 0.549583911895752 sec\n",
      "Episode 5031, len8, loss:-57.6910, fail, steps:80, opt steps:12, total reward:-24.0000, 0.548872709274292 sec\n",
      "Episode 5032, len10, loss:-68.0381, fail, steps:80, opt steps:41, total reward:-24.0000, 0.549501895904541 sec\n",
      "Episode 5033, len6, loss:-49.8441, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5500340461730957 sec\n",
      "Episode 5034, len8, loss:-60.0841, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5443875789642334 sec\n",
      "Episode 5035, len8, loss:-44.6574, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5494101047515869 sec\n",
      "Episode 5036, len10, loss:-64.8966, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5477702617645264 sec\n",
      "Episode 5037, len6, loss:-43.0515, fail, steps:80, opt steps:11, total reward:-24.0000, 0.548790693283081 sec\n",
      "Episode 5038, len6, loss:-53.6022, fail, steps:80, opt steps:16, total reward:-24.7000, 0.544724702835083 sec\n",
      "Episode 5039, len8, loss:-55.5795, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5493972301483154 sec\n",
      "Episode 5040, len12, loss:-71.5559, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5509853363037109 sec\n",
      "Episode 5041, len6, loss:-41.6336, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5498013496398926 sec\n",
      "Episode 5042, len8, loss:-52.0929, fail, steps:80, opt steps:35, total reward:-24.0000, 0.6003139019012451 sec\n",
      "Episode 5043, len8, loss:-48.6560, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5491383075714111 sec\n",
      "Episode 5044, len12, loss:-78.6160, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5489888191223145 sec\n",
      "Episode 5045, len6, loss:-48.8560, fail, steps:80, opt steps:8, total reward:-24.0000, 0.551616907119751 sec\n",
      "Episode 5046, len8, loss:-49.5203, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5504331588745117 sec\n",
      "Episode 5047, len10, loss:-68.8415, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5507986545562744 sec\n",
      "Episode 5048, len6, loss:-44.0773, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5505259037017822 sec\n",
      "Episode 5049, len12, loss:-80.6260, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5489461421966553 sec\n",
      "Episode 5050, len12, loss:-71.4055, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5500738620758057 sec\n",
      "Episode 5051, len8, loss:-50.8238, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5491611957550049 sec\n",
      "Episode 5052, len6, loss:-48.9310, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5495574474334717 sec\n",
      "Episode 5053, len6, loss:-48.4205, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5503988265991211 sec\n",
      "Episode 5054, len12, loss:-78.9457, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5492031574249268 sec\n",
      "Episode 5055, len12, loss:-87.4775, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5499706268310547 sec\n",
      "Episode 5056, len6, loss:-49.9075, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5994107723236084 sec\n",
      "Episode 5057, len12, loss:-72.0904, fail, steps:80, opt steps:43, total reward:-24.0000, 0.550933837890625 sec\n",
      "Episode 5058, len10, loss:-81.7834, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5509328842163086 sec\n",
      "Episode 5059, len12, loss:-87.2094, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5504376888275146 sec\n",
      "Episode 5060, len6, loss:-59.4461, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5446524620056152 sec\n",
      "Episode 5061, len6, loss:-46.2685, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5487849712371826 sec\n",
      "Episode 5062, len10, loss:-71.0901, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5487606525421143 sec\n",
      "Episode 5063, len6, loss:-49.3683, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5506744384765625 sec\n",
      "Episode 5064, len8, loss:-57.4225, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5516595840454102 sec\n",
      "Episode 5065, len8, loss:-62.3890, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5498385429382324 sec\n",
      "Episode 5066, len6, loss:-46.6549, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5490949153900146 sec\n",
      "Episode 5067, len12, loss:-81.8114, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5483863353729248 sec\n",
      "Episode 5068, len6, loss:-45.1836, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5474660396575928 sec\n",
      "Episode 5069, len6, loss:-48.5140, fail, steps:80, opt steps:10, total reward:-24.0000, 0.549534797668457 sec\n",
      "Episode 5070, len10, loss:-73.0331, fail, steps:80, opt steps:28, total reward:-24.0000, 0.6034438610076904 sec\n",
      "Episode 5071, len8, loss:-51.5983, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5475819110870361 sec\n",
      "Episode 5072, len8, loss:-59.7344, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5492849349975586 sec\n",
      "Episode 5073, len6, loss:-52.8220, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5440423488616943 sec\n",
      "Episode 5074, len12, loss:-74.2769, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5484678745269775 sec\n",
      "Episode 5075, len12, loss:-85.9227, fail, steps:80, opt steps:28, total reward:-24.7000, 0.5441374778747559 sec\n",
      "Episode 5076, len6, loss:-47.2874, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5483627319335938 sec\n",
      "Episode 5077, len12, loss:-74.2048, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5486860275268555 sec\n",
      "Episode 5078, len12, loss:-71.7015, fail, steps:80, opt steps:56, total reward:-24.0000, 0.549267053604126 sec\n",
      "Episode 5079, len12, loss:-78.1837, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5500133037567139 sec\n",
      "Episode 5080, len10, loss:-76.8253, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5500726699829102 sec\n",
      "Episode 5081, len10, loss:-68.3705, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5494592189788818 sec\n",
      "Episode 5082, len6, loss:-49.3120, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5495095252990723 sec\n",
      "Episode 5083, len6, loss:-47.7154, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5484488010406494 sec\n",
      "Episode 5084, len10, loss:-66.4059, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5493652820587158 sec\n",
      "Episode 5085, len6, loss:-45.2094, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6003208160400391 sec\n",
      "Episode 5086, len8, loss:-51.8022, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5489261150360107 sec\n",
      "Episode 5087, len8, loss:-45.6177, fail, steps:80, opt steps:32, total reward:-22.7000, 0.5446116924285889 sec\n",
      "Episode 5088, len12, loss:-72.1860, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5485711097717285 sec\n",
      "Episode 5089, len12, loss:-76.2523, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5479443073272705 sec\n",
      "Episode 5090, len6, loss:-46.0468, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5486876964569092 sec\n",
      "Episode 5091, len10, loss:-64.9449, fail, steps:80, opt steps:23, total reward:-23.7000, 0.5440618991851807 sec\n",
      "Episode 5092, len6, loss:-44.0268, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5484752655029297 sec\n",
      "Episode 5093, len6, loss:-50.2668, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5492675304412842 sec\n",
      "Episode 5094, len8, loss:-47.6728, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5478630065917969 sec\n",
      "Episode 5095, len6, loss:-51.2618, fail, steps:80, opt steps:7, total reward:-24.0000, 0.549285888671875 sec\n",
      "Episode 5096, len12, loss:-89.9168, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5498709678649902 sec\n",
      "Episode 5097, len6, loss:-36.8332, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5497043132781982 sec\n",
      "Episode 5098, len10, loss:-65.3541, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5496928691864014 sec\n",
      "Episode 5099, len8, loss:-50.9572, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5493531227111816 sec\n",
      "Episode 5100, len10, loss:-65.0834, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5492966175079346 sec\n",
      "Episode 5101, len10, loss:-62.5601, fail, steps:80, opt steps:31, total reward:-24.0000, 0.599597692489624 sec\n",
      "Episode 5102, len8, loss:-58.3580, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5459527969360352 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5103, len10, loss:-66.3666, fail, steps:80, opt steps:19, total reward:-24.0000, 0.549182653427124 sec\n",
      "Episode 5104, len10, loss:-70.4799, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5481078624725342 sec\n",
      "Episode 5105, len8, loss:-40.5543, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5485446453094482 sec\n",
      "Episode 5106, len8, loss:-55.0273, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5499155521392822 sec\n",
      "Episode 5107, len12, loss:-68.6835, fail, steps:80, opt steps:55, total reward:-24.0000, 0.550621509552002 sec\n",
      "Episode 5108, len8, loss:-47.6361, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5496656894683838 sec\n",
      "Episode 5109, len10, loss:-70.0246, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5486819744110107 sec\n",
      "Episode 5110, len10, loss:-61.0595, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5494651794433594 sec\n",
      "Episode 5111, len6, loss:-42.4880, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5499594211578369 sec\n",
      "Episode 5112, len8, loss:-44.2380, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5494732856750488 sec\n",
      "Episode 5113, len8, loss:-56.8403, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5496611595153809 sec\n",
      "Episode 5114, len6, loss:-42.5901, fail, steps:80, opt steps:17, total reward:-23.7000, 0.544905424118042 sec\n",
      "Episode 5115, len8, loss:-51.1275, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5488979816436768 sec\n",
      "Episode 5116, len6, loss:-42.2114, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5488636493682861 sec\n",
      "Episode 5117, len6, loss:-48.1544, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6019136905670166 sec\n",
      "Episode 5118, len6, loss:-45.4854, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5505807399749756 sec\n",
      "Episode 5119, len12, loss:-74.0040, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5498621463775635 sec\n",
      "Episode 5120, len10, loss:-60.2884, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5498595237731934 sec\n",
      "Episode 5121, len6, loss:-49.5582, fail, steps:80, opt steps:5, total reward:-24.7000, 0.545172929763794 sec\n",
      "Episode 5122, len6, loss:-48.5297, fail, steps:80, opt steps:21, total reward:-23.7000, 0.5447800159454346 sec\n",
      "Episode 5123, len12, loss:-73.4406, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5488507747650146 sec\n",
      "Episode 5124, len8, loss:-50.2764, fail, steps:80, opt steps:27, total reward:-24.0000, 0.548926830291748 sec\n",
      "Episode 5125, len12, loss:-46.9667, fail, steps:0, opt steps:57, total reward:-10.0000, 0.022121429443359375 sec\n",
      "Episode 5126, len6, loss:-39.6693, fail, steps:80, opt steps:11, total reward:-24.0000, 0.4925508499145508 sec\n",
      "Episode 5127, len8, loss:-44.7287, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5233306884765625 sec\n",
      "Episode 5128, len10, loss:-57.2071, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5337352752685547 sec\n",
      "Episode 5129, len8, loss:-39.4968, fail, steps:80, opt steps:24, total reward:-24.0000, 0.539118766784668 sec\n",
      "Episode 5130, len12, loss:-72.1512, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5441896915435791 sec\n",
      "Episode 5131, len10, loss:-57.7249, fail, steps:80, opt steps:19, total reward:-24.0000, 0.597792387008667 sec\n",
      "Episode 5132, len10, loss:-58.8106, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5515680313110352 sec\n",
      "Episode 5133, len12, loss:-73.4506, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5491795539855957 sec\n",
      "Episode 5134, len8, loss:-53.1641, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5493993759155273 sec\n",
      "Episode 5135, len6, loss:-41.1466, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5503246784210205 sec\n",
      "Episode 5136, len12, loss:-55.9959, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5496106147766113 sec\n",
      "Episode 5137, len8, loss:-45.0839, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5491244792938232 sec\n",
      "Episode 5138, len12, loss:-76.0242, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5497908592224121 sec\n",
      "Episode 5139, len6, loss:-40.9592, fail, steps:80, opt steps:13, total reward:-24.0000, 0.548851490020752 sec\n",
      "Episode 5140, len12, loss:-69.1043, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5507364273071289 sec\n",
      "Episode 5141, len8, loss:-44.7659, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5491166114807129 sec\n",
      "Episode 5142, len6, loss:-43.3291, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5481405258178711 sec\n",
      "Episode 5143, len10, loss:-63.1953, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5490269660949707 sec\n",
      "Episode 5144, len10, loss:-57.5821, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5483019351959229 sec\n",
      "Episode 5145, len10, loss:-62.3340, fail, steps:80, opt steps:37, total reward:-24.0000, 0.6015055179595947 sec\n",
      "Episode 5146, len8, loss:-50.4435, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5501682758331299 sec\n",
      "Episode 5147, len12, loss:-79.8758, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5499253273010254 sec\n",
      "Episode 5148, len8, loss:-54.1225, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5500860214233398 sec\n",
      "Episode 5149, len12, loss:-73.0739, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5495364665985107 sec\n",
      "Episode 5150, len8, loss:-52.7105, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5499725341796875 sec\n",
      "Episode 5151, len12, loss:-72.0823, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5485286712646484 sec\n",
      "Episode 5152, len12, loss:-76.2439, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5496344566345215 sec\n",
      "Episode 5153, len10, loss:-71.5344, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5505402088165283 sec\n",
      "Episode 5154, len8, loss:-52.0398, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5506081581115723 sec\n",
      "Episode 5155, len8, loss:-65.3878, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5514695644378662 sec\n",
      "Episode 5156, len8, loss:-66.2829, fail, steps:80, opt steps:34, total reward:-24.7000, 0.5450499057769775 sec\n",
      "Episode 5157, len6, loss:-39.9216, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5504341125488281 sec\n",
      "Episode 5158, len10, loss:-68.9508, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5508770942687988 sec\n",
      "Episode 5159, len8, loss:-56.8887, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5991740226745605 sec\n",
      "Episode 5160, len8, loss:-49.9030, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5500013828277588 sec\n",
      "Episode 5161, len6, loss:-43.8935, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5488643646240234 sec\n",
      "Episode 5162, len6, loss:-47.0738, fail, steps:80, opt steps:11, total reward:-24.0000, 0.549445629119873 sec\n",
      "Episode 5163, len8, loss:-62.9641, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5501766204833984 sec\n",
      "Episode 5164, len8, loss:-50.3703, fail, steps:80, opt steps:9, total reward:-24.0000, 0.550696849822998 sec\n",
      "Episode 5165, len6, loss:-48.9811, fail, steps:0, opt steps:10, total reward:-10.0000, 0.022021770477294922 sec\n",
      "Episode 5166, len8, loss:-46.2253, fail, steps:80, opt steps:30, total reward:-24.0000, 0.4914364814758301 sec\n",
      "Episode 5167, len10, loss:-61.6076, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5238087177276611 sec\n",
      "Episode 5168, len8, loss:-53.4323, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5333693027496338 sec\n",
      "Episode 5169, len6, loss:-44.2508, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5390291213989258 sec\n",
      "Episode 5170, len12, loss:-64.6304, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5434997081756592 sec\n",
      "Episode 5171, len8, loss:-50.4232, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5443594455718994 sec\n",
      "Episode 5172, len6, loss:-46.9734, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5475952625274658 sec\n",
      "Episode 5173, len8, loss:-43.1385, fail, steps:80, opt steps:26, total reward:-22.7000, 0.5430805683135986 sec\n",
      "Episode 5174, len6, loss:-38.1719, fail, steps:80, opt steps:19, total reward:-24.0000, 0.600081205368042 sec\n",
      "Episode 5175, len12, loss:-71.4680, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5480413436889648 sec\n",
      "Episode 5176, len6, loss:-43.4252, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5477190017700195 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5177, len6, loss:-40.8496, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5486345291137695 sec\n",
      "Episode 5178, len6, loss:-45.3596, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5484476089477539 sec\n",
      "Episode 5179, len6, loss:-44.2492, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5475139617919922 sec\n",
      "Episode 5180, len12, loss:-76.8417, fail, steps:80, opt steps:69, total reward:-24.0000, 0.5498969554901123 sec\n",
      "Episode 5181, len6, loss:-45.3394, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5493979454040527 sec\n",
      "Episode 5182, len10, loss:-71.0502, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5494277477264404 sec\n",
      "Episode 5183, len8, loss:-63.3072, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5455887317657471 sec\n",
      "Episode 5184, len12, loss:-82.2192, fail, steps:80, opt steps:70, total reward:-24.0000, 0.5488827228546143 sec\n",
      "Episode 5185, len10, loss:-63.6585, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5486438274383545 sec\n",
      "Episode 5186, len10, loss:-61.2246, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5489089488983154 sec\n",
      "Episode 5187, len6, loss:-42.2251, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5493967533111572 sec\n",
      "Episode 5188, len8, loss:-63.3081, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5985000133514404 sec\n",
      "Episode 5189, len6, loss:-39.9501, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5489377975463867 sec\n",
      "Episode 5190, len6, loss:-45.7786, fail, steps:80, opt steps:15, total reward:-24.0000, 0.548414945602417 sec\n",
      "Episode 5191, len8, loss:-52.7876, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5479931831359863 sec\n",
      "Episode 5192, len8, loss:-58.8734, fail, steps:80, opt steps:31, total reward:-24.7000, 0.5447490215301514 sec\n",
      "Episode 5193, len12, loss:-77.9320, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5484731197357178 sec\n",
      "Episode 5194, len10, loss:-66.6488, fail, steps:80, opt steps:35, total reward:-24.0000, 0.547846794128418 sec\n",
      "Episode 5195, len6, loss:-47.7637, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5478641986846924 sec\n",
      "Episode 5196, len8, loss:-58.7434, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5512533187866211 sec\n",
      "Episode 5197, len6, loss:-44.3554, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5497643947601318 sec\n",
      "Episode 5198, len10, loss:-73.3941, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5446805953979492 sec\n",
      "Episode 5199, len8, loss:-50.6075, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5493171215057373 sec\n",
      "Episode 5200, len12, loss:-85.6072, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5471491813659668 sec\n",
      "Episode 5201, len6, loss:-49.1758, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5490608215332031 sec\n",
      "Episode 5202, len8, loss:-61.7465, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5481002330780029 sec\n",
      "Episode 5203, len8, loss:-56.1576, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5986325740814209 sec\n",
      "Episode 5204, len6, loss:-49.0844, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5497453212738037 sec\n",
      "Episode 5205, len12, loss:-72.5192, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5501787662506104 sec\n",
      "Episode 5206, len12, loss:-75.3140, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5483675003051758 sec\n",
      "Episode 5207, len10, loss:-82.8104, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5486831665039062 sec\n",
      "Episode 5208, len8, loss:-59.6234, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5474958419799805 sec\n",
      "Episode 5209, len8, loss:-60.2018, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5498416423797607 sec\n",
      "Episode 5210, len12, loss:-95.8032, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5518581867218018 sec\n",
      "Episode 5211, len10, loss:-79.3015, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5485186576843262 sec\n",
      "Episode 5212, len12, loss:-90.9263, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5507011413574219 sec\n",
      "Episode 5213, len10, loss:-83.5635, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5488002300262451 sec\n",
      "Episode 5214, len8, loss:-69.7971, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5493364334106445 sec\n",
      "Episode 5215, len10, loss:-89.1827, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5505797863006592 sec\n",
      "Episode 5216, len6, loss:-54.6979, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5485539436340332 sec\n",
      "Episode 5217, len8, loss:-60.3783, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5506913661956787 sec\n",
      "Episode 5218, len6, loss:-62.6256, fail, steps:80, opt steps:21, total reward:-24.7000, 0.544257640838623 sec\n",
      "Episode 5219, len12, loss:-89.7576, fail, steps:80, opt steps:28, total reward:-24.0000, 0.6020324230194092 sec\n",
      "Episode 5220, len12, loss:-97.9315, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5437984466552734 sec\n",
      "Episode 5221, len10, loss:-70.7298, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5495829582214355 sec\n",
      "Episode 5222, len10, loss:-82.3062, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5478787422180176 sec\n",
      "Episode 5223, len10, loss:-67.3491, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5496904850006104 sec\n",
      "Episode 5224, len6, loss:-45.7111, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5485184192657471 sec\n",
      "Episode 5225, len6, loss:-52.4533, fail, steps:80, opt steps:3, total reward:-24.0000, 0.54933762550354 sec\n",
      "Episode 5226, len10, loss:-85.9843, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5494322776794434 sec\n",
      "Episode 5227, len12, loss:-88.2834, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5513339042663574 sec\n",
      "Episode 5228, len12, loss:-85.2703, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5504562854766846 sec\n",
      "Episode 5229, len12, loss:-83.9885, fail, steps:80, opt steps:75, total reward:-24.0000, 0.5502603054046631 sec\n",
      "Episode 5230, len8, loss:-73.3082, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5492773056030273 sec\n",
      "Episode 5231, len12, loss:-98.1571, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5495936870574951 sec\n",
      "Episode 5232, len10, loss:-75.9799, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5488872528076172 sec\n",
      "Episode 5233, len6, loss:-49.2816, fail, steps:80, opt steps:6, total reward:-24.0000, 0.547966480255127 sec\n",
      "Episode 5234, len6, loss:-50.7043, fail, steps:80, opt steps:8, total reward:-24.0000, 0.547992467880249 sec\n",
      "Episode 5235, len10, loss:-77.2593, fail, steps:80, opt steps:21, total reward:-24.0000, 0.6047892570495605 sec\n",
      "Episode 5236, len12, loss:-92.1560, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5504124164581299 sec\n",
      "Episode 5237, len12, loss:-98.5345, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5500798225402832 sec\n",
      "Episode 5238, len6, loss:-54.8178, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5505406856536865 sec\n",
      "Episode 5239, len8, loss:-70.7126, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5492644309997559 sec\n",
      "Episode 5240, len12, loss:-96.8925, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5488312244415283 sec\n",
      "Episode 5241, len6, loss:-54.3093, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5495667457580566 sec\n",
      "Episode 5242, len6, loss:-59.4436, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5504240989685059 sec\n",
      "Episode 5243, len12, loss:-96.3255, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5485014915466309 sec\n",
      "Episode 5244, len6, loss:-60.9891, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5490009784698486 sec\n",
      "Episode 5245, len8, loss:-72.2597, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5500106811523438 sec\n",
      "Episode 5246, len8, loss:-69.6725, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5494592189788818 sec\n",
      "Episode 5247, len6, loss:-60.8343, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5487802028656006 sec\n",
      "Episode 5248, len8, loss:-69.9509, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6035521030426025 sec\n",
      "Episode 5249, len12, loss:-98.4741, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5501604080200195 sec\n",
      "Episode 5250, len12, loss:-100.8378, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5495574474334717 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5251, len10, loss:-77.3274, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5504024028778076 sec\n",
      "Episode 5252, len8, loss:-73.9143, fail, steps:80, opt steps:13, total reward:-24.0000, 0.549412727355957 sec\n",
      "Episode 5253, len8, loss:-68.2867, fail, steps:80, opt steps:22, total reward:-24.0000, 0.548820972442627 sec\n",
      "Episode 5254, len10, loss:-75.6281, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5497281551361084 sec\n",
      "Episode 5255, len8, loss:-63.1263, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5492837429046631 sec\n",
      "Episode 5256, len8, loss:-67.1459, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5474021434783936 sec\n",
      "Episode 5257, len10, loss:-79.5791, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5482051372528076 sec\n",
      "Episode 5258, len8, loss:-68.0268, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5473048686981201 sec\n",
      "Episode 5259, len10, loss:-80.3907, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5508406162261963 sec\n",
      "Episode 5260, len10, loss:-90.0863, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5502636432647705 sec\n",
      "Episode 5261, len12, loss:-90.5638, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5523240566253662 sec\n",
      "Episode 5262, len6, loss:-52.8863, fail, steps:80, opt steps:15, total reward:-22.7000, 0.5969173908233643 sec\n",
      "Episode 5263, len8, loss:-68.8170, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5489420890808105 sec\n",
      "Episode 5264, len12, loss:-95.9035, fail, steps:80, opt steps:41, total reward:-24.7000, 0.5449163913726807 sec\n",
      "Episode 5265, len8, loss:-75.0238, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5480756759643555 sec\n",
      "Episode 5266, len12, loss:-81.3661, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5496163368225098 sec\n",
      "Episode 5267, len10, loss:-84.0435, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5500223636627197 sec\n",
      "Episode 5268, len8, loss:-69.1597, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5503849983215332 sec\n",
      "Episode 5269, len12, loss:-91.9230, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5483977794647217 sec\n",
      "Episode 5270, len10, loss:-80.3999, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5481624603271484 sec\n",
      "Episode 5271, len6, loss:-62.7819, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5485222339630127 sec\n",
      "Episode 5272, len6, loss:-64.3951, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5479233264923096 sec\n",
      "Episode 5273, len6, loss:-54.1349, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5487430095672607 sec\n",
      "Episode 5274, len12, loss:-86.3842, fail, steps:80, opt steps:65, total reward:-24.0000, 0.54886794090271 sec\n",
      "Episode 5275, len6, loss:-58.7771, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5494089126586914 sec\n",
      "Episode 5276, len10, loss:-76.0538, fail, steps:80, opt steps:34, total reward:-24.0000, 0.6015141010284424 sec\n",
      "Episode 5277, len6, loss:-60.2576, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5480294227600098 sec\n",
      "Episode 5278, len12, loss:-95.1394, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5504276752471924 sec\n",
      "Episode 5279, len10, loss:-83.2594, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5492489337921143 sec\n",
      "Episode 5280, len8, loss:-71.2903, fail, steps:80, opt steps:31, total reward:-24.7000, 0.544835090637207 sec\n",
      "Episode 5281, len12, loss:-85.8360, fail, steps:80, opt steps:49, total reward:-24.0000, 0.549706220626831 sec\n",
      "Episode 5282, len12, loss:-93.4060, fail, steps:80, opt steps:61, total reward:-24.0000, 0.549278736114502 sec\n",
      "Episode 5283, len12, loss:-96.0818, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5480575561523438 sec\n",
      "Episode 5284, len6, loss:-53.8303, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5462021827697754 sec\n",
      "Episode 5285, len8, loss:-67.0075, fail, steps:80, opt steps:27, total reward:-24.0000, 0.54726243019104 sec\n",
      "Episode 5286, len10, loss:-90.3300, fail, steps:80, opt steps:19, total reward:-24.0000, 0.547964334487915 sec\n",
      "Episode 5287, len8, loss:-63.7433, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5487856864929199 sec\n",
      "Episode 5288, len12, loss:-95.2361, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5497758388519287 sec\n",
      "Episode 5289, len8, loss:-66.5074, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5492246150970459 sec\n",
      "Episode 5290, len10, loss:-79.7788, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5991702079772949 sec\n",
      "Episode 5291, len6, loss:-66.9341, fail, steps:80, opt steps:20, total reward:-24.0000, 0.547778844833374 sec\n",
      "Episode 5292, len6, loss:-62.1639, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5476484298706055 sec\n",
      "Episode 5293, len8, loss:-62.1434, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5506973266601562 sec\n",
      "Episode 5294, len10, loss:-77.7031, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5483345985412598 sec\n",
      "Episode 5295, len8, loss:-58.7374, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5490515232086182 sec\n",
      "Episode 5296, len12, loss:-87.6899, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5493698120117188 sec\n",
      "Episode 5297, len10, loss:-81.0908, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5500638484954834 sec\n",
      "Episode 5298, len12, loss:-87.9331, fail, steps:80, opt steps:57, total reward:-24.0000, 0.548922061920166 sec\n",
      "Episode 5299, len8, loss:-69.5310, fail, steps:80, opt steps:15, total reward:-24.0000, 0.549440860748291 sec\n",
      "Episode 5300, len10, loss:-78.4052, fail, steps:80, opt steps:37, total reward:-24.0000, 0.54854416847229 sec\n",
      "Episode 5301, len8, loss:-63.0950, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5493662357330322 sec\n",
      "Episode 5302, len6, loss:-61.9055, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5495166778564453 sec\n",
      "Episode 5303, len10, loss:-78.0915, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5488471984863281 sec\n",
      "Episode 5304, len12, loss:-89.5040, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5990822315216064 sec\n",
      "Episode 5305, len10, loss:-88.5147, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5489816665649414 sec\n",
      "Episode 5306, len6, loss:-63.3294, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5489528179168701 sec\n",
      "Episode 5307, len12, loss:-93.3805, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5486288070678711 sec\n",
      "Episode 5308, len10, loss:-88.9210, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5500640869140625 sec\n",
      "Episode 5309, len8, loss:-78.0726, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5493228435516357 sec\n",
      "Episode 5310, len10, loss:-84.3245, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5486879348754883 sec\n",
      "Episode 5311, len12, loss:-100.2266, fail, steps:80, opt steps:29, total reward:-24.0000, 0.547957181930542 sec\n",
      "Episode 5312, len12, loss:-94.2183, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5502514839172363 sec\n",
      "Episode 5313, len12, loss:-96.7975, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5501117706298828 sec\n",
      "Episode 5314, len6, loss:-56.8237, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5493414402008057 sec\n",
      "Episode 5315, len12, loss:-97.4503, fail, steps:80, opt steps:43, total reward:-24.7000, 0.5447604656219482 sec\n",
      "Episode 5316, len6, loss:-59.8254, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5483458042144775 sec\n",
      "Episode 5317, len10, loss:-84.6737, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5485615730285645 sec\n",
      "Episode 5318, len8, loss:-74.6477, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5490939617156982 sec\n",
      "Episode 5319, len10, loss:-76.0383, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5980303287506104 sec\n",
      "Episode 5320, len6, loss:-59.1150, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5494756698608398 sec\n",
      "Episode 5321, len6, loss:-59.3390, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5487489700317383 sec\n",
      "Episode 5322, len8, loss:-72.6237, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5475752353668213 sec\n",
      "Episode 5323, len12, loss:-101.8021, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5444622039794922 sec\n",
      "Episode 5324, len10, loss:-80.1009, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5483870506286621 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5325, len8, loss:-64.7785, fail, steps:80, opt steps:28, total reward:-22.7000, 0.5441281795501709 sec\n",
      "Episode 5326, len10, loss:-78.4202, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5500152111053467 sec\n",
      "Episode 5327, len10, loss:-84.7084, fail, steps:80, opt steps:36, total reward:-24.0000, 0.550243616104126 sec\n",
      "Episode 5328, len10, loss:-84.5943, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5499715805053711 sec\n",
      "Episode 5329, len12, loss:-101.0019, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5498740673065186 sec\n",
      "Episode 5330, len12, loss:-100.4363, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5487356185913086 sec\n",
      "Episode 5331, len10, loss:-83.1076, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5489537715911865 sec\n",
      "Episode 5332, len8, loss:-71.7025, fail, steps:80, opt steps:27, total reward:-24.0000, 0.547692060470581 sec\n",
      "Episode 5333, len8, loss:-73.7158, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5496444702148438 sec\n",
      "Episode 5334, len6, loss:-60.9642, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5475201606750488 sec\n",
      "Episode 5335, len12, loss:-93.3542, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5998177528381348 sec\n",
      "Episode 5336, len12, loss:-100.8586, fail, steps:80, opt steps:51, total reward:-24.7000, 0.5437567234039307 sec\n",
      "Episode 5337, len12, loss:-102.0304, fail, steps:80, opt steps:33, total reward:-24.0000, 0.548964262008667 sec\n",
      "Episode 5338, len12, loss:-100.3379, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5499560832977295 sec\n",
      "Episode 5339, len12, loss:-99.6559, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5499486923217773 sec\n",
      "Episode 5340, len8, loss:-73.5013, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5498189926147461 sec\n",
      "Episode 5341, len12, loss:-100.8516, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5510392189025879 sec\n",
      "Episode 5342, len6, loss:-63.6979, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5496797561645508 sec\n",
      "Episode 5343, len10, loss:-93.8615, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5485401153564453 sec\n",
      "Episode 5344, len10, loss:-88.2109, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5504801273345947 sec\n",
      "Episode 5345, len6, loss:-61.2673, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5488049983978271 sec\n",
      "Episode 5346, len10, loss:-90.8511, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5491158962249756 sec\n",
      "Episode 5347, len6, loss:-64.9721, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5474245548248291 sec\n",
      "Episode 5348, len10, loss:-85.9332, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5493466854095459 sec\n",
      "Episode 5349, len8, loss:-75.9543, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5489141941070557 sec\n",
      "Episode 5350, len12, loss:-94.4696, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5551328659057617 sec\n",
      "Episode 5351, len8, loss:-72.3358, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5992159843444824 sec\n",
      "Episode 5352, len12, loss:-96.7555, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5498597621917725 sec\n",
      "Episode 5353, len10, loss:-80.4383, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5504701137542725 sec\n",
      "Episode 5354, len10, loss:-78.4322, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5486388206481934 sec\n",
      "Episode 5355, len10, loss:-91.1917, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5493013858795166 sec\n",
      "Episode 5356, len12, loss:-90.2662, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5488555431365967 sec\n",
      "Episode 5357, len8, loss:-67.3440, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5490310192108154 sec\n",
      "Episode 5358, len6, loss:-61.5962, fail, steps:80, opt steps:8, total reward:-24.0000, 0.549813985824585 sec\n",
      "Episode 5359, len10, loss:-81.6443, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5491528511047363 sec\n",
      "Episode 5360, len8, loss:-66.3613, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5495126247406006 sec\n",
      "Episode 5361, len8, loss:-76.8239, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5492663383483887 sec\n",
      "Episode 5362, len12, loss:-102.1752, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5498549938201904 sec\n",
      "Episode 5363, len10, loss:-84.4035, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5489389896392822 sec\n",
      "Episode 5364, len6, loss:-68.1289, fail, steps:80, opt steps:18, total reward:-24.0000, 0.6016936302185059 sec\n",
      "Episode 5365, len6, loss:-56.7173, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5475144386291504 sec\n",
      "Episode 5366, len8, loss:-72.5209, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5534653663635254 sec\n",
      "Episode 5367, len8, loss:-65.1739, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5514190196990967 sec\n",
      "Episode 5368, len8, loss:-70.7744, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5493829250335693 sec\n",
      "Episode 5369, len10, loss:-78.5523, fail, steps:80, opt steps:31, total reward:-24.0000, 0.549121618270874 sec\n",
      "Episode 5370, len10, loss:-84.4666, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5496711730957031 sec\n",
      "Episode 5371, len6, loss:-57.3148, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5492887496948242 sec\n",
      "Episode 5372, len8, loss:-71.6608, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5432965755462646 sec\n",
      "Episode 5373, len12, loss:-90.5704, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5492446422576904 sec\n",
      "Episode 5374, len10, loss:-81.2412, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5491502285003662 sec\n",
      "Episode 5375, len8, loss:-65.9776, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5474247932434082 sec\n",
      "Episode 5376, len10, loss:-79.3122, fail, steps:80, opt steps:31, total reward:-24.0000, 0.549588680267334 sec\n",
      "Episode 5377, len10, loss:-81.8954, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5501575469970703 sec\n",
      "Episode 5378, len12, loss:-92.0695, fail, steps:80, opt steps:50, total reward:-24.0000, 0.6000094413757324 sec\n",
      "Episode 5379, len10, loss:-74.6600, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5480451583862305 sec\n",
      "Episode 5380, len6, loss:-62.6333, fail, steps:80, opt steps:6, total reward:-24.0000, 0.548856258392334 sec\n",
      "Episode 5381, len6, loss:-51.5607, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5474793910980225 sec\n",
      "Episode 5382, len12, loss:-81.3500, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5490176677703857 sec\n",
      "Episode 5383, len10, loss:-84.8102, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5496821403503418 sec\n",
      "Episode 5384, len12, loss:-91.9930, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5478429794311523 sec\n",
      "Episode 5385, len6, loss:-66.8448, fail, steps:80, opt steps:13, total reward:-25.4000, 0.5401835441589355 sec\n",
      "Episode 5386, len12, loss:-88.7886, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5465459823608398 sec\n",
      "Episode 5387, len12, loss:-86.1095, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5485246181488037 sec\n",
      "Episode 5388, len10, loss:-75.6345, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5494058132171631 sec\n",
      "Episode 5389, len12, loss:-94.5409, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5487439632415771 sec\n",
      "Episode 5390, len12, loss:-84.6801, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5500552654266357 sec\n",
      "Episode 5391, len6, loss:-48.7740, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5493483543395996 sec\n",
      "Episode 5392, len10, loss:-79.2202, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5995655059814453 sec\n",
      "Episode 5393, len6, loss:-57.6108, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5491361618041992 sec\n",
      "Episode 5394, len6, loss:-52.1875, fail, steps:80, opt steps:13, total reward:-24.0000, 0.548743486404419 sec\n",
      "Episode 5395, len10, loss:-75.7528, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5479726791381836 sec\n",
      "Episode 5396, len6, loss:-51.8469, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5483138561248779 sec\n",
      "Episode 5397, len12, loss:-88.9814, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5493316650390625 sec\n",
      "Episode 5398, len10, loss:-81.9677, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5501298904418945 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5399, len10, loss:-86.6810, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5486688613891602 sec\n",
      "Episode 5400, len10, loss:-84.1127, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5485935211181641 sec\n",
      "Episode 5401, len8, loss:-61.3268, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5479006767272949 sec\n",
      "Episode 5402, len12, loss:-90.0411, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5488567352294922 sec\n",
      "Episode 5403, len10, loss:-86.2553, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5488040447235107 sec\n",
      "Episode 5404, len12, loss:-94.3497, fail, steps:80, opt steps:73, total reward:-24.0000, 0.5490498542785645 sec\n",
      "Episode 5405, len8, loss:-70.0072, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5486383438110352 sec\n",
      "Episode 5406, len12, loss:-102.0154, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5993821620941162 sec\n",
      "Episode 5407, len10, loss:-85.5265, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5496494770050049 sec\n",
      "Episode 5408, len8, loss:-65.7548, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5485756397247314 sec\n",
      "Episode 5409, len6, loss:-53.1460, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5491800308227539 sec\n",
      "Episode 5410, len10, loss:-76.6040, fail, steps:80, opt steps:22, total reward:-24.0000, 0.548900842666626 sec\n",
      "Episode 5411, len8, loss:-62.9109, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5483605861663818 sec\n",
      "Episode 5412, len10, loss:-87.6543, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548720121383667 sec\n",
      "Episode 5413, len10, loss:-82.1562, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5480690002441406 sec\n",
      "Episode 5414, len6, loss:-54.0136, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5489354133605957 sec\n",
      "Episode 5415, len6, loss:-54.2713, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5484440326690674 sec\n",
      "Episode 5416, len6, loss:-57.8473, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5475606918334961 sec\n",
      "Episode 5417, len6, loss:-53.5327, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5475852489471436 sec\n",
      "Episode 5418, len10, loss:-72.7138, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5477228164672852 sec\n",
      "Episode 5419, len8, loss:-62.2851, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5486509799957275 sec\n",
      "Episode 5420, len10, loss:-76.7445, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5981411933898926 sec\n",
      "Episode 5421, len8, loss:-60.4823, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5479440689086914 sec\n",
      "Episode 5422, len6, loss:-49.4941, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5482020378112793 sec\n",
      "Episode 5423, len12, loss:-92.1092, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5477054119110107 sec\n",
      "Episode 5424, len8, loss:-65.4392, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5475897789001465 sec\n",
      "Episode 5425, len6, loss:-52.9630, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5476577281951904 sec\n",
      "Episode 5426, len6, loss:-57.6689, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5478403568267822 sec\n",
      "Episode 5427, len12, loss:-90.9195, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5475654602050781 sec\n",
      "Episode 5428, len8, loss:-55.1281, fail, steps:80, opt steps:32, total reward:-22.7000, 0.5442607402801514 sec\n",
      "Episode 5429, len8, loss:-63.1739, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5468094348907471 sec\n",
      "Episode 5430, len8, loss:-68.1783, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5489501953125 sec\n",
      "Episode 5431, len10, loss:-76.2646, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5473508834838867 sec\n",
      "Episode 5432, len8, loss:-69.9117, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5476481914520264 sec\n",
      "Episode 5433, len6, loss:-53.6424, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5466821193695068 sec\n",
      "Episode 5434, len12, loss:-90.9148, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5474796295166016 sec\n",
      "Episode 5435, len6, loss:-47.9432, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5979669094085693 sec\n",
      "Episode 5436, len6, loss:-50.9385, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5474562644958496 sec\n",
      "Episode 5437, len12, loss:-98.4585, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5471372604370117 sec\n",
      "Episode 5438, len12, loss:-88.2814, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5466415882110596 sec\n",
      "Episode 5439, len6, loss:-49.4171, fail, steps:80, opt steps:19, total reward:-24.0000, 0.547199010848999 sec\n",
      "Episode 5440, len6, loss:-52.1860, fail, steps:80, opt steps:11, total reward:-24.0000, 0.547736644744873 sec\n",
      "Episode 5441, len6, loss:-59.4262, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5439949035644531 sec\n",
      "Episode 5442, len6, loss:-53.3155, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5474653244018555 sec\n",
      "Episode 5443, len12, loss:-93.1788, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5481283664703369 sec\n",
      "Episode 5444, len10, loss:-77.2293, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5491561889648438 sec\n",
      "Episode 5445, len8, loss:-68.1494, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5481476783752441 sec\n",
      "Episode 5446, len10, loss:-86.6704, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5497081279754639 sec\n",
      "Episode 5447, len6, loss:-50.0057, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5473964214324951 sec\n",
      "Episode 5448, len10, loss:-83.2980, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5475153923034668 sec\n",
      "Episode 5449, len12, loss:-96.6908, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5467140674591064 sec\n",
      "Episode 5450, len12, loss:-96.2495, fail, steps:80, opt steps:47, total reward:-23.7000, 0.5443034172058105 sec\n",
      "Episode 5451, len8, loss:-66.2856, fail, steps:80, opt steps:15, total reward:-24.0000, 0.6015677452087402 sec\n",
      "Episode 5452, len8, loss:-72.5657, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5475966930389404 sec\n",
      "Episode 5453, len12, loss:-97.0390, fail, steps:80, opt steps:51, total reward:-24.0000, 0.54874587059021 sec\n",
      "Episode 5454, len10, loss:-82.3080, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5497982501983643 sec\n",
      "Episode 5455, len10, loss:-81.0478, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5481679439544678 sec\n",
      "Episode 5456, len8, loss:-76.4877, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5495562553405762 sec\n",
      "Episode 5457, len12, loss:-92.9822, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5494701862335205 sec\n",
      "Episode 5458, len12, loss:-96.2321, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5488722324371338 sec\n",
      "Episode 5459, len8, loss:-72.3234, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5476477146148682 sec\n",
      "Episode 5460, len8, loss:-74.1911, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5477144718170166 sec\n",
      "Episode 5461, len8, loss:-75.7013, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5478215217590332 sec\n",
      "Episode 5462, len8, loss:-71.4240, fail, steps:80, opt steps:15, total reward:-24.0000, 0.547835111618042 sec\n",
      "Episode 5463, len12, loss:-95.6661, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5479774475097656 sec\n",
      "Episode 5464, len6, loss:-66.8272, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5433242321014404 sec\n",
      "Episode 5465, len8, loss:-76.3097, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5461597442626953 sec\n",
      "Episode 5466, len8, loss:-68.6649, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5480420589447021 sec\n",
      "Episode 5467, len6, loss:-58.9331, fail, steps:80, opt steps:5, total reward:-24.0000, 0.6033430099487305 sec\n",
      "Episode 5468, len8, loss:-69.0988, fail, steps:80, opt steps:29, total reward:-24.0000, 0.548140287399292 sec\n",
      "Episode 5469, len8, loss:-71.7475, fail, steps:80, opt steps:29, total reward:-24.0000, 0.547945499420166 sec\n",
      "Episode 5470, len6, loss:-58.4046, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5487518310546875 sec\n",
      "Episode 5471, len10, loss:-82.6714, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5494379997253418 sec\n",
      "Episode 5472, len12, loss:-90.0310, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5488290786743164 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5473, len8, loss:-73.5728, fail, steps:80, opt steps:21, total reward:-24.0000, 0.548654317855835 sec\n",
      "Episode 5474, len10, loss:-76.4957, fail, steps:80, opt steps:36, total reward:-24.0000, 0.547553539276123 sec\n",
      "Episode 5475, len6, loss:-54.1993, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5462696552276611 sec\n",
      "Episode 5476, len6, loss:-55.1691, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5500917434692383 sec\n",
      "Episode 5477, len8, loss:-72.2752, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5483613014221191 sec\n",
      "Episode 5478, len12, loss:-91.5720, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5482096672058105 sec\n",
      "Episode 5479, len12, loss:-94.9249, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5496187210083008 sec\n",
      "Episode 5480, len10, loss:-83.0538, fail, steps:80, opt steps:26, total reward:-24.0000, 0.6079764366149902 sec\n",
      "Episode 5481, len12, loss:-94.6715, fail, steps:80, opt steps:38, total reward:-24.0000, 0.549290657043457 sec\n",
      "Episode 5482, len10, loss:-77.6239, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5494041442871094 sec\n",
      "Episode 5483, len10, loss:-83.5912, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5488932132720947 sec\n",
      "Episode 5484, len12, loss:-99.6189, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5492501258850098 sec\n",
      "Episode 5485, len12, loss:-105.0673, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5487203598022461 sec\n",
      "Episode 5486, len6, loss:-53.5560, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5485341548919678 sec\n",
      "Episode 5487, len6, loss:-60.2905, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5483086109161377 sec\n",
      "Episode 5488, len6, loss:-60.4145, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5481505393981934 sec\n",
      "Episode 5489, len8, loss:-70.2967, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5476422309875488 sec\n",
      "Episode 5490, len12, loss:-93.8070, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5485618114471436 sec\n",
      "Episode 5491, len6, loss:-52.1076, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5482523441314697 sec\n",
      "Episode 5492, len8, loss:-64.2784, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5495507717132568 sec\n",
      "Episode 5493, len10, loss:-89.3047, fail, steps:80, opt steps:29, total reward:-24.0000, 0.548851728439331 sec\n",
      "Episode 5494, len12, loss:-91.8410, fail, steps:80, opt steps:28, total reward:-24.0000, 0.604820728302002 sec\n",
      "Episode 5495, len12, loss:-89.5113, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5488741397857666 sec\n",
      "Episode 5496, len10, loss:-83.4955, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5497462749481201 sec\n",
      "Episode 5497, len8, loss:-64.9168, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5480902194976807 sec\n",
      "Episode 5498, len12, loss:-96.5369, fail, steps:80, opt steps:77, total reward:-24.0000, 0.5470829010009766 sec\n",
      "Episode 5499, len12, loss:-88.5807, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5483956336975098 sec\n",
      "Episode 5500, len6, loss:-52.6271, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5482513904571533 sec\n",
      "Episode 5501, len6, loss:-55.1752, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5502862930297852 sec\n",
      "Episode 5502, len10, loss:-79.5287, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5494985580444336 sec\n",
      "Episode 5503, len10, loss:-78.5400, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5491805076599121 sec\n",
      "Episode 5504, len8, loss:-61.3881, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5482437610626221 sec\n",
      "Episode 5505, len6, loss:-48.3566, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5488686561584473 sec\n",
      "Episode 5506, len8, loss:-64.2815, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5490987300872803 sec\n",
      "Episode 5507, len6, loss:-49.4935, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5501613616943359 sec\n",
      "Episode 5508, len6, loss:-53.0647, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6037335395812988 sec\n",
      "Episode 5509, len8, loss:-64.9959, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5483458042144775 sec\n",
      "Episode 5510, len10, loss:-76.8339, fail, steps:80, opt steps:37, total reward:-23.7000, 0.5459444522857666 sec\n",
      "Episode 5511, len10, loss:-84.8058, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5514249801635742 sec\n",
      "Episode 5512, len6, loss:-54.1354, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5501770973205566 sec\n",
      "Episode 5513, len8, loss:-68.2763, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5501270294189453 sec\n",
      "Episode 5514, len6, loss:-52.9132, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5498313903808594 sec\n",
      "Episode 5515, len6, loss:-55.3715, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5500330924987793 sec\n",
      "Episode 5516, len6, loss:-50.5267, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5500540733337402 sec\n",
      "Episode 5517, len6, loss:-56.8656, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5485749244689941 sec\n",
      "Episode 5518, len8, loss:-67.2750, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5487635135650635 sec\n",
      "Episode 5519, len6, loss:-54.6993, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5502276420593262 sec\n",
      "Episode 5520, len8, loss:-62.3377, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5498974323272705 sec\n",
      "Episode 5521, len12, loss:-87.7551, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5494685173034668 sec\n",
      "Episode 5522, len10, loss:-88.0650, fail, steps:80, opt steps:21, total reward:-24.0000, 0.59969162940979 sec\n",
      "Episode 5523, len10, loss:-84.2297, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5489072799682617 sec\n",
      "Episode 5524, len6, loss:-56.8228, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5510776042938232 sec\n",
      "Episode 5525, len8, loss:-63.6090, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5514199733734131 sec\n",
      "Episode 5526, len10, loss:-79.4801, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5482945442199707 sec\n",
      "Episode 5527, len8, loss:-71.3891, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5496101379394531 sec\n",
      "Episode 5528, len12, loss:-93.0940, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5481929779052734 sec\n",
      "Episode 5529, len10, loss:-85.7589, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5511207580566406 sec\n",
      "Episode 5530, len10, loss:-84.2914, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5488371849060059 sec\n",
      "Episode 5531, len12, loss:-92.3203, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5492920875549316 sec\n",
      "Episode 5532, len10, loss:-82.9514, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5490713119506836 sec\n",
      "Episode 5533, len12, loss:-82.5858, fail, steps:80, opt steps:50, total reward:-22.7000, 0.5439820289611816 sec\n",
      "Episode 5534, len12, loss:-95.9448, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5492022037506104 sec\n",
      "Episode 5535, len10, loss:-84.3711, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5505771636962891 sec\n",
      "Episode 5536, len10, loss:-82.9818, fail, steps:80, opt steps:37, total reward:-24.0000, 0.6001284122467041 sec\n",
      "Episode 5537, len8, loss:-66.8008, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5494425296783447 sec\n",
      "Episode 5538, len8, loss:-66.8984, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5499730110168457 sec\n",
      "Episode 5539, len8, loss:-67.7703, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5486741065979004 sec\n",
      "Episode 5540, len6, loss:-58.2929, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5488016605377197 sec\n",
      "Episode 5541, len12, loss:-90.1029, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5495460033416748 sec\n",
      "Episode 5542, len12, loss:-87.8796, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5509827136993408 sec\n",
      "Episode 5543, len12, loss:-88.4918, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5491399765014648 sec\n",
      "Episode 5544, len8, loss:-78.0127, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5489773750305176 sec\n",
      "Episode 5545, len8, loss:-71.9625, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5508236885070801 sec\n",
      "Episode 5546, len12, loss:-96.5633, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5502703189849854 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5547, len12, loss:-98.3288, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5499515533447266 sec\n",
      "Episode 5548, len10, loss:-74.4227, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5478687286376953 sec\n",
      "Episode 5549, len8, loss:-65.0234, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5483541488647461 sec\n",
      "Episode 5550, len8, loss:-68.0163, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5485866069793701 sec\n",
      "Episode 5551, len10, loss:-77.8422, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5977137088775635 sec\n",
      "Episode 5552, len12, loss:-93.1113, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5496346950531006 sec\n",
      "Episode 5553, len12, loss:-95.3530, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5501012802124023 sec\n",
      "Episode 5554, len8, loss:-70.5099, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5489475727081299 sec\n",
      "Episode 5555, len12, loss:-93.8706, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5474636554718018 sec\n",
      "Episode 5556, len10, loss:-76.6286, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5506079196929932 sec\n",
      "Episode 5557, len6, loss:-55.0265, fail, steps:80, opt steps:8, total reward:-24.0000, 0.550762414932251 sec\n",
      "Episode 5558, len10, loss:-81.2108, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5486361980438232 sec\n",
      "Episode 5559, len6, loss:-61.1694, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5492868423461914 sec\n",
      "Episode 5560, len8, loss:-61.6191, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5475659370422363 sec\n",
      "Episode 5561, len10, loss:-82.6076, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5498380661010742 sec\n",
      "Episode 5562, len6, loss:-58.3505, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5467848777770996 sec\n",
      "Episode 5563, len10, loss:-80.8917, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5484781265258789 sec\n",
      "Episode 5564, len6, loss:-61.5918, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5484895706176758 sec\n",
      "Episode 5565, len10, loss:-82.9320, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5484373569488525 sec\n",
      "Episode 5566, len6, loss:-59.4069, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5475866794586182 sec\n",
      "Episode 5567, len12, loss:-90.0972, fail, steps:80, opt steps:55, total reward:-24.0000, 0.604222297668457 sec\n",
      "Episode 5568, len10, loss:-82.6247, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5525007247924805 sec\n",
      "Episode 5569, len8, loss:-73.1914, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5482449531555176 sec\n",
      "Episode 5570, len12, loss:-83.7503, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5480766296386719 sec\n",
      "Episode 5571, len8, loss:-74.1510, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5500349998474121 sec\n",
      "Episode 5572, len10, loss:-73.9470, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5487630367279053 sec\n",
      "Episode 5573, len10, loss:-75.4679, fail, steps:80, opt steps:40, total reward:-24.0000, 0.548302173614502 sec\n",
      "Episode 5574, len10, loss:-85.1012, fail, steps:80, opt steps:47, total reward:-24.0000, 0.549069881439209 sec\n",
      "Episode 5575, len10, loss:-78.0927, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5486242771148682 sec\n",
      "Episode 5576, len12, loss:-87.5602, fail, steps:80, opt steps:55, total reward:-24.0000, 0.549257755279541 sec\n",
      "Episode 5577, len8, loss:-67.1254, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5495395660400391 sec\n",
      "Episode 5578, len8, loss:-65.1678, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5472493171691895 sec\n",
      "Episode 5579, len10, loss:-81.3013, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5489873886108398 sec\n",
      "Episode 5580, len8, loss:-60.0297, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5473244190216064 sec\n",
      "Episode 5581, len8, loss:-72.2616, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5491502285003662 sec\n",
      "Episode 5582, len12, loss:-96.2232, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5485818386077881 sec\n",
      "Episode 5583, len8, loss:-74.5830, fail, steps:80, opt steps:18, total reward:-24.0000, 0.6023375988006592 sec\n",
      "Episode 5584, len6, loss:-52.9185, fail, steps:80, opt steps:11, total reward:-24.0000, 0.547339916229248 sec\n",
      "Episode 5585, len8, loss:-66.4521, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5489575862884521 sec\n",
      "Episode 5586, len8, loss:-63.6352, fail, steps:80, opt steps:22, total reward:-22.7000, 0.5444164276123047 sec\n",
      "Episode 5587, len12, loss:-80.3659, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5489566326141357 sec\n",
      "Episode 5588, len6, loss:-51.9456, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5468006134033203 sec\n",
      "Episode 5589, len12, loss:-86.0263, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5478639602661133 sec\n",
      "Episode 5590, len6, loss:-43.9650, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5477292537689209 sec\n",
      "Episode 5591, len8, loss:-57.7162, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5474834442138672 sec\n",
      "Episode 5592, len6, loss:-57.7356, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5485668182373047 sec\n",
      "Episode 5593, len10, loss:-77.9294, fail, steps:80, opt steps:32, total reward:-23.7000, 0.5430679321289062 sec\n",
      "Episode 5594, len10, loss:-70.2768, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5480940341949463 sec\n",
      "Episode 5595, len6, loss:-53.6970, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5491321086883545 sec\n",
      "Episode 5596, len10, loss:-73.3808, fail, steps:80, opt steps:32, total reward:-24.0000, 0.6043441295623779 sec\n",
      "Episode 5597, len8, loss:-60.6000, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5485701560974121 sec\n",
      "Episode 5598, len8, loss:-62.9219, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5472476482391357 sec\n",
      "Episode 5599, len12, loss:-86.2967, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5475845336914062 sec\n",
      "Episode 5600, len10, loss:-80.1677, fail, steps:80, opt steps:26, total reward:-24.0000, 0.547468900680542 sec\n",
      "Episode 5601, len8, loss:-66.0916, fail, steps:80, opt steps:27, total reward:-24.0000, 0.548084020614624 sec\n",
      "Episode 5602, len12, loss:-98.6564, fail, steps:80, opt steps:50, total reward:-23.7000, 0.5434432029724121 sec\n",
      "Episode 5603, len8, loss:-62.5191, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5470337867736816 sec\n",
      "Episode 5604, len10, loss:-80.8117, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5478129386901855 sec\n",
      "Episode 5605, len6, loss:-60.9964, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5468509197235107 sec\n",
      "Episode 5606, len8, loss:-65.0890, fail, steps:80, opt steps:27, total reward:-24.0000, 0.547999382019043 sec\n",
      "Episode 5607, len8, loss:-72.9708, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5472269058227539 sec\n",
      "Episode 5608, len8, loss:-69.6549, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5486485958099365 sec\n",
      "Episode 5609, len8, loss:-67.5399, fail, steps:80, opt steps:31, total reward:-24.0000, 0.549567699432373 sec\n",
      "Episode 5610, len10, loss:-84.4665, fail, steps:80, opt steps:30, total reward:-24.0000, 0.6004207134246826 sec\n",
      "Episode 5611, len6, loss:-57.7402, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5492074489593506 sec\n",
      "Episode 5612, len8, loss:-61.1259, fail, steps:80, opt steps:26, total reward:-24.0000, 0.547762393951416 sec\n",
      "Episode 5613, len12, loss:-90.2576, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5476846694946289 sec\n",
      "Episode 5614, len8, loss:-64.6223, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5483009815216064 sec\n",
      "Episode 5615, len6, loss:-56.1535, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5475866794586182 sec\n",
      "Episode 5616, len10, loss:-82.5645, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5482878684997559 sec\n",
      "Episode 5617, len12, loss:-82.4523, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5489604473114014 sec\n",
      "Episode 5618, len8, loss:-60.8387, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5485639572143555 sec\n",
      "Episode 5619, len12, loss:-89.7627, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5480892658233643 sec\n",
      "Episode 5620, len6, loss:-58.3353, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5483157634735107 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5621, len12, loss:-89.5168, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5497448444366455 sec\n",
      "Episode 5622, len12, loss:-93.0354, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5489377975463867 sec\n",
      "Episode 5623, len6, loss:-58.5780, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5480129718780518 sec\n",
      "Episode 5624, len6, loss:-61.0883, fail, steps:80, opt steps:15, total reward:-24.0000, 0.6000697612762451 sec\n",
      "Episode 5625, len10, loss:-82.3652, fail, steps:80, opt steps:49, total reward:-24.0000, 0.548213005065918 sec\n",
      "Episode 5626, len8, loss:-67.7514, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5478723049163818 sec\n",
      "Episode 5627, len10, loss:-86.5179, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5495834350585938 sec\n",
      "Episode 5628, len8, loss:-66.5665, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5488653182983398 sec\n",
      "Episode 5629, len12, loss:-86.0157, fail, steps:80, opt steps:70, total reward:-24.0000, 0.5505549907684326 sec\n",
      "Episode 5630, len12, loss:-89.6971, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5485727787017822 sec\n",
      "Episode 5631, len12, loss:-84.7484, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5487351417541504 sec\n",
      "Episode 5632, len10, loss:-87.4659, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5498054027557373 sec\n",
      "Episode 5633, len6, loss:-56.7830, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5501799583435059 sec\n",
      "Episode 5634, len10, loss:-71.4037, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5494039058685303 sec\n",
      "Episode 5635, len10, loss:-79.5560, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5502324104309082 sec\n",
      "Episode 5636, len12, loss:-82.7623, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5489208698272705 sec\n",
      "Episode 5637, len10, loss:-73.2224, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5498456954956055 sec\n",
      "Episode 5638, len8, loss:-61.9609, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5995726585388184 sec\n",
      "Episode 5639, len6, loss:-57.4397, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5481653213500977 sec\n",
      "Episode 5640, len12, loss:-96.8385, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5491511821746826 sec\n",
      "Episode 5641, len12, loss:-86.4565, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5484611988067627 sec\n",
      "Episode 5642, len6, loss:-58.1143, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5493202209472656 sec\n",
      "Episode 5643, len10, loss:-69.6414, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5485260486602783 sec\n",
      "Episode 5644, len10, loss:-76.3650, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5480690002441406 sec\n",
      "Episode 5645, len6, loss:-47.5142, fail, steps:80, opt steps:8, total reward:-24.0000, 0.549921989440918 sec\n",
      "Episode 5646, len10, loss:-77.0653, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5485644340515137 sec\n",
      "Episode 5647, len12, loss:-86.5774, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5491368770599365 sec\n",
      "Episode 5648, len8, loss:-64.9066, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5500853061676025 sec\n",
      "Episode 5649, len10, loss:-75.7965, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5489025115966797 sec\n",
      "Episode 5650, len10, loss:-85.6516, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5466558933258057 sec\n",
      "Episode 5651, len12, loss:-89.7276, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5484461784362793 sec\n",
      "Episode 5652, len12, loss:-93.9041, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5994303226470947 sec\n",
      "Episode 5653, len8, loss:-69.3742, fail, steps:80, opt steps:24, total reward:-24.0000, 0.549513578414917 sec\n",
      "Episode 5654, len10, loss:-79.1457, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5478641986846924 sec\n",
      "Episode 5655, len12, loss:-91.4611, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5498197078704834 sec\n",
      "Episode 5656, len8, loss:-69.4613, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5468175411224365 sec\n",
      "Episode 5657, len8, loss:-70.6545, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5486884117126465 sec\n",
      "Episode 5658, len6, loss:-49.4056, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5498263835906982 sec\n",
      "Episode 5659, len10, loss:-74.4522, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5492098331451416 sec\n",
      "Episode 5660, len12, loss:-88.3219, fail, steps:80, opt steps:68, total reward:-24.0000, 0.5489959716796875 sec\n",
      "Episode 5661, len12, loss:-89.1624, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5497534275054932 sec\n",
      "Episode 5662, len6, loss:-61.3796, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5501210689544678 sec\n",
      "Episode 5663, len12, loss:-88.6199, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5493457317352295 sec\n",
      "Episode 5664, len6, loss:-48.7840, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5481207370758057 sec\n",
      "Episode 5665, len6, loss:-45.5740, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5492637157440186 sec\n",
      "Episode 5666, len10, loss:-76.4128, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5498709678649902 sec\n",
      "Episode 5667, len6, loss:-57.5743, fail, steps:80, opt steps:7, total reward:-24.0000, 0.599132776260376 sec\n",
      "Episode 5668, len10, loss:-78.0776, fail, steps:80, opt steps:45, total reward:-24.0000, 0.549309492111206 sec\n",
      "Episode 5669, len12, loss:-86.0200, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5497589111328125 sec\n",
      "Episode 5670, len8, loss:-65.0533, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5488872528076172 sec\n",
      "Episode 5671, len10, loss:-75.8383, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5495977401733398 sec\n",
      "Episode 5672, len6, loss:-54.5728, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5491640567779541 sec\n",
      "Episode 5673, len12, loss:-88.5381, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5493044853210449 sec\n",
      "Episode 5674, len12, loss:-87.9488, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5508699417114258 sec\n",
      "Episode 5675, len6, loss:-57.3183, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5508959293365479 sec\n",
      "Episode 5676, len8, loss:-67.2876, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5481250286102295 sec\n",
      "Episode 5677, len8, loss:-74.6602, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5503075122833252 sec\n",
      "Episode 5678, len12, loss:-89.0206, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5496931076049805 sec\n",
      "Episode 5679, len6, loss:-57.1466, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5495164394378662 sec\n",
      "Episode 5680, len12, loss:-86.9923, fail, steps:80, opt steps:71, total reward:-24.0000, 0.5481455326080322 sec\n",
      "Episode 5681, len12, loss:-92.3792, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5488619804382324 sec\n",
      "Episode 5682, len10, loss:-79.9399, fail, steps:80, opt steps:26, total reward:-24.0000, 0.548914909362793 sec\n",
      "Episode 5683, len10, loss:-76.7120, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5991613864898682 sec\n",
      "Episode 5684, len8, loss:-67.1481, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5491805076599121 sec\n",
      "Episode 5685, len10, loss:-78.5101, fail, steps:80, opt steps:46, total reward:-24.0000, 0.548853874206543 sec\n",
      "Episode 5686, len10, loss:-82.4846, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5501048564910889 sec\n",
      "Episode 5687, len12, loss:-94.3661, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5492587089538574 sec\n",
      "Episode 5688, len12, loss:-85.6503, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5511620044708252 sec\n",
      "Episode 5689, len6, loss:-49.5757, fail, steps:80, opt steps:19, total reward:-24.0000, 0.551124095916748 sec\n",
      "Episode 5690, len8, loss:-64.2614, fail, steps:80, opt steps:25, total reward:-24.0000, 0.55098557472229 sec\n",
      "Episode 5691, len8, loss:-69.2929, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5505962371826172 sec\n",
      "Episode 5692, len12, loss:-96.2790, fail, steps:80, opt steps:36, total reward:-24.7000, 0.5453951358795166 sec\n",
      "Episode 5693, len6, loss:-51.1530, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5501251220703125 sec\n",
      "Episode 5694, len6, loss:-60.7284, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5493721961975098 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5695, len8, loss:-77.5238, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5488333702087402 sec\n",
      "Episode 5696, len6, loss:-56.9069, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5491735935211182 sec\n",
      "Episode 5697, len8, loss:-70.5706, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5505211353302002 sec\n",
      "Episode 5698, len8, loss:-68.7890, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5502650737762451 sec\n",
      "Episode 5699, len6, loss:-65.8964, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5962903499603271 sec\n",
      "Episode 5700, len12, loss:-84.3206, fail, steps:80, opt steps:72, total reward:-22.7000, 0.5454261302947998 sec\n",
      "Episode 5701, len10, loss:-82.5913, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5496585369110107 sec\n",
      "Episode 5702, len8, loss:-67.7037, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5523171424865723 sec\n",
      "Episode 5703, len6, loss:-55.5800, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5493512153625488 sec\n",
      "Episode 5704, len10, loss:-79.5911, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5512809753417969 sec\n",
      "Episode 5705, len10, loss:-86.9293, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5496330261230469 sec\n",
      "Episode 5706, len8, loss:-75.6059, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5502700805664062 sec\n",
      "Episode 5707, len8, loss:-69.7278, fail, steps:80, opt steps:24, total reward:-24.0000, 0.549328088760376 sec\n",
      "Episode 5708, len10, loss:-85.6293, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5495390892028809 sec\n",
      "Episode 5709, len6, loss:-56.6246, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5493977069854736 sec\n",
      "Episode 5710, len8, loss:-62.5886, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5506720542907715 sec\n",
      "Episode 5711, len8, loss:-64.3622, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5498738288879395 sec\n",
      "Episode 5712, len12, loss:-96.4610, fail, steps:80, opt steps:56, total reward:-24.0000, 0.6029138565063477 sec\n",
      "Episode 5713, len6, loss:-61.1438, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5468833446502686 sec\n",
      "Episode 5714, len8, loss:-65.6776, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5464887619018555 sec\n",
      "Episode 5715, len12, loss:-98.9048, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5499134063720703 sec\n",
      "Episode 5716, len12, loss:-93.8500, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5488295555114746 sec\n",
      "Episode 5717, len8, loss:-67.2935, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5484921932220459 sec\n",
      "Episode 5718, len10, loss:-92.1697, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5488786697387695 sec\n",
      "Episode 5719, len6, loss:-61.9000, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5482208728790283 sec\n",
      "Episode 5720, len6, loss:-55.7360, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5493571758270264 sec\n",
      "Episode 5721, len8, loss:-65.9305, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5489060878753662 sec\n",
      "Episode 5722, len10, loss:-82.1147, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5497663021087646 sec\n",
      "Episode 5723, len8, loss:-69.8413, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5489606857299805 sec\n",
      "Episode 5724, len8, loss:-74.5715, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5497167110443115 sec\n",
      "Episode 5725, len6, loss:-56.0217, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5492653846740723 sec\n",
      "Episode 5726, len6, loss:-57.2300, fail, steps:80, opt steps:18, total reward:-24.0000, 0.6033761501312256 sec\n",
      "Episode 5727, len6, loss:-52.5900, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5480794906616211 sec\n",
      "Episode 5728, len6, loss:-61.1294, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5475654602050781 sec\n",
      "Episode 5729, len10, loss:-75.0914, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5500180721282959 sec\n",
      "Episode 5730, len12, loss:-95.2608, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5481891632080078 sec\n",
      "Episode 5731, len8, loss:-72.0184, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5497705936431885 sec\n",
      "Episode 5732, len10, loss:-85.3725, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5499105453491211 sec\n",
      "Episode 5733, len10, loss:-81.3042, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5486431121826172 sec\n",
      "Episode 5734, len6, loss:-56.7427, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5500931739807129 sec\n",
      "Episode 5735, len6, loss:-56.2328, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490233898162842 sec\n",
      "Episode 5736, len12, loss:-96.7966, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5451071262359619 sec\n",
      "Episode 5737, len6, loss:-48.7811, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5485458374023438 sec\n",
      "Episode 5738, len8, loss:-68.2639, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5504803657531738 sec\n",
      "Episode 5739, len8, loss:-66.1814, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5518991947174072 sec\n",
      "Episode 5740, len8, loss:-69.0034, fail, steps:80, opt steps:33, total reward:-24.0000, 0.6004235744476318 sec\n",
      "Episode 5741, len8, loss:-75.8630, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5506265163421631 sec\n",
      "Episode 5742, len6, loss:-61.1506, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5461990833282471 sec\n",
      "Episode 5743, len6, loss:-58.4841, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5476655960083008 sec\n",
      "Episode 5744, len6, loss:-49.0928, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5485568046569824 sec\n",
      "Episode 5745, len6, loss:-60.2749, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485930442810059 sec\n",
      "Episode 5746, len10, loss:-86.2910, fail, steps:80, opt steps:29, total reward:-24.0000, 0.548431396484375 sec\n",
      "Episode 5747, len10, loss:-84.6246, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5488510131835938 sec\n",
      "Episode 5748, len12, loss:-100.1876, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5502994060516357 sec\n",
      "Episode 5749, len10, loss:-81.2722, fail, steps:80, opt steps:43, total reward:-24.0000, 0.548926830291748 sec\n",
      "Episode 5750, len8, loss:-82.3544, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5489869117736816 sec\n",
      "Episode 5751, len10, loss:-88.6352, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5509006977081299 sec\n",
      "Episode 5752, len6, loss:-60.3128, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5482590198516846 sec\n",
      "Episode 5753, len6, loss:-60.6843, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5496227741241455 sec\n",
      "Episode 5754, len8, loss:-73.7424, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5995793342590332 sec\n",
      "Episode 5755, len10, loss:-86.0890, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5486226081848145 sec\n",
      "Episode 5756, len8, loss:-73.3000, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5490677356719971 sec\n",
      "Episode 5757, len8, loss:-82.0494, fail, steps:80, opt steps:27, total reward:-24.0000, 0.550325870513916 sec\n",
      "Episode 5758, len8, loss:-76.0235, fail, steps:80, opt steps:33, total reward:-24.0000, 0.550239086151123 sec\n",
      "Episode 5759, len12, loss:-102.0489, fail, steps:80, opt steps:41, total reward:-24.0000, 0.549370288848877 sec\n",
      "Episode 5760, len8, loss:-73.7772, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5488166809082031 sec\n",
      "Episode 5761, len6, loss:-61.9650, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5488495826721191 sec\n",
      "Episode 5762, len10, loss:-85.5006, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5480554103851318 sec\n",
      "Episode 5763, len10, loss:-85.4982, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5511252880096436 sec\n",
      "Episode 5764, len6, loss:-62.7291, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5499072074890137 sec\n",
      "Episode 5765, len10, loss:-90.0277, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5505118370056152 sec\n",
      "Episode 5766, len6, loss:-61.1325, fail, steps:80, opt steps:21, total reward:-23.7000, 0.5459425449371338 sec\n",
      "Episode 5767, len6, loss:-57.1859, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5486311912536621 sec\n",
      "Episode 5768, len12, loss:-97.8051, fail, steps:80, opt steps:44, total reward:-24.0000, 0.6000795364379883 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5769, len12, loss:-94.7291, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5490195751190186 sec\n",
      "Episode 5770, len6, loss:-68.1283, fail, steps:80, opt steps:20, total reward:-24.0000, 0.548846960067749 sec\n",
      "Episode 5771, len10, loss:-86.8388, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5489504337310791 sec\n",
      "Episode 5772, len8, loss:-73.7984, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5497262477874756 sec\n",
      "Episode 5773, len12, loss:-98.9540, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5477755069732666 sec\n",
      "Episode 5774, len8, loss:-82.2253, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5495555400848389 sec\n",
      "Episode 5775, len6, loss:-67.0380, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5489726066589355 sec\n",
      "Episode 5776, len6, loss:-59.1421, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5485877990722656 sec\n",
      "Episode 5777, len6, loss:-65.2633, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5491068363189697 sec\n",
      "Episode 5778, len6, loss:-63.2554, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5497875213623047 sec\n",
      "Episode 5779, len8, loss:-75.5726, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5497744083404541 sec\n",
      "Episode 5780, len10, loss:-76.5973, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5487031936645508 sec\n",
      "Episode 5781, len12, loss:-98.8513, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5500509738922119 sec\n",
      "Episode 5782, len12, loss:-95.5578, fail, steps:80, opt steps:78, total reward:-24.0000, 0.5507707595825195 sec\n",
      "Episode 5783, len12, loss:-96.2216, fail, steps:80, opt steps:71, total reward:-24.0000, 0.5986311435699463 sec\n",
      "Episode 5784, len8, loss:-75.9756, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5479190349578857 sec\n",
      "Episode 5785, len10, loss:-90.3089, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5544216632843018 sec\n",
      "Episode 5786, len12, loss:-103.6057, fail, steps:80, opt steps:41, total reward:-24.0000, 0.549243688583374 sec\n",
      "Episode 5787, len10, loss:-84.9234, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5488846302032471 sec\n",
      "Episode 5788, len12, loss:-95.6507, fail, steps:80, opt steps:69, total reward:-24.0000, 0.5497307777404785 sec\n",
      "Episode 5789, len10, loss:-85.2058, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5487930774688721 sec\n",
      "Episode 5790, len12, loss:-96.5220, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5496292114257812 sec\n",
      "Episode 5791, len8, loss:-69.4541, fail, steps:80, opt steps:29, total reward:-24.0000, 0.549689769744873 sec\n",
      "Episode 5792, len10, loss:-82.5556, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5491864681243896 sec\n",
      "Episode 5793, len6, loss:-62.3741, fail, steps:80, opt steps:13, total reward:-24.0000, 0.549161434173584 sec\n",
      "Episode 5794, len6, loss:-64.1275, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5480468273162842 sec\n",
      "Episode 5795, len6, loss:-68.4137, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5500764846801758 sec\n",
      "Episode 5796, len10, loss:-84.9518, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5503008365631104 sec\n",
      "Episode 5797, len10, loss:-80.3826, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5498290061950684 sec\n",
      "Episode 5798, len12, loss:-97.1861, fail, steps:80, opt steps:60, total reward:-24.7000, 0.5439221858978271 sec\n",
      "Episode 5799, len12, loss:-101.3432, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5984458923339844 sec\n",
      "Episode 5800, len8, loss:-74.0582, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5500271320343018 sec\n",
      "Episode 5801, len6, loss:-62.9970, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5486500263214111 sec\n",
      "Episode 5802, len6, loss:-63.3514, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5484828948974609 sec\n",
      "Episode 5803, len12, loss:-92.5354, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5487813949584961 sec\n",
      "Episode 5804, len8, loss:-74.5585, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5495271682739258 sec\n",
      "Episode 5805, len6, loss:-63.4025, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5490703582763672 sec\n",
      "Episode 5806, len6, loss:-66.9313, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5480325222015381 sec\n",
      "Episode 5807, len12, loss:-94.0240, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5498037338256836 sec\n",
      "Episode 5808, len6, loss:-62.0638, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5478005409240723 sec\n",
      "Episode 5809, len6, loss:-62.1810, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5484013557434082 sec\n",
      "Episode 5810, len6, loss:-60.0855, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5502054691314697 sec\n",
      "Episode 5811, len10, loss:-85.9868, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5488557815551758 sec\n",
      "Episode 5812, len12, loss:-91.5521, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5503280162811279 sec\n",
      "Episode 5813, len12, loss:-89.7706, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5480329990386963 sec\n",
      "Episode 5814, len10, loss:-91.5355, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5497262477874756 sec\n",
      "Episode 5815, len6, loss:-58.5450, fail, steps:80, opt steps:7, total reward:-24.0000, 0.6001801490783691 sec\n",
      "Episode 5816, len8, loss:-70.4469, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5487749576568604 sec\n",
      "Episode 5817, len12, loss:-90.4545, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5455906391143799 sec\n",
      "Episode 5818, len8, loss:-74.1294, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5483536720275879 sec\n",
      "Episode 5819, len10, loss:-80.8446, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5491712093353271 sec\n",
      "Episode 5820, len8, loss:-75.3127, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5493025779724121 sec\n",
      "Episode 5821, len10, loss:-88.7574, fail, steps:80, opt steps:19, total reward:-24.0000, 0.54913330078125 sec\n",
      "Episode 5822, len12, loss:-87.5456, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5501663684844971 sec\n",
      "Episode 5823, len12, loss:-101.2149, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5453271865844727 sec\n",
      "Episode 5824, len8, loss:-88.9499, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5434720516204834 sec\n",
      "Episode 5825, len12, loss:-88.1406, fail, steps:80, opt steps:36, total reward:-24.0000, 0.546722412109375 sec\n",
      "Episode 5826, len10, loss:-91.0420, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5490837097167969 sec\n",
      "Episode 5827, len8, loss:-69.9142, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5479717254638672 sec\n",
      "Episode 5828, len12, loss:-102.2209, fail, steps:80, opt steps:47, total reward:-24.7000, 0.6035354137420654 sec\n",
      "Episode 5829, len6, loss:-55.8463, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5479683876037598 sec\n",
      "Episode 5830, len8, loss:-65.1829, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5471196174621582 sec\n",
      "Episode 5831, len8, loss:-75.0737, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5446250438690186 sec\n",
      "Episode 5832, len6, loss:-53.7916, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5487658977508545 sec\n",
      "Episode 5833, len8, loss:-85.3565, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5488226413726807 sec\n",
      "Episode 5834, len10, loss:-82.6992, fail, steps:80, opt steps:26, total reward:-24.0000, 0.547839879989624 sec\n",
      "Episode 5835, len8, loss:-74.7055, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5476527214050293 sec\n",
      "Episode 5836, len12, loss:-90.1409, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5490803718566895 sec\n",
      "Episode 5837, len8, loss:-75.1548, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5651774406433105 sec\n",
      "Episode 5838, len8, loss:-66.3535, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5478918552398682 sec\n",
      "Episode 5839, len6, loss:-54.7097, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5480177402496338 sec\n",
      "Episode 5840, len8, loss:-72.1225, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5474228858947754 sec\n",
      "Episode 5841, len8, loss:-75.3313, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5468289852142334 sec\n",
      "Episode 5842, len6, loss:-56.9015, fail, steps:80, opt steps:13, total reward:-24.0000, 0.6073858737945557 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5843, len8, loss:-75.1619, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5485599040985107 sec\n",
      "Episode 5844, len8, loss:-74.1251, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5476343631744385 sec\n",
      "Episode 5845, len8, loss:-77.6721, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5485386848449707 sec\n",
      "Episode 5846, len12, loss:-91.6817, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5471365451812744 sec\n",
      "Episode 5847, len8, loss:-74.4230, fail, steps:80, opt steps:9, total reward:-24.0000, 0.549555778503418 sec\n",
      "Episode 5848, len6, loss:-56.7388, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5476312637329102 sec\n",
      "Episode 5849, len10, loss:-80.5182, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5471682548522949 sec\n",
      "Episode 5850, len12, loss:-98.7874, fail, steps:80, opt steps:54, total reward:-24.7000, 0.5456151962280273 sec\n",
      "Episode 5851, len10, loss:-80.9693, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5489485263824463 sec\n",
      "Episode 5852, len12, loss:-88.3197, fail, steps:80, opt steps:32, total reward:-24.0000, 0.547400951385498 sec\n",
      "Episode 5853, len8, loss:-73.8415, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5488429069519043 sec\n",
      "Episode 5854, len12, loss:-99.9827, fail, steps:80, opt steps:62, total reward:-24.7000, 0.5427367687225342 sec\n",
      "Episode 5855, len12, loss:-95.6610, fail, steps:80, opt steps:38, total reward:-24.0000, 0.547842264175415 sec\n",
      "Episode 5856, len8, loss:-70.8727, fail, steps:80, opt steps:27, total reward:-24.0000, 0.6048214435577393 sec\n",
      "Episode 5857, len6, loss:-56.8420, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5467984676361084 sec\n",
      "Episode 5858, len10, loss:-82.8572, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5483958721160889 sec\n",
      "Episode 5859, len8, loss:-73.7652, fail, steps:80, opt steps:29, total reward:-24.0000, 0.546699047088623 sec\n",
      "Episode 5860, len6, loss:-61.8930, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5486655235290527 sec\n",
      "Episode 5861, len8, loss:-75.7920, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5493419170379639 sec\n",
      "Episode 5862, len6, loss:-58.5474, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5496490001678467 sec\n",
      "Episode 5863, len6, loss:-63.9692, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5480039119720459 sec\n",
      "Episode 5864, len10, loss:-77.3017, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5482826232910156 sec\n",
      "Episode 5865, len6, loss:-61.4765, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5479514598846436 sec\n",
      "Episode 5866, len12, loss:-83.5702, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5473361015319824 sec\n",
      "Episode 5867, len12, loss:-90.2066, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5470383167266846 sec\n",
      "Episode 5868, len8, loss:-77.2834, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5472719669342041 sec\n",
      "Episode 5869, len6, loss:-60.8214, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5483310222625732 sec\n",
      "Episode 5870, len8, loss:-73.4673, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5964367389678955 sec\n",
      "Episode 5871, len6, loss:-63.2724, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5486335754394531 sec\n",
      "Episode 5872, len6, loss:-62.5366, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5488858222961426 sec\n",
      "Episode 5873, len8, loss:-74.6184, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5482776165008545 sec\n",
      "Episode 5874, len8, loss:-84.1784, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5476882457733154 sec\n",
      "Episode 5875, len8, loss:-74.2930, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5478744506835938 sec\n",
      "Episode 5876, len8, loss:-80.0036, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5496516227722168 sec\n",
      "Episode 5877, len8, loss:-78.6616, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5473496913909912 sec\n",
      "Episode 5878, len10, loss:-78.1928, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5468466281890869 sec\n",
      "Episode 5879, len10, loss:-76.2701, fail, steps:80, opt steps:24, total reward:-24.0000, 0.547116756439209 sec\n",
      "Episode 5880, len12, loss:-78.4360, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5469326972961426 sec\n",
      "Episode 5881, len8, loss:-72.7975, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5470764636993408 sec\n",
      "Episode 5882, len8, loss:-77.3970, fail, steps:80, opt steps:25, total reward:-24.0000, 0.546607494354248 sec\n",
      "Episode 5883, len10, loss:-82.0918, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5472290515899658 sec\n",
      "Episode 5884, len10, loss:-68.2318, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5990304946899414 sec\n",
      "Episode 5885, len12, loss:-81.0817, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5490200519561768 sec\n",
      "Episode 5886, len10, loss:-78.5733, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5477378368377686 sec\n",
      "Episode 5887, len8, loss:-73.0952, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5479035377502441 sec\n",
      "Episode 5888, len12, loss:-86.5382, fail, steps:80, opt steps:25, total reward:-24.0000, 0.546757698059082 sec\n",
      "Episode 5889, len6, loss:-53.7694, fail, steps:80, opt steps:21, total reward:-22.7000, 0.5435805320739746 sec\n",
      "Episode 5890, len8, loss:-78.5062, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5471930503845215 sec\n",
      "Episode 5891, len6, loss:-63.8789, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5484490394592285 sec\n",
      "Episode 5892, len10, loss:-86.3162, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5469586849212646 sec\n",
      "Episode 5893, len8, loss:-76.3509, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5484127998352051 sec\n",
      "Episode 5894, len10, loss:-82.9259, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5485832691192627 sec\n",
      "Episode 5895, len10, loss:-83.0176, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5474553108215332 sec\n",
      "Episode 5896, len6, loss:-60.3556, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5477538108825684 sec\n",
      "Episode 5897, len12, loss:-87.1389, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5483748912811279 sec\n",
      "Episode 5898, len8, loss:-66.0402, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5479397773742676 sec\n",
      "Episode 5899, len10, loss:-74.7775, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5996708869934082 sec\n",
      "Episode 5900, len12, loss:-87.2525, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5475037097930908 sec\n",
      "Episode 5901, len8, loss:-72.6885, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5474948883056641 sec\n",
      "Episode 5902, len6, loss:-58.3032, fail, steps:80, opt steps:13, total reward:-24.0000, 0.549041748046875 sec\n",
      "Episode 5903, len8, loss:-72.2019, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5472674369812012 sec\n",
      "Episode 5904, len10, loss:-83.0959, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5478465557098389 sec\n",
      "Episode 5905, len12, loss:-86.2541, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5471920967102051 sec\n",
      "Episode 5906, len8, loss:-67.0908, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5471775531768799 sec\n",
      "Episode 5907, len10, loss:-82.6793, fail, steps:80, opt steps:47, total reward:-24.0000, 0.547360897064209 sec\n",
      "Episode 5908, len12, loss:-102.1790, fail, steps:80, opt steps:48, total reward:-24.7000, 0.542565107345581 sec\n",
      "Episode 5909, len8, loss:-68.8241, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5475621223449707 sec\n",
      "Episode 5910, len10, loss:-74.9256, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5483837127685547 sec\n",
      "Episode 5911, len6, loss:-47.9014, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5483167171478271 sec\n",
      "Episode 5912, len8, loss:-83.3130, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5443124771118164 sec\n",
      "Episode 5913, len8, loss:-60.3000, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5476970672607422 sec\n",
      "Episode 5914, len6, loss:-56.7629, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5478577613830566 sec\n",
      "Episode 5915, len8, loss:-81.0491, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5970230102539062 sec\n",
      "Episode 5916, len12, loss:-85.8027, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5488934516906738 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5917, len12, loss:-89.3789, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5490715503692627 sec\n",
      "Episode 5918, len12, loss:-77.5300, fail, steps:80, opt steps:72, total reward:-24.0000, 0.5475254058837891 sec\n",
      "Episode 5919, len10, loss:-74.7246, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5493021011352539 sec\n",
      "Episode 5920, len6, loss:-47.2370, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5496830940246582 sec\n",
      "Episode 5921, len12, loss:-85.5438, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5492668151855469 sec\n",
      "Episode 5922, len8, loss:-64.9029, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5478243827819824 sec\n",
      "Episode 5923, len8, loss:-75.7891, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5489692687988281 sec\n",
      "Episode 5924, len10, loss:-81.7394, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5492963790893555 sec\n",
      "Episode 5925, len8, loss:-68.1858, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5476858615875244 sec\n",
      "Episode 5926, len12, loss:-91.5717, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5476644039154053 sec\n",
      "Episode 5927, len12, loss:-95.3987, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5481317043304443 sec\n",
      "Episode 5928, len10, loss:-76.7640, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5488736629486084 sec\n",
      "Episode 5929, len12, loss:-81.8998, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5476720333099365 sec\n",
      "Episode 5930, len10, loss:-74.4375, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5480656623840332 sec\n",
      "Episode 5931, len10, loss:-75.8082, fail, steps:80, opt steps:36, total reward:-24.0000, 0.6029505729675293 sec\n",
      "Episode 5932, len8, loss:-74.8202, fail, steps:80, opt steps:32, total reward:-24.7000, 0.5443315505981445 sec\n",
      "Episode 5933, len12, loss:-88.5526, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5475218296051025 sec\n",
      "Episode 5934, len12, loss:-84.3140, fail, steps:80, opt steps:33, total reward:-24.0000, 0.549767017364502 sec\n",
      "Episode 5935, len8, loss:-78.8548, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5447077751159668 sec\n",
      "Episode 5936, len10, loss:-80.7680, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5478980541229248 sec\n",
      "Episode 5937, len10, loss:-84.3128, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5478847026824951 sec\n",
      "Episode 5938, len12, loss:-102.8517, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5494189262390137 sec\n",
      "Episode 5939, len12, loss:-91.2834, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5482437610626221 sec\n",
      "Episode 5940, len12, loss:-93.8281, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5491764545440674 sec\n",
      "Episode 5941, len8, loss:-67.2591, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5479452610015869 sec\n",
      "Episode 5942, len8, loss:-74.7241, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5496034622192383 sec\n",
      "Episode 5943, len8, loss:-72.7861, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5492508411407471 sec\n",
      "Episode 5944, len8, loss:-64.7317, fail, steps:80, opt steps:25, total reward:-24.0000, 0.6079723834991455 sec\n",
      "Episode 5945, len12, loss:-90.0298, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5485610961914062 sec\n",
      "Episode 5946, len10, loss:-80.8987, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5485763549804688 sec\n",
      "Episode 5947, len8, loss:-70.8694, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548912763595581 sec\n",
      "Episode 5948, len12, loss:-84.5240, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5487658977508545 sec\n",
      "Episode 5949, len10, loss:-86.8269, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5473716259002686 sec\n",
      "Episode 5950, len10, loss:-90.2155, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5482208728790283 sec\n",
      "Episode 5951, len10, loss:-83.8891, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5464940071105957 sec\n",
      "Episode 5952, len6, loss:-55.2766, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5488533973693848 sec\n",
      "Episode 5953, len8, loss:-76.2979, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5483031272888184 sec\n",
      "Episode 5954, len12, loss:-91.4238, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5485954284667969 sec\n",
      "Episode 5955, len8, loss:-76.8061, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5481781959533691 sec\n",
      "Episode 5956, len12, loss:-94.6645, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5480649471282959 sec\n",
      "Episode 5957, len10, loss:-83.2914, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5484066009521484 sec\n",
      "Episode 5958, len10, loss:-83.2718, fail, steps:80, opt steps:40, total reward:-24.0000, 0.6056332588195801 sec\n",
      "Episode 5959, len12, loss:-88.7631, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5488755702972412 sec\n",
      "Episode 5960, len12, loss:-86.5045, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5546424388885498 sec\n",
      "Episode 5961, len10, loss:-87.0465, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5530776977539062 sec\n",
      "Episode 5962, len8, loss:-71.3224, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5503058433532715 sec\n",
      "Episode 5963, len12, loss:-100.9919, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5489952564239502 sec\n",
      "Episode 5964, len6, loss:-55.1461, fail, steps:80, opt steps:6, total reward:-24.0000, 0.549222469329834 sec\n",
      "Episode 5965, len12, loss:-92.1856, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5510940551757812 sec\n",
      "Episode 5966, len10, loss:-95.0198, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5462205410003662 sec\n",
      "Episode 5967, len6, loss:-59.8116, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5490643978118896 sec\n",
      "Episode 5968, len8, loss:-72.8424, fail, steps:80, opt steps:23, total reward:-24.0000, 0.549522876739502 sec\n",
      "Episode 5969, len8, loss:-70.6102, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5492823123931885 sec\n",
      "Episode 5970, len8, loss:-73.1103, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5496997833251953 sec\n",
      "Episode 5971, len8, loss:-78.5908, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5452601909637451 sec\n",
      "Episode 5972, len6, loss:-55.4236, fail, steps:80, opt steps:7, total reward:-24.0000, 0.599973201751709 sec\n",
      "Episode 5973, len12, loss:-100.2944, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5501863956451416 sec\n",
      "Episode 5974, len8, loss:-72.4492, fail, steps:80, opt steps:21, total reward:-24.0000, 0.549717903137207 sec\n",
      "Episode 5975, len6, loss:-58.6844, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5488684177398682 sec\n",
      "Episode 5976, len10, loss:-84.8324, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5499739646911621 sec\n",
      "Episode 5977, len6, loss:-56.7903, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5490920543670654 sec\n",
      "Episode 5978, len10, loss:-85.2720, fail, steps:80, opt steps:46, total reward:-24.0000, 0.551142692565918 sec\n",
      "Episode 5979, len8, loss:-77.4119, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5491471290588379 sec\n",
      "Episode 5980, len12, loss:-97.9069, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5497846603393555 sec\n",
      "Episode 5981, len6, loss:-60.4633, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5489087104797363 sec\n",
      "Episode 5982, len10, loss:-84.0203, fail, steps:80, opt steps:44, total reward:-24.0000, 0.549919843673706 sec\n",
      "Episode 5983, len8, loss:-73.0347, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5500087738037109 sec\n",
      "Episode 5984, len10, loss:-89.0753, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5502290725708008 sec\n",
      "Episode 5985, len6, loss:-53.9620, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5499663352966309 sec\n",
      "Episode 5986, len8, loss:-76.2766, fail, steps:80, opt steps:25, total reward:-24.0000, 0.6020886898040771 sec\n",
      "Episode 5987, len10, loss:-87.2482, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5520610809326172 sec\n",
      "Episode 5988, len10, loss:-90.6010, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5486619472503662 sec\n",
      "Episode 5989, len12, loss:-93.3899, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5493314266204834 sec\n",
      "Episode 5990, len6, loss:-56.8647, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5484728813171387 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5991, len12, loss:-97.1903, fail, steps:80, opt steps:43, total reward:-24.7000, 0.5437331199645996 sec\n",
      "Episode 5992, len10, loss:-87.6553, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5489962100982666 sec\n",
      "Episode 5993, len6, loss:-68.4833, fail, steps:80, opt steps:10, total reward:-24.7000, 0.5434894561767578 sec\n",
      "Episode 5994, len12, loss:-96.7206, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5473787784576416 sec\n",
      "Episode 5995, len8, loss:-73.1603, fail, steps:80, opt steps:15, total reward:-24.0000, 0.547987699508667 sec\n",
      "Episode 5996, len8, loss:-75.3158, fail, steps:80, opt steps:21, total reward:-24.7000, 0.5448172092437744 sec\n",
      "Episode 5997, len6, loss:-59.5525, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5489115715026855 sec\n",
      "Episode 5998, len12, loss:-98.9269, fail, steps:80, opt steps:61, total reward:-24.0000, 0.550189733505249 sec\n",
      "Episode 5999, len6, loss:-60.8179, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5486118793487549 sec\n",
      "Episode 6000, len8, loss:-72.7828, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5978744029998779 sec\n",
      "Checkpoint saved at episode 6000 to /home/mcwave/code/autocode/datasets/rl_sort_transformer_easy/list6_12_transformer3_128_gamma07_step80_v3_merge_2_sorted/ckpt_6000_0.0000_26.24_vs_5.25.pth\n",
      "Learning rate = 0.000089\n",
      "Episode 6001, len10, loss:-89.1477, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5425331592559814 sec\n",
      "Episode 6002, len8, loss:-75.2284, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5537896156311035 sec\n",
      "Episode 6003, len8, loss:-71.4761, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5495328903198242 sec\n",
      "Episode 6004, len10, loss:-86.7851, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5484938621520996 sec\n",
      "Episode 6005, len8, loss:-74.3500, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5488765239715576 sec\n",
      "Episode 6006, len10, loss:-87.0483, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5494704246520996 sec\n",
      "Episode 6007, len6, loss:-65.5263, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5495593547821045 sec\n",
      "Episode 6008, len6, loss:-52.9158, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5484890937805176 sec\n",
      "Episode 6009, len6, loss:-55.0348, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5489733219146729 sec\n",
      "Episode 6010, len10, loss:-91.0455, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5494823455810547 sec\n",
      "Episode 6011, len8, loss:-81.7505, fail, steps:80, opt steps:28, total reward:-24.0000, 0.549030065536499 sec\n",
      "Episode 6012, len8, loss:-69.0475, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5515592098236084 sec\n",
      "Episode 6013, len10, loss:-88.1105, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5494861602783203 sec\n",
      "Episode 6014, len8, loss:-81.5855, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5494015216827393 sec\n",
      "Episode 6015, len6, loss:-58.2728, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5492134094238281 sec\n",
      "Episode 6016, len6, loss:-56.0453, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5987186431884766 sec\n",
      "Episode 6017, len8, loss:-73.9525, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5503919124603271 sec\n",
      "Episode 6018, len8, loss:-75.1982, fail, steps:80, opt steps:25, total reward:-24.0000, 0.549513578414917 sec\n",
      "Episode 6019, len8, loss:-75.0227, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5503404140472412 sec\n",
      "Episode 6020, len8, loss:-80.5360, fail, steps:80, opt steps:24, total reward:-24.0000, 0.550412654876709 sec\n",
      "Episode 6021, len8, loss:-74.2046, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5495903491973877 sec\n",
      "Episode 6022, len12, loss:-99.4754, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5495400428771973 sec\n",
      "Episode 6023, len6, loss:-64.5767, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5489850044250488 sec\n",
      "Episode 6024, len12, loss:-102.6650, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5511326789855957 sec\n",
      "Episode 6025, len12, loss:-106.4531, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5491182804107666 sec\n",
      "Episode 6026, len8, loss:-86.4310, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5478832721710205 sec\n",
      "Episode 6027, len6, loss:-58.2254, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5495560169219971 sec\n",
      "Episode 6028, len6, loss:-59.3940, fail, steps:80, opt steps:13, total reward:-24.0000, 0.547910213470459 sec\n",
      "Episode 6029, len8, loss:-75.4247, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5474514961242676 sec\n",
      "Episode 6030, len10, loss:-88.3404, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5482265949249268 sec\n",
      "Episode 6031, len6, loss:-62.7289, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5480983257293701 sec\n",
      "Episode 6032, len6, loss:-68.0215, fail, steps:80, opt steps:21, total reward:-24.0000, 0.6034114360809326 sec\n",
      "Episode 6033, len10, loss:-86.5183, fail, steps:80, opt steps:23, total reward:-24.0000, 0.548781156539917 sec\n",
      "Episode 6034, len6, loss:-62.8528, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5476510524749756 sec\n",
      "Episode 6035, len10, loss:-86.4029, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5484538078308105 sec\n",
      "Episode 6036, len10, loss:-96.2839, fail, steps:80, opt steps:22, total reward:-24.0000, 0.550478458404541 sec\n",
      "Episode 6037, len6, loss:-66.1037, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5474536418914795 sec\n",
      "Episode 6038, len6, loss:-59.5588, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5477581024169922 sec\n",
      "Episode 6039, len10, loss:-95.1567, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5474212169647217 sec\n",
      "Episode 6040, len10, loss:-90.5823, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5484359264373779 sec\n",
      "Episode 6041, len10, loss:-86.6474, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5475664138793945 sec\n",
      "Episode 6042, len12, loss:-97.4668, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5481433868408203 sec\n",
      "Episode 6043, len12, loss:-100.0607, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5488152503967285 sec\n",
      "Episode 6044, len12, loss:-99.4046, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5491323471069336 sec\n",
      "Episode 6045, len10, loss:-87.6961, fail, steps:80, opt steps:44, total reward:-24.0000, 0.6020898818969727 sec\n",
      "Episode 6046, len6, loss:-62.6171, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5494711399078369 sec\n",
      "Episode 6047, len12, loss:-101.6194, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5492784976959229 sec\n",
      "Episode 6048, len6, loss:-61.1763, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5476930141448975 sec\n",
      "Episode 6049, len12, loss:-101.8476, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5483415126800537 sec\n",
      "Episode 6050, len8, loss:-75.9508, fail, steps:80, opt steps:34, total reward:-24.0000, 0.548201322555542 sec\n",
      "Episode 6051, len12, loss:-96.6519, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5492336750030518 sec\n",
      "Episode 6052, len6, loss:-64.3898, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5484445095062256 sec\n",
      "Episode 6053, len12, loss:-83.8609, fail, steps:80, opt steps:55, total reward:-24.0000, 0.548682451248169 sec\n",
      "Episode 6054, len12, loss:-91.1989, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5492374897003174 sec\n",
      "Episode 6055, len8, loss:-81.2649, fail, steps:80, opt steps:18, total reward:-24.0000, 0.548776388168335 sec\n",
      "Episode 6056, len10, loss:-83.8758, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5476138591766357 sec\n",
      "Episode 6057, len12, loss:-101.0639, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5474128723144531 sec\n",
      "Episode 6058, len6, loss:-58.5091, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5476834774017334 sec\n",
      "Episode 6059, len8, loss:-72.9857, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5998144149780273 sec\n",
      "Episode 6060, len12, loss:-97.0600, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5489578247070312 sec\n",
      "Episode 6061, len12, loss:-98.9931, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5494935512542725 sec\n",
      "Episode 6062, len6, loss:-57.4817, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5473709106445312 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6063, len12, loss:-97.3188, fail, steps:80, opt steps:49, total reward:-24.0000, 0.548525333404541 sec\n",
      "Episode 6064, len12, loss:-107.2305, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5485572814941406 sec\n",
      "Episode 6065, len8, loss:-80.9537, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5502352714538574 sec\n",
      "Episode 6066, len12, loss:-93.7639, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5495100021362305 sec\n",
      "Episode 6067, len12, loss:-95.0812, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5494730472564697 sec\n",
      "Episode 6068, len6, loss:-60.5597, fail, steps:80, opt steps:14, total reward:-24.0000, 0.548342227935791 sec\n",
      "Episode 6069, len6, loss:-60.0199, fail, steps:80, opt steps:13, total reward:-22.7000, 0.5428576469421387 sec\n",
      "Episode 6070, len6, loss:-60.4934, fail, steps:80, opt steps:19, total reward:-24.0000, 0.548130989074707 sec\n",
      "Episode 6071, len10, loss:-83.9952, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5484066009521484 sec\n",
      "Episode 6072, len12, loss:-92.4971, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5491137504577637 sec\n",
      "Episode 6073, len10, loss:-90.6528, fail, steps:80, opt steps:35, total reward:-24.0000, 0.6046640872955322 sec\n",
      "Episode 6074, len10, loss:-82.5739, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5494823455810547 sec\n",
      "Episode 6075, len8, loss:-76.1249, fail, steps:80, opt steps:12, total reward:-24.0000, 0.549323320388794 sec\n",
      "Episode 6076, len10, loss:-85.5086, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5486459732055664 sec\n",
      "Episode 6077, len12, loss:-97.3764, fail, steps:80, opt steps:44, total reward:-24.0000, 0.549649715423584 sec\n",
      "Episode 6078, len10, loss:-84.2569, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5490462779998779 sec\n",
      "Episode 6079, len6, loss:-62.6514, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5504450798034668 sec\n",
      "Episode 6080, len12, loss:-95.9075, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5487456321716309 sec\n",
      "Episode 6081, len10, loss:-91.7415, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5480971336364746 sec\n",
      "Episode 6082, len6, loss:-63.8376, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5480380058288574 sec\n",
      "Episode 6083, len12, loss:-92.2293, fail, steps:80, opt steps:50, total reward:-23.7000, 0.5459835529327393 sec\n",
      "Episode 6084, len10, loss:-91.9783, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5442249774932861 sec\n",
      "Episode 6085, len8, loss:-69.7432, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5466833114624023 sec\n",
      "Episode 6086, len12, loss:-95.7062, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5483763217926025 sec\n",
      "Episode 6087, len6, loss:-63.7536, fail, steps:80, opt steps:16, total reward:-24.0000, 0.599560022354126 sec\n",
      "Episode 6088, len10, loss:-93.1443, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5479714870452881 sec\n",
      "Episode 6089, len6, loss:-61.3312, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5481927394866943 sec\n",
      "Episode 6090, len6, loss:-62.9839, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5480325222015381 sec\n",
      "Episode 6091, len12, loss:-97.5567, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5481851100921631 sec\n",
      "Episode 6092, len10, loss:-87.8704, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5497000217437744 sec\n",
      "Episode 6093, len8, loss:-75.8985, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5490672588348389 sec\n",
      "Episode 6094, len6, loss:-65.5142, fail, steps:80, opt steps:12, total reward:-24.0000, 0.547990083694458 sec\n",
      "Episode 6095, len8, loss:-72.1861, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5480942726135254 sec\n",
      "Episode 6096, len12, loss:-102.9093, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5481884479522705 sec\n",
      "Episode 6097, len12, loss:-96.9970, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5499856472015381 sec\n",
      "Episode 6098, len10, loss:-83.7008, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5480747222900391 sec\n",
      "Episode 6099, len8, loss:-81.6276, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5477471351623535 sec\n",
      "Episode 6100, len12, loss:-94.1689, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5486009120941162 sec\n",
      "Episode 6101, len8, loss:-73.6606, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5999851226806641 sec\n",
      "Episode 6102, len6, loss:-65.4562, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5485150814056396 sec\n",
      "Episode 6103, len12, loss:-96.7252, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5485732555389404 sec\n",
      "Episode 6104, len10, loss:-86.9440, fail, steps:80, opt steps:39, total reward:-24.0000, 0.547776460647583 sec\n",
      "Episode 6105, len10, loss:-83.9913, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5492715835571289 sec\n",
      "Episode 6106, len12, loss:-93.4379, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5482585430145264 sec\n",
      "Episode 6107, len6, loss:-61.1958, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5471556186676025 sec\n",
      "Episode 6108, len6, loss:-63.2843, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5491080284118652 sec\n",
      "Episode 6109, len8, loss:-77.4554, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5476531982421875 sec\n",
      "Episode 6110, len10, loss:-89.7699, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5498969554901123 sec\n",
      "Episode 6111, len6, loss:-59.4399, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5487518310546875 sec\n",
      "Episode 6112, len8, loss:-83.0262, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5483312606811523 sec\n",
      "Episode 6113, len8, loss:-78.0369, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5486023426055908 sec\n",
      "Episode 6114, len6, loss:-63.4919, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5473568439483643 sec\n",
      "Episode 6115, len6, loss:-65.0575, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5479686260223389 sec\n",
      "Episode 6116, len12, loss:-98.2583, fail, steps:80, opt steps:64, total reward:-24.0000, 0.6026036739349365 sec\n",
      "Episode 6117, len8, loss:-84.1324, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5469827651977539 sec\n",
      "Episode 6118, len10, loss:-92.3191, fail, steps:80, opt steps:43, total reward:-24.7000, 0.5425755977630615 sec\n",
      "Episode 6119, len6, loss:-62.5726, fail, steps:80, opt steps:20, total reward:-24.0000, 0.547203779220581 sec\n",
      "Episode 6120, len6, loss:-57.3125, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5462205410003662 sec\n",
      "Episode 6121, len10, loss:-83.9624, fail, steps:80, opt steps:27, total reward:-24.0000, 0.548290491104126 sec\n",
      "Episode 6122, len6, loss:-60.8726, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5472671985626221 sec\n",
      "Episode 6123, len10, loss:-85.5089, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5497267246246338 sec\n",
      "Episode 6124, len12, loss:-89.9928, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5471782684326172 sec\n",
      "Episode 6125, len8, loss:-75.5118, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5485866069793701 sec\n",
      "Episode 6126, len6, loss:-58.5606, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5483255386352539 sec\n",
      "Episode 6127, len6, loss:-66.1585, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5478212833404541 sec\n",
      "Episode 6128, len10, loss:-80.6094, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5480856895446777 sec\n",
      "Episode 6129, len10, loss:-80.5042, fail, steps:80, opt steps:37, total reward:-24.0000, 0.546947717666626 sec\n",
      "Episode 6130, len12, loss:-95.3481, fail, steps:80, opt steps:62, total reward:-24.0000, 0.548781156539917 sec\n",
      "Episode 6131, len6, loss:-58.7198, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5473177433013916 sec\n",
      "Episode 6132, len6, loss:-64.2109, fail, steps:80, opt steps:21, total reward:-24.0000, 0.6007637977600098 sec\n",
      "Episode 6133, len8, loss:-79.0719, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5420219898223877 sec\n",
      "Episode 6134, len12, loss:-94.5433, fail, steps:80, opt steps:71, total reward:-24.7000, 0.5415980815887451 sec\n",
      "Episode 6135, len10, loss:-83.7382, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5470387935638428 sec\n",
      "Episode 6136, len12, loss:-97.5796, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5480248928070068 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6137, len12, loss:-92.3404, fail, steps:80, opt steps:37, total reward:-24.0000, 0.548703670501709 sec\n",
      "Episode 6138, len6, loss:-58.6475, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5482821464538574 sec\n",
      "Episode 6139, len6, loss:-56.5775, fail, steps:80, opt steps:7, total reward:-24.0000, 0.548086404800415 sec\n",
      "Episode 6140, len8, loss:-74.5014, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5489964485168457 sec\n",
      "Episode 6141, len12, loss:-105.1937, fail, steps:80, opt steps:54, total reward:-24.7000, 0.5446810722351074 sec\n",
      "Episode 6142, len8, loss:-76.3500, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5480449199676514 sec\n",
      "Episode 6143, len12, loss:-98.0411, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5478203296661377 sec\n",
      "Episode 6144, len10, loss:-88.7530, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5475196838378906 sec\n",
      "Episode 6145, len10, loss:-88.5935, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5474517345428467 sec\n",
      "Episode 6146, len8, loss:-76.6597, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5469739437103271 sec\n",
      "Episode 6147, len8, loss:-75.3480, fail, steps:80, opt steps:19, total reward:-24.0000, 0.547982931137085 sec\n",
      "Episode 6148, len6, loss:-57.8914, fail, steps:80, opt steps:13, total reward:-24.0000, 0.6018908023834229 sec\n",
      "Episode 6149, len8, loss:-72.3943, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5466454029083252 sec\n",
      "Episode 6150, len8, loss:-71.8502, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5465316772460938 sec\n",
      "Episode 6151, len6, loss:-59.2994, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5480117797851562 sec\n",
      "Episode 6152, len6, loss:-58.7709, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5495169162750244 sec\n",
      "Episode 6153, len6, loss:-63.2759, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5474159717559814 sec\n",
      "Episode 6154, len6, loss:-62.7410, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5478382110595703 sec\n",
      "Episode 6155, len6, loss:-62.7719, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5486304759979248 sec\n",
      "Episode 6156, len10, loss:-97.4732, fail, steps:80, opt steps:35, total reward:-24.7000, 0.5438408851623535 sec\n",
      "Episode 6157, len6, loss:-66.0729, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5422515869140625 sec\n",
      "Episode 6158, len6, loss:-61.3853, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5473239421844482 sec\n",
      "Episode 6159, len10, loss:-91.4648, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5468704700469971 sec\n",
      "Episode 6160, len8, loss:-74.9356, fail, steps:80, opt steps:26, total reward:-24.0000, 0.547691822052002 sec\n",
      "Episode 6161, len12, loss:-97.0313, fail, steps:80, opt steps:78, total reward:-24.0000, 0.6079399585723877 sec\n",
      "Episode 6162, len6, loss:-62.1882, fail, steps:80, opt steps:6, total reward:-24.0000, 0.548079252243042 sec\n",
      "Episode 6163, len8, loss:-76.0300, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5472493171691895 sec\n",
      "Episode 6164, len12, loss:-96.3734, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5481016635894775 sec\n",
      "Episode 6165, len10, loss:-83.3195, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5475537776947021 sec\n",
      "Episode 6166, len6, loss:-70.1574, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5443620681762695 sec\n",
      "Episode 6167, len12, loss:-98.8750, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5472214221954346 sec\n",
      "Episode 6168, len6, loss:-62.8263, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5468668937683105 sec\n",
      "Episode 6169, len6, loss:-65.3212, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5435078144073486 sec\n",
      "Episode 6170, len6, loss:-56.6970, fail, steps:80, opt steps:7, total reward:-22.7000, 0.541701078414917 sec\n",
      "Episode 6171, len6, loss:-60.6829, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5467665195465088 sec\n",
      "Episode 6172, len8, loss:-80.8084, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5470538139343262 sec\n",
      "Episode 6173, len8, loss:-78.2736, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5472195148468018 sec\n",
      "Episode 6174, len8, loss:-81.6515, fail, steps:80, opt steps:15, total reward:-24.0000, 0.54886794090271 sec\n",
      "Episode 6175, len12, loss:-100.3854, fail, steps:80, opt steps:56, total reward:-24.0000, 0.6065254211425781 sec\n",
      "Episode 6176, len10, loss:-87.0761, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5436058044433594 sec\n",
      "Episode 6177, len8, loss:-77.2232, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5479555130004883 sec\n",
      "Episode 6178, len12, loss:-94.9005, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5467970371246338 sec\n",
      "Episode 6179, len12, loss:-103.0294, fail, steps:80, opt steps:41, total reward:-24.0000, 0.548159122467041 sec\n",
      "Episode 6180, len12, loss:-96.7357, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5485262870788574 sec\n",
      "Episode 6181, len10, loss:-87.0353, fail, steps:80, opt steps:23, total reward:-24.0000, 0.548508882522583 sec\n",
      "Episode 6182, len12, loss:-96.6998, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5486977100372314 sec\n",
      "Episode 6183, len12, loss:-95.6059, fail, steps:80, opt steps:62, total reward:-24.0000, 0.547710657119751 sec\n",
      "Episode 6184, len12, loss:-99.9680, fail, steps:80, opt steps:52, total reward:-24.0000, 0.548640251159668 sec\n",
      "Episode 6185, len10, loss:-83.1892, fail, steps:80, opt steps:25, total reward:-24.0000, 0.546396017074585 sec\n",
      "Episode 6186, len8, loss:-74.7081, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5484354496002197 sec\n",
      "Episode 6187, len12, loss:-106.1330, fail, steps:80, opt steps:53, total reward:-24.0000, 0.547762393951416 sec\n",
      "Episode 6188, len8, loss:-67.9061, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5477509498596191 sec\n",
      "Episode 6189, len12, loss:-91.3185, fail, steps:80, opt steps:43, total reward:-24.0000, 0.6068253517150879 sec\n",
      "Episode 6190, len10, loss:-89.1330, fail, steps:80, opt steps:33, total reward:-24.0000, 0.547846794128418 sec\n",
      "Episode 6191, len8, loss:-73.5513, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5483627319335938 sec\n",
      "Episode 6192, len8, loss:-70.2840, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5477578639984131 sec\n",
      "Episode 6193, len12, loss:-96.4003, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5477757453918457 sec\n",
      "Episode 6194, len12, loss:-100.8163, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5493214130401611 sec\n",
      "Episode 6195, len12, loss:-94.1949, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5481753349304199 sec\n",
      "Episode 6196, len10, loss:-88.5641, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5478522777557373 sec\n",
      "Episode 6197, len12, loss:-97.7668, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5485966205596924 sec\n",
      "Episode 6198, len10, loss:-88.2347, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5478713512420654 sec\n",
      "Episode 6199, len6, loss:-63.3557, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5465741157531738 sec\n",
      "Episode 6200, len8, loss:-75.1232, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5436217784881592 sec\n",
      "Episode 6201, len6, loss:-57.5148, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5480659008026123 sec\n",
      "Episode 6202, len10, loss:-87.0947, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5485234260559082 sec\n",
      "Episode 6203, len12, loss:-102.2435, fail, steps:80, opt steps:39, total reward:-24.0000, 0.6021826267242432 sec\n",
      "Episode 6204, len8, loss:-80.4277, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5476729869842529 sec\n",
      "Episode 6205, len8, loss:-74.6230, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5480971336364746 sec\n",
      "Episode 6206, len12, loss:-99.8646, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5487263202667236 sec\n",
      "Episode 6207, len12, loss:-96.7229, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5486793518066406 sec\n",
      "Episode 6208, len12, loss:-94.6358, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5487070083618164 sec\n",
      "Episode 6209, len12, loss:-91.4705, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5491039752960205 sec\n",
      "Episode 6210, len8, loss:-76.8867, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5480606555938721 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6211, len12, loss:-109.1784, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5477662086486816 sec\n",
      "Episode 6212, len8, loss:-77.3183, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5491213798522949 sec\n",
      "Episode 6213, len6, loss:-67.4408, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5441696643829346 sec\n",
      "Episode 6214, len8, loss:-75.5262, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5470595359802246 sec\n",
      "Episode 6215, len10, loss:-91.2979, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5469348430633545 sec\n",
      "Episode 6216, len8, loss:-76.8064, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5473909378051758 sec\n",
      "Episode 6217, len8, loss:-79.3553, fail, steps:80, opt steps:25, total reward:-24.0000, 0.6015923023223877 sec\n",
      "Episode 6218, len8, loss:-78.5073, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5479879379272461 sec\n",
      "Episode 6219, len10, loss:-92.0429, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5518066883087158 sec\n",
      "Episode 6220, len12, loss:-97.7917, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5505366325378418 sec\n",
      "Episode 6221, len6, loss:-66.0977, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5474321842193604 sec\n",
      "Episode 6222, len10, loss:-88.5240, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5470819473266602 sec\n",
      "Episode 6223, len6, loss:-62.6869, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5464210510253906 sec\n",
      "Episode 6224, len10, loss:-92.7198, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5474586486816406 sec\n",
      "Episode 6225, len12, loss:-101.0146, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5478284358978271 sec\n",
      "Episode 6226, len6, loss:-59.2877, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5479652881622314 sec\n",
      "Episode 6227, len10, loss:-88.3067, fail, steps:80, opt steps:35, total reward:-24.7000, 0.5443568229675293 sec\n",
      "Episode 6228, len12, loss:-98.0352, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5477654933929443 sec\n",
      "Episode 6229, len8, loss:-75.7429, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5475068092346191 sec\n",
      "Episode 6230, len12, loss:-105.6507, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5482115745544434 sec\n",
      "Episode 6231, len12, loss:-104.2124, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5498015880584717 sec\n",
      "Episode 6232, len8, loss:-78.2320, fail, steps:80, opt steps:9, total reward:-24.0000, 0.6011645793914795 sec\n",
      "Episode 6233, len12, loss:-101.7396, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5475623607635498 sec\n",
      "Episode 6234, len8, loss:-74.1030, fail, steps:80, opt steps:20, total reward:-24.0000, 0.547417402267456 sec\n",
      "Episode 6235, len10, loss:-84.3708, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5480945110321045 sec\n",
      "Episode 6236, len12, loss:-94.8222, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5482504367828369 sec\n",
      "Episode 6237, len8, loss:-81.1300, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5475099086761475 sec\n",
      "Episode 6238, len10, loss:-88.6438, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5486009120941162 sec\n",
      "Episode 6239, len6, loss:-64.8392, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5484471321105957 sec\n",
      "Episode 6240, len8, loss:-77.7180, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5476686954498291 sec\n",
      "Episode 6241, len10, loss:-90.7441, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5488290786743164 sec\n",
      "Episode 6242, len10, loss:-88.2896, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5492913722991943 sec\n",
      "Episode 6243, len12, loss:-94.8099, fail, steps:80, opt steps:56, total reward:-24.0000, 0.547356367111206 sec\n",
      "Episode 6244, len6, loss:-62.6868, fail, steps:80, opt steps:19, total reward:-24.0000, 0.548194169998169 sec\n",
      "Episode 6245, len6, loss:-61.9212, fail, steps:80, opt steps:18, total reward:-24.0000, 0.549443244934082 sec\n",
      "Episode 6246, len6, loss:-68.2247, fail, steps:80, opt steps:13, total reward:-24.7000, 0.543938398361206 sec\n",
      "Episode 6247, len8, loss:-74.5727, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5472981929779053 sec\n",
      "Episode 6248, len10, loss:-90.9351, fail, steps:80, opt steps:45, total reward:-24.0000, 0.6019241809844971 sec\n",
      "Episode 6249, len8, loss:-75.8642, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5499002933502197 sec\n",
      "Episode 6250, len10, loss:-91.8782, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5470106601715088 sec\n",
      "Episode 6251, len6, loss:-59.2617, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5469410419464111 sec\n",
      "Episode 6252, len6, loss:-67.4911, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5477557182312012 sec\n",
      "Episode 6253, len8, loss:-77.5504, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5485484600067139 sec\n",
      "Episode 6254, len12, loss:-96.3883, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5492777824401855 sec\n",
      "Episode 6255, len8, loss:-76.8208, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5479514598846436 sec\n",
      "Episode 6256, len8, loss:-72.6706, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5472521781921387 sec\n",
      "Episode 6257, len8, loss:-69.5930, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5471179485321045 sec\n",
      "Episode 6258, len8, loss:-73.6748, fail, steps:80, opt steps:21, total reward:-24.0000, 0.547450065612793 sec\n",
      "Episode 6259, len8, loss:-73.6848, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5478048324584961 sec\n",
      "Episode 6260, len8, loss:-76.8183, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5479791164398193 sec\n",
      "Episode 6261, len10, loss:-88.6092, fail, steps:80, opt steps:40, total reward:-24.0000, 0.549567461013794 sec\n",
      "Episode 6262, len6, loss:-63.0198, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5479962825775146 sec\n",
      "Episode 6263, len10, loss:-81.4381, fail, steps:80, opt steps:17, total reward:-24.0000, 0.548708438873291 sec\n",
      "Episode 6264, len12, loss:-103.8390, fail, steps:80, opt steps:73, total reward:-24.0000, 0.600630521774292 sec\n",
      "Episode 6265, len12, loss:-93.4352, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5480904579162598 sec\n",
      "Episode 6266, len6, loss:-65.1170, fail, steps:80, opt steps:13, total reward:-24.0000, 0.547677755355835 sec\n",
      "Episode 6267, len12, loss:-102.2503, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5485439300537109 sec\n",
      "Episode 6268, len12, loss:-102.5146, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5506973266601562 sec\n",
      "Episode 6269, len8, loss:-73.8446, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5486423969268799 sec\n",
      "Episode 6270, len6, loss:-56.1646, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5491602420806885 sec\n",
      "Episode 6271, len8, loss:-70.6209, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5480153560638428 sec\n",
      "Episode 6272, len10, loss:-82.2252, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5495524406433105 sec\n",
      "Episode 6273, len10, loss:-87.9501, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5474634170532227 sec\n",
      "Episode 6274, len6, loss:-62.4239, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5479111671447754 sec\n",
      "Episode 6275, len10, loss:-95.2338, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5486783981323242 sec\n",
      "Episode 6276, len12, loss:-101.2633, fail, steps:80, opt steps:44, total reward:-24.0000, 0.548661470413208 sec\n",
      "Episode 6277, len12, loss:-100.7178, fail, steps:80, opt steps:41, total reward:-24.0000, 0.6022121906280518 sec\n",
      "Episode 6278, len10, loss:-91.4343, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5487914085388184 sec\n",
      "Episode 6279, len6, loss:-61.4380, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5491869449615479 sec\n",
      "Episode 6280, len10, loss:-84.9756, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5484828948974609 sec\n",
      "Episode 6281, len8, loss:-68.9471, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5485694408416748 sec\n",
      "Episode 6282, len8, loss:-68.7652, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5509700775146484 sec\n",
      "Episode 6283, len10, loss:-84.0840, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5488021373748779 sec\n",
      "Episode 6284, len12, loss:-95.3934, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5481963157653809 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6285, len12, loss:-97.7281, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5483050346374512 sec\n",
      "Episode 6286, len12, loss:-93.8421, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5497386455535889 sec\n",
      "Episode 6287, len10, loss:-84.8866, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5489082336425781 sec\n",
      "Episode 6288, len12, loss:-98.5759, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5498590469360352 sec\n",
      "Episode 6289, len8, loss:-71.9154, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5490574836730957 sec\n",
      "Episode 6290, len8, loss:-72.8827, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5491650104522705 sec\n",
      "Episode 6291, len8, loss:-73.2030, fail, steps:80, opt steps:29, total reward:-24.0000, 0.6026902198791504 sec\n",
      "Episode 6292, len10, loss:-90.0536, fail, steps:80, opt steps:49, total reward:-23.7000, 0.5453548431396484 sec\n",
      "Episode 6293, len10, loss:-81.4281, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5480353832244873 sec\n",
      "Episode 6294, len10, loss:-87.4359, fail, steps:80, opt steps:10, total reward:-24.0000, 0.548133134841919 sec\n",
      "Episode 6295, len8, loss:-70.2475, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5502221584320068 sec\n",
      "Episode 6296, len6, loss:-62.3716, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5489370822906494 sec\n",
      "Episode 6297, len6, loss:-65.1566, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485892295837402 sec\n",
      "Episode 6298, len6, loss:-63.1804, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5474352836608887 sec\n",
      "Episode 6299, len12, loss:-95.9861, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5484175682067871 sec\n",
      "Episode 6300, len12, loss:-94.8458, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5484652519226074 sec\n",
      "Episode 6301, len8, loss:-74.0960, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5488283634185791 sec\n",
      "Episode 6302, len12, loss:-96.3245, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5501384735107422 sec\n",
      "Episode 6303, len8, loss:-79.7879, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5494387149810791 sec\n",
      "Episode 6304, len6, loss:-59.8023, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5499138832092285 sec\n",
      "Episode 6305, len6, loss:-58.3765, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5987448692321777 sec\n",
      "Episode 6306, len8, loss:-79.7193, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5493347644805908 sec\n",
      "Episode 6307, len10, loss:-86.8215, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5489518642425537 sec\n",
      "Episode 6308, len12, loss:-97.3149, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5496158599853516 sec\n",
      "Episode 6309, len12, loss:-95.2574, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5497641563415527 sec\n",
      "Episode 6310, len10, loss:-100.4554, fail, steps:80, opt steps:26, total reward:-24.7000, 0.545943021774292 sec\n",
      "Episode 6311, len10, loss:-90.1439, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5475022792816162 sec\n",
      "Episode 6312, len10, loss:-80.0964, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5485584735870361 sec\n",
      "Episode 6313, len6, loss:-61.3196, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5483238697052002 sec\n",
      "Episode 6314, len8, loss:-70.1043, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5476095676422119 sec\n",
      "Episode 6315, len6, loss:-61.4700, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5485787391662598 sec\n",
      "Episode 6316, len10, loss:-80.1675, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5483520030975342 sec\n",
      "Episode 6317, len6, loss:-66.2893, fail, steps:80, opt steps:6, total reward:-24.0000, 0.549191951751709 sec\n",
      "Episode 6318, len6, loss:-64.9632, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5488743782043457 sec\n",
      "Episode 6319, len12, loss:-109.0107, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5946044921875 sec\n",
      "Episode 6320, len6, loss:-67.3513, fail, steps:80, opt steps:18, total reward:-24.0000, 0.548398494720459 sec\n",
      "Episode 6321, len10, loss:-84.5608, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5500423908233643 sec\n",
      "Episode 6322, len8, loss:-73.1307, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5492405891418457 sec\n",
      "Episode 6323, len6, loss:-55.5093, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5512783527374268 sec\n",
      "Episode 6324, len12, loss:-100.3899, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5482032299041748 sec\n",
      "Episode 6325, len6, loss:-63.1963, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5497617721557617 sec\n",
      "Episode 6326, len6, loss:-60.0189, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5492968559265137 sec\n",
      "Episode 6327, len8, loss:-78.1139, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5482378005981445 sec\n",
      "Episode 6328, len8, loss:-71.4391, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5494101047515869 sec\n",
      "Episode 6329, len8, loss:-73.5934, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5527074337005615 sec\n",
      "Episode 6330, len10, loss:-85.6069, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5499272346496582 sec\n",
      "Episode 6331, len8, loss:-75.1963, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5511434078216553 sec\n",
      "Episode 6332, len12, loss:-92.6299, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5511300563812256 sec\n",
      "Episode 6333, len8, loss:-77.6476, fail, steps:80, opt steps:30, total reward:-24.0000, 0.6016652584075928 sec\n",
      "Episode 6334, len10, loss:-89.4233, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5481305122375488 sec\n",
      "Episode 6335, len6, loss:-52.5430, fail, steps:80, opt steps:13, total reward:-22.7000, 0.5435926914215088 sec\n",
      "Episode 6336, len10, loss:-89.4631, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5477511882781982 sec\n",
      "Episode 6337, len8, loss:-71.0442, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5481953620910645 sec\n",
      "Episode 6338, len6, loss:-66.0922, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5475804805755615 sec\n",
      "Episode 6339, len8, loss:-73.5719, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5484781265258789 sec\n",
      "Episode 6340, len8, loss:-70.8755, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5497150421142578 sec\n",
      "Episode 6341, len12, loss:-98.9607, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5483291149139404 sec\n",
      "Episode 6342, len6, loss:-59.6812, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5487415790557861 sec\n",
      "Episode 6343, len8, loss:-76.9562, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5480446815490723 sec\n",
      "Episode 6344, len8, loss:-76.1012, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5489218235015869 sec\n",
      "Episode 6345, len12, loss:-98.1446, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5485353469848633 sec\n",
      "Episode 6346, len8, loss:-74.1416, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5488479137420654 sec\n",
      "Episode 6347, len6, loss:-57.6030, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5479106903076172 sec\n",
      "Episode 6348, len6, loss:-61.1075, fail, steps:80, opt steps:11, total reward:-24.0000, 0.6004500389099121 sec\n",
      "Episode 6349, len12, loss:-95.6209, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5470538139343262 sec\n",
      "Episode 6350, len8, loss:-75.7846, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5475971698760986 sec\n",
      "Episode 6351, len8, loss:-72.2401, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5467326641082764 sec\n",
      "Episode 6352, len8, loss:-72.8094, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5468416213989258 sec\n",
      "Episode 6353, len8, loss:-76.6290, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5459139347076416 sec\n",
      "Episode 6354, len10, loss:-91.5889, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5488135814666748 sec\n",
      "Episode 6355, len10, loss:-89.8864, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5493738651275635 sec\n",
      "Episode 6356, len8, loss:-78.9454, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5460083484649658 sec\n",
      "Episode 6357, len12, loss:-107.4214, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5482993125915527 sec\n",
      "Episode 6358, len8, loss:-76.5387, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5469250679016113 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6359, len6, loss:-66.6489, fail, steps:80, opt steps:8, total reward:-24.7000, 0.5427052974700928 sec\n",
      "Episode 6360, len8, loss:-72.0326, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5465927124023438 sec\n",
      "Episode 6361, len10, loss:-91.7367, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5471997261047363 sec\n",
      "Episode 6362, len12, loss:-96.0673, fail, steps:80, opt steps:52, total reward:-24.0000, 0.548875093460083 sec\n",
      "Episode 6363, len12, loss:-93.6264, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5477099418640137 sec\n",
      "Episode 6364, len8, loss:-72.4775, fail, steps:80, opt steps:23, total reward:-24.0000, 0.6010282039642334 sec\n",
      "Episode 6365, len12, loss:-93.9120, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5467524528503418 sec\n",
      "Episode 6366, len6, loss:-60.5671, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5460426807403564 sec\n",
      "Episode 6367, len6, loss:-60.7122, fail, steps:80, opt steps:11, total reward:-24.0000, 0.546511173248291 sec\n",
      "Episode 6368, len12, loss:-99.3414, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5455811023712158 sec\n",
      "Episode 6369, len10, loss:-91.5340, fail, steps:80, opt steps:44, total reward:-24.0000, 0.548309326171875 sec\n",
      "Episode 6370, len12, loss:-97.9072, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5483286380767822 sec\n",
      "Episode 6371, len8, loss:-70.1344, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5463404655456543 sec\n",
      "Episode 6372, len8, loss:-73.9592, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5472033023834229 sec\n",
      "Episode 6373, len8, loss:-77.9187, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5482180118560791 sec\n",
      "Episode 6374, len8, loss:-74.8144, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5464200973510742 sec\n",
      "Episode 6375, len10, loss:-81.6873, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5471394062042236 sec\n",
      "Episode 6376, len12, loss:-94.6054, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5477778911590576 sec\n",
      "Episode 6377, len6, loss:-59.1543, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5469214916229248 sec\n",
      "Episode 6378, len12, loss:-99.8609, fail, steps:80, opt steps:41, total reward:-24.0000, 0.54720139503479 sec\n",
      "Episode 6379, len10, loss:-92.0707, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5462870597839355 sec\n",
      "Episode 6380, len10, loss:-91.8358, fail, steps:80, opt steps:48, total reward:-24.0000, 0.604015588760376 sec\n",
      "Episode 6381, len12, loss:-95.6807, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5472457408905029 sec\n",
      "Episode 6382, len8, loss:-79.6656, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5470943450927734 sec\n",
      "Episode 6383, len8, loss:-80.2539, fail, steps:80, opt steps:19, total reward:-24.0000, 0.548405647277832 sec\n",
      "Episode 6384, len8, loss:-72.8356, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5479216575622559 sec\n",
      "Episode 6385, len12, loss:-99.4922, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5471398830413818 sec\n",
      "Episode 6386, len8, loss:-81.4861, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5490171909332275 sec\n",
      "Episode 6387, len6, loss:-67.3215, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5433964729309082 sec\n",
      "Episode 6388, len12, loss:-92.1429, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5482079982757568 sec\n",
      "Episode 6389, len8, loss:-79.6689, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5464153289794922 sec\n",
      "Episode 6390, len10, loss:-93.0392, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5476582050323486 sec\n",
      "Episode 6391, len8, loss:-77.0647, fail, steps:80, opt steps:27, total reward:-24.0000, 0.547353982925415 sec\n",
      "Episode 6392, len10, loss:-87.0720, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5475893020629883 sec\n",
      "Episode 6393, len10, loss:-89.3398, fail, steps:80, opt steps:47, total reward:-24.0000, 0.6009488105773926 sec\n",
      "Episode 6394, len10, loss:-91.5465, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5482628345489502 sec\n",
      "Episode 6395, len6, loss:-59.3536, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5477635860443115 sec\n",
      "Episode 6396, len12, loss:-95.7740, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5473661422729492 sec\n",
      "Episode 6397, len12, loss:-96.3566, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5485048294067383 sec\n",
      "Episode 6398, len8, loss:-78.7337, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5469081401824951 sec\n",
      "Episode 6399, len8, loss:-80.5718, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5477063655853271 sec\n",
      "Episode 6400, len12, loss:-100.0300, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5484609603881836 sec\n",
      "Episode 6401, len10, loss:-90.4901, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5482838153839111 sec\n",
      "Episode 6402, len6, loss:-67.5246, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5475928783416748 sec\n",
      "Episode 6403, len6, loss:-63.2963, fail, steps:80, opt steps:20, total reward:-24.0000, 0.545914888381958 sec\n",
      "Episode 6404, len8, loss:-72.9237, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5471506118774414 sec\n",
      "Episode 6405, len8, loss:-76.5557, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5476558208465576 sec\n",
      "Episode 6406, len6, loss:-60.5657, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5487806797027588 sec\n",
      "Episode 6407, len10, loss:-92.5887, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5995535850524902 sec\n",
      "Episode 6408, len12, loss:-116.2964, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5469791889190674 sec\n",
      "Episode 6409, len10, loss:-93.7903, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5432400703430176 sec\n",
      "Episode 6410, len12, loss:-106.7359, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5470118522644043 sec\n",
      "Episode 6411, len6, loss:-64.5963, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5473992824554443 sec\n",
      "Episode 6412, len6, loss:-70.0875, fail, steps:80, opt steps:14, total reward:-24.7000, 0.544276237487793 sec\n",
      "Episode 6413, len12, loss:-91.4222, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5478775501251221 sec\n",
      "Episode 6414, len12, loss:-103.8634, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5470898151397705 sec\n",
      "Episode 6415, len10, loss:-89.0954, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5477113723754883 sec\n",
      "Episode 6416, len12, loss:-95.9469, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5478358268737793 sec\n",
      "Episode 6417, len10, loss:-100.1246, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5478858947753906 sec\n",
      "Episode 6418, len8, loss:-79.9439, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5474720001220703 sec\n",
      "Episode 6419, len8, loss:-71.9716, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5473804473876953 sec\n",
      "Episode 6420, len6, loss:-68.0039, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5471510887145996 sec\n",
      "Episode 6421, len6, loss:-66.2042, fail, steps:80, opt steps:21, total reward:-24.0000, 0.6036205291748047 sec\n",
      "Episode 6422, len8, loss:-77.9989, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5482351779937744 sec\n",
      "Episode 6423, len10, loss:-91.1171, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5474653244018555 sec\n",
      "Episode 6424, len10, loss:-90.8610, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5481514930725098 sec\n",
      "Episode 6425, len12, loss:-101.6068, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5481152534484863 sec\n",
      "Episode 6426, len6, loss:-67.3031, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5486555099487305 sec\n",
      "Episode 6427, len6, loss:-66.9118, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5479648113250732 sec\n",
      "Episode 6428, len8, loss:-81.5123, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5487802028656006 sec\n",
      "Episode 6429, len6, loss:-63.0070, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5460429191589355 sec\n",
      "Episode 6430, len6, loss:-72.1553, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5421457290649414 sec\n",
      "Episode 6431, len6, loss:-67.4287, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5466980934143066 sec\n",
      "Episode 6432, len8, loss:-71.1654, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5465383529663086 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6433, len8, loss:-85.5907, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5472753047943115 sec\n",
      "Episode 6434, len6, loss:-70.1328, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5489873886108398 sec\n",
      "Episode 6435, len6, loss:-63.7337, fail, steps:80, opt steps:17, total reward:-22.7000, 0.5933573246002197 sec\n",
      "Episode 6436, len6, loss:-63.7696, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5476555824279785 sec\n",
      "Episode 6437, len12, loss:-97.8946, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5561604499816895 sec\n",
      "Episode 6438, len6, loss:-66.7358, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5480341911315918 sec\n",
      "Episode 6439, len10, loss:-86.3587, fail, steps:80, opt steps:22, total reward:-24.0000, 0.548922061920166 sec\n",
      "Episode 6440, len6, loss:-67.2524, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5486311912536621 sec\n",
      "Episode 6441, len10, loss:-98.1470, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5449540615081787 sec\n",
      "Episode 6442, len10, loss:-91.2580, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5494766235351562 sec\n",
      "Episode 6443, len6, loss:-72.5979, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5486998558044434 sec\n",
      "Episode 6444, len8, loss:-81.8114, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5495691299438477 sec\n",
      "Episode 6445, len12, loss:-107.4603, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5509710311889648 sec\n",
      "Episode 6446, len6, loss:-67.2201, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5485684871673584 sec\n",
      "Episode 6447, len10, loss:-96.0002, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5489320755004883 sec\n",
      "Episode 6448, len10, loss:-93.0705, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5490784645080566 sec\n",
      "Episode 6449, len12, loss:-110.3898, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5995619297027588 sec\n",
      "Episode 6450, len8, loss:-88.8842, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5448448657989502 sec\n",
      "Episode 6451, len8, loss:-75.6649, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5484635829925537 sec\n",
      "Episode 6452, len8, loss:-80.1327, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5484662055969238 sec\n",
      "Episode 6453, len10, loss:-91.7553, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5498433113098145 sec\n",
      "Episode 6454, len12, loss:-112.4466, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5508947372436523 sec\n",
      "Episode 6455, len6, loss:-73.8796, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5498013496398926 sec\n",
      "Episode 6456, len6, loss:-71.8032, fail, steps:80, opt steps:13, total reward:-24.0000, 0.549036979675293 sec\n",
      "Episode 6457, len12, loss:-116.3197, fail, steps:80, opt steps:33, total reward:-24.7000, 0.5453813076019287 sec\n",
      "Episode 6458, len12, loss:-104.3363, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5497293472290039 sec\n",
      "Episode 6459, len12, loss:-105.9041, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5484483242034912 sec\n",
      "Episode 6460, len8, loss:-83.6501, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5486922264099121 sec\n",
      "Episode 6461, len6, loss:-68.0533, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5484774112701416 sec\n",
      "Episode 6462, len12, loss:-114.0378, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5460758209228516 sec\n",
      "Episode 6463, len10, loss:-90.6919, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5483512878417969 sec\n",
      "Episode 6464, len12, loss:-108.2724, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5990715026855469 sec\n",
      "Episode 6465, len10, loss:-92.6488, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5494229793548584 sec\n",
      "Episode 6466, len12, loss:-98.6024, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5495023727416992 sec\n",
      "Episode 6467, len12, loss:-107.4299, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5500597953796387 sec\n",
      "Episode 6468, len6, loss:-68.5567, fail, steps:80, opt steps:19, total reward:-24.0000, 0.547839879989624 sec\n",
      "Episode 6469, len6, loss:-70.2898, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5492358207702637 sec\n",
      "Episode 6470, len10, loss:-92.7455, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5498616695404053 sec\n",
      "Episode 6471, len12, loss:-104.7500, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5496509075164795 sec\n",
      "Episode 6472, len8, loss:-78.4386, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5497565269470215 sec\n",
      "Episode 6473, len10, loss:-91.7452, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5488250255584717 sec\n",
      "Episode 6474, len8, loss:-81.3787, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5492458343505859 sec\n",
      "Episode 6475, len12, loss:-100.8637, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5500774383544922 sec\n",
      "Episode 6476, len10, loss:-93.5394, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5492370128631592 sec\n",
      "Episode 6477, len10, loss:-96.1681, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5486965179443359 sec\n",
      "Episode 6478, len6, loss:-64.8868, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5487229824066162 sec\n",
      "Episode 6479, len10, loss:-95.2310, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5505609512329102 sec\n",
      "Episode 6480, len8, loss:-81.9437, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5988080501556396 sec\n",
      "Episode 6481, len12, loss:-108.5874, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5448503494262695 sec\n",
      "Episode 6482, len8, loss:-77.2401, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5477933883666992 sec\n",
      "Episode 6483, len8, loss:-82.6632, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5490241050720215 sec\n",
      "Episode 6484, len12, loss:-102.2694, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5504162311553955 sec\n",
      "Episode 6485, len8, loss:-81.4557, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5513956546783447 sec\n",
      "Episode 6486, len10, loss:-87.2547, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5477850437164307 sec\n",
      "Episode 6487, len12, loss:-101.6793, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5502734184265137 sec\n",
      "Episode 6488, len12, loss:-100.0497, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5494894981384277 sec\n",
      "Episode 6489, len6, loss:-74.5146, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5449137687683105 sec\n",
      "Episode 6490, len10, loss:-91.7670, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5490298271179199 sec\n",
      "Episode 6491, len6, loss:-67.6730, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5491278171539307 sec\n",
      "Episode 6492, len12, loss:-95.0636, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5494370460510254 sec\n",
      "Episode 6493, len6, loss:-70.2091, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5487136840820312 sec\n",
      "Episode 6494, len12, loss:-100.3647, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5499627590179443 sec\n",
      "Episode 6495, len10, loss:-89.8239, fail, steps:80, opt steps:31, total reward:-24.0000, 0.548593282699585 sec\n",
      "Episode 6496, len8, loss:-80.3795, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5993857383728027 sec\n",
      "Episode 6497, len12, loss:-99.0128, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5495452880859375 sec\n",
      "Episode 6498, len12, loss:-99.6979, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5485384464263916 sec\n",
      "Episode 6499, len6, loss:-69.6397, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5486485958099365 sec\n",
      "Episode 6500, len6, loss:-75.4994, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5483496189117432 sec\n",
      "Episode 6501, len6, loss:-67.6921, fail, steps:80, opt steps:13, total reward:-24.0000, 0.548433780670166 sec\n",
      "Episode 6502, len8, loss:-87.3168, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5489447116851807 sec\n",
      "Episode 6503, len8, loss:-75.7793, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5489952564239502 sec\n",
      "Episode 6504, len6, loss:-70.0096, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5479819774627686 sec\n",
      "Episode 6505, len8, loss:-78.5412, fail, steps:80, opt steps:17, total reward:-24.0000, 0.548520565032959 sec\n",
      "Episode 6506, len10, loss:-92.4043, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5493643283843994 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6507, len12, loss:-100.7821, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5493264198303223 sec\n",
      "Episode 6508, len6, loss:-63.3959, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5500316619873047 sec\n",
      "Episode 6509, len12, loss:-102.1889, fail, steps:80, opt steps:57, total reward:-24.0000, 0.6027982234954834 sec\n",
      "Episode 6510, len10, loss:-93.0907, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5497856140136719 sec\n",
      "Episode 6511, len8, loss:-73.7667, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5502076148986816 sec\n",
      "Episode 6512, len6, loss:-66.4910, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5493745803833008 sec\n",
      "Episode 6513, len8, loss:-82.6445, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5491535663604736 sec\n",
      "Episode 6514, len8, loss:-77.3711, fail, steps:80, opt steps:20, total reward:-24.0000, 0.54888916015625 sec\n",
      "Episode 6515, len12, loss:-103.0992, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5495243072509766 sec\n",
      "Episode 6516, len8, loss:-79.9669, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5486931800842285 sec\n",
      "Episode 6517, len6, loss:-66.1665, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5494143962860107 sec\n",
      "Episode 6518, len6, loss:-63.0874, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5484950542449951 sec\n",
      "Episode 6519, len10, loss:-87.2595, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5496766567230225 sec\n",
      "Episode 6520, len10, loss:-88.9836, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5495738983154297 sec\n",
      "Episode 6521, len6, loss:-65.2473, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5499403476715088 sec\n",
      "Episode 6522, len6, loss:-66.2715, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5502610206604004 sec\n",
      "Episode 6523, len10, loss:-85.8621, fail, steps:80, opt steps:34, total reward:-24.0000, 0.6010725498199463 sec\n",
      "Episode 6524, len8, loss:-67.6853, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5503373146057129 sec\n",
      "Episode 6525, len10, loss:-78.5883, fail, steps:80, opt steps:43, total reward:-24.0000, 0.549419641494751 sec\n",
      "Episode 6526, len12, loss:-102.0863, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5502035617828369 sec\n",
      "Episode 6527, len6, loss:-56.8686, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5491371154785156 sec\n",
      "Episode 6528, len8, loss:-73.7942, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5508527755737305 sec\n",
      "Episode 6529, len8, loss:-78.4576, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5507595539093018 sec\n",
      "Episode 6530, len12, loss:-95.7088, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5487990379333496 sec\n",
      "Episode 6531, len6, loss:-58.3245, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5481576919555664 sec\n",
      "Episode 6532, len8, loss:-74.2799, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5481231212615967 sec\n",
      "Episode 6533, len12, loss:-98.5144, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5488848686218262 sec\n",
      "Episode 6534, len6, loss:-59.7462, fail, steps:80, opt steps:7, total reward:-24.0000, 0.550520658493042 sec\n",
      "Episode 6535, len10, loss:-89.0773, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5499472618103027 sec\n",
      "Episode 6536, len6, loss:-63.9403, fail, steps:80, opt steps:6, total reward:-24.0000, 0.549210786819458 sec\n",
      "Episode 6537, len8, loss:-80.7609, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5989470481872559 sec\n",
      "Episode 6538, len12, loss:-101.1308, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5489435195922852 sec\n",
      "Episode 6539, len8, loss:-71.6603, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5482962131500244 sec\n",
      "Episode 6540, len8, loss:-81.2679, fail, steps:80, opt steps:27, total reward:-24.0000, 0.54952073097229 sec\n",
      "Episode 6541, len10, loss:-95.4197, fail, steps:80, opt steps:31, total reward:-23.7000, 0.5446529388427734 sec\n",
      "Episode 6542, len8, loss:-82.1432, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5479702949523926 sec\n",
      "Episode 6543, len10, loss:-90.8714, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5488951206207275 sec\n",
      "Episode 6544, len8, loss:-75.2936, fail, steps:80, opt steps:15, total reward:-24.0000, 0.549649715423584 sec\n",
      "Episode 6545, len10, loss:-94.9261, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5480434894561768 sec\n",
      "Episode 6546, len6, loss:-64.6105, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5485172271728516 sec\n",
      "Episode 6547, len6, loss:-66.4333, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485818386077881 sec\n",
      "Episode 6548, len12, loss:-99.7202, fail, steps:80, opt steps:68, total reward:-24.0000, 0.5507950782775879 sec\n",
      "Episode 6549, len6, loss:-62.8486, fail, steps:80, opt steps:14, total reward:-24.0000, 0.549269437789917 sec\n",
      "Episode 6550, len12, loss:-99.9884, fail, steps:80, opt steps:73, total reward:-24.0000, 0.5501573085784912 sec\n",
      "Episode 6551, len12, loss:-102.3234, fail, steps:80, opt steps:72, total reward:-24.0000, 0.5992438793182373 sec\n",
      "Episode 6552, len6, loss:-64.9732, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5484044551849365 sec\n",
      "Episode 6553, len10, loss:-99.9409, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5494379997253418 sec\n",
      "Episode 6554, len6, loss:-68.4083, fail, steps:80, opt steps:18, total reward:-24.0000, 0.548973560333252 sec\n",
      "Episode 6555, len8, loss:-72.0683, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5488755702972412 sec\n",
      "Episode 6556, len10, loss:-90.6085, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5485801696777344 sec\n",
      "Episode 6557, len10, loss:-88.1009, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5496082305908203 sec\n",
      "Episode 6558, len12, loss:-97.6043, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5500733852386475 sec\n",
      "Episode 6559, len10, loss:-89.0769, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5494663715362549 sec\n",
      "Episode 6560, len10, loss:-93.7232, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5500669479370117 sec\n",
      "Episode 6561, len8, loss:-72.5667, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5505564212799072 sec\n",
      "Episode 6562, len6, loss:-63.7465, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5495338439941406 sec\n",
      "Episode 6563, len12, loss:-105.7132, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5489089488983154 sec\n",
      "Episode 6564, len6, loss:-61.5203, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5490207672119141 sec\n",
      "Episode 6565, len6, loss:-61.5366, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5986943244934082 sec\n",
      "Episode 6566, len10, loss:-92.8414, fail, steps:80, opt steps:39, total reward:-23.7000, 0.5464608669281006 sec\n",
      "Episode 6567, len10, loss:-88.3050, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5491805076599121 sec\n",
      "Episode 6568, len12, loss:-97.7480, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5477955341339111 sec\n",
      "Episode 6569, len10, loss:-93.4901, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5489954948425293 sec\n",
      "Episode 6570, len8, loss:-83.8655, fail, steps:80, opt steps:26, total reward:-24.0000, 0.548593282699585 sec\n",
      "Episode 6571, len10, loss:-87.1625, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5498371124267578 sec\n",
      "Episode 6572, len12, loss:-101.3614, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5501551628112793 sec\n",
      "Episode 6573, len12, loss:-100.0854, fail, steps:80, opt steps:53, total reward:-24.0000, 0.550166130065918 sec\n",
      "Episode 6574, len12, loss:-102.7732, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5492432117462158 sec\n",
      "Episode 6575, len12, loss:-105.6270, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5498692989349365 sec\n",
      "Episode 6576, len6, loss:-69.5019, fail, steps:80, opt steps:6, total reward:-24.0000, 0.548447847366333 sec\n",
      "Episode 6577, len12, loss:-103.7823, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5479152202606201 sec\n",
      "Episode 6578, len6, loss:-71.0307, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5484840869903564 sec\n",
      "Episode 6579, len12, loss:-98.8197, fail, steps:80, opt steps:41, total reward:-24.0000, 0.549065113067627 sec\n",
      "Episode 6580, len6, loss:-66.7505, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5983576774597168 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6581, len10, loss:-93.0431, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5490272045135498 sec\n",
      "Episode 6582, len10, loss:-93.8737, fail, steps:80, opt steps:34, total reward:-24.0000, 0.550023078918457 sec\n",
      "Episode 6583, len6, loss:-69.0651, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5501675605773926 sec\n",
      "Episode 6584, len10, loss:-90.7632, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5499954223632812 sec\n",
      "Episode 6585, len10, loss:-90.0568, fail, steps:80, opt steps:34, total reward:-24.0000, 0.548600435256958 sec\n",
      "Episode 6586, len12, loss:-105.3312, fail, steps:80, opt steps:57, total reward:-24.0000, 0.547903299331665 sec\n",
      "Episode 6587, len12, loss:-104.8432, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5506572723388672 sec\n",
      "Episode 6588, len6, loss:-67.0514, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5493564605712891 sec\n",
      "Episode 6589, len8, loss:-81.8871, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5492196083068848 sec\n",
      "Episode 6590, len8, loss:-78.9725, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5491342544555664 sec\n",
      "Episode 6591, len10, loss:-92.4711, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5489146709442139 sec\n",
      "Episode 6592, len12, loss:-97.5367, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5502662658691406 sec\n",
      "Episode 6593, len8, loss:-87.1633, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5479075908660889 sec\n",
      "Episode 6594, len12, loss:-104.0593, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5491476058959961 sec\n",
      "Episode 6595, len6, loss:-74.4141, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5449976921081543 sec\n",
      "Episode 6596, len12, loss:-97.6471, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5994179248809814 sec\n",
      "Episode 6597, len6, loss:-63.5473, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5480782985687256 sec\n",
      "Episode 6598, len10, loss:-87.0194, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5486066341400146 sec\n",
      "Episode 6599, len8, loss:-79.2864, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5493888854980469 sec\n",
      "Episode 6600, len6, loss:-66.4955, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5493967533111572 sec\n",
      "Episode 6601, len8, loss:-85.8731, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5497820377349854 sec\n",
      "Episode 6602, len12, loss:-106.8247, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5496282577514648 sec\n",
      "Episode 6603, len10, loss:-96.7210, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5487232208251953 sec\n",
      "Episode 6604, len10, loss:-86.0958, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5495471954345703 sec\n",
      "Episode 6605, len8, loss:-85.0436, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5477585792541504 sec\n",
      "Episode 6606, len12, loss:-101.7305, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5496370792388916 sec\n",
      "Episode 6607, len10, loss:-92.0873, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5488698482513428 sec\n",
      "Episode 6608, len6, loss:-69.2235, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5489382743835449 sec\n",
      "Episode 6609, len12, loss:-102.9117, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5473384857177734 sec\n",
      "Episode 6610, len10, loss:-89.3937, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5493788719177246 sec\n",
      "Episode 6611, len10, loss:-88.6290, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5497157573699951 sec\n",
      "Episode 6612, len10, loss:-93.7494, fail, steps:80, opt steps:38, total reward:-24.0000, 0.6002752780914307 sec\n",
      "Episode 6613, len8, loss:-83.1966, fail, steps:80, opt steps:28, total reward:-24.0000, 0.548053503036499 sec\n",
      "Episode 6614, len10, loss:-91.3397, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5487971305847168 sec\n",
      "Episode 6615, len8, loss:-84.2986, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5492444038391113 sec\n",
      "Episode 6616, len8, loss:-73.7625, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5483531951904297 sec\n",
      "Episode 6617, len6, loss:-73.0261, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5497679710388184 sec\n",
      "Episode 6618, len10, loss:-97.9917, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5501186847686768 sec\n",
      "Episode 6619, len12, loss:-102.4741, fail, steps:80, opt steps:29, total reward:-24.0000, 0.548994779586792 sec\n",
      "Episode 6620, len12, loss:-99.2433, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5481059551239014 sec\n",
      "Episode 6621, len12, loss:-103.8134, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5498323440551758 sec\n",
      "Episode 6622, len6, loss:-67.6302, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5481066703796387 sec\n",
      "Episode 6623, len12, loss:-114.4821, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5450878143310547 sec\n",
      "Episode 6624, len6, loss:-70.9906, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5482637882232666 sec\n",
      "Episode 6625, len10, loss:-98.4654, fail, steps:80, opt steps:26, total reward:-24.0000, 0.6035637855529785 sec\n",
      "Episode 6626, len6, loss:-72.2762, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5505177974700928 sec\n",
      "Episode 6627, len12, loss:-110.5963, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5491044521331787 sec\n",
      "Episode 6628, len8, loss:-88.7717, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5501432418823242 sec\n",
      "Episode 6629, len6, loss:-72.0882, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5495195388793945 sec\n",
      "Episode 6630, len10, loss:-91.6496, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5507721900939941 sec\n",
      "Episode 6631, len8, loss:-79.4463, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5492312908172607 sec\n",
      "Episode 6632, len10, loss:-89.6907, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5483033657073975 sec\n",
      "Episode 6633, len12, loss:-101.8468, fail, steps:80, opt steps:61, total reward:-24.0000, 0.549321174621582 sec\n",
      "Episode 6634, len12, loss:-105.4818, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5485923290252686 sec\n",
      "Episode 6635, len12, loss:-104.0805, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5479714870452881 sec\n",
      "Episode 6636, len10, loss:-85.8940, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5495643615722656 sec\n",
      "Episode 6637, len8, loss:-77.8341, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5495514869689941 sec\n",
      "Episode 6638, len10, loss:-93.1901, fail, steps:80, opt steps:27, total reward:-24.0000, 0.550046443939209 sec\n",
      "Episode 6639, len8, loss:-74.8145, fail, steps:80, opt steps:20, total reward:-24.0000, 0.6009917259216309 sec\n",
      "Episode 6640, len12, loss:-103.7818, fail, steps:80, opt steps:71, total reward:-24.0000, 0.550429105758667 sec\n",
      "Episode 6641, len6, loss:-72.8373, fail, steps:80, opt steps:10, total reward:-24.0000, 0.550283670425415 sec\n",
      "Episode 6642, len6, loss:-66.5659, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5486428737640381 sec\n",
      "Episode 6643, len12, loss:-102.5768, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5491213798522949 sec\n",
      "Episode 6644, len6, loss:-68.2539, fail, steps:80, opt steps:13, total reward:-24.0000, 0.548149824142456 sec\n",
      "Episode 6645, len10, loss:-79.3846, fail, steps:80, opt steps:42, total reward:-22.7000, 0.545116662979126 sec\n",
      "Episode 6646, len8, loss:-76.4743, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5494911670684814 sec\n",
      "Episode 6647, len12, loss:-108.8859, fail, steps:80, opt steps:47, total reward:-24.0000, 0.550156831741333 sec\n",
      "Episode 6648, len8, loss:-77.9995, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5482110977172852 sec\n",
      "Episode 6649, len10, loss:-92.1883, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5488796234130859 sec\n",
      "Episode 6650, len10, loss:-95.8306, fail, steps:80, opt steps:34, total reward:-24.0000, 0.549593448638916 sec\n",
      "Episode 6651, len12, loss:-103.5492, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5497639179229736 sec\n",
      "Episode 6652, len10, loss:-96.9197, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5500998497009277 sec\n",
      "Episode 6653, len12, loss:-103.3106, fail, steps:80, opt steps:14, total reward:-24.0000, 0.6031520366668701 sec\n",
      "Episode 6654, len12, loss:-101.6505, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5559959411621094 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6655, len10, loss:-93.6329, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5502324104309082 sec\n",
      "Episode 6656, len8, loss:-77.9866, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5486593246459961 sec\n",
      "Episode 6657, len12, loss:-101.5069, fail, steps:80, opt steps:60, total reward:-24.0000, 0.54937744140625 sec\n",
      "Episode 6658, len12, loss:-98.8718, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5504324436187744 sec\n",
      "Episode 6659, len6, loss:-74.5236, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5501446723937988 sec\n",
      "Episode 6660, len12, loss:-102.2401, fail, steps:80, opt steps:51, total reward:-24.7000, 0.5457000732421875 sec\n",
      "Episode 6661, len10, loss:-84.8792, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5481958389282227 sec\n",
      "Episode 6662, len10, loss:-90.6360, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5489647388458252 sec\n",
      "Episode 6663, len10, loss:-88.9166, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5493230819702148 sec\n",
      "Episode 6664, len8, loss:-68.9137, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5499207973480225 sec\n",
      "Episode 6665, len8, loss:-73.5428, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5486974716186523 sec\n",
      "Episode 6666, len12, loss:-97.0318, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5507545471191406 sec\n",
      "Episode 6667, len10, loss:-90.4281, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5985167026519775 sec\n",
      "Episode 6668, len6, loss:-71.7273, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5489673614501953 sec\n",
      "Episode 6669, len12, loss:-101.0265, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5494978427886963 sec\n",
      "Episode 6670, len8, loss:-83.4290, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5492501258850098 sec\n",
      "Episode 6671, len6, loss:-70.2497, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5483708381652832 sec\n",
      "Episode 6672, len8, loss:-76.8228, fail, steps:80, opt steps:36, total reward:-24.0000, 0.550152063369751 sec\n",
      "Episode 6673, len8, loss:-75.0101, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5498518943786621 sec\n",
      "Episode 6674, len8, loss:-76.9512, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5482926368713379 sec\n",
      "Episode 6675, len8, loss:-71.6110, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5474495887756348 sec\n",
      "Episode 6676, len12, loss:-103.8824, fail, steps:80, opt steps:13, total reward:-24.0000, 0.550029993057251 sec\n",
      "Episode 6677, len6, loss:-69.9154, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5494906902313232 sec\n",
      "Episode 6678, len10, loss:-79.7397, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5503406524658203 sec\n",
      "Episode 6679, len10, loss:-83.6160, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5500466823577881 sec\n",
      "Episode 6680, len6, loss:-72.5487, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5498995780944824 sec\n",
      "Episode 6681, len10, loss:-86.3672, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5982019901275635 sec\n",
      "Episode 6682, len8, loss:-72.7205, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5497848987579346 sec\n",
      "Episode 6683, len6, loss:-71.0018, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5489041805267334 sec\n",
      "Episode 6684, len8, loss:-69.0259, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5488400459289551 sec\n",
      "Episode 6685, len12, loss:-98.3611, fail, steps:80, opt steps:73, total reward:-24.0000, 0.547295331954956 sec\n",
      "Episode 6686, len12, loss:-102.4782, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5495567321777344 sec\n",
      "Episode 6687, len6, loss:-69.9221, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5498247146606445 sec\n",
      "Episode 6688, len12, loss:-98.4126, fail, steps:80, opt steps:58, total reward:-24.0000, 0.550046443939209 sec\n",
      "Episode 6689, len12, loss:-83.6420, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5494005680084229 sec\n",
      "Episode 6690, len12, loss:-97.0155, fail, steps:80, opt steps:48, total reward:-24.0000, 0.549384355545044 sec\n",
      "Episode 6691, len10, loss:-81.4709, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5497756004333496 sec\n",
      "Episode 6692, len10, loss:-75.8658, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5476806163787842 sec\n",
      "Episode 6693, len12, loss:-94.3363, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5478713512420654 sec\n",
      "Episode 6694, len6, loss:-66.3342, fail, steps:80, opt steps:14, total reward:-24.0000, 0.548687219619751 sec\n",
      "Episode 6695, len10, loss:-85.1190, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5473935604095459 sec\n",
      "Episode 6696, len8, loss:-65.9710, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5971403121948242 sec\n",
      "Episode 6697, len8, loss:-70.3751, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5464107990264893 sec\n",
      "Episode 6698, len12, loss:-97.7341, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5443565845489502 sec\n",
      "Episode 6699, len12, loss:-92.7470, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5473814010620117 sec\n",
      "Episode 6700, len8, loss:-73.6096, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5481352806091309 sec\n",
      "Episode 6701, len10, loss:-89.6357, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5485773086547852 sec\n",
      "Episode 6702, len8, loss:-67.3268, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5493073463439941 sec\n",
      "Episode 6703, len10, loss:-84.4921, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5489888191223145 sec\n",
      "Episode 6704, len10, loss:-88.5116, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5480268001556396 sec\n",
      "Episode 6705, len8, loss:-77.7285, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5594959259033203 sec\n",
      "Episode 6706, len12, loss:-106.1812, fail, steps:80, opt steps:51, total reward:-24.7000, 0.5460300445556641 sec\n",
      "Episode 6707, len6, loss:-71.7251, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5486531257629395 sec\n",
      "Episode 6708, len10, loss:-91.1466, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5491187572479248 sec\n",
      "Episode 6709, len6, loss:-69.1949, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5503487586975098 sec\n",
      "Episode 6710, len8, loss:-67.7702, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5481646060943604 sec\n",
      "Episode 6711, len12, loss:-90.0329, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5518550872802734 sec\n",
      "Episode 6712, len6, loss:-73.7460, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5983474254608154 sec\n",
      "Episode 6713, len12, loss:-90.9062, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5517070293426514 sec\n",
      "Episode 6714, len6, loss:-74.8323, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5476455688476562 sec\n",
      "Episode 6715, len12, loss:-100.1740, fail, steps:80, opt steps:33, total reward:-24.0000, 0.54990553855896 sec\n",
      "Episode 6716, len8, loss:-70.8740, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5502984523773193 sec\n",
      "Episode 6717, len6, loss:-80.0155, fail, steps:80, opt steps:11, total reward:-24.7000, 0.5458223819732666 sec\n",
      "Episode 6718, len12, loss:-100.7175, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5495729446411133 sec\n",
      "Episode 6719, len12, loss:-96.2541, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5499069690704346 sec\n",
      "Episode 6720, len12, loss:-98.2526, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5498459339141846 sec\n",
      "Episode 6721, len10, loss:-90.6786, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5497968196868896 sec\n",
      "Episode 6722, len12, loss:-103.0215, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5492293834686279 sec\n",
      "Episode 6723, len12, loss:-100.4741, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5498504638671875 sec\n",
      "Episode 6724, len6, loss:-75.0851, fail, steps:80, opt steps:21, total reward:-24.0000, 0.549475908279419 sec\n",
      "Episode 6725, len10, loss:-82.5654, fail, steps:80, opt steps:34, total reward:-24.0000, 0.548994779586792 sec\n",
      "Episode 6726, len8, loss:-73.1133, fail, steps:80, opt steps:19, total reward:-24.0000, 0.548651933670044 sec\n",
      "Episode 6727, len6, loss:-68.2746, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5505003929138184 sec\n",
      "Episode 6728, len8, loss:-80.2405, fail, steps:80, opt steps:6, total reward:-24.0000, 0.6006050109863281 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6729, len6, loss:-72.4362, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5495860576629639 sec\n",
      "Episode 6730, len6, loss:-70.8476, fail, steps:80, opt steps:18, total reward:-24.0000, 0.549821138381958 sec\n",
      "Episode 6731, len6, loss:-74.1299, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5489370822906494 sec\n",
      "Episode 6732, len10, loss:-87.3478, fail, steps:80, opt steps:31, total reward:-24.0000, 0.549889326095581 sec\n",
      "Episode 6733, len12, loss:-95.6342, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5490515232086182 sec\n",
      "Episode 6734, len10, loss:-79.8937, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5479099750518799 sec\n",
      "Episode 6735, len12, loss:-103.7052, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5500333309173584 sec\n",
      "Episode 6736, len10, loss:-84.1275, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5497341156005859 sec\n",
      "Episode 6737, len12, loss:-94.7865, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5477993488311768 sec\n",
      "Episode 6738, len6, loss:-65.8836, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5491940975189209 sec\n",
      "Episode 6739, len8, loss:-80.7183, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5495963096618652 sec\n",
      "Episode 6740, len12, loss:-97.8381, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5503582954406738 sec\n",
      "Episode 6741, len6, loss:-74.4225, fail, steps:80, opt steps:11, total reward:-24.0000, 0.6019706726074219 sec\n",
      "Episode 6742, len6, loss:-65.2790, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5500802993774414 sec\n",
      "Episode 6743, len12, loss:-97.5281, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5498902797698975 sec\n",
      "Episode 6744, len12, loss:-103.0241, fail, steps:80, opt steps:51, total reward:-24.7000, 0.5453712940216064 sec\n",
      "Episode 6745, len8, loss:-73.3146, fail, steps:80, opt steps:21, total reward:-23.7000, 0.5445084571838379 sec\n",
      "Episode 6746, len10, loss:-92.3838, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5481462478637695 sec\n",
      "Episode 6747, len8, loss:-77.3790, fail, steps:80, opt steps:23, total reward:-24.0000, 0.549004077911377 sec\n",
      "Episode 6748, len6, loss:-74.5736, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5479958057403564 sec\n",
      "Episode 6749, len6, loss:-67.9080, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5490772724151611 sec\n",
      "Episode 6750, len6, loss:-75.7287, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5494229793548584 sec\n",
      "Episode 6751, len8, loss:-70.4639, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5489847660064697 sec\n",
      "Episode 6752, len6, loss:-72.3341, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5492076873779297 sec\n",
      "Episode 6753, len12, loss:-95.4456, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5501968860626221 sec\n",
      "Episode 6754, len8, loss:-77.8029, fail, steps:80, opt steps:15, total reward:-24.0000, 0.549921989440918 sec\n",
      "Episode 6755, len10, loss:-87.8804, fail, steps:80, opt steps:30, total reward:-24.0000, 0.6015257835388184 sec\n",
      "Episode 6756, len10, loss:-83.8000, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5501511096954346 sec\n",
      "Episode 6757, len12, loss:-96.7371, fail, steps:80, opt steps:39, total reward:-24.0000, 0.550311803817749 sec\n",
      "Episode 6758, len10, loss:-81.5371, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5493109226226807 sec\n",
      "Episode 6759, len8, loss:-76.4276, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5495812892913818 sec\n",
      "Episode 6760, len8, loss:-77.2032, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5460913181304932 sec\n",
      "Episode 6761, len12, loss:-103.4348, fail, steps:80, opt steps:62, total reward:-23.7000, 0.5462114810943604 sec\n",
      "Episode 6762, len12, loss:-94.4660, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5500013828277588 sec\n",
      "Episode 6763, len8, loss:-80.2416, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5441138744354248 sec\n",
      "Episode 6764, len10, loss:-86.6028, fail, steps:80, opt steps:32, total reward:-24.0000, 0.549053430557251 sec\n",
      "Episode 6765, len6, loss:-69.3343, fail, steps:80, opt steps:17, total reward:-24.0000, 0.548891544342041 sec\n",
      "Episode 6766, len10, loss:-86.4115, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5491597652435303 sec\n",
      "Episode 6767, len8, loss:-79.4823, fail, steps:80, opt steps:11, total reward:-24.0000, 0.551182746887207 sec\n",
      "Episode 6768, len12, loss:-99.9570, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5493359565734863 sec\n",
      "Episode 6769, len10, loss:-90.8113, fail, steps:80, opt steps:30, total reward:-24.0000, 0.600761890411377 sec\n",
      "Episode 6770, len8, loss:-75.3558, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5493261814117432 sec\n",
      "Episode 6771, len6, loss:-67.7970, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5508584976196289 sec\n",
      "Episode 6772, len8, loss:-79.3981, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5495755672454834 sec\n",
      "Episode 6773, len6, loss:-65.7641, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5493991374969482 sec\n",
      "Episode 6774, len8, loss:-77.7051, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5507800579071045 sec\n",
      "Episode 6775, len12, loss:-92.2793, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5499720573425293 sec\n",
      "Episode 6776, len8, loss:-71.1832, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5493261814117432 sec\n",
      "Episode 6777, len10, loss:-86.4363, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5480465888977051 sec\n",
      "Episode 6778, len12, loss:-103.1568, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5503249168395996 sec\n",
      "Episode 6779, len12, loss:-94.1015, fail, steps:80, opt steps:55, total reward:-24.0000, 0.55019211769104 sec\n",
      "Episode 6780, len8, loss:-79.0596, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5493490695953369 sec\n",
      "Episode 6781, len12, loss:-102.5910, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5493350028991699 sec\n",
      "Episode 6782, len6, loss:-64.4047, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5504631996154785 sec\n",
      "Episode 6783, len8, loss:-81.2641, fail, steps:80, opt steps:21, total reward:-24.0000, 0.6007728576660156 sec\n",
      "Episode 6784, len8, loss:-83.0363, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5495462417602539 sec\n",
      "Episode 6785, len12, loss:-103.3844, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5493416786193848 sec\n",
      "Episode 6786, len12, loss:-96.6745, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5500674247741699 sec\n",
      "Episode 6787, len6, loss:-72.2378, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5502011775970459 sec\n",
      "Episode 6788, len8, loss:-74.1477, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5508913993835449 sec\n",
      "Episode 6789, len12, loss:-100.8454, fail, steps:80, opt steps:72, total reward:-24.0000, 0.5490243434906006 sec\n",
      "Episode 6790, len8, loss:-83.8754, fail, steps:80, opt steps:23, total reward:-24.7000, 0.5440711975097656 sec\n",
      "Episode 6791, len10, loss:-92.9422, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5484676361083984 sec\n",
      "Episode 6792, len6, loss:-74.5955, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5490686893463135 sec\n",
      "Episode 6793, len6, loss:-64.6612, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5485799312591553 sec\n",
      "Episode 6794, len6, loss:-63.4496, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5489692687988281 sec\n",
      "Episode 6795, len6, loss:-63.9495, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485668182373047 sec\n",
      "Episode 6796, len8, loss:-80.2067, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5491771697998047 sec\n",
      "Episode 6797, len10, loss:-87.4713, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5994560718536377 sec\n",
      "Episode 6798, len6, loss:-70.3046, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5489647388458252 sec\n",
      "Episode 6799, len6, loss:-74.3941, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5487551689147949 sec\n",
      "Episode 6800, len6, loss:-77.4821, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5460610389709473 sec\n",
      "Episode 6801, len12, loss:-95.8195, fail, steps:80, opt steps:68, total reward:-24.0000, 0.5494625568389893 sec\n",
      "Episode 6802, len10, loss:-88.3480, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5480382442474365 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6803, len8, loss:-77.5687, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5484423637390137 sec\n",
      "Episode 6804, len8, loss:-75.1386, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5496783256530762 sec\n",
      "Episode 6805, len10, loss:-88.1616, fail, steps:80, opt steps:50, total reward:-24.0000, 0.550743579864502 sec\n",
      "Episode 6806, len8, loss:-80.0049, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5499708652496338 sec\n",
      "Episode 6807, len6, loss:-70.1697, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5497004985809326 sec\n",
      "Episode 6808, len6, loss:-65.5218, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5499839782714844 sec\n",
      "Episode 6809, len10, loss:-90.1134, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5483813285827637 sec\n",
      "Episode 6810, len8, loss:-78.5735, fail, steps:80, opt steps:27, total reward:-24.0000, 0.550123929977417 sec\n",
      "Episode 6811, len8, loss:-75.8155, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5480861663818359 sec\n",
      "Episode 6812, len10, loss:-89.5614, fail, steps:80, opt steps:36, total reward:-24.0000, 0.601125955581665 sec\n",
      "Episode 6813, len6, loss:-64.5739, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5472218990325928 sec\n",
      "Episode 6814, len6, loss:-71.3186, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5470197200775146 sec\n",
      "Episode 6815, len12, loss:-100.5280, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5475001335144043 sec\n",
      "Episode 6816, len12, loss:-99.9993, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5476341247558594 sec\n",
      "Episode 6817, len10, loss:-87.7476, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5482614040374756 sec\n",
      "Episode 6818, len6, loss:-65.3164, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5476205348968506 sec\n",
      "Episode 6819, len10, loss:-92.2313, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5487217903137207 sec\n",
      "Episode 6820, len12, loss:-104.5059, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5487444400787354 sec\n",
      "Episode 6821, len10, loss:-94.0427, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5463621616363525 sec\n",
      "Episode 6822, len12, loss:-103.2006, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5483150482177734 sec\n",
      "Episode 6823, len10, loss:-94.5128, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5474042892456055 sec\n",
      "Episode 6824, len8, loss:-75.0847, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5470044612884521 sec\n",
      "Episode 6825, len6, loss:-68.9922, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5482676029205322 sec\n",
      "Episode 6826, len10, loss:-88.1635, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5560903549194336 sec\n",
      "Episode 6827, len8, loss:-81.8032, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5482425689697266 sec\n",
      "Episode 6828, len6, loss:-66.5558, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6020526885986328 sec\n",
      "Episode 6829, len12, loss:-102.7368, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5492520332336426 sec\n",
      "Episode 6830, len12, loss:-108.3244, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5469303131103516 sec\n",
      "Episode 6831, len12, loss:-98.7051, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5485823154449463 sec\n",
      "Episode 6832, len12, loss:-96.5382, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5482516288757324 sec\n",
      "Episode 6833, len12, loss:-100.3337, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5498232841491699 sec\n",
      "Episode 6834, len8, loss:-80.5909, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5490233898162842 sec\n",
      "Episode 6835, len12, loss:-100.6850, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5492041110992432 sec\n",
      "Episode 6836, len10, loss:-90.2595, fail, steps:80, opt steps:32, total reward:-24.0000, 0.548346757888794 sec\n",
      "Episode 6837, len6, loss:-69.4114, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5466701984405518 sec\n",
      "Episode 6838, len12, loss:-105.9933, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5483663082122803 sec\n",
      "Episode 6839, len8, loss:-76.6275, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5475258827209473 sec\n",
      "Episode 6840, len10, loss:-94.5073, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5482578277587891 sec\n",
      "Episode 6841, len12, loss:-102.0758, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5477495193481445 sec\n",
      "Episode 6842, len10, loss:-93.2124, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5479719638824463 sec\n",
      "Episode 6843, len12, loss:-97.5417, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5500800609588623 sec\n",
      "Episode 6844, len12, loss:-94.8437, fail, steps:80, opt steps:40, total reward:-24.0000, 0.6040380001068115 sec\n",
      "Episode 6845, len10, loss:-82.8759, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5481786727905273 sec\n",
      "Episode 6846, len8, loss:-73.2891, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5472586154937744 sec\n",
      "Episode 6847, len8, loss:-74.6112, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5489640235900879 sec\n",
      "Episode 6848, len6, loss:-62.7948, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5508978366851807 sec\n",
      "Episode 6849, len6, loss:-61.5847, fail, steps:80, opt steps:13, total reward:-24.0000, 0.549109935760498 sec\n",
      "Episode 6850, len12, loss:-95.5512, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5496830940246582 sec\n",
      "Episode 6851, len6, loss:-65.4150, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5494329929351807 sec\n",
      "Episode 6852, len12, loss:-99.0312, fail, steps:80, opt steps:49, total reward:-24.0000, 0.550847053527832 sec\n",
      "Episode 6853, len10, loss:-86.1641, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5493128299713135 sec\n",
      "Episode 6854, len8, loss:-77.4490, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5493144989013672 sec\n",
      "Episode 6855, len10, loss:-86.6603, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5497500896453857 sec\n",
      "Episode 6856, len6, loss:-63.0091, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5494899749755859 sec\n",
      "Episode 6857, len6, loss:-63.2921, fail, steps:80, opt steps:7, total reward:-24.0000, 0.6049342155456543 sec\n",
      "Episode 6858, len10, loss:-89.2457, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5498650074005127 sec\n",
      "Episode 6859, len12, loss:-98.8237, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5481517314910889 sec\n",
      "Episode 6860, len6, loss:-69.8335, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485866069793701 sec\n",
      "Episode 6861, len6, loss:-67.6715, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5488395690917969 sec\n",
      "Episode 6862, len12, loss:-91.3808, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5496580600738525 sec\n",
      "Episode 6863, len12, loss:-100.8406, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5496392250061035 sec\n",
      "Episode 6864, len6, loss:-62.1293, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5488259792327881 sec\n",
      "Episode 6865, len8, loss:-73.3960, fail, steps:80, opt steps:23, total reward:-24.0000, 0.549680233001709 sec\n",
      "Episode 6866, len12, loss:-94.1039, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5497956275939941 sec\n",
      "Episode 6867, len8, loss:-79.9902, fail, steps:80, opt steps:25, total reward:-24.7000, 0.544813871383667 sec\n",
      "Episode 6868, len6, loss:-65.3194, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5493190288543701 sec\n",
      "Episode 6869, len6, loss:-69.5747, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5498201847076416 sec\n",
      "Episode 6870, len6, loss:-68.3508, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5486719608306885 sec\n",
      "Episode 6871, len12, loss:-97.3294, fail, steps:80, opt steps:61, total reward:-24.0000, 0.6049056053161621 sec\n",
      "Episode 6872, len8, loss:-76.1462, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5539476871490479 sec\n",
      "Episode 6873, len10, loss:-87.6715, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5487954616546631 sec\n",
      "Episode 6874, len8, loss:-63.5963, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5495693683624268 sec\n",
      "Episode 6875, len8, loss:-69.9930, fail, steps:80, opt steps:21, total reward:-24.0000, 0.548086404800415 sec\n",
      "Episode 6876, len10, loss:-83.0881, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5497558116912842 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6877, len12, loss:-99.3642, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5499205589294434 sec\n",
      "Episode 6878, len10, loss:-89.5971, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5493628978729248 sec\n",
      "Episode 6879, len6, loss:-68.3892, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5504095554351807 sec\n",
      "Episode 6880, len8, loss:-76.0298, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5500881671905518 sec\n",
      "Episode 6881, len6, loss:-72.6621, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5498065948486328 sec\n",
      "Episode 6882, len10, loss:-79.6359, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5487353801727295 sec\n",
      "Episode 6883, len8, loss:-65.9646, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5498225688934326 sec\n",
      "Episode 6884, len8, loss:-61.6829, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5492873191833496 sec\n",
      "Episode 6885, len12, loss:-96.0077, fail, steps:80, opt steps:30, total reward:-24.0000, 0.6009974479675293 sec\n",
      "Episode 6886, len8, loss:-68.6848, fail, steps:80, opt steps:14, total reward:-24.0000, 0.549607515335083 sec\n",
      "Episode 6887, len10, loss:-79.8032, fail, steps:80, opt steps:31, total reward:-24.0000, 0.548151969909668 sec\n",
      "Episode 6888, len8, loss:-67.4523, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5484368801116943 sec\n",
      "Episode 6889, len8, loss:-65.1569, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5486176013946533 sec\n",
      "Episode 6890, len10, loss:-82.4572, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5481874942779541 sec\n",
      "Episode 6891, len8, loss:-65.7364, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5503380298614502 sec\n",
      "Episode 6892, len10, loss:-93.8533, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5484225749969482 sec\n",
      "Episode 6893, len12, loss:-91.7489, fail, steps:80, opt steps:37, total reward:-24.0000, 0.549731969833374 sec\n",
      "Episode 6894, len6, loss:-71.3270, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5498964786529541 sec\n",
      "Episode 6895, len10, loss:-80.2507, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5495414733886719 sec\n",
      "Episode 6896, len12, loss:-96.0889, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5494730472564697 sec\n",
      "Episode 6897, len12, loss:-94.6983, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5494906902313232 sec\n",
      "Episode 6898, len6, loss:-71.3161, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5484294891357422 sec\n",
      "Episode 6899, len10, loss:-77.4449, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5995519161224365 sec\n",
      "Episode 6900, len12, loss:-93.6378, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5496706962585449 sec\n",
      "Episode 6901, len12, loss:-94.1503, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5489640235900879 sec\n",
      "Episode 6902, len10, loss:-82.0292, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5492575168609619 sec\n",
      "Episode 6903, len12, loss:-87.5343, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5506954193115234 sec\n",
      "Episode 6904, len6, loss:-67.3399, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5491774082183838 sec\n",
      "Episode 6905, len12, loss:-96.5283, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5498237609863281 sec\n",
      "Episode 6906, len12, loss:-91.8309, fail, steps:80, opt steps:43, total reward:-24.0000, 0.54860520362854 sec\n",
      "Episode 6907, len6, loss:-69.3800, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5494832992553711 sec\n",
      "Episode 6908, len10, loss:-87.6450, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5498828887939453 sec\n",
      "Episode 6909, len6, loss:-71.9311, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5500571727752686 sec\n",
      "Episode 6910, len12, loss:-95.2570, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5505335330963135 sec\n",
      "Episode 6911, len8, loss:-72.2093, fail, steps:80, opt steps:33, total reward:-24.0000, 0.548891544342041 sec\n",
      "Episode 6912, len8, loss:-69.0225, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5505270957946777 sec\n",
      "Episode 6913, len12, loss:-99.8646, fail, steps:80, opt steps:47, total reward:-24.0000, 0.600475549697876 sec\n",
      "Episode 6914, len6, loss:-70.2055, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5487794876098633 sec\n",
      "Episode 6915, len8, loss:-63.3886, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5504279136657715 sec\n",
      "Episode 6916, len8, loss:-60.8286, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5499014854431152 sec\n",
      "Episode 6917, len8, loss:-70.7517, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5505890846252441 sec\n",
      "Episode 6918, len10, loss:-89.3977, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5500166416168213 sec\n",
      "Episode 6919, len12, loss:-99.3932, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5492067337036133 sec\n",
      "Episode 6920, len10, loss:-92.5135, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5498065948486328 sec\n",
      "Episode 6921, len10, loss:-79.8613, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5524590015411377 sec\n",
      "Episode 6922, len8, loss:-63.4174, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5494699478149414 sec\n",
      "Episode 6923, len12, loss:-95.5781, fail, steps:80, opt steps:63, total reward:-24.0000, 0.549785852432251 sec\n",
      "Episode 6924, len8, loss:-72.2164, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5498154163360596 sec\n",
      "Episode 6925, len12, loss:-98.6932, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5504233837127686 sec\n",
      "Episode 6926, len10, loss:-84.5206, fail, steps:80, opt steps:19, total reward:-24.0000, 0.548729419708252 sec\n",
      "Episode 6927, len12, loss:-95.0138, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5489885807037354 sec\n",
      "Episode 6928, len8, loss:-71.8034, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5998144149780273 sec\n",
      "Episode 6929, len12, loss:-92.5417, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5487511157989502 sec\n",
      "Episode 6930, len6, loss:-69.7067, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5487689971923828 sec\n",
      "Episode 6931, len10, loss:-79.7915, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5495781898498535 sec\n",
      "Episode 6932, len12, loss:-98.6705, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5490071773529053 sec\n",
      "Episode 6933, len6, loss:-67.3746, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5487279891967773 sec\n",
      "Episode 6934, len10, loss:-76.3674, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5504980087280273 sec\n",
      "Episode 6935, len12, loss:-88.9267, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5491471290588379 sec\n",
      "Episode 6936, len12, loss:-97.9352, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5493478775024414 sec\n",
      "Episode 6937, len12, loss:-95.2155, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5499176979064941 sec\n",
      "Episode 6938, len10, loss:-80.2176, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5487575531005859 sec\n",
      "Episode 6939, len12, loss:-101.8071, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5497121810913086 sec\n",
      "Episode 6940, len10, loss:-86.2232, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5491111278533936 sec\n",
      "Episode 6941, len12, loss:-93.9697, fail, steps:80, opt steps:23, total reward:-24.0000, 0.549821138381958 sec\n",
      "Episode 6942, len8, loss:-72.0396, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5502800941467285 sec\n",
      "Episode 6943, len12, loss:-98.4311, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5488908290863037 sec\n",
      "Episode 6944, len8, loss:-76.2160, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5991082191467285 sec\n",
      "Episode 6945, len12, loss:-97.2886, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5481517314910889 sec\n",
      "Episode 6946, len10, loss:-76.7159, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5476934909820557 sec\n",
      "Episode 6947, len10, loss:-80.5711, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5469768047332764 sec\n",
      "Episode 6948, len8, loss:-69.0987, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5489518642425537 sec\n",
      "Episode 6949, len12, loss:-92.9161, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485496520996094 sec\n",
      "Episode 6950, len12, loss:-89.8825, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5474107265472412 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6951, len6, loss:-62.4070, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5483853816986084 sec\n",
      "Episode 6952, len12, loss:-97.6472, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5490546226501465 sec\n",
      "Episode 6953, len8, loss:-69.3556, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5449402332305908 sec\n",
      "Episode 6954, len10, loss:-75.7691, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5480408668518066 sec\n",
      "Episode 6955, len6, loss:-66.9662, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5483212471008301 sec\n",
      "Episode 6956, len12, loss:-91.1053, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5493454933166504 sec\n",
      "Episode 6957, len8, loss:-67.0072, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5486791133880615 sec\n",
      "Episode 6958, len8, loss:-64.2514, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5481736660003662 sec\n",
      "Episode 6959, len10, loss:-90.3448, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5479152202606201 sec\n",
      "Episode 6960, len12, loss:-90.8975, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5986666679382324 sec\n",
      "Episode 6961, len8, loss:-64.2866, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5489568710327148 sec\n",
      "Episode 6962, len8, loss:-59.7240, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5503182411193848 sec\n",
      "Episode 6963, len12, loss:-88.0164, fail, steps:80, opt steps:75, total reward:-24.0000, 0.5499277114868164 sec\n",
      "Episode 6964, len8, loss:-63.8590, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5483689308166504 sec\n",
      "Episode 6965, len6, loss:-64.8913, fail, steps:80, opt steps:13, total reward:-24.0000, 0.549088716506958 sec\n",
      "Episode 6966, len10, loss:-86.1062, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5519850254058838 sec\n",
      "Episode 6967, len6, loss:-70.3291, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5482604503631592 sec\n",
      "Episode 6968, len12, loss:-83.3856, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5514280796051025 sec\n",
      "Episode 6969, len8, loss:-71.0431, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5502846240997314 sec\n",
      "Episode 6970, len12, loss:-94.2937, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5479226112365723 sec\n",
      "Episode 6971, len10, loss:-83.2590, fail, steps:80, opt steps:34, total reward:-24.0000, 0.548811674118042 sec\n",
      "Episode 6972, len8, loss:-70.7569, fail, steps:80, opt steps:33, total reward:-24.0000, 0.549708366394043 sec\n",
      "Episode 6973, len8, loss:-80.0548, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5971510410308838 sec\n",
      "Episode 6974, len12, loss:-95.8143, fail, steps:80, opt steps:61, total reward:-24.0000, 0.548922061920166 sec\n",
      "Episode 6975, len12, loss:-97.1717, fail, steps:80, opt steps:67, total reward:-24.0000, 0.549126148223877 sec\n",
      "Episode 6976, len12, loss:-98.9338, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5495574474334717 sec\n",
      "Episode 6977, len10, loss:-81.6843, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5493924617767334 sec\n",
      "Episode 6978, len10, loss:-87.3002, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5494682788848877 sec\n",
      "Episode 6979, len8, loss:-67.2437, fail, steps:80, opt steps:16, total reward:-24.0000, 0.549292802810669 sec\n",
      "Episode 6980, len10, loss:-87.3815, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5499382019042969 sec\n",
      "Episode 6981, len10, loss:-80.3893, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5504796504974365 sec\n",
      "Episode 6982, len6, loss:-63.4851, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5488901138305664 sec\n",
      "Episode 6983, len10, loss:-79.5077, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5495977401733398 sec\n",
      "Episode 6984, len10, loss:-88.4292, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5488810539245605 sec\n",
      "Episode 6985, len8, loss:-68.8901, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5506913661956787 sec\n",
      "Episode 6986, len6, loss:-69.0990, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5484507083892822 sec\n",
      "Episode 6987, len8, loss:-64.8612, fail, steps:80, opt steps:16, total reward:-24.0000, 0.6048793792724609 sec\n",
      "Episode 6988, len6, loss:-63.7973, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5485339164733887 sec\n",
      "Episode 6989, len10, loss:-75.1429, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5489366054534912 sec\n",
      "Episode 6990, len8, loss:-60.8460, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485172271728516 sec\n",
      "Episode 6991, len10, loss:-82.4941, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5492455959320068 sec\n",
      "Episode 6992, len6, loss:-68.9361, fail, steps:80, opt steps:6, total reward:-24.0000, 0.548222541809082 sec\n",
      "Episode 6993, len8, loss:-66.1327, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5476205348968506 sec\n",
      "Episode 6994, len12, loss:-92.6073, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5485358238220215 sec\n",
      "Episode 6995, len6, loss:-61.7732, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5478231906890869 sec\n",
      "Episode 6996, len6, loss:-66.1951, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5486476421356201 sec\n",
      "Episode 6997, len10, loss:-90.7745, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5494916439056396 sec\n",
      "Episode 6998, len12, loss:-88.2177, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5488035678863525 sec\n",
      "Episode 6999, len10, loss:-85.5722, fail, steps:80, opt steps:26, total reward:-24.0000, 0.551842212677002 sec\n",
      "Episode 7000, len6, loss:-65.9150, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5489356517791748 sec\n",
      "Checkpoint saved at episode 7000 to /home/mcwave/code/autocode/datasets/rl_sort_transformer_easy/list6_12_transformer3_128_gamma07_step80_v3_merge_2_sorted/ckpt_7000_0.0000_26.24_vs_5.25.pth\n",
      "Learning rate = 0.000087\n",
      "Episode 7001, len8, loss:-64.4643, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5966963768005371 sec\n",
      "Episode 7002, len8, loss:-62.8464, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5492846965789795 sec\n",
      "Episode 7003, len10, loss:-82.8956, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5504348278045654 sec\n",
      "Episode 7004, len10, loss:-84.8917, fail, steps:80, opt steps:35, total reward:-24.7000, 0.545691728591919 sec\n",
      "Episode 7005, len6, loss:-66.7606, fail, steps:80, opt steps:18, total reward:-24.0000, 0.549915075302124 sec\n",
      "Episode 7006, len10, loss:-81.1559, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5500009059906006 sec\n",
      "Episode 7007, len12, loss:-97.2015, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5485775470733643 sec\n",
      "Episode 7008, len8, loss:-65.6591, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5486934185028076 sec\n",
      "Episode 7009, len12, loss:-97.2626, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5503284931182861 sec\n",
      "Episode 7010, len10, loss:-89.2039, fail, steps:80, opt steps:35, total reward:-24.0000, 0.552849292755127 sec\n",
      "Episode 7011, len10, loss:-86.4668, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5490894317626953 sec\n",
      "Episode 7012, len10, loss:-81.5223, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5501720905303955 sec\n",
      "Episode 7013, len8, loss:-63.2307, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5490131378173828 sec\n",
      "Episode 7014, len10, loss:-80.7111, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5497012138366699 sec\n",
      "Episode 7015, len12, loss:-87.5447, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5496666431427002 sec\n",
      "Episode 7016, len6, loss:-65.4442, fail, steps:80, opt steps:7, total reward:-24.0000, 0.599254846572876 sec\n",
      "Episode 7017, len12, loss:-88.7171, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5509388446807861 sec\n",
      "Episode 7018, len8, loss:-61.6117, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5498032569885254 sec\n",
      "Episode 7019, len8, loss:-66.1012, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5534677505493164 sec\n",
      "Episode 7020, len10, loss:-88.5845, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5478460788726807 sec\n",
      "Episode 7021, len12, loss:-92.6125, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5497403144836426 sec\n",
      "Episode 7022, len8, loss:-64.0633, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5472877025604248 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7023, len10, loss:-81.3594, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5468275547027588 sec\n",
      "Episode 7024, len12, loss:-89.7405, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5490548610687256 sec\n",
      "Episode 7025, len6, loss:-69.4537, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5474023818969727 sec\n",
      "Episode 7026, len10, loss:-86.2124, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5480291843414307 sec\n",
      "Episode 7027, len6, loss:-65.4944, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5478143692016602 sec\n",
      "Episode 7028, len10, loss:-72.5804, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5502216815948486 sec\n",
      "Episode 7029, len12, loss:-90.4059, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5492749214172363 sec\n",
      "Episode 7030, len8, loss:-59.9340, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548358678817749 sec\n",
      "Episode 7031, len8, loss:-60.1377, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5497171878814697 sec\n",
      "Episode 7032, len12, loss:-91.6566, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5972754955291748 sec\n",
      "Episode 7033, len12, loss:-92.2905, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5494804382324219 sec\n",
      "Episode 7034, len8, loss:-57.0702, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5483713150024414 sec\n",
      "Episode 7035, len10, loss:-82.6476, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5478630065917969 sec\n",
      "Episode 7036, len12, loss:-98.4975, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5499649047851562 sec\n",
      "Episode 7037, len10, loss:-88.3902, fail, steps:80, opt steps:27, total reward:-24.0000, 0.547865629196167 sec\n",
      "Episode 7038, len8, loss:-69.8700, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5493309497833252 sec\n",
      "Episode 7039, len12, loss:-91.3491, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5480968952178955 sec\n",
      "Episode 7040, len12, loss:-97.6627, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5476095676422119 sec\n",
      "Episode 7041, len6, loss:-65.2899, fail, steps:80, opt steps:3, total reward:-24.0000, 0.547252893447876 sec\n",
      "Episode 7042, len6, loss:-64.4073, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5485188961029053 sec\n",
      "Episode 7043, len12, loss:-90.3495, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5483477115631104 sec\n",
      "Episode 7044, len12, loss:-96.1125, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5483009815216064 sec\n",
      "Episode 7045, len10, loss:-84.2992, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5502002239227295 sec\n",
      "Episode 7046, len10, loss:-87.7320, fail, steps:80, opt steps:37, total reward:-24.0000, 0.548598051071167 sec\n",
      "Episode 7047, len8, loss:-68.6299, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5509617328643799 sec\n",
      "Episode 7048, len10, loss:-86.0071, fail, steps:80, opt steps:35, total reward:-24.0000, 0.6002728939056396 sec\n",
      "Episode 7049, len12, loss:-95.3451, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5491147041320801 sec\n",
      "Episode 7050, len6, loss:-68.1036, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5491738319396973 sec\n",
      "Episode 7051, len10, loss:-83.9184, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5495443344116211 sec\n",
      "Episode 7052, len6, loss:-62.9302, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5495519638061523 sec\n",
      "Episode 7053, len10, loss:-87.4866, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5495600700378418 sec\n",
      "Episode 7054, len10, loss:-81.6248, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5484464168548584 sec\n",
      "Episode 7055, len8, loss:-71.3679, fail, steps:80, opt steps:21, total reward:-24.7000, 0.543471097946167 sec\n",
      "Episode 7056, len12, loss:-96.2180, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5483629703521729 sec\n",
      "Episode 7057, len6, loss:-62.6335, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5475609302520752 sec\n",
      "Episode 7058, len12, loss:-93.6057, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5482301712036133 sec\n",
      "Episode 7059, len10, loss:-79.4984, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5483534336090088 sec\n",
      "Episode 7060, len8, loss:-64.7840, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5494832992553711 sec\n",
      "Episode 7061, len6, loss:-55.0472, fail, steps:80, opt steps:8, total reward:-24.0000, 0.6033971309661865 sec\n",
      "Episode 7062, len6, loss:-63.0071, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5491423606872559 sec\n",
      "Episode 7063, len6, loss:-60.2854, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5477132797241211 sec\n",
      "Episode 7064, len12, loss:-90.7937, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5496134757995605 sec\n",
      "Episode 7065, len6, loss:-64.2038, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5493552684783936 sec\n",
      "Episode 7066, len8, loss:-69.8812, fail, steps:80, opt steps:9, total reward:-24.7000, 0.5452690124511719 sec\n",
      "Episode 7067, len6, loss:-66.2534, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5491611957550049 sec\n",
      "Episode 7068, len6, loss:-62.1307, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5483899116516113 sec\n",
      "Episode 7069, len12, loss:-98.0976, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5484836101531982 sec\n",
      "Episode 7070, len12, loss:-88.8541, fail, steps:80, opt steps:43, total reward:-24.0000, 0.549044132232666 sec\n",
      "Episode 7071, len8, loss:-68.7339, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5499088764190674 sec\n",
      "Episode 7072, len6, loss:-62.3030, fail, steps:80, opt steps:10, total reward:-24.0000, 0.548736572265625 sec\n",
      "Episode 7073, len12, loss:-96.3580, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5495500564575195 sec\n",
      "Episode 7074, len10, loss:-77.2335, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5495200157165527 sec\n",
      "Episode 7075, len6, loss:-64.7099, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6019694805145264 sec\n",
      "Episode 7076, len8, loss:-73.2770, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5489411354064941 sec\n",
      "Episode 7077, len8, loss:-77.4827, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5486879348754883 sec\n",
      "Episode 7078, len12, loss:-94.3520, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5481407642364502 sec\n",
      "Episode 7079, len8, loss:-71.3896, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5491580963134766 sec\n",
      "Episode 7080, len10, loss:-85.5262, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5485413074493408 sec\n",
      "Episode 7081, len12, loss:-109.2043, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5489764213562012 sec\n",
      "Episode 7082, len8, loss:-67.8808, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5489754676818848 sec\n",
      "Episode 7083, len8, loss:-72.4429, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5502028465270996 sec\n",
      "Episode 7084, len8, loss:-69.3058, fail, steps:80, opt steps:34, total reward:-24.0000, 0.549447774887085 sec\n",
      "Episode 7085, len6, loss:-68.0549, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5490829944610596 sec\n",
      "Episode 7086, len12, loss:-83.4820, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5506958961486816 sec\n",
      "Episode 7087, len12, loss:-88.6873, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5483152866363525 sec\n",
      "Episode 7088, len10, loss:-79.3911, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5576496124267578 sec\n",
      "Episode 7089, len12, loss:-94.0399, fail, steps:80, opt steps:63, total reward:-24.0000, 0.6034102439880371 sec\n",
      "Episode 7090, len6, loss:-64.3606, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5485329627990723 sec\n",
      "Episode 7091, len10, loss:-85.8925, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5508842468261719 sec\n",
      "Episode 7092, len12, loss:-100.2984, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5494179725646973 sec\n",
      "Episode 7093, len12, loss:-96.2068, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5485727787017822 sec\n",
      "Episode 7094, len12, loss:-98.0968, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5489435195922852 sec\n",
      "Episode 7095, len8, loss:-66.0176, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5484857559204102 sec\n",
      "Episode 7096, len8, loss:-68.1492, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5487523078918457 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7097, len10, loss:-87.9485, fail, steps:80, opt steps:43, total reward:-23.7000, 0.5438005924224854 sec\n",
      "Episode 7098, len6, loss:-72.3633, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5481231212615967 sec\n",
      "Episode 7099, len6, loss:-63.4302, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5499062538146973 sec\n",
      "Episode 7100, len8, loss:-66.7561, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5490808486938477 sec\n",
      "Episode 7101, len8, loss:-63.8465, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5487890243530273 sec\n",
      "Episode 7102, len6, loss:-73.7331, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5491929054260254 sec\n",
      "Episode 7103, len12, loss:-99.1360, fail, steps:80, opt steps:50, total reward:-24.0000, 0.599043607711792 sec\n",
      "Episode 7104, len6, loss:-66.2820, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5487420558929443 sec\n",
      "Episode 7105, len8, loss:-64.2365, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5490405559539795 sec\n",
      "Episode 7106, len12, loss:-90.8716, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5504229068756104 sec\n",
      "Episode 7107, len6, loss:-73.8750, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5496740341186523 sec\n",
      "Episode 7108, len12, loss:-100.4803, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5489938259124756 sec\n",
      "Episode 7109, len12, loss:-86.0057, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5488059520721436 sec\n",
      "Episode 7110, len6, loss:-66.5790, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5471794605255127 sec\n",
      "Episode 7111, len6, loss:-68.0804, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5481562614440918 sec\n",
      "Episode 7112, len12, loss:-92.2461, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5493419170379639 sec\n",
      "Episode 7113, len6, loss:-69.1257, fail, steps:80, opt steps:7, total reward:-24.0000, 0.548001766204834 sec\n",
      "Episode 7114, len10, loss:-82.5372, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5497543811798096 sec\n",
      "Episode 7115, len12, loss:-92.5076, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5484516620635986 sec\n",
      "Episode 7116, len10, loss:-86.2800, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5486669540405273 sec\n",
      "Episode 7117, len6, loss:-71.0390, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5991652011871338 sec\n",
      "Episode 7118, len8, loss:-61.6849, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5495712757110596 sec\n",
      "Episode 7119, len8, loss:-68.6526, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5466814041137695 sec\n",
      "Episode 7120, len8, loss:-71.4478, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5479881763458252 sec\n",
      "Episode 7121, len10, loss:-81.3763, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5478003025054932 sec\n",
      "Episode 7122, len10, loss:-83.6317, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5479240417480469 sec\n",
      "Episode 7123, len12, loss:-87.8331, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5483236312866211 sec\n",
      "Episode 7124, len6, loss:-67.9115, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5495345592498779 sec\n",
      "Episode 7125, len8, loss:-58.2906, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5472614765167236 sec\n",
      "Episode 7126, len8, loss:-57.1960, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5496525764465332 sec\n",
      "Episode 7127, len12, loss:-84.0139, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5480751991271973 sec\n",
      "Episode 7128, len8, loss:-66.3143, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5483391284942627 sec\n",
      "Episode 7129, len8, loss:-65.8643, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5485105514526367 sec\n",
      "Episode 7130, len6, loss:-64.0404, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5474143028259277 sec\n",
      "Episode 7131, len8, loss:-52.8072, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5475032329559326 sec\n",
      "Episode 7132, len12, loss:-85.9847, fail, steps:80, opt steps:27, total reward:-24.0000, 0.6022069454193115 sec\n",
      "Episode 7133, len6, loss:-69.0356, fail, steps:80, opt steps:20, total reward:-24.0000, 0.548062801361084 sec\n",
      "Episode 7134, len8, loss:-62.0751, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5461266040802002 sec\n",
      "Episode 7135, len12, loss:-94.4085, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5479795932769775 sec\n",
      "Episode 7136, len8, loss:-65.8361, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5470521450042725 sec\n",
      "Episode 7137, len10, loss:-78.8262, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5477027893066406 sec\n",
      "Episode 7138, len12, loss:-88.5707, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5484647750854492 sec\n",
      "Episode 7139, len6, loss:-73.4239, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5474424362182617 sec\n",
      "Episode 7140, len10, loss:-85.4584, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5481677055358887 sec\n",
      "Episode 7141, len10, loss:-83.7773, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5462801456451416 sec\n",
      "Episode 7142, len10, loss:-85.8441, fail, steps:80, opt steps:36, total reward:-24.0000, 0.548133134841919 sec\n",
      "Episode 7143, len10, loss:-84.3290, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5480124950408936 sec\n",
      "Episode 7144, len8, loss:-63.4515, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5483431816101074 sec\n",
      "Episode 7145, len6, loss:-67.8894, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5477075576782227 sec\n",
      "Episode 7146, len6, loss:-72.6155, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5478696823120117 sec\n",
      "Episode 7147, len12, loss:-99.3563, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5478377342224121 sec\n",
      "Episode 7148, len6, loss:-72.7809, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5963759422302246 sec\n",
      "Episode 7149, len8, loss:-59.9880, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5466556549072266 sec\n",
      "Episode 7150, len8, loss:-68.9691, fail, steps:80, opt steps:17, total reward:-24.0000, 0.547102689743042 sec\n",
      "Episode 7151, len10, loss:-81.8799, fail, steps:80, opt steps:43, total reward:-24.0000, 0.547863245010376 sec\n",
      "Episode 7152, len6, loss:-74.0517, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5477306842803955 sec\n",
      "Episode 7153, len10, loss:-84.7427, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5472261905670166 sec\n",
      "Episode 7154, len6, loss:-75.4181, fail, steps:80, opt steps:18, total reward:-24.0000, 0.547778844833374 sec\n",
      "Episode 7155, len6, loss:-69.5963, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5475099086761475 sec\n",
      "Episode 7156, len10, loss:-78.1446, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5474326610565186 sec\n",
      "Episode 7157, len12, loss:-87.1904, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5471072196960449 sec\n",
      "Episode 7158, len10, loss:-94.5201, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5502467155456543 sec\n",
      "Episode 7159, len6, loss:-72.9262, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5494711399078369 sec\n",
      "Episode 7160, len10, loss:-78.9202, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5499598979949951 sec\n",
      "Episode 7161, len10, loss:-86.4110, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5489718914031982 sec\n",
      "Episode 7162, len12, loss:-96.6262, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5486197471618652 sec\n",
      "Episode 7163, len6, loss:-70.2935, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5484235286712646 sec\n",
      "Episode 7164, len10, loss:-91.9756, fail, steps:80, opt steps:39, total reward:-24.0000, 0.598785400390625 sec\n",
      "Episode 7165, len6, loss:-70.8378, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5499241352081299 sec\n",
      "Episode 7166, len10, loss:-79.9002, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5489969253540039 sec\n",
      "Episode 7167, len10, loss:-74.4600, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5480453968048096 sec\n",
      "Episode 7168, len10, loss:-75.8533, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5474977493286133 sec\n",
      "Episode 7169, len8, loss:-63.5339, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5484380722045898 sec\n",
      "Episode 7170, len6, loss:-68.0372, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5466954708099365 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7171, len8, loss:-63.2363, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5429840087890625 sec\n",
      "Episode 7172, len10, loss:-93.8592, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5429286956787109 sec\n",
      "Episode 7173, len8, loss:-78.0818, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5472307205200195 sec\n",
      "Episode 7174, len6, loss:-76.3386, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5465903282165527 sec\n",
      "Episode 7175, len12, loss:-93.2196, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5483286380767822 sec\n",
      "Episode 7176, len6, loss:-74.3684, fail, steps:80, opt steps:13, total reward:-24.0000, 0.548224925994873 sec\n",
      "Episode 7177, len6, loss:-72.1511, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6065399646759033 sec\n",
      "Episode 7178, len8, loss:-65.7245, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5472853183746338 sec\n",
      "Episode 7179, len6, loss:-66.1560, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5487778186798096 sec\n",
      "Episode 7180, len6, loss:-67.5622, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5487232208251953 sec\n",
      "Episode 7181, len6, loss:-69.1570, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5481274127960205 sec\n",
      "Episode 7182, len10, loss:-83.1482, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5477104187011719 sec\n",
      "Episode 7183, len6, loss:-75.9339, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5478973388671875 sec\n",
      "Episode 7184, len8, loss:-61.1236, fail, steps:80, opt steps:21, total reward:-24.0000, 0.548194408416748 sec\n",
      "Episode 7185, len6, loss:-66.8351, fail, steps:80, opt steps:14, total reward:-24.0000, 0.548508882522583 sec\n",
      "Episode 7186, len10, loss:-79.0891, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5461757183074951 sec\n",
      "Episode 7187, len10, loss:-81.2633, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5490028858184814 sec\n",
      "Episode 7188, len12, loss:-100.2737, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5475678443908691 sec\n",
      "Episode 7189, len12, loss:-89.4094, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5474841594696045 sec\n",
      "Episode 7190, len10, loss:-78.6652, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5489389896392822 sec\n",
      "Episode 7191, len10, loss:-83.9648, fail, steps:80, opt steps:28, total reward:-24.0000, 0.6010894775390625 sec\n",
      "Episode 7192, len6, loss:-74.8621, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5491094589233398 sec\n",
      "Episode 7193, len12, loss:-97.3982, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5481946468353271 sec\n",
      "Episode 7194, len8, loss:-59.3176, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5487847328186035 sec\n",
      "Episode 7195, len10, loss:-82.8285, fail, steps:80, opt steps:20, total reward:-24.0000, 0.548438549041748 sec\n",
      "Episode 7196, len8, loss:-69.4057, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5483014583587646 sec\n",
      "Episode 7197, len10, loss:-85.4930, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5479960441589355 sec\n",
      "Episode 7198, len6, loss:-68.6818, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5483226776123047 sec\n",
      "Episode 7199, len10, loss:-81.6310, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5476574897766113 sec\n",
      "Episode 7200, len10, loss:-82.1977, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5480785369873047 sec\n",
      "Episode 7201, len12, loss:-93.2310, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5479402542114258 sec\n",
      "Episode 7202, len12, loss:-94.9306, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5484530925750732 sec\n",
      "Episode 7203, len6, loss:-67.7634, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5479190349578857 sec\n",
      "Episode 7204, len10, loss:-75.6851, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5470218658447266 sec\n",
      "Episode 7205, len6, loss:-65.7748, fail, steps:80, opt steps:5, total reward:-24.0000, 0.604771614074707 sec\n",
      "Episode 7206, len12, loss:-91.8028, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5488874912261963 sec\n",
      "Episode 7207, len8, loss:-65.1387, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5486464500427246 sec\n",
      "Episode 7208, len6, loss:-68.6373, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5494685173034668 sec\n",
      "Episode 7209, len12, loss:-92.7370, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5490498542785645 sec\n",
      "Episode 7210, len8, loss:-64.6251, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5470588207244873 sec\n",
      "Episode 7211, len10, loss:-82.0013, fail, steps:80, opt steps:27, total reward:-24.0000, 0.547415018081665 sec\n",
      "Episode 7212, len6, loss:-72.2084, fail, steps:80, opt steps:10, total reward:-24.0000, 0.547175407409668 sec\n",
      "Episode 7213, len6, loss:-70.8217, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5475859642028809 sec\n",
      "Episode 7214, len6, loss:-71.0064, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5463416576385498 sec\n",
      "Episode 7215, len8, loss:-69.4390, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5471389293670654 sec\n",
      "Episode 7216, len10, loss:-80.7171, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5491361618041992 sec\n",
      "Episode 7217, len8, loss:-65.2536, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5478682518005371 sec\n",
      "Episode 7218, len10, loss:-88.7906, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5469591617584229 sec\n",
      "Episode 7219, len10, loss:-87.9331, fail, steps:80, opt steps:36, total reward:-24.0000, 0.6012864112854004 sec\n",
      "Episode 7220, len12, loss:-88.4926, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5470771789550781 sec\n",
      "Episode 7221, len8, loss:-65.6528, fail, steps:80, opt steps:28, total reward:-24.0000, 0.548309326171875 sec\n",
      "Episode 7222, len6, loss:-71.5458, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5489170551300049 sec\n",
      "Episode 7223, len8, loss:-63.0948, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5466151237487793 sec\n",
      "Episode 7224, len12, loss:-92.4928, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5479512214660645 sec\n",
      "Episode 7225, len8, loss:-70.4293, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5487387180328369 sec\n",
      "Episode 7226, len6, loss:-71.9624, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5479419231414795 sec\n",
      "Episode 7227, len6, loss:-69.3994, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5482759475708008 sec\n",
      "Episode 7228, len12, loss:-97.5792, fail, steps:80, opt steps:53, total reward:-24.0000, 0.548121452331543 sec\n",
      "Episode 7229, len6, loss:-72.3794, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5476474761962891 sec\n",
      "Episode 7230, len6, loss:-67.3144, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5481734275817871 sec\n",
      "Episode 7231, len8, loss:-69.0006, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5469858646392822 sec\n",
      "Episode 7232, len10, loss:-82.9056, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5480601787567139 sec\n",
      "Episode 7233, len6, loss:-80.0773, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5941483974456787 sec\n",
      "Episode 7234, len10, loss:-68.0437, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5492274761199951 sec\n",
      "Episode 7235, len6, loss:-69.3148, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5482528209686279 sec\n",
      "Episode 7236, len12, loss:-106.5739, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5482323169708252 sec\n",
      "Episode 7237, len12, loss:-86.1053, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5479450225830078 sec\n",
      "Episode 7238, len12, loss:-86.7364, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5489974021911621 sec\n",
      "Episode 7239, len10, loss:-80.8742, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5476596355438232 sec\n",
      "Episode 7240, len8, loss:-65.0948, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5461502075195312 sec\n",
      "Episode 7241, len6, loss:-73.2939, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5479145050048828 sec\n",
      "Episode 7242, len10, loss:-83.3179, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5479483604431152 sec\n",
      "Episode 7243, len10, loss:-78.3981, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5472946166992188 sec\n",
      "Episode 7244, len10, loss:-78.9927, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5487327575683594 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7245, len12, loss:-96.3313, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5496535301208496 sec\n",
      "Episode 7246, len10, loss:-82.3628, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5489480495452881 sec\n",
      "Episode 7247, len12, loss:-88.7588, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5468242168426514 sec\n",
      "Episode 7248, len12, loss:-95.4146, fail, steps:80, opt steps:45, total reward:-24.0000, 0.6024644374847412 sec\n",
      "Episode 7249, len8, loss:-68.8153, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5479834079742432 sec\n",
      "Episode 7250, len6, loss:-70.8741, fail, steps:80, opt steps:14, total reward:-24.0000, 0.548431396484375 sec\n",
      "Episode 7251, len6, loss:-72.1542, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5488133430480957 sec\n",
      "Episode 7252, len8, loss:-72.6928, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5489790439605713 sec\n",
      "Episode 7253, len8, loss:-62.6300, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5481390953063965 sec\n",
      "Episode 7254, len10, loss:-85.5659, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5506715774536133 sec\n",
      "Episode 7255, len12, loss:-93.0721, fail, steps:80, opt steps:77, total reward:-24.0000, 0.5485851764678955 sec\n",
      "Episode 7256, len8, loss:-75.9587, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5498740673065186 sec\n",
      "Episode 7257, len8, loss:-68.6342, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5510320663452148 sec\n",
      "Episode 7258, len6, loss:-68.1323, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5486226081848145 sec\n",
      "Episode 7259, len12, loss:-93.3420, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5491330623626709 sec\n",
      "Episode 7260, len12, loss:-85.8139, fail, steps:80, opt steps:42, total reward:-22.7000, 0.5437226295471191 sec\n",
      "Episode 7261, len10, loss:-82.1008, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5478053092956543 sec\n",
      "Episode 7262, len6, loss:-75.4053, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5486733913421631 sec\n",
      "Episode 7263, len10, loss:-87.4019, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5491857528686523 sec\n",
      "Episode 7264, len12, loss:-87.4614, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5992038249969482 sec\n",
      "Episode 7265, len10, loss:-90.3209, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5473535060882568 sec\n",
      "Episode 7266, len8, loss:-70.4050, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5503060817718506 sec\n",
      "Episode 7267, len6, loss:-72.7021, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5507891178131104 sec\n",
      "Episode 7268, len10, loss:-78.6432, fail, steps:80, opt steps:35, total reward:-24.0000, 0.548985481262207 sec\n",
      "Episode 7269, len6, loss:-72.5695, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5483810901641846 sec\n",
      "Episode 7270, len8, loss:-69.4008, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5490498542785645 sec\n",
      "Episode 7271, len8, loss:-68.3176, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5491948127746582 sec\n",
      "Episode 7272, len12, loss:-88.4413, fail, steps:80, opt steps:27, total reward:-24.0000, 0.548393726348877 sec\n",
      "Episode 7273, len10, loss:-83.3061, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5491094589233398 sec\n",
      "Episode 7274, len6, loss:-75.2005, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5491759777069092 sec\n",
      "Episode 7275, len10, loss:-70.5406, fail, steps:80, opt steps:41, total reward:-24.0000, 0.547947883605957 sec\n",
      "Episode 7276, len6, loss:-73.7505, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5481898784637451 sec\n",
      "Episode 7277, len8, loss:-68.5413, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5493736267089844 sec\n",
      "Episode 7278, len6, loss:-70.1843, fail, steps:80, opt steps:6, total reward:-24.0000, 0.547919750213623 sec\n",
      "Episode 7279, len12, loss:-90.2122, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5490515232086182 sec\n",
      "Episode 7280, len12, loss:-87.2684, fail, steps:80, opt steps:33, total reward:-24.0000, 0.599900484085083 sec\n",
      "Episode 7281, len10, loss:-84.9325, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5485284328460693 sec\n",
      "Episode 7282, len10, loss:-86.1158, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5492579936981201 sec\n",
      "Episode 7283, len6, loss:-72.9919, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5497395992279053 sec\n",
      "Episode 7284, len8, loss:-61.9282, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5486435890197754 sec\n",
      "Episode 7285, len8, loss:-62.2041, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5489559173583984 sec\n",
      "Episode 7286, len6, loss:-72.2519, fail, steps:80, opt steps:11, total reward:-24.0000, 0.55019211769104 sec\n",
      "Episode 7287, len8, loss:-60.8868, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5492749214172363 sec\n",
      "Episode 7288, len10, loss:-72.4929, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5488038063049316 sec\n",
      "Episode 7289, len8, loss:-58.7475, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5486581325531006 sec\n",
      "Episode 7290, len12, loss:-91.5489, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5503833293914795 sec\n",
      "Episode 7291, len10, loss:-74.4064, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5470333099365234 sec\n",
      "Episode 7292, len12, loss:-92.5679, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5499758720397949 sec\n",
      "Episode 7293, len12, loss:-92.7598, fail, steps:80, opt steps:60, total reward:-24.0000, 0.6035852432250977 sec\n",
      "Episode 7294, len10, loss:-88.8244, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5492620468139648 sec\n",
      "Episode 7295, len6, loss:-75.0262, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5500133037567139 sec\n",
      "Episode 7296, len8, loss:-60.5939, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5503687858581543 sec\n",
      "Episode 7297, len10, loss:-80.3308, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5487689971923828 sec\n",
      "Episode 7298, len10, loss:-82.8691, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5484397411346436 sec\n",
      "Episode 7299, len12, loss:-91.2590, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5494680404663086 sec\n",
      "Episode 7300, len6, loss:-72.3534, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5491278171539307 sec\n",
      "Episode 7301, len6, loss:-74.1357, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5488705635070801 sec\n",
      "Episode 7302, len10, loss:-77.4629, fail, steps:80, opt steps:16, total reward:-24.0000, 0.549752950668335 sec\n",
      "Episode 7303, len8, loss:-65.6094, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5490546226501465 sec\n",
      "Episode 7304, len12, loss:-93.5835, fail, steps:80, opt steps:45, total reward:-24.0000, 0.549288272857666 sec\n",
      "Episode 7305, len8, loss:-65.3262, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5530552864074707 sec\n",
      "Episode 7306, len8, loss:-61.6495, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5516512393951416 sec\n",
      "Episode 7307, len10, loss:-75.8694, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5994031429290771 sec\n",
      "Episode 7308, len8, loss:-57.1168, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5510547161102295 sec\n",
      "Episode 7309, len6, loss:-68.4854, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5484066009521484 sec\n",
      "Episode 7310, len6, loss:-70.9835, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5495595932006836 sec\n",
      "Episode 7311, len10, loss:-85.7645, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5507838726043701 sec\n",
      "Episode 7312, len6, loss:-72.2390, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5495200157165527 sec\n",
      "Episode 7313, len8, loss:-69.8792, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5494463443756104 sec\n",
      "Episode 7314, len12, loss:-100.8085, fail, steps:80, opt steps:47, total reward:-24.7000, 0.5451014041900635 sec\n",
      "Episode 7315, len6, loss:-73.5538, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5481448173522949 sec\n",
      "Episode 7316, len10, loss:-87.7045, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5493838787078857 sec\n",
      "Episode 7317, len6, loss:-77.3407, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5493886470794678 sec\n",
      "Episode 7318, len10, loss:-78.1497, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5494935512542725 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7319, len8, loss:-64.2769, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5496554374694824 sec\n",
      "Episode 7320, len6, loss:-75.1108, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5495598316192627 sec\n",
      "Episode 7321, len6, loss:-74.8753, fail, steps:80, opt steps:5, total reward:-24.0000, 0.6020803451538086 sec\n",
      "Episode 7322, len10, loss:-77.3476, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5502870082855225 sec\n",
      "Episode 7323, len6, loss:-73.2357, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5491983890533447 sec\n",
      "Episode 7324, len10, loss:-69.8480, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5499134063720703 sec\n",
      "Episode 7325, len10, loss:-81.5922, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5501351356506348 sec\n",
      "Episode 7326, len8, loss:-67.4615, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5483548641204834 sec\n",
      "Episode 7327, len10, loss:-89.2579, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5482232570648193 sec\n",
      "Episode 7328, len8, loss:-65.0405, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5476961135864258 sec\n",
      "Episode 7329, len8, loss:-74.8007, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5505378246307373 sec\n",
      "Episode 7330, len12, loss:-92.2167, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5476410388946533 sec\n",
      "Episode 7331, len10, loss:-77.5283, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5521883964538574 sec\n",
      "Episode 7332, len12, loss:-96.1859, fail, steps:80, opt steps:78, total reward:-24.0000, 0.5493865013122559 sec\n",
      "Episode 7333, len8, loss:-70.3862, fail, steps:80, opt steps:6, total reward:-24.0000, 0.549537181854248 sec\n",
      "Episode 7334, len6, loss:-73.8069, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5497214794158936 sec\n",
      "Episode 7335, len6, loss:-81.7182, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5944740772247314 sec\n",
      "Episode 7336, len10, loss:-87.0510, fail, steps:80, opt steps:41, total reward:-24.0000, 0.548222541809082 sec\n",
      "Episode 7337, len12, loss:-85.7586, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5482544898986816 sec\n",
      "Episode 7338, len10, loss:-76.3578, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5484821796417236 sec\n",
      "Episode 7339, len6, loss:-76.0196, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5484457015991211 sec\n",
      "Episode 7340, len8, loss:-68.8336, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5513331890106201 sec\n",
      "Episode 7341, len8, loss:-74.3917, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5487966537475586 sec\n",
      "Episode 7342, len12, loss:-96.9617, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5499429702758789 sec\n",
      "Episode 7343, len8, loss:-65.5933, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5501244068145752 sec\n",
      "Episode 7344, len8, loss:-66.4914, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5498511791229248 sec\n",
      "Episode 7345, len8, loss:-68.3124, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5489804744720459 sec\n",
      "Episode 7346, len10, loss:-84.8083, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5497119426727295 sec\n",
      "Episode 7347, len10, loss:-75.4514, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5493371486663818 sec\n",
      "Episode 7348, len6, loss:-73.9983, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5490419864654541 sec\n",
      "Episode 7349, len6, loss:-73.6904, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5998992919921875 sec\n",
      "Episode 7350, len6, loss:-78.6963, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5495195388793945 sec\n",
      "Episode 7351, len6, loss:-73.3720, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5484623908996582 sec\n",
      "Episode 7352, len6, loss:-76.1220, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5500006675720215 sec\n",
      "Episode 7353, len8, loss:-54.4712, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5501255989074707 sec\n",
      "Episode 7354, len12, loss:-87.9791, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5498785972595215 sec\n",
      "Episode 7355, len8, loss:-54.2969, fail, steps:80, opt steps:27, total reward:-24.0000, 0.548198938369751 sec\n",
      "Episode 7356, len10, loss:-68.5822, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5493941307067871 sec\n",
      "Episode 7357, len8, loss:-59.2298, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5506880283355713 sec\n",
      "Episode 7358, len8, loss:-51.1087, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5494949817657471 sec\n",
      "Episode 7359, len10, loss:-82.4773, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5505306720733643 sec\n",
      "Episode 7360, len10, loss:-67.1088, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5507786273956299 sec\n",
      "Episode 7361, len12, loss:-79.9551, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5500180721282959 sec\n",
      "Episode 7362, len6, loss:-81.6552, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5448014736175537 sec\n",
      "Episode 7363, len6, loss:-76.3300, fail, steps:80, opt steps:5, total reward:-24.0000, 0.547656774520874 sec\n",
      "Episode 7364, len6, loss:-75.8874, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5987582206726074 sec\n",
      "Episode 7365, len8, loss:-54.0415, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5490691661834717 sec\n",
      "Episode 7366, len6, loss:-78.8712, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5480279922485352 sec\n",
      "Episode 7367, len10, loss:-70.4971, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5482125282287598 sec\n",
      "Episode 7368, len8, loss:-53.3391, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5507113933563232 sec\n",
      "Episode 7369, len10, loss:-73.2923, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5499064922332764 sec\n",
      "Episode 7370, len6, loss:-77.1881, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5481781959533691 sec\n",
      "Episode 7371, len12, loss:-94.9600, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5496218204498291 sec\n",
      "Episode 7372, len10, loss:-79.3799, fail, steps:80, opt steps:19, total reward:-24.0000, 0.549203634262085 sec\n",
      "Episode 7373, len10, loss:-63.9850, fail, steps:80, opt steps:19, total reward:-24.0000, 0.549828290939331 sec\n",
      "Episode 7374, len10, loss:-67.5369, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5495388507843018 sec\n",
      "Episode 7375, len10, loss:-66.3502, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5481655597686768 sec\n",
      "Episode 7376, len8, loss:-54.9091, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5489799976348877 sec\n",
      "Episode 7377, len8, loss:-51.8420, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5490481853485107 sec\n",
      "Episode 7378, len10, loss:-65.3867, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5488145351409912 sec\n",
      "Episode 7379, len8, loss:-58.1764, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5505666732788086 sec\n",
      "Episode 7380, len6, loss:-73.2953, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5968081951141357 sec\n",
      "Episode 7381, len10, loss:-62.8935, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5494318008422852 sec\n",
      "Episode 7382, len12, loss:-88.5654, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5512964725494385 sec\n",
      "Episode 7383, len10, loss:-60.4122, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5500297546386719 sec\n",
      "Episode 7384, len10, loss:-72.5883, fail, steps:80, opt steps:41, total reward:-24.0000, 0.54929518699646 sec\n",
      "Episode 7385, len6, loss:-74.5792, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5498197078704834 sec\n",
      "Episode 7386, len6, loss:-77.1044, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5492479801177979 sec\n",
      "Episode 7387, len12, loss:-87.9906, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5494940280914307 sec\n",
      "Episode 7388, len8, loss:-60.8192, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5486321449279785 sec\n",
      "Episode 7389, len6, loss:-75.9737, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5484085083007812 sec\n",
      "Episode 7390, len6, loss:-72.9999, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5494630336761475 sec\n",
      "Episode 7391, len12, loss:-80.7542, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5486795902252197 sec\n",
      "Episode 7392, len10, loss:-60.5478, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5492713451385498 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7393, len12, loss:-84.1517, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5499603748321533 sec\n",
      "Episode 7394, len12, loss:-85.6787, fail, steps:80, opt steps:17, total reward:-24.0000, 0.548555850982666 sec\n",
      "Episode 7395, len8, loss:-52.7554, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5490984916687012 sec\n",
      "Episode 7396, len8, loss:-44.7690, fail, steps:80, opt steps:27, total reward:-24.0000, 0.6008708477020264 sec\n",
      "Episode 7397, len10, loss:-71.8730, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5503084659576416 sec\n",
      "Episode 7398, len6, loss:-73.4231, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5497055053710938 sec\n",
      "Episode 7399, len6, loss:-73.1764, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5506978034973145 sec\n",
      "Episode 7400, len8, loss:-50.4161, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5505204200744629 sec\n",
      "Episode 7401, len10, loss:-67.7506, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5505499839782715 sec\n",
      "Episode 7402, len6, loss:-74.7806, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5485885143280029 sec\n",
      "Episode 7403, len6, loss:-72.0623, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5487008094787598 sec\n",
      "Episode 7404, len8, loss:-46.1453, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5490033626556396 sec\n",
      "Episode 7405, len6, loss:-71.6440, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5484228134155273 sec\n",
      "Episode 7406, len6, loss:-69.9088, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5493531227111816 sec\n",
      "Episode 7407, len8, loss:-55.5769, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5485067367553711 sec\n",
      "Episode 7408, len6, loss:-71.7248, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5520997047424316 sec\n",
      "Episode 7409, len8, loss:-50.7420, fail, steps:80, opt steps:9, total reward:-24.0000, 0.6036767959594727 sec\n",
      "Episode 7410, len8, loss:-54.9163, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5494225025177002 sec\n",
      "Episode 7411, len12, loss:-83.3312, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5497899055480957 sec\n",
      "Episode 7412, len10, loss:-68.3389, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5505878925323486 sec\n",
      "Episode 7413, len12, loss:-95.5676, fail, steps:80, opt steps:47, total reward:-24.0000, 0.548041820526123 sec\n",
      "Episode 7414, len8, loss:-55.6501, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5495321750640869 sec\n",
      "Episode 7415, len8, loss:-43.7783, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5481662750244141 sec\n",
      "Episode 7416, len10, loss:-73.7364, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5484931468963623 sec\n",
      "Episode 7417, len12, loss:-88.9811, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5487663745880127 sec\n",
      "Episode 7418, len6, loss:-71.0639, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5493309497833252 sec\n",
      "Episode 7419, len12, loss:-81.0320, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5508267879486084 sec\n",
      "Episode 7420, len6, loss:-74.2996, fail, steps:80, opt steps:20, total reward:-24.0000, 0.54998779296875 sec\n",
      "Episode 7421, len12, loss:-81.2032, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5498054027557373 sec\n",
      "Episode 7422, len6, loss:-75.4712, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5493600368499756 sec\n",
      "Episode 7423, len8, loss:-43.1068, fail, steps:80, opt steps:28, total reward:-24.0000, 0.601752519607544 sec\n",
      "Episode 7424, len6, loss:-73.1455, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5507264137268066 sec\n",
      "Episode 7425, len6, loss:-72.8950, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5496816635131836 sec\n",
      "Episode 7426, len10, loss:-82.2296, fail, steps:80, opt steps:27, total reward:-24.0000, 0.549354076385498 sec\n",
      "Episode 7427, len8, loss:-40.8284, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548429012298584 sec\n",
      "Episode 7428, len8, loss:-48.8528, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5481765270233154 sec\n",
      "Episode 7429, len6, loss:-74.1543, fail, steps:80, opt steps:11, total reward:-24.0000, 0.549595832824707 sec\n",
      "Episode 7430, len10, loss:-63.4427, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5486676692962646 sec\n",
      "Episode 7431, len6, loss:-71.2300, fail, steps:80, opt steps:8, total reward:-24.0000, 0.550055742263794 sec\n",
      "Episode 7432, len6, loss:-74.8583, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5491173267364502 sec\n",
      "Episode 7433, len12, loss:-85.5441, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5503401756286621 sec\n",
      "Episode 7434, len6, loss:-68.0582, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5496912002563477 sec\n",
      "Episode 7435, len8, loss:-55.6839, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5494973659515381 sec\n",
      "Episode 7436, len8, loss:-53.2353, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5503730773925781 sec\n",
      "Episode 7437, len8, loss:-55.0962, fail, steps:80, opt steps:34, total reward:-24.0000, 0.6006803512573242 sec\n",
      "Episode 7438, len6, loss:-73.6757, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5500283241271973 sec\n",
      "Episode 7439, len8, loss:-52.6958, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5487930774688721 sec\n",
      "Episode 7440, len10, loss:-66.2305, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5516684055328369 sec\n",
      "Episode 7441, len10, loss:-63.6009, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5514376163482666 sec\n",
      "Episode 7442, len12, loss:-79.1268, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5487556457519531 sec\n",
      "Episode 7443, len6, loss:-70.9092, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5487141609191895 sec\n",
      "Episode 7444, len10, loss:-66.3190, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5495636463165283 sec\n",
      "Episode 7445, len6, loss:-69.1676, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5503902435302734 sec\n",
      "Episode 7446, len10, loss:-65.2185, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5486545562744141 sec\n",
      "Episode 7447, len8, loss:-50.5379, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5504786968231201 sec\n",
      "Episode 7448, len12, loss:-89.3327, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5505266189575195 sec\n",
      "Episode 7449, len6, loss:-78.4181, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5495400428771973 sec\n",
      "Episode 7450, len12, loss:-85.0454, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5497653484344482 sec\n",
      "Episode 7451, len12, loss:-90.3919, fail, steps:80, opt steps:49, total reward:-24.0000, 0.6023175716400146 sec\n",
      "Episode 7452, len10, loss:-74.6655, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5490982532501221 sec\n",
      "Episode 7453, len6, loss:-66.9604, fail, steps:80, opt steps:18, total reward:-23.7000, 0.5442347526550293 sec\n",
      "Episode 7454, len8, loss:-53.2787, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5500030517578125 sec\n",
      "Episode 7455, len12, loss:-85.7701, fail, steps:80, opt steps:41, total reward:-24.0000, 0.549799919128418 sec\n",
      "Episode 7456, len6, loss:-66.2848, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5487303733825684 sec\n",
      "Episode 7457, len12, loss:-72.1014, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5493125915527344 sec\n",
      "Episode 7458, len6, loss:-73.4248, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5491981506347656 sec\n",
      "Episode 7459, len6, loss:-69.2112, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5484461784362793 sec\n",
      "Episode 7460, len12, loss:-81.5690, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5492796897888184 sec\n",
      "Episode 7461, len6, loss:-73.6190, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5496070384979248 sec\n",
      "Episode 7462, len10, loss:-64.9397, fail, steps:80, opt steps:20, total reward:-24.0000, 0.550915002822876 sec\n",
      "Episode 7463, len6, loss:-65.5607, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5505697727203369 sec\n",
      "Episode 7464, len10, loss:-72.3978, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5503766536712646 sec\n",
      "Episode 7465, len6, loss:-64.2100, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5994584560394287 sec\n",
      "Episode 7466, len10, loss:-69.6466, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5484416484832764 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7467, len10, loss:-71.5086, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5488524436950684 sec\n",
      "Episode 7468, len8, loss:-42.9741, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5482156276702881 sec\n",
      "Episode 7469, len12, loss:-79.9251, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5495505332946777 sec\n",
      "Episode 7470, len6, loss:-59.9545, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5484545230865479 sec\n",
      "Episode 7471, len8, loss:-41.6804, fail, steps:80, opt steps:12, total reward:-24.0000, 0.550727128982544 sec\n",
      "Episode 7472, len12, loss:-82.2402, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5494046211242676 sec\n",
      "Episode 7473, len12, loss:-80.3891, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5497117042541504 sec\n",
      "Episode 7474, len6, loss:-62.7360, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5504889488220215 sec\n",
      "Episode 7475, len12, loss:-78.6483, fail, steps:80, opt steps:39, total reward:-24.0000, 0.549781084060669 sec\n",
      "Episode 7476, len6, loss:-68.8534, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5505480766296387 sec\n",
      "Episode 7477, len12, loss:-82.8131, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5494723320007324 sec\n",
      "Episode 7478, len8, loss:-57.1674, fail, steps:80, opt steps:32, total reward:-24.0000, 0.549630880355835 sec\n",
      "Episode 7479, len6, loss:-71.4813, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5490820407867432 sec\n",
      "Episode 7480, len12, loss:-95.1638, fail, steps:80, opt steps:43, total reward:-24.7000, 0.5934686660766602 sec\n",
      "Episode 7481, len10, loss:-59.1370, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5481138229370117 sec\n",
      "Episode 7482, len10, loss:-65.5964, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5486853122711182 sec\n",
      "Episode 7483, len12, loss:-87.1035, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5491940975189209 sec\n",
      "Episode 7484, len8, loss:-45.5703, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5494985580444336 sec\n",
      "Episode 7485, len12, loss:-88.2124, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5494837760925293 sec\n",
      "Episode 7486, len6, loss:-66.9372, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5482275485992432 sec\n",
      "Episode 7487, len8, loss:-61.2196, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5455372333526611 sec\n",
      "Episode 7488, len8, loss:-48.5877, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5487182140350342 sec\n",
      "Episode 7489, len8, loss:-49.2389, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5475864410400391 sec\n",
      "Episode 7490, len6, loss:-60.9703, fail, steps:80, opt steps:10, total reward:-24.0000, 0.548724889755249 sec\n",
      "Episode 7491, len10, loss:-58.6630, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5498065948486328 sec\n",
      "Episode 7492, len12, loss:-94.4842, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5482175350189209 sec\n",
      "Episode 7493, len12, loss:-85.7766, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5487442016601562 sec\n",
      "Episode 7494, len12, loss:-95.5704, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5487451553344727 sec\n",
      "Episode 7495, len10, loss:-71.6845, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5478792190551758 sec\n",
      "Episode 7496, len6, loss:-65.4857, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5982151031494141 sec\n",
      "Episode 7497, len12, loss:-90.1632, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5479187965393066 sec\n",
      "Episode 7498, len10, loss:-68.4832, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5490307807922363 sec\n",
      "Episode 7499, len6, loss:-70.4475, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5480432510375977 sec\n",
      "Episode 7500, len12, loss:-79.1248, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5481131076812744 sec\n",
      "Episode 7501, len6, loss:-74.8153, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5483784675598145 sec\n",
      "Episode 7502, len12, loss:-85.3766, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5482461452484131 sec\n",
      "Episode 7503, len10, loss:-67.5653, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5486717224121094 sec\n",
      "Episode 7504, len12, loss:-92.0847, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5493638515472412 sec\n",
      "Episode 7505, len10, loss:-72.3852, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5487713813781738 sec\n",
      "Episode 7506, len12, loss:-81.7122, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5491852760314941 sec\n",
      "Episode 7507, len10, loss:-74.1974, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5486631393432617 sec\n",
      "Episode 7508, len6, loss:-65.4909, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5465929508209229 sec\n",
      "Episode 7509, len6, loss:-73.1110, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5493805408477783 sec\n",
      "Episode 7510, len12, loss:-81.0289, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5498182773590088 sec\n",
      "Episode 7511, len12, loss:-86.8244, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5501086711883545 sec\n",
      "Episode 7512, len10, loss:-64.8964, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5997250080108643 sec\n",
      "Episode 7513, len6, loss:-69.5947, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5496523380279541 sec\n",
      "Episode 7514, len8, loss:-56.4851, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5478236675262451 sec\n",
      "Episode 7515, len10, loss:-66.8621, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5477416515350342 sec\n",
      "Episode 7516, len8, loss:-45.1205, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5487942695617676 sec\n",
      "Episode 7517, len6, loss:-68.9191, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5484628677368164 sec\n",
      "Episode 7518, len10, loss:-72.7283, fail, steps:80, opt steps:27, total reward:-24.0000, 0.548975944519043 sec\n",
      "Episode 7519, len8, loss:-60.8840, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5479774475097656 sec\n",
      "Episode 7520, len10, loss:-70.6749, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5498065948486328 sec\n",
      "Episode 7521, len8, loss:-55.9176, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5493178367614746 sec\n",
      "Episode 7522, len10, loss:-71.5678, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5493390560150146 sec\n",
      "Episode 7523, len6, loss:-70.0972, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5597352981567383 sec\n",
      "Episode 7524, len12, loss:-94.7939, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5498783588409424 sec\n",
      "Episode 7525, len12, loss:-78.3283, fail, steps:80, opt steps:43, total reward:-24.0000, 0.6029210090637207 sec\n",
      "Episode 7526, len6, loss:-68.0940, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5504558086395264 sec\n",
      "Episode 7527, len10, loss:-67.0045, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5499403476715088 sec\n",
      "Episode 7528, len8, loss:-55.6220, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5491268634796143 sec\n",
      "Episode 7529, len8, loss:-42.5166, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5504984855651855 sec\n",
      "Episode 7530, len6, loss:-68.2740, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5490601062774658 sec\n",
      "Episode 7531, len8, loss:-51.4124, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5504164695739746 sec\n",
      "Episode 7532, len10, loss:-68.1772, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5491189956665039 sec\n",
      "Episode 7533, len6, loss:-68.7683, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5492582321166992 sec\n",
      "Episode 7534, len12, loss:-88.4826, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5498731136322021 sec\n",
      "Episode 7535, len6, loss:-67.7942, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5495426654815674 sec\n",
      "Episode 7536, len8, loss:-54.3888, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5495011806488037 sec\n",
      "Episode 7537, len12, loss:-86.2976, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5471160411834717 sec\n",
      "Episode 7538, len10, loss:-70.5401, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5489425659179688 sec\n",
      "Episode 7539, len8, loss:-54.5045, fail, steps:80, opt steps:18, total reward:-24.0000, 0.6021678447723389 sec\n",
      "Episode 7540, len10, loss:-71.9369, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5499379634857178 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7541, len8, loss:-56.1595, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490870475769043 sec\n",
      "Episode 7542, len12, loss:-84.7270, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5505795478820801 sec\n",
      "Episode 7543, len8, loss:-51.0789, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5493566989898682 sec\n",
      "Episode 7544, len6, loss:-69.3221, fail, steps:80, opt steps:17, total reward:-24.0000, 0.549109935760498 sec\n",
      "Episode 7545, len12, loss:-87.8789, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5490710735321045 sec\n",
      "Episode 7546, len10, loss:-65.2343, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5495967864990234 sec\n",
      "Episode 7547, len10, loss:-69.0600, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5505151748657227 sec\n",
      "Episode 7548, len8, loss:-55.9902, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5494289398193359 sec\n",
      "Episode 7549, len10, loss:-62.8486, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5487849712371826 sec\n",
      "Episode 7550, len6, loss:-68.2161, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5499577522277832 sec\n",
      "Episode 7551, len8, loss:-58.7117, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5477385520935059 sec\n",
      "Episode 7552, len6, loss:-69.1019, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5478897094726562 sec\n",
      "Episode 7553, len8, loss:-64.9032, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5991237163543701 sec\n",
      "Episode 7554, len8, loss:-50.9615, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5470731258392334 sec\n",
      "Episode 7555, len10, loss:-62.4449, fail, steps:80, opt steps:25, total reward:-24.0000, 0.546323299407959 sec\n",
      "Episode 7556, len8, loss:-42.4504, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5480504035949707 sec\n",
      "Episode 7557, len10, loss:-64.1619, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5482652187347412 sec\n",
      "Episode 7558, len10, loss:-74.7155, fail, steps:80, opt steps:39, total reward:-24.0000, 0.54734206199646 sec\n",
      "Episode 7559, len10, loss:-69.6624, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5483465194702148 sec\n",
      "Episode 7560, len12, loss:-83.3934, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5482296943664551 sec\n",
      "Episode 7561, len6, loss:-68.2234, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5481748580932617 sec\n",
      "Episode 7562, len8, loss:-35.3316, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5471327304840088 sec\n",
      "Episode 7563, len8, loss:-45.1185, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5478074550628662 sec\n",
      "Episode 7564, len8, loss:-40.1076, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5484480857849121 sec\n",
      "Episode 7565, len8, loss:-51.1748, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5501346588134766 sec\n",
      "Episode 7566, len10, loss:-50.5942, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5504045486450195 sec\n",
      "Episode 7567, len8, loss:-41.7095, fail, steps:80, opt steps:21, total reward:-24.0000, 0.6007707118988037 sec\n",
      "Episode 7568, len12, loss:-74.6245, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5483510494232178 sec\n",
      "Episode 7569, len12, loss:-64.8454, fail, steps:80, opt steps:44, total reward:-23.7000, 0.5451874732971191 sec\n",
      "Episode 7570, len12, loss:-74.4153, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5498437881469727 sec\n",
      "Episode 7571, len12, loss:-73.9171, fail, steps:80, opt steps:59, total reward:-23.7000, 0.5456089973449707 sec\n",
      "Episode 7572, len8, loss:-35.6104, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5480024814605713 sec\n",
      "Episode 7573, len12, loss:-90.4496, fail, steps:80, opt steps:57, total reward:-24.7000, 0.5449082851409912 sec\n",
      "Episode 7574, len10, loss:-59.7089, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5490190982818604 sec\n",
      "Episode 7575, len6, loss:-61.6982, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5479919910430908 sec\n",
      "Episode 7576, len10, loss:-64.7622, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5486512184143066 sec\n",
      "Episode 7577, len10, loss:-62.7425, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5504429340362549 sec\n",
      "Episode 7578, len8, loss:-45.9515, fail, steps:80, opt steps:16, total reward:-24.0000, 0.549074649810791 sec\n",
      "Episode 7579, len12, loss:-86.0760, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5485038757324219 sec\n",
      "Episode 7580, len6, loss:-60.8366, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5497026443481445 sec\n",
      "Episode 7581, len12, loss:-69.3226, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5986840724945068 sec\n",
      "Episode 7582, len6, loss:-66.6764, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5496993064880371 sec\n",
      "Episode 7583, len8, loss:-41.6009, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5484433174133301 sec\n",
      "Episode 7584, len10, loss:-71.4705, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5505647659301758 sec\n",
      "Episode 7585, len6, loss:-67.2965, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5739438533782959 sec\n",
      "Episode 7586, len12, loss:-89.0391, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5482845306396484 sec\n",
      "Episode 7587, len8, loss:-43.3583, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5468242168426514 sec\n",
      "Episode 7588, len10, loss:-62.6411, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5462672710418701 sec\n",
      "Episode 7589, len8, loss:-49.6238, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5471539497375488 sec\n",
      "Episode 7590, len6, loss:-62.7641, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5485086441040039 sec\n",
      "Episode 7591, len6, loss:-64.8070, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5479550361633301 sec\n",
      "Episode 7592, len6, loss:-62.6979, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5478084087371826 sec\n",
      "Episode 7593, len12, loss:-80.1146, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5478208065032959 sec\n",
      "Episode 7594, len10, loss:-64.9043, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5496680736541748 sec\n",
      "Episode 7595, len6, loss:-63.8555, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5481836795806885 sec\n",
      "Episode 7596, len12, loss:-87.9548, fail, steps:80, opt steps:37, total reward:-24.0000, 0.6000392436981201 sec\n",
      "Episode 7597, len8, loss:-42.4386, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5476162433624268 sec\n",
      "Episode 7598, len12, loss:-81.6499, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5482354164123535 sec\n",
      "Episode 7599, len6, loss:-70.9490, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5482518672943115 sec\n",
      "Episode 7600, len10, loss:-68.6482, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5484790802001953 sec\n",
      "Episode 7601, len8, loss:-53.5532, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5467455387115479 sec\n",
      "Episode 7602, len6, loss:-60.8439, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5483865737915039 sec\n",
      "Episode 7603, len8, loss:-63.5273, fail, steps:80, opt steps:20, total reward:-24.0000, 0.551069974899292 sec\n",
      "Episode 7604, len12, loss:-80.2307, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5497548580169678 sec\n",
      "Episode 7605, len12, loss:-94.2486, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5487592220306396 sec\n",
      "Episode 7606, len12, loss:-78.0606, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5489053726196289 sec\n",
      "Episode 7607, len6, loss:-71.1062, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5480043888092041 sec\n",
      "Episode 7608, len10, loss:-60.4496, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5489964485168457 sec\n",
      "Episode 7609, len8, loss:-52.6177, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5481605529785156 sec\n",
      "Episode 7610, len10, loss:-75.9302, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5497384071350098 sec\n",
      "Episode 7611, len8, loss:-49.1360, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5479435920715332 sec\n",
      "Episode 7612, len12, loss:-93.0803, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5974752902984619 sec\n",
      "Episode 7613, len8, loss:-60.3202, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5435011386871338 sec\n",
      "Episode 7614, len6, loss:-59.8320, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5491428375244141 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7615, len6, loss:-63.2714, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5476655960083008 sec\n",
      "Episode 7616, len10, loss:-65.4022, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5477144718170166 sec\n",
      "Episode 7617, len12, loss:-78.8038, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5475306510925293 sec\n",
      "Episode 7618, len10, loss:-67.4027, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5490376949310303 sec\n",
      "Episode 7619, len12, loss:-93.8461, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5492045879364014 sec\n",
      "Episode 7620, len12, loss:-90.9456, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5483012199401855 sec\n",
      "Episode 7621, len8, loss:-52.3981, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5485715866088867 sec\n",
      "Episode 7622, len10, loss:-71.0600, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5482535362243652 sec\n",
      "Episode 7623, len8, loss:-57.0368, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5493960380554199 sec\n",
      "Episode 7624, len8, loss:-51.3973, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5481216907501221 sec\n",
      "Episode 7625, len8, loss:-53.3145, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5487136840820312 sec\n",
      "Episode 7626, len8, loss:-54.4631, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5476093292236328 sec\n",
      "Episode 7627, len10, loss:-64.5368, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5485739707946777 sec\n",
      "Episode 7628, len6, loss:-67.0257, fail, steps:80, opt steps:5, total reward:-24.0000, 0.600043535232544 sec\n",
      "Episode 7629, len12, loss:-91.7977, fail, steps:80, opt steps:71, total reward:-24.0000, 0.5491373538970947 sec\n",
      "Episode 7630, len8, loss:-47.9869, fail, steps:80, opt steps:35, total reward:-24.0000, 0.549673318862915 sec\n",
      "Episode 7631, len8, loss:-45.4447, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5478143692016602 sec\n",
      "Episode 7632, len6, loss:-62.6893, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5475223064422607 sec\n",
      "Episode 7633, len6, loss:-60.5184, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5471789836883545 sec\n",
      "Episode 7634, len6, loss:-63.3336, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5478503704071045 sec\n",
      "Episode 7635, len8, loss:-55.0095, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5479781627655029 sec\n",
      "Episode 7636, len8, loss:-57.0032, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5478780269622803 sec\n",
      "Episode 7637, len10, loss:-62.3199, fail, steps:80, opt steps:31, total reward:-23.7000, 0.5450143814086914 sec\n",
      "Episode 7638, len8, loss:-51.2453, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5478880405426025 sec\n",
      "Episode 7639, len12, loss:-85.0450, fail, steps:80, opt steps:51, total reward:-24.0000, 0.549750566482544 sec\n",
      "Episode 7640, len10, loss:-67.7869, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5469579696655273 sec\n",
      "Episode 7641, len6, loss:-69.6261, fail, steps:80, opt steps:3, total reward:-24.0000, 0.6024560928344727 sec\n",
      "Episode 7642, len12, loss:-87.3211, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5494437217712402 sec\n",
      "Episode 7643, len6, loss:-63.4952, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5489156246185303 sec\n",
      "Episode 7644, len8, loss:-41.1101, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5486774444580078 sec\n",
      "Episode 7645, len12, loss:-79.0117, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5476346015930176 sec\n",
      "Episode 7646, len6, loss:-71.0513, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5431053638458252 sec\n",
      "Episode 7647, len12, loss:-83.8028, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5483181476593018 sec\n",
      "Episode 7648, len12, loss:-66.4158, fail, steps:80, opt steps:45, total reward:-22.7000, 0.5439810752868652 sec\n",
      "Episode 7649, len10, loss:-61.8946, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5469875335693359 sec\n",
      "Episode 7650, len8, loss:-46.5683, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5474727153778076 sec\n",
      "Episode 7651, len6, loss:-65.6546, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5476951599121094 sec\n",
      "Episode 7652, len8, loss:-52.0852, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5420889854431152 sec\n",
      "Episode 7653, len6, loss:-63.8963, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5490672588348389 sec\n",
      "Episode 7654, len10, loss:-72.4745, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5500199794769287 sec\n",
      "Episode 7655, len8, loss:-51.1311, fail, steps:80, opt steps:19, total reward:-24.0000, 0.6015636920928955 sec\n",
      "Episode 7656, len12, loss:-88.5337, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5477063655853271 sec\n",
      "Episode 7657, len12, loss:-93.9620, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5494790077209473 sec\n",
      "Episode 7658, len10, loss:-70.8262, fail, steps:80, opt steps:36, total reward:-24.0000, 0.548525333404541 sec\n",
      "Episode 7659, len8, loss:-53.9610, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5481467247009277 sec\n",
      "Episode 7660, len12, loss:-81.8069, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5476894378662109 sec\n",
      "Episode 7661, len10, loss:-61.5346, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5489671230316162 sec\n",
      "Episode 7662, len6, loss:-64.0110, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5481796264648438 sec\n",
      "Episode 7663, len10, loss:-67.4686, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5499892234802246 sec\n",
      "Episode 7664, len8, loss:-42.9333, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5485293865203857 sec\n",
      "Episode 7665, len12, loss:-84.2530, fail, steps:80, opt steps:43, total reward:-24.0000, 0.549095869064331 sec\n",
      "Episode 7666, len8, loss:-48.7434, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5477802753448486 sec\n",
      "Episode 7667, len12, loss:-82.2220, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5500738620758057 sec\n",
      "Episode 7668, len12, loss:-88.4394, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5495622158050537 sec\n",
      "Episode 7669, len8, loss:-46.3114, fail, steps:80, opt steps:29, total reward:-24.0000, 0.600433349609375 sec\n",
      "Episode 7670, len10, loss:-70.3037, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5491738319396973 sec\n",
      "Episode 7671, len8, loss:-52.2110, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5434715747833252 sec\n",
      "Episode 7672, len8, loss:-44.6821, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5492167472839355 sec\n",
      "Episode 7673, len12, loss:-77.3978, fail, steps:80, opt steps:37, total reward:-24.0000, 0.547325849533081 sec\n",
      "Episode 7674, len10, loss:-67.8994, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5491139888763428 sec\n",
      "Episode 7675, len10, loss:-71.1789, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5479855537414551 sec\n",
      "Episode 7676, len12, loss:-84.0569, fail, steps:80, opt steps:56, total reward:-24.0000, 0.548412561416626 sec\n",
      "Episode 7677, len12, loss:-83.7197, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5487580299377441 sec\n",
      "Episode 7678, len10, loss:-70.5270, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5480692386627197 sec\n",
      "Episode 7679, len8, loss:-47.3925, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5473983287811279 sec\n",
      "Episode 7680, len8, loss:-38.0328, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5439198017120361 sec\n",
      "Episode 7681, len6, loss:-64.3347, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5476031303405762 sec\n",
      "Episode 7682, len8, loss:-37.7227, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5483303070068359 sec\n",
      "Episode 7683, len8, loss:-38.8621, fail, steps:80, opt steps:17, total reward:-24.7000, 0.5952425003051758 sec\n",
      "Episode 7684, len12, loss:-94.0419, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5487184524536133 sec\n",
      "Episode 7685, len8, loss:-36.9561, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5496504306793213 sec\n",
      "Episode 7686, len8, loss:-46.1623, fail, steps:80, opt steps:31, total reward:-24.0000, 0.548473596572876 sec\n",
      "Episode 7687, len10, loss:-60.0693, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5483825206756592 sec\n",
      "Episode 7688, len12, loss:-80.5232, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5471336841583252 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7689, len8, loss:-42.6923, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5464603900909424 sec\n",
      "Episode 7690, len6, loss:-65.2666, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5477240085601807 sec\n",
      "Episode 7691, len6, loss:-71.7204, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5474822521209717 sec\n",
      "Episode 7692, len10, loss:-61.7559, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5480315685272217 sec\n",
      "Episode 7693, len10, loss:-68.3224, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5479130744934082 sec\n",
      "Episode 7694, len10, loss:-59.0506, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5486910343170166 sec\n",
      "Episode 7695, len10, loss:-65.0251, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5461962223052979 sec\n",
      "Episode 7696, len10, loss:-74.3925, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5470602512359619 sec\n",
      "Episode 7697, len12, loss:-99.9966, fail, steps:80, opt steps:71, total reward:-24.0000, 0.5989105701446533 sec\n",
      "Episode 7698, len8, loss:-56.2321, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5477883815765381 sec\n",
      "Episode 7699, len10, loss:-73.0241, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5480227470397949 sec\n",
      "Episode 7700, len8, loss:-52.0598, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548281192779541 sec\n",
      "Episode 7701, len8, loss:-44.0816, fail, steps:80, opt steps:16, total reward:-24.0000, 0.550708532333374 sec\n",
      "Episode 7702, len12, loss:-88.0179, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5477588176727295 sec\n",
      "Episode 7703, len8, loss:-44.9103, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5474991798400879 sec\n",
      "Episode 7704, len10, loss:-69.5407, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5475835800170898 sec\n",
      "Episode 7705, len10, loss:-69.4774, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5494921207427979 sec\n",
      "Episode 7706, len10, loss:-67.1701, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5471570491790771 sec\n",
      "Episode 7707, len12, loss:-88.3145, fail, steps:80, opt steps:68, total reward:-24.0000, 0.5483741760253906 sec\n",
      "Episode 7708, len10, loss:-67.2686, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5485551357269287 sec\n",
      "Episode 7709, len8, loss:-59.2176, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5482687950134277 sec\n",
      "Episode 7710, len10, loss:-66.9368, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5468769073486328 sec\n",
      "Episode 7711, len6, loss:-68.5457, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5487978458404541 sec\n",
      "Episode 7712, len10, loss:-71.0034, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5997786521911621 sec\n",
      "Episode 7713, len12, loss:-87.3668, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5486891269683838 sec\n",
      "Episode 7714, len12, loss:-102.3851, fail, steps:80, opt steps:61, total reward:-24.7000, 0.5422732830047607 sec\n",
      "Episode 7715, len8, loss:-55.9105, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5470342636108398 sec\n",
      "Episode 7716, len10, loss:-74.9189, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5476939678192139 sec\n",
      "Episode 7717, len12, loss:-100.6304, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5477797985076904 sec\n",
      "Episode 7718, len10, loss:-87.5554, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5480566024780273 sec\n",
      "Episode 7719, len8, loss:-58.1560, fail, steps:80, opt steps:25, total reward:-24.0000, 0.549091100692749 sec\n",
      "Episode 7720, len8, loss:-64.8134, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5484893321990967 sec\n",
      "Episode 7721, len10, loss:-78.3394, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5465145111083984 sec\n",
      "Episode 7722, len8, loss:-64.1072, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5476493835449219 sec\n",
      "Episode 7723, len10, loss:-80.2280, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5486409664154053 sec\n",
      "Episode 7724, len8, loss:-73.2924, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5485892295837402 sec\n",
      "Episode 7725, len10, loss:-72.7978, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5475361347198486 sec\n",
      "Episode 7726, len12, loss:-97.8627, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5488839149475098 sec\n",
      "Episode 7727, len12, loss:-89.6918, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5477564334869385 sec\n",
      "Episode 7728, len12, loss:-91.0660, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5973865985870361 sec\n",
      "Episode 7729, len10, loss:-76.5621, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5480802059173584 sec\n",
      "Episode 7730, len10, loss:-82.5742, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5448768138885498 sec\n",
      "Episode 7731, len10, loss:-80.0163, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5478143692016602 sec\n",
      "Episode 7732, len8, loss:-59.1596, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5477309226989746 sec\n",
      "Episode 7733, len6, loss:-67.4581, fail, steps:80, opt steps:11, total reward:-24.0000, 0.548084020614624 sec\n",
      "Episode 7734, len8, loss:-61.7779, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5488681793212891 sec\n",
      "Episode 7735, len10, loss:-82.0913, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5481491088867188 sec\n",
      "Episode 7736, len10, loss:-83.9102, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5493714809417725 sec\n",
      "Episode 7737, len10, loss:-77.9321, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5495731830596924 sec\n",
      "Episode 7738, len10, loss:-94.8099, fail, steps:80, opt steps:22, total reward:-24.7000, 0.5450179576873779 sec\n",
      "Episode 7739, len6, loss:-65.6624, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5482273101806641 sec\n",
      "Episode 7740, len6, loss:-66.9440, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5615634918212891 sec\n",
      "Episode 7741, len12, loss:-91.7383, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5493595600128174 sec\n",
      "Episode 7742, len6, loss:-68.9624, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5478665828704834 sec\n",
      "Episode 7743, len6, loss:-63.2504, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5481958389282227 sec\n",
      "Episode 7744, len12, loss:-95.3226, fail, steps:80, opt steps:33, total reward:-24.0000, 0.601837158203125 sec\n",
      "Episode 7745, len6, loss:-68.2749, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5488104820251465 sec\n",
      "Episode 7746, len12, loss:-99.5882, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5487797260284424 sec\n",
      "Episode 7747, len8, loss:-59.1935, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5482180118560791 sec\n",
      "Episode 7748, len10, loss:-84.6654, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5505495071411133 sec\n",
      "Episode 7749, len6, loss:-69.8271, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5472545623779297 sec\n",
      "Episode 7750, len10, loss:-76.0022, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5489597320556641 sec\n",
      "Episode 7751, len10, loss:-81.7421, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5496842861175537 sec\n",
      "Episode 7752, len8, loss:-65.8094, fail, steps:80, opt steps:25, total reward:-24.0000, 0.549365758895874 sec\n",
      "Episode 7753, len8, loss:-67.8679, fail, steps:80, opt steps:21, total reward:-24.0000, 0.54976487159729 sec\n",
      "Episode 7754, len6, loss:-65.5835, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5484206676483154 sec\n",
      "Episode 7755, len12, loss:-90.0471, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5499258041381836 sec\n",
      "Episode 7756, len12, loss:-82.6877, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5481362342834473 sec\n",
      "Episode 7757, len8, loss:-63.5875, fail, steps:80, opt steps:12, total reward:-24.0000, 0.6028597354888916 sec\n",
      "Episode 7758, len12, loss:-95.0178, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5500571727752686 sec\n",
      "Episode 7759, len8, loss:-62.7897, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5496935844421387 sec\n",
      "Episode 7760, len10, loss:-83.1132, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5488548278808594 sec\n",
      "Episode 7761, len6, loss:-71.2849, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5478780269622803 sec\n",
      "Episode 7762, len10, loss:-82.2752, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5491552352905273 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7763, len8, loss:-66.4804, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5493237972259521 sec\n",
      "Episode 7764, len10, loss:-86.6305, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5482480525970459 sec\n",
      "Episode 7765, len12, loss:-98.3536, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5491008758544922 sec\n",
      "Episode 7766, len10, loss:-77.6002, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5494668483734131 sec\n",
      "Episode 7767, len8, loss:-66.6799, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5469744205474854 sec\n",
      "Episode 7768, len6, loss:-68.7179, fail, steps:80, opt steps:15, total reward:-24.0000, 0.547126293182373 sec\n",
      "Episode 7769, len10, loss:-75.9893, fail, steps:80, opt steps:35, total reward:-24.0000, 0.548598051071167 sec\n",
      "Episode 7770, len8, loss:-66.0462, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5493342876434326 sec\n",
      "Episode 7771, len12, loss:-110.1642, fail, steps:80, opt steps:49, total reward:-24.0000, 0.6008951663970947 sec\n",
      "Episode 7772, len10, loss:-89.6945, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5495305061340332 sec\n",
      "Episode 7773, len10, loss:-67.6426, fail, steps:80, opt steps:31, total reward:-24.0000, 0.548271656036377 sec\n",
      "Episode 7774, len12, loss:-106.0958, fail, steps:80, opt steps:44, total reward:-24.7000, 0.5458238124847412 sec\n",
      "Episode 7775, len10, loss:-72.7526, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5476455688476562 sec\n",
      "Episode 7776, len6, loss:-74.1613, fail, steps:80, opt steps:15, total reward:-24.0000, 0.546180248260498 sec\n",
      "Episode 7777, len10, loss:-76.4873, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5481159687042236 sec\n",
      "Episode 7778, len6, loss:-74.7894, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5483496189117432 sec\n",
      "Episode 7779, len6, loss:-71.1517, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5464496612548828 sec\n",
      "Episode 7780, len6, loss:-74.1668, fail, steps:80, opt steps:14, total reward:-24.0000, 0.547243595123291 sec\n",
      "Episode 7781, len10, loss:-69.1269, fail, steps:80, opt steps:26, total reward:-24.0000, 0.547081470489502 sec\n",
      "Episode 7782, len6, loss:-69.9935, fail, steps:80, opt steps:17, total reward:-24.0000, 0.548419713973999 sec\n",
      "Episode 7783, len10, loss:-79.2358, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5475711822509766 sec\n",
      "Episode 7784, len6, loss:-74.2296, fail, steps:80, opt steps:5, total reward:-24.0000, 0.549471378326416 sec\n",
      "Episode 7785, len10, loss:-69.6711, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5992052555084229 sec\n",
      "Episode 7786, len10, loss:-90.8913, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5472853183746338 sec\n",
      "Episode 7787, len10, loss:-76.5680, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5480208396911621 sec\n",
      "Episode 7788, len12, loss:-98.8432, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5497055053710938 sec\n",
      "Episode 7789, len8, loss:-68.9961, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5479423999786377 sec\n",
      "Episode 7790, len8, loss:-62.2508, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5465240478515625 sec\n",
      "Episode 7791, len8, loss:-72.3077, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5468661785125732 sec\n",
      "Episode 7792, len6, loss:-76.4496, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5470306873321533 sec\n",
      "Episode 7793, len12, loss:-107.7641, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5463070869445801 sec\n",
      "Episode 7794, len6, loss:-73.1787, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5479292869567871 sec\n",
      "Episode 7795, len10, loss:-83.6339, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5486836433410645 sec\n",
      "Episode 7796, len6, loss:-68.8691, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5479373931884766 sec\n",
      "Episode 7797, len12, loss:-100.3620, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5491654872894287 sec\n",
      "Episode 7798, len10, loss:-92.9247, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5486099720001221 sec\n",
      "Episode 7799, len10, loss:-86.4903, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5999972820281982 sec\n",
      "Episode 7800, len10, loss:-88.4987, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5477554798126221 sec\n",
      "Episode 7801, len12, loss:-89.0611, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5482141971588135 sec\n",
      "Episode 7802, len8, loss:-69.8451, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5485796928405762 sec\n",
      "Episode 7803, len12, loss:-96.3368, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5485920906066895 sec\n",
      "Episode 7804, len12, loss:-97.2409, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5468428134918213 sec\n",
      "Episode 7805, len6, loss:-69.1960, fail, steps:80, opt steps:20, total reward:-24.0000, 0.547440767288208 sec\n",
      "Episode 7806, len6, loss:-72.4785, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5477926731109619 sec\n",
      "Episode 7807, len10, loss:-83.9147, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5477330684661865 sec\n",
      "Episode 7808, len6, loss:-75.4835, fail, steps:80, opt steps:15, total reward:-24.7000, 0.5437073707580566 sec\n",
      "Episode 7809, len10, loss:-80.2799, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5467870235443115 sec\n",
      "Episode 7810, len10, loss:-82.1512, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5478677749633789 sec\n",
      "Episode 7811, len12, loss:-100.0068, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5476517677307129 sec\n",
      "Episode 7812, len10, loss:-90.5881, fail, steps:80, opt steps:38, total reward:-24.0000, 0.549645185470581 sec\n",
      "Episode 7813, len10, loss:-83.5786, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5986213684082031 sec\n",
      "Episode 7814, len10, loss:-83.5005, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5470056533813477 sec\n",
      "Episode 7815, len8, loss:-70.9661, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5474562644958496 sec\n",
      "Episode 7816, len6, loss:-70.6321, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5476579666137695 sec\n",
      "Episode 7817, len12, loss:-94.5943, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5487749576568604 sec\n",
      "Episode 7818, len12, loss:-103.9342, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5487406253814697 sec\n",
      "Episode 7819, len10, loss:-88.5284, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5491678714752197 sec\n",
      "Episode 7820, len6, loss:-72.4427, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5479001998901367 sec\n",
      "Episode 7821, len6, loss:-68.4230, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5485076904296875 sec\n",
      "Episode 7822, len12, loss:-97.2850, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5501735210418701 sec\n",
      "Episode 7823, len6, loss:-66.8708, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5473370552062988 sec\n",
      "Episode 7824, len8, loss:-75.7813, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5485901832580566 sec\n",
      "Episode 7825, len8, loss:-66.7430, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5483982563018799 sec\n",
      "Episode 7826, len6, loss:-68.4376, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5489816665649414 sec\n",
      "Episode 7827, len8, loss:-67.0220, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5504770278930664 sec\n",
      "Episode 7828, len12, loss:-105.3449, fail, steps:80, opt steps:37, total reward:-24.0000, 0.598931074142456 sec\n",
      "Episode 7829, len10, loss:-85.5747, fail, steps:80, opt steps:37, total reward:-24.0000, 0.548377275466919 sec\n",
      "Episode 7830, len6, loss:-67.1656, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5490102767944336 sec\n",
      "Episode 7831, len12, loss:-100.7591, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5487766265869141 sec\n",
      "Episode 7832, len8, loss:-67.8904, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5504448413848877 sec\n",
      "Episode 7833, len6, loss:-70.5724, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5492210388183594 sec\n",
      "Episode 7834, len12, loss:-99.9050, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5492916107177734 sec\n",
      "Episode 7835, len6, loss:-71.9050, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5508263111114502 sec\n",
      "Episode 7836, len8, loss:-73.8394, fail, steps:80, opt steps:32, total reward:-24.0000, 0.549738883972168 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7837, len12, loss:-99.3691, fail, steps:80, opt steps:73, total reward:-24.0000, 0.5492727756500244 sec\n",
      "Episode 7838, len8, loss:-70.2590, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5494852066040039 sec\n",
      "Episode 7839, len12, loss:-98.5119, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5491194725036621 sec\n",
      "Episode 7840, len8, loss:-77.0701, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5491509437561035 sec\n",
      "Episode 7841, len12, loss:-96.1794, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5497355461120605 sec\n",
      "Episode 7842, len8, loss:-67.0324, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5497920513153076 sec\n",
      "Episode 7843, len8, loss:-77.9120, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5495235919952393 sec\n",
      "Episode 7844, len6, loss:-68.7750, fail, steps:80, opt steps:3, total reward:-24.0000, 0.598675012588501 sec\n",
      "Episode 7845, len6, loss:-70.7005, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5483865737915039 sec\n",
      "Episode 7846, len12, loss:-98.6058, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5483956336975098 sec\n",
      "Episode 7847, len8, loss:-76.9238, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485308170318604 sec\n",
      "Episode 7848, len10, loss:-80.6385, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5479905605316162 sec\n",
      "Episode 7849, len12, loss:-95.3916, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5511102676391602 sec\n",
      "Episode 7850, len10, loss:-82.0064, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5493803024291992 sec\n",
      "Episode 7851, len6, loss:-69.0620, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5487942695617676 sec\n",
      "Episode 7852, len12, loss:-98.4872, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5519702434539795 sec\n",
      "Episode 7853, len6, loss:-70.7856, fail, steps:80, opt steps:13, total reward:-24.0000, 0.54905104637146 sec\n",
      "Episode 7854, len12, loss:-108.3981, fail, steps:80, opt steps:59, total reward:-24.7000, 0.5439987182617188 sec\n",
      "Episode 7855, len10, loss:-82.1528, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5484187602996826 sec\n",
      "Episode 7856, len6, loss:-69.9398, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5477795600891113 sec\n",
      "Episode 7857, len10, loss:-81.6763, fail, steps:80, opt steps:36, total reward:-24.0000, 0.550309419631958 sec\n",
      "Episode 7858, len10, loss:-84.6714, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5484030246734619 sec\n",
      "Episode 7859, len10, loss:-81.3294, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5490818023681641 sec\n",
      "Episode 7860, len8, loss:-75.7501, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5994224548339844 sec\n",
      "Episode 7861, len10, loss:-79.8880, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5495376586914062 sec\n",
      "Episode 7862, len10, loss:-81.9100, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5492773056030273 sec\n",
      "Episode 7863, len6, loss:-72.0564, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5479505062103271 sec\n",
      "Episode 7864, len8, loss:-72.4436, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5489826202392578 sec\n",
      "Episode 7865, len8, loss:-77.0897, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5480287075042725 sec\n",
      "Episode 7866, len8, loss:-76.3010, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5489969253540039 sec\n",
      "Episode 7867, len12, loss:-101.4920, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5499658584594727 sec\n",
      "Episode 7868, len12, loss:-102.5117, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5481576919555664 sec\n",
      "Episode 7869, len8, loss:-80.2522, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5479128360748291 sec\n",
      "Episode 7870, len10, loss:-88.6892, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5500261783599854 sec\n",
      "Episode 7871, len8, loss:-73.8960, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5490753650665283 sec\n",
      "Episode 7872, len6, loss:-68.2074, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5479598045349121 sec\n",
      "Episode 7873, len6, loss:-71.4194, fail, steps:80, opt steps:12, total reward:-24.0000, 0.6034119129180908 sec\n",
      "Episode 7874, len10, loss:-78.2078, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5495684146881104 sec\n",
      "Episode 7875, len8, loss:-74.3131, fail, steps:80, opt steps:33, total reward:-24.0000, 0.549576997756958 sec\n",
      "Episode 7876, len8, loss:-71.2080, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5502054691314697 sec\n",
      "Episode 7877, len6, loss:-71.9348, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5474565029144287 sec\n",
      "Episode 7878, len10, loss:-79.5892, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5495340824127197 sec\n",
      "Episode 7879, len12, loss:-104.8780, fail, steps:80, opt steps:42, total reward:-24.0000, 0.551513671875 sec\n",
      "Episode 7880, len8, loss:-71.4566, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5506939888000488 sec\n",
      "Episode 7881, len8, loss:-77.9360, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5493495464324951 sec\n",
      "Episode 7882, len12, loss:-92.7378, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5497827529907227 sec\n",
      "Episode 7883, len8, loss:-67.8231, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5483608245849609 sec\n",
      "Episode 7884, len6, loss:-71.1067, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5478405952453613 sec\n",
      "Episode 7885, len8, loss:-73.0310, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5483713150024414 sec\n",
      "Episode 7886, len12, loss:-99.8823, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5500092506408691 sec\n",
      "Episode 7887, len6, loss:-73.1235, fail, steps:80, opt steps:11, total reward:-24.0000, 0.6017167568206787 sec\n",
      "Episode 7888, len8, loss:-77.5461, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5504589080810547 sec\n",
      "Episode 7889, len8, loss:-74.6137, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5489284992218018 sec\n",
      "Episode 7890, len6, loss:-73.3128, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5489897727966309 sec\n",
      "Episode 7891, len10, loss:-86.9360, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5478966236114502 sec\n",
      "Episode 7892, len10, loss:-86.8062, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5489513874053955 sec\n",
      "Episode 7893, len6, loss:-73.6012, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5495750904083252 sec\n",
      "Episode 7894, len6, loss:-69.1895, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5485203266143799 sec\n",
      "Episode 7895, len12, loss:-105.9982, fail, steps:80, opt steps:48, total reward:-24.0000, 0.548966646194458 sec\n",
      "Episode 7896, len10, loss:-84.1987, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5487658977508545 sec\n",
      "Episode 7897, len12, loss:-100.0082, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5511832237243652 sec\n",
      "Episode 7898, len10, loss:-85.6510, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5504570007324219 sec\n",
      "Episode 7899, len10, loss:-86.2027, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5483169555664062 sec\n",
      "Episode 7900, len6, loss:-73.0054, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5497488975524902 sec\n",
      "Episode 7901, len10, loss:-84.2298, fail, steps:80, opt steps:32, total reward:-24.0000, 0.6008765697479248 sec\n",
      "Episode 7902, len10, loss:-84.7567, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5495524406433105 sec\n",
      "Episode 7903, len12, loss:-99.9380, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5480730533599854 sec\n",
      "Episode 7904, len10, loss:-80.9492, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5491108894348145 sec\n",
      "Episode 7905, len12, loss:-94.5659, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5496575832366943 sec\n",
      "Episode 7906, len12, loss:-99.2304, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5492837429046631 sec\n",
      "Episode 7907, len10, loss:-87.1981, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5484955310821533 sec\n",
      "Episode 7908, len6, loss:-68.2515, fail, steps:80, opt steps:13, total reward:-24.0000, 0.548511266708374 sec\n",
      "Episode 7909, len10, loss:-87.2925, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5493979454040527 sec\n",
      "Episode 7910, len6, loss:-69.2998, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5489873886108398 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7911, len8, loss:-78.4435, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5504522323608398 sec\n",
      "Episode 7912, len12, loss:-98.3887, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5500822067260742 sec\n",
      "Episode 7913, len6, loss:-70.8291, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5481276512145996 sec\n",
      "Episode 7914, len12, loss:-101.0237, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5501554012298584 sec\n",
      "Episode 7915, len8, loss:-76.0665, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5986740589141846 sec\n",
      "Episode 7916, len6, loss:-71.6408, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5488684177398682 sec\n",
      "Episode 7917, len8, loss:-78.3689, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5495495796203613 sec\n",
      "Episode 7918, len6, loss:-68.0505, fail, steps:80, opt steps:7, total reward:-24.0000, 0.549269437789917 sec\n",
      "Episode 7919, len8, loss:-75.5530, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5487844944000244 sec\n",
      "Episode 7920, len6, loss:-77.7326, fail, steps:80, opt steps:16, total reward:-24.7000, 0.546410322189331 sec\n",
      "Episode 7921, len10, loss:-83.4234, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5483760833740234 sec\n",
      "Episode 7922, len12, loss:-93.7402, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5494065284729004 sec\n",
      "Episode 7923, len10, loss:-91.8244, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5496656894683838 sec\n",
      "Episode 7924, len12, loss:-99.1977, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5488381385803223 sec\n",
      "Episode 7925, len6, loss:-73.6981, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5495719909667969 sec\n",
      "Episode 7926, len8, loss:-72.9344, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5490248203277588 sec\n",
      "Episode 7927, len10, loss:-81.5813, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5515408515930176 sec\n",
      "Episode 7928, len12, loss:-98.8914, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5492007732391357 sec\n",
      "Episode 7929, len10, loss:-80.7634, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5984783172607422 sec\n",
      "Episode 7930, len8, loss:-76.4279, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5492408275604248 sec\n",
      "Episode 7931, len8, loss:-80.2206, fail, steps:80, opt steps:16, total reward:-24.0000, 0.549055814743042 sec\n",
      "Episode 7932, len6, loss:-75.2090, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5492284297943115 sec\n",
      "Episode 7933, len10, loss:-87.7195, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5491750240325928 sec\n",
      "Episode 7934, len12, loss:-99.5382, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5479385852813721 sec\n",
      "Episode 7935, len12, loss:-94.9156, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5491960048675537 sec\n",
      "Episode 7936, len12, loss:-93.5909, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5505695343017578 sec\n",
      "Episode 7937, len8, loss:-79.0880, fail, steps:80, opt steps:15, total reward:-24.0000, 0.548565149307251 sec\n",
      "Episode 7938, len8, loss:-78.4543, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5493357181549072 sec\n",
      "Episode 7939, len8, loss:-83.7374, fail, steps:80, opt steps:19, total reward:-23.7000, 0.5437257289886475 sec\n",
      "Episode 7940, len12, loss:-97.0992, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5497517585754395 sec\n",
      "Episode 7941, len10, loss:-85.7557, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5488452911376953 sec\n",
      "Episode 7942, len10, loss:-77.5334, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5484590530395508 sec\n",
      "Episode 7943, len12, loss:-96.7933, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5495710372924805 sec\n",
      "Episode 7944, len6, loss:-69.8029, fail, steps:80, opt steps:14, total reward:-24.0000, 0.599069356918335 sec\n",
      "Episode 7945, len6, loss:-74.3649, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5481185913085938 sec\n",
      "Episode 7946, len12, loss:-99.0968, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5496170520782471 sec\n",
      "Episode 7947, len8, loss:-84.5469, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5489802360534668 sec\n",
      "Episode 7948, len6, loss:-71.7563, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5486886501312256 sec\n",
      "Episode 7949, len6, loss:-71.1293, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5487852096557617 sec\n",
      "Episode 7950, len8, loss:-80.1117, fail, steps:80, opt steps:15, total reward:-24.0000, 0.548893928527832 sec\n",
      "Episode 7951, len12, loss:-100.7991, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5500595569610596 sec\n",
      "Episode 7952, len12, loss:-97.4209, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5484046936035156 sec\n",
      "Episode 7953, len12, loss:-96.9940, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5497536659240723 sec\n",
      "Episode 7954, len6, loss:-81.6731, fail, steps:80, opt steps:3, total reward:-24.7000, 0.5455048084259033 sec\n",
      "Episode 7955, len6, loss:-69.6629, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5483081340789795 sec\n",
      "Episode 7956, len10, loss:-88.4114, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5492091178894043 sec\n",
      "Episode 7957, len8, loss:-78.3238, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5565354824066162 sec\n",
      "Episode 7958, len10, loss:-81.4578, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5497598648071289 sec\n",
      "Episode 7959, len12, loss:-97.8327, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5483362674713135 sec\n",
      "Episode 7960, len6, loss:-75.7254, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5991969108581543 sec\n",
      "Episode 7961, len8, loss:-80.3545, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5486335754394531 sec\n",
      "Episode 7962, len6, loss:-69.2715, fail, steps:80, opt steps:13, total reward:-24.0000, 0.550278902053833 sec\n",
      "Episode 7963, len12, loss:-97.3207, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5499768257141113 sec\n",
      "Episode 7964, len12, loss:-107.6946, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5500876903533936 sec\n",
      "Episode 7965, len6, loss:-72.5488, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5498957633972168 sec\n",
      "Episode 7966, len12, loss:-103.0147, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5514137744903564 sec\n",
      "Episode 7967, len8, loss:-82.3694, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5506219863891602 sec\n",
      "Episode 7968, len10, loss:-86.9071, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5511593818664551 sec\n",
      "Episode 7969, len6, loss:-74.2449, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5525784492492676 sec\n",
      "Episode 7970, len10, loss:-80.0189, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5500507354736328 sec\n",
      "Episode 7971, len10, loss:-90.5656, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5487256050109863 sec\n",
      "Episode 7972, len8, loss:-84.2358, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5488197803497314 sec\n",
      "Episode 7973, len12, loss:-108.7154, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5498976707458496 sec\n",
      "Episode 7974, len10, loss:-94.5066, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5489902496337891 sec\n",
      "Episode 7975, len6, loss:-72.5052, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5493369102478027 sec\n",
      "Episode 7976, len8, loss:-83.4601, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5995862483978271 sec\n",
      "Episode 7977, len12, loss:-104.6652, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5490031242370605 sec\n",
      "Episode 7978, len12, loss:-93.7159, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5503132343292236 sec\n",
      "Episode 7979, len12, loss:-105.1896, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5502605438232422 sec\n",
      "Episode 7980, len10, loss:-85.6959, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5494034290313721 sec\n",
      "Episode 7981, len10, loss:-96.0507, fail, steps:80, opt steps:19, total reward:-24.0000, 0.549386739730835 sec\n",
      "Episode 7982, len10, loss:-94.3112, fail, steps:80, opt steps:29, total reward:-24.0000, 0.550792932510376 sec\n",
      "Episode 7983, len12, loss:-112.3536, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5500154495239258 sec\n",
      "Episode 7984, len12, loss:-96.0621, fail, steps:80, opt steps:44, total reward:-24.0000, 0.548729658126831 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7985, len8, loss:-79.4774, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5486757755279541 sec\n",
      "Episode 7986, len10, loss:-90.6227, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5508279800415039 sec\n",
      "Episode 7987, len12, loss:-101.6966, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5507445335388184 sec\n",
      "Episode 7988, len12, loss:-99.9610, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5496213436126709 sec\n",
      "Episode 7989, len6, loss:-70.7365, fail, steps:80, opt steps:13, total reward:-24.0000, 0.6043319702148438 sec\n",
      "Episode 7990, len12, loss:-100.6494, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5508749485015869 sec\n",
      "Episode 7991, len12, loss:-104.5709, fail, steps:80, opt steps:22, total reward:-24.0000, 0.551276445388794 sec\n",
      "Episode 7992, len8, loss:-80.7531, fail, steps:80, opt steps:16, total reward:-24.0000, 0.548882246017456 sec\n",
      "Episode 7993, len10, loss:-86.8103, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5497264862060547 sec\n",
      "Episode 7994, len6, loss:-74.5211, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5499117374420166 sec\n",
      "Episode 7995, len8, loss:-75.7667, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5481667518615723 sec\n",
      "Episode 7996, len8, loss:-83.9582, fail, steps:80, opt steps:7, total reward:-24.0000, 0.549412727355957 sec\n",
      "Episode 7997, len6, loss:-70.0066, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5487720966339111 sec\n",
      "Episode 7998, len12, loss:-101.6005, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5495748519897461 sec\n",
      "Episode 7999, len12, loss:-94.2935, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5505187511444092 sec\n",
      "Episode 8000, len6, loss:-72.5254, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5489468574523926 sec\n",
      "Checkpoint saved at episode 8000 to /home/mcwave/code/autocode/datasets/rl_sort_transformer_easy/list6_12_transformer3_128_gamma07_step80_v3_merge_2_sorted/ckpt_8000_0.0000_26.24_vs_5.25.pth\n",
      "Learning rate = 0.000085\n",
      "Episode 8001, len6, loss:-68.6194, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5478949546813965 sec\n",
      "Episode 8002, len12, loss:-96.6147, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5490226745605469 sec\n",
      "Episode 8003, len6, loss:-70.4454, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5974581241607666 sec\n",
      "Episode 8004, len12, loss:-98.9033, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5495412349700928 sec\n",
      "Episode 8005, len8, loss:-83.8493, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5513336658477783 sec\n",
      "Episode 8006, len8, loss:-80.0272, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490529537200928 sec\n",
      "Episode 8007, len8, loss:-81.7047, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5477960109710693 sec\n",
      "Episode 8008, len10, loss:-77.4770, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5495264530181885 sec\n",
      "Episode 8009, len8, loss:-75.5273, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5498783588409424 sec\n",
      "Episode 8010, len6, loss:-75.0851, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5442266464233398 sec\n",
      "Episode 8011, len10, loss:-76.6465, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5485720634460449 sec\n",
      "Episode 8012, len12, loss:-93.1058, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5483214855194092 sec\n",
      "Episode 8013, len6, loss:-66.1533, fail, steps:80, opt steps:13, total reward:-22.7000, 0.5446817874908447 sec\n",
      "Episode 8014, len10, loss:-88.9203, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5491681098937988 sec\n",
      "Episode 8015, len10, loss:-83.0105, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5499632358551025 sec\n",
      "Episode 8016, len12, loss:-95.7772, fail, steps:80, opt steps:41, total reward:-24.0000, 0.550572395324707 sec\n",
      "Episode 8017, len6, loss:-70.6578, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5980415344238281 sec\n",
      "Episode 8018, len8, loss:-81.7236, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5478134155273438 sec\n",
      "Episode 8019, len6, loss:-72.0805, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5520761013031006 sec\n",
      "Episode 8020, len10, loss:-85.9526, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5487189292907715 sec\n",
      "Episode 8021, len6, loss:-73.0984, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5484089851379395 sec\n",
      "Episode 8022, len6, loss:-76.1146, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5469129085540771 sec\n",
      "Episode 8023, len12, loss:-106.0324, fail, steps:80, opt steps:39, total reward:-24.7000, 0.5453484058380127 sec\n",
      "Episode 8024, len12, loss:-96.1467, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5493786334991455 sec\n",
      "Episode 8025, len6, loss:-69.1369, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5479183197021484 sec\n",
      "Episode 8026, len12, loss:-98.2093, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5492813587188721 sec\n",
      "Episode 8027, len8, loss:-84.2677, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5484323501586914 sec\n",
      "Episode 8028, len6, loss:-76.3111, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5480377674102783 sec\n",
      "Episode 8029, len6, loss:-71.4361, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5480141639709473 sec\n",
      "Episode 8030, len12, loss:-96.2637, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5490727424621582 sec\n",
      "Episode 8031, len8, loss:-77.7604, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5468790531158447 sec\n",
      "Episode 8032, len10, loss:-80.7250, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5987107753753662 sec\n",
      "Episode 8033, len8, loss:-80.2740, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5480177402496338 sec\n",
      "Episode 8034, len12, loss:-98.2083, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5490293502807617 sec\n",
      "Episode 8035, len6, loss:-78.9711, fail, steps:80, opt steps:21, total reward:-24.4000, 0.539592981338501 sec\n",
      "Episode 8036, len6, loss:-71.0009, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5477809906005859 sec\n",
      "Episode 8037, len6, loss:-74.1578, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5471999645233154 sec\n",
      "Episode 8038, len10, loss:-88.9728, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5484440326690674 sec\n",
      "Episode 8039, len10, loss:-83.4784, fail, steps:80, opt steps:27, total reward:-24.7000, 0.5433988571166992 sec\n",
      "Episode 8040, len12, loss:-94.9049, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5477049350738525 sec\n",
      "Episode 8041, len8, loss:-78.7025, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5476603507995605 sec\n",
      "Episode 8042, len8, loss:-79.0880, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5495307445526123 sec\n",
      "Episode 8043, len12, loss:-104.8085, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5489401817321777 sec\n",
      "Episode 8044, len12, loss:-96.6703, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5489304065704346 sec\n",
      "Episode 8045, len8, loss:-83.8631, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5492136478424072 sec\n",
      "Episode 8046, len12, loss:-99.4563, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5484299659729004 sec\n",
      "Episode 8047, len6, loss:-72.5244, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5479583740234375 sec\n",
      "Episode 8048, len12, loss:-100.7200, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5997641086578369 sec\n",
      "Episode 8049, len10, loss:-82.7604, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5488796234130859 sec\n",
      "Episode 8050, len6, loss:-70.2954, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5494835376739502 sec\n",
      "Episode 8051, len8, loss:-78.9295, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5483150482177734 sec\n",
      "Episode 8052, len10, loss:-77.7691, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5503885746002197 sec\n",
      "Episode 8053, len12, loss:-90.9815, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5483276844024658 sec\n",
      "Episode 8054, len12, loss:-102.3290, fail, steps:80, opt steps:55, total reward:-24.0000, 0.548480749130249 sec\n",
      "Episode 8055, len6, loss:-69.9314, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5481369495391846 sec\n",
      "Episode 8056, len12, loss:-99.4995, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5482845306396484 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8057, len8, loss:-88.7911, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5471489429473877 sec\n",
      "Episode 8058, len12, loss:-94.2354, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5485024452209473 sec\n",
      "Episode 8059, len8, loss:-82.8638, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5516695976257324 sec\n",
      "Episode 8060, len8, loss:-79.8115, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5485320091247559 sec\n",
      "Episode 8061, len10, loss:-77.5165, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5488202571868896 sec\n",
      "Episode 8062, len6, loss:-73.2927, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5483279228210449 sec\n",
      "Episode 8063, len8, loss:-84.7449, fail, steps:80, opt steps:17, total reward:-24.0000, 0.550656795501709 sec\n",
      "Episode 8064, len8, loss:-77.6057, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5996465682983398 sec\n",
      "Episode 8065, len6, loss:-72.8373, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5507967472076416 sec\n",
      "Episode 8066, len6, loss:-72.6943, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5483899116516113 sec\n",
      "Episode 8067, len12, loss:-90.8137, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5504488945007324 sec\n",
      "Episode 8068, len6, loss:-73.2117, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5493500232696533 sec\n",
      "Episode 8069, len8, loss:-79.6002, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5522584915161133 sec\n",
      "Episode 8070, len8, loss:-77.4896, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5476295948028564 sec\n",
      "Episode 8071, len6, loss:-74.9635, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5484251976013184 sec\n",
      "Episode 8072, len6, loss:-72.5680, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5472545623779297 sec\n",
      "Episode 8073, len8, loss:-84.0019, fail, steps:80, opt steps:28, total reward:-24.0000, 0.54744553565979 sec\n",
      "Episode 8074, len10, loss:-80.2427, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5501992702484131 sec\n",
      "Episode 8075, len6, loss:-72.3590, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5536115169525146 sec\n",
      "Episode 8076, len6, loss:-70.8310, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5483534336090088 sec\n",
      "Episode 8077, len10, loss:-85.3437, fail, steps:80, opt steps:29, total reward:-24.0000, 0.6091883182525635 sec\n",
      "Episode 8078, len10, loss:-82.2081, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5498306751251221 sec\n",
      "Episode 8079, len8, loss:-83.2812, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5475635528564453 sec\n",
      "Episode 8080, len6, loss:-73.3442, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5475084781646729 sec\n",
      "Episode 8081, len12, loss:-94.7747, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5478668212890625 sec\n",
      "Episode 8082, len12, loss:-97.6552, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5483493804931641 sec\n",
      "Episode 8083, len6, loss:-74.9856, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5484752655029297 sec\n",
      "Episode 8084, len6, loss:-76.9431, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5476505756378174 sec\n",
      "Episode 8085, len12, loss:-94.0195, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5493032932281494 sec\n",
      "Episode 8086, len6, loss:-74.5180, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5467588901519775 sec\n",
      "Episode 8087, len12, loss:-90.3834, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5480647087097168 sec\n",
      "Episode 8088, len6, loss:-74.2492, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5476975440979004 sec\n",
      "Episode 8089, len12, loss:-84.6408, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5484590530395508 sec\n",
      "Episode 8090, len6, loss:-70.0440, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5479531288146973 sec\n",
      "Episode 8091, len8, loss:-84.1299, fail, steps:80, opt steps:33, total reward:-24.0000, 0.6067092418670654 sec\n",
      "Episode 8092, len8, loss:-82.9184, fail, steps:80, opt steps:14, total reward:-24.0000, 0.549445629119873 sec\n",
      "Episode 8093, len10, loss:-79.9889, fail, steps:80, opt steps:37, total reward:-24.0000, 0.549257755279541 sec\n",
      "Episode 8094, len8, loss:-78.3524, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5478317737579346 sec\n",
      "Episode 8095, len12, loss:-97.4786, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5474681854248047 sec\n",
      "Episode 8096, len10, loss:-75.0110, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5479094982147217 sec\n",
      "Episode 8097, len8, loss:-84.2271, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5483653545379639 sec\n",
      "Episode 8098, len6, loss:-71.5959, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5472581386566162 sec\n",
      "Episode 8099, len6, loss:-74.1093, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5477616786956787 sec\n",
      "Episode 8100, len12, loss:-92.3799, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5485963821411133 sec\n",
      "Episode 8101, len12, loss:-99.9629, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5481727123260498 sec\n",
      "Episode 8102, len10, loss:-76.2899, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5479319095611572 sec\n",
      "Episode 8103, len10, loss:-82.9422, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5481681823730469 sec\n",
      "Episode 8104, len12, loss:-93.0766, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5471346378326416 sec\n",
      "Episode 8105, len8, loss:-76.8372, fail, steps:80, opt steps:21, total reward:-24.0000, 0.6035115718841553 sec\n",
      "Episode 8106, len6, loss:-68.7929, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5497899055480957 sec\n",
      "Episode 8107, len12, loss:-92.0691, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5482547283172607 sec\n",
      "Episode 8108, len8, loss:-81.4965, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5473582744598389 sec\n",
      "Episode 8109, len12, loss:-93.5120, fail, steps:80, opt steps:77, total reward:-24.0000, 0.548414945602417 sec\n",
      "Episode 8110, len8, loss:-80.5453, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5482385158538818 sec\n",
      "Episode 8111, len8, loss:-80.9026, fail, steps:80, opt steps:9, total reward:-24.0000, 0.546804666519165 sec\n",
      "Episode 8112, len12, loss:-91.0847, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5491762161254883 sec\n",
      "Episode 8113, len6, loss:-73.0440, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5467851161956787 sec\n",
      "Episode 8114, len6, loss:-71.8024, fail, steps:80, opt steps:11, total reward:-24.0000, 0.54770827293396 sec\n",
      "Episode 8115, len8, loss:-79.8942, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490951538085938 sec\n",
      "Episode 8116, len6, loss:-67.8344, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5474040508270264 sec\n",
      "Episode 8117, len10, loss:-76.2544, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548572301864624 sec\n",
      "Episode 8118, len12, loss:-101.4336, fail, steps:80, opt steps:44, total reward:-24.0000, 0.549135684967041 sec\n",
      "Episode 8119, len8, loss:-84.5121, fail, steps:80, opt steps:23, total reward:-24.0000, 0.6028780937194824 sec\n",
      "Episode 8120, len12, loss:-95.1488, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5488357543945312 sec\n",
      "Episode 8121, len10, loss:-78.1867, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5488324165344238 sec\n",
      "Episode 8122, len8, loss:-84.2017, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5479109287261963 sec\n",
      "Episode 8123, len6, loss:-72.0150, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5476226806640625 sec\n",
      "Episode 8124, len6, loss:-71.2389, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5477185249328613 sec\n",
      "Episode 8125, len6, loss:-72.2645, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5484778881072998 sec\n",
      "Episode 8126, len12, loss:-87.7312, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5480835437774658 sec\n",
      "Episode 8127, len10, loss:-82.1890, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5477626323699951 sec\n",
      "Episode 8128, len6, loss:-73.9669, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5486171245574951 sec\n",
      "Episode 8129, len10, loss:-71.4764, fail, steps:80, opt steps:44, total reward:-24.0000, 0.547877311706543 sec\n",
      "Episode 8130, len10, loss:-70.6826, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5489053726196289 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8131, len8, loss:-78.6672, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5492489337921143 sec\n",
      "Episode 8132, len6, loss:-77.3148, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5479371547698975 sec\n",
      "Episode 8133, len6, loss:-79.8687, fail, steps:80, opt steps:13, total reward:-24.0000, 0.6028611660003662 sec\n",
      "Episode 8134, len6, loss:-73.3486, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5492441654205322 sec\n",
      "Episode 8135, len8, loss:-81.5788, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5482749938964844 sec\n",
      "Episode 8136, len12, loss:-101.7004, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5484399795532227 sec\n",
      "Episode 8137, len10, loss:-76.2659, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5490059852600098 sec\n",
      "Episode 8138, len8, loss:-83.6719, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5488183498382568 sec\n",
      "Episode 8139, len10, loss:-78.5339, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5488624572753906 sec\n",
      "Episode 8140, len10, loss:-78.7567, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5476250648498535 sec\n",
      "Episode 8141, len6, loss:-73.7287, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5480334758758545 sec\n",
      "Episode 8142, len12, loss:-97.0179, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5483171939849854 sec\n",
      "Episode 8143, len6, loss:-75.2009, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5474622249603271 sec\n",
      "Episode 8144, len10, loss:-84.0116, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5482656955718994 sec\n",
      "Episode 8145, len8, loss:-80.0408, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5484302043914795 sec\n",
      "Episode 8146, len6, loss:-75.5107, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5479466915130615 sec\n",
      "Episode 8147, len6, loss:-70.0937, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5483169555664062 sec\n",
      "Episode 8148, len8, loss:-76.0221, fail, steps:80, opt steps:22, total reward:-24.0000, 0.6012117862701416 sec\n",
      "Episode 8149, len6, loss:-71.1146, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5483319759368896 sec\n",
      "Episode 8150, len12, loss:-86.1359, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5484626293182373 sec\n",
      "Episode 8151, len8, loss:-79.1286, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5478370189666748 sec\n",
      "Episode 8152, len12, loss:-96.5125, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5480911731719971 sec\n",
      "Episode 8153, len6, loss:-72.9114, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5473556518554688 sec\n",
      "Episode 8154, len12, loss:-99.6192, fail, steps:80, opt steps:51, total reward:-24.0000, 0.548471212387085 sec\n",
      "Episode 8155, len12, loss:-96.1498, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5490748882293701 sec\n",
      "Episode 8156, len8, loss:-79.9329, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5479929447174072 sec\n",
      "Episode 8157, len12, loss:-96.6858, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5492393970489502 sec\n",
      "Episode 8158, len8, loss:-85.1585, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5478653907775879 sec\n",
      "Episode 8159, len10, loss:-83.0207, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5484118461608887 sec\n",
      "Episode 8160, len10, loss:-81.8520, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5496747493743896 sec\n",
      "Episode 8161, len10, loss:-79.2073, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5490314960479736 sec\n",
      "Episode 8162, len6, loss:-71.1253, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5484979152679443 sec\n",
      "Episode 8163, len10, loss:-73.8241, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5482895374298096 sec\n",
      "Episode 8164, len8, loss:-80.7857, fail, steps:80, opt steps:18, total reward:-24.0000, 0.6023318767547607 sec\n",
      "Episode 8165, len12, loss:-86.3950, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5489835739135742 sec\n",
      "Episode 8166, len12, loss:-94.2025, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5474302768707275 sec\n",
      "Episode 8167, len10, loss:-86.1205, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5493147373199463 sec\n",
      "Episode 8168, len12, loss:-94.0391, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5485951900482178 sec\n",
      "Episode 8169, len10, loss:-77.0467, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5478031635284424 sec\n",
      "Episode 8170, len12, loss:-98.1904, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5487568378448486 sec\n",
      "Episode 8171, len12, loss:-88.4154, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5478711128234863 sec\n",
      "Episode 8172, len8, loss:-77.3681, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5486009120941162 sec\n",
      "Episode 8173, len8, loss:-84.0809, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5485610961914062 sec\n",
      "Episode 8174, len8, loss:-82.0862, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5530214309692383 sec\n",
      "Episode 8175, len12, loss:-95.4584, fail, steps:80, opt steps:50, total reward:-24.0000, 0.547370195388794 sec\n",
      "Episode 8176, len12, loss:-86.8479, fail, steps:80, opt steps:66, total reward:-24.0000, 0.549156665802002 sec\n",
      "Episode 8177, len12, loss:-84.6972, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5487229824066162 sec\n",
      "Episode 8178, len10, loss:-76.0691, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5483047962188721 sec\n",
      "Episode 8179, len8, loss:-81.3977, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5487525463104248 sec\n",
      "Episode 8180, len8, loss:-83.1061, fail, steps:80, opt steps:34, total reward:-24.0000, 0.6036584377288818 sec\n",
      "Episode 8181, len6, loss:-61.1480, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5481870174407959 sec\n",
      "Episode 8182, len12, loss:-87.1709, fail, steps:80, opt steps:26, total reward:-24.0000, 0.548192024230957 sec\n",
      "Episode 8183, len6, loss:-65.8881, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5490846633911133 sec\n",
      "Episode 8184, len6, loss:-71.1522, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5473887920379639 sec\n",
      "Episode 8185, len6, loss:-65.6288, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5466876029968262 sec\n",
      "Episode 8186, len10, loss:-72.5823, fail, steps:80, opt steps:31, total reward:-24.0000, 0.549210786819458 sec\n",
      "Episode 8187, len8, loss:-75.0651, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5484626293182373 sec\n",
      "Episode 8188, len10, loss:-74.1407, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5481958389282227 sec\n",
      "Episode 8189, len8, loss:-83.6678, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5474309921264648 sec\n",
      "Episode 8190, len6, loss:-63.2082, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5478885173797607 sec\n",
      "Episode 8191, len12, loss:-88.1212, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5485823154449463 sec\n",
      "Episode 8192, len6, loss:-69.1677, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5491647720336914 sec\n",
      "Episode 8193, len12, loss:-92.7933, fail, steps:80, opt steps:37, total reward:-24.0000, 0.608006477355957 sec\n",
      "Episode 8194, len8, loss:-81.8776, fail, steps:80, opt steps:27, total reward:-24.0000, 0.54964280128479 sec\n",
      "Episode 8195, len6, loss:-64.9384, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5477280616760254 sec\n",
      "Episode 8196, len6, loss:-71.0554, fail, steps:80, opt steps:12, total reward:-24.0000, 0.547919750213623 sec\n",
      "Episode 8197, len10, loss:-80.4993, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5484087467193604 sec\n",
      "Episode 8198, len10, loss:-74.6605, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5471465587615967 sec\n",
      "Episode 8199, len8, loss:-80.1038, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5479156970977783 sec\n",
      "Episode 8200, len6, loss:-65.3663, fail, steps:80, opt steps:10, total reward:-24.0000, 0.549335241317749 sec\n",
      "Episode 8201, len8, loss:-76.1516, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5479443073272705 sec\n",
      "Episode 8202, len8, loss:-75.0266, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5481839179992676 sec\n",
      "Episode 8203, len12, loss:-96.6743, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5480697154998779 sec\n",
      "Episode 8204, len8, loss:-78.2336, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5479967594146729 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8205, len6, loss:-65.3027, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5485436916351318 sec\n",
      "Episode 8206, len10, loss:-75.7523, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5487136840820312 sec\n",
      "Episode 8207, len8, loss:-78.6651, fail, steps:80, opt steps:19, total reward:-24.0000, 0.6059644222259521 sec\n",
      "Episode 8208, len6, loss:-61.1578, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5486454963684082 sec\n",
      "Episode 8209, len12, loss:-93.6415, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5477182865142822 sec\n",
      "Episode 8210, len10, loss:-75.2451, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5488982200622559 sec\n",
      "Episode 8211, len12, loss:-89.3413, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5488162040710449 sec\n",
      "Episode 8212, len12, loss:-90.0220, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5487380027770996 sec\n",
      "Episode 8213, len6, loss:-66.5394, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5494546890258789 sec\n",
      "Episode 8214, len8, loss:-84.6357, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5433251857757568 sec\n",
      "Episode 8215, len12, loss:-97.4383, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5482611656188965 sec\n",
      "Episode 8216, len6, loss:-68.3327, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5479152202606201 sec\n",
      "Episode 8217, len10, loss:-82.1886, fail, steps:80, opt steps:21, total reward:-24.0000, 0.547809362411499 sec\n",
      "Episode 8218, len10, loss:-84.6806, fail, steps:80, opt steps:41, total reward:-24.0000, 0.546964168548584 sec\n",
      "Episode 8219, len6, loss:-66.8410, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5485563278198242 sec\n",
      "Episode 8220, len10, loss:-77.6585, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5492417812347412 sec\n",
      "Episode 8221, len8, loss:-73.6752, fail, steps:80, opt steps:18, total reward:-24.0000, 0.6039354801177979 sec\n",
      "Episode 8222, len10, loss:-77.5977, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5471034049987793 sec\n",
      "Episode 8223, len8, loss:-77.4995, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5491085052490234 sec\n",
      "Episode 8224, len12, loss:-89.2854, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5485568046569824 sec\n",
      "Episode 8225, len12, loss:-86.3171, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5478332042694092 sec\n",
      "Episode 8226, len12, loss:-91.3506, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5487024784088135 sec\n",
      "Episode 8227, len6, loss:-59.2149, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5465753078460693 sec\n",
      "Episode 8228, len10, loss:-74.4790, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5473105907440186 sec\n",
      "Episode 8229, len12, loss:-88.6881, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5470569133758545 sec\n",
      "Episode 8230, len12, loss:-91.9142, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5475735664367676 sec\n",
      "Episode 8231, len12, loss:-98.5262, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5487532615661621 sec\n",
      "Episode 8232, len8, loss:-76.7098, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5473978519439697 sec\n",
      "Episode 8233, len6, loss:-59.9926, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5479767322540283 sec\n",
      "Episode 8234, len10, loss:-71.2850, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5485272407531738 sec\n",
      "Episode 8235, len10, loss:-78.7441, fail, steps:80, opt steps:31, total reward:-24.0000, 0.602344274520874 sec\n",
      "Episode 8236, len12, loss:-88.3508, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5497305393218994 sec\n",
      "Episode 8237, len8, loss:-70.0215, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5485384464263916 sec\n",
      "Episode 8238, len8, loss:-83.9073, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5478396415710449 sec\n",
      "Episode 8239, len6, loss:-65.6339, fail, steps:80, opt steps:19, total reward:-23.7000, 0.54396653175354 sec\n",
      "Episode 8240, len6, loss:-60.8542, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5477180480957031 sec\n",
      "Episode 8241, len8, loss:-77.3792, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5485460758209229 sec\n",
      "Episode 8242, len6, loss:-65.2330, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5480735301971436 sec\n",
      "Episode 8243, len10, loss:-84.4863, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5479419231414795 sec\n",
      "Episode 8244, len6, loss:-73.4723, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5485389232635498 sec\n",
      "Episode 8245, len6, loss:-55.8236, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5497872829437256 sec\n",
      "Episode 8246, len12, loss:-82.7028, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5503604412078857 sec\n",
      "Episode 8247, len12, loss:-90.0641, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5497782230377197 sec\n",
      "Episode 8248, len6, loss:-58.9646, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5491149425506592 sec\n",
      "Episode 8249, len6, loss:-66.0791, fail, steps:80, opt steps:18, total reward:-24.0000, 0.6013948917388916 sec\n",
      "Episode 8250, len12, loss:-87.6030, fail, steps:80, opt steps:66, total reward:-24.0000, 0.54787278175354 sec\n",
      "Episode 8251, len8, loss:-80.8079, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5476233959197998 sec\n",
      "Episode 8252, len10, loss:-74.9657, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5492241382598877 sec\n",
      "Episode 8253, len10, loss:-70.9263, fail, steps:80, opt steps:19, total reward:-24.0000, 0.548933744430542 sec\n",
      "Episode 8254, len12, loss:-86.1006, fail, steps:80, opt steps:46, total reward:-24.0000, 0.548090934753418 sec\n",
      "Episode 8255, len12, loss:-87.8853, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5483736991882324 sec\n",
      "Episode 8256, len6, loss:-68.6023, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5467205047607422 sec\n",
      "Episode 8257, len6, loss:-67.9735, fail, steps:80, opt steps:11, total reward:-24.0000, 0.547896146774292 sec\n",
      "Episode 8258, len10, loss:-67.7823, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5476877689361572 sec\n",
      "Episode 8259, len8, loss:-82.5240, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5489060878753662 sec\n",
      "Episode 8260, len10, loss:-85.5758, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5479741096496582 sec\n",
      "Episode 8261, len8, loss:-75.7230, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5482981204986572 sec\n",
      "Episode 8262, len10, loss:-79.5813, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5478949546813965 sec\n",
      "Episode 8263, len8, loss:-76.8689, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5476884841918945 sec\n",
      "Episode 8264, len12, loss:-89.6709, fail, steps:80, opt steps:45, total reward:-24.0000, 0.6014044284820557 sec\n",
      "Episode 8265, len12, loss:-94.0597, fail, steps:80, opt steps:48, total reward:-24.0000, 0.54819655418396 sec\n",
      "Episode 8266, len12, loss:-104.8483, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5476176738739014 sec\n",
      "Episode 8267, len12, loss:-88.9862, fail, steps:80, opt steps:36, total reward:-24.0000, 0.547088623046875 sec\n",
      "Episode 8268, len8, loss:-75.3232, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5478243827819824 sec\n",
      "Episode 8269, len12, loss:-95.9050, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5470929145812988 sec\n",
      "Episode 8270, len12, loss:-96.7587, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5478780269622803 sec\n",
      "Episode 8271, len6, loss:-54.6009, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5476372241973877 sec\n",
      "Episode 8272, len8, loss:-76.1024, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5480303764343262 sec\n",
      "Episode 8273, len12, loss:-82.7471, fail, steps:80, opt steps:52, total reward:-24.0000, 0.548114538192749 sec\n",
      "Episode 8274, len12, loss:-89.0060, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5480823516845703 sec\n",
      "Episode 8275, len8, loss:-77.5465, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5485081672668457 sec\n",
      "Episode 8276, len8, loss:-72.3493, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5474534034729004 sec\n",
      "Episode 8277, len6, loss:-67.0652, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5471212863922119 sec\n",
      "Episode 8278, len6, loss:-62.7073, fail, steps:80, opt steps:13, total reward:-24.0000, 0.546912670135498 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8279, len10, loss:-71.3231, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5474033355712891 sec\n",
      "Episode 8280, len6, loss:-64.1286, fail, steps:80, opt steps:7, total reward:-24.0000, 0.600520133972168 sec\n",
      "Episode 8281, len8, loss:-80.9371, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5490331649780273 sec\n",
      "Episode 8282, len6, loss:-66.3845, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5469837188720703 sec\n",
      "Episode 8283, len8, loss:-73.7762, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5475804805755615 sec\n",
      "Episode 8284, len6, loss:-61.1187, fail, steps:80, opt steps:11, total reward:-24.0000, 0.547351598739624 sec\n",
      "Episode 8285, len12, loss:-96.7292, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5480670928955078 sec\n",
      "Episode 8286, len10, loss:-78.8401, fail, steps:80, opt steps:40, total reward:-24.0000, 0.547992467880249 sec\n",
      "Episode 8287, len8, loss:-73.4320, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5463709831237793 sec\n",
      "Episode 8288, len6, loss:-61.0903, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5491182804107666 sec\n",
      "Episode 8289, len10, loss:-70.4479, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5476028919219971 sec\n",
      "Episode 8290, len10, loss:-74.7801, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5474843978881836 sec\n",
      "Episode 8291, len10, loss:-81.3499, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5482773780822754 sec\n",
      "Episode 8292, len6, loss:-63.6641, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5475442409515381 sec\n",
      "Episode 8293, len12, loss:-89.7014, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5466077327728271 sec\n",
      "Episode 8294, len10, loss:-73.9765, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5477645397186279 sec\n",
      "Episode 8295, len6, loss:-70.4782, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5474936962127686 sec\n",
      "Episode 8296, len8, loss:-76.4478, fail, steps:80, opt steps:14, total reward:-24.0000, 0.6016006469726562 sec\n",
      "Episode 8297, len6, loss:-60.8233, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5477232933044434 sec\n",
      "Episode 8298, len12, loss:-86.1170, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5488259792327881 sec\n",
      "Episode 8299, len6, loss:-66.5458, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5479981899261475 sec\n",
      "Episode 8300, len12, loss:-96.1242, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5477335453033447 sec\n",
      "Episode 8301, len10, loss:-75.8766, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5482492446899414 sec\n",
      "Episode 8302, len12, loss:-89.2210, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5484864711761475 sec\n",
      "Episode 8303, len10, loss:-70.5382, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5486605167388916 sec\n",
      "Episode 8304, len10, loss:-72.1723, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5474154949188232 sec\n",
      "Episode 8305, len12, loss:-90.5677, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5474443435668945 sec\n",
      "Episode 8306, len10, loss:-60.5758, fail, steps:80, opt steps:33, total reward:-24.0000, 0.547081470489502 sec\n",
      "Episode 8307, len6, loss:-63.0284, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5467991828918457 sec\n",
      "Episode 8308, len12, loss:-94.1134, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5468521118164062 sec\n",
      "Episode 8309, len8, loss:-82.6096, fail, steps:80, opt steps:27, total reward:-24.0000, 0.6080007553100586 sec\n",
      "Episode 8310, len12, loss:-86.2578, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5491495132446289 sec\n",
      "Episode 8311, len12, loss:-91.8779, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5483994483947754 sec\n",
      "Episode 8312, len8, loss:-83.3299, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490052700042725 sec\n",
      "Episode 8313, len10, loss:-73.6808, fail, steps:80, opt steps:44, total reward:-24.0000, 0.548825740814209 sec\n",
      "Episode 8314, len6, loss:-67.2093, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5474410057067871 sec\n",
      "Episode 8315, len10, loss:-67.9403, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5468733310699463 sec\n",
      "Episode 8316, len12, loss:-86.8313, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5473709106445312 sec\n",
      "Episode 8317, len12, loss:-86.3275, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5486025810241699 sec\n",
      "Episode 8318, len6, loss:-70.1214, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5421924591064453 sec\n",
      "Episode 8319, len6, loss:-66.9310, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5469343662261963 sec\n",
      "Episode 8320, len6, loss:-69.9349, fail, steps:80, opt steps:18, total reward:-24.0000, 0.546358585357666 sec\n",
      "Episode 8321, len6, loss:-67.2632, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5475337505340576 sec\n",
      "Episode 8322, len10, loss:-73.5931, fail, steps:80, opt steps:37, total reward:-24.7000, 0.5434257984161377 sec\n",
      "Episode 8323, len8, loss:-80.2306, fail, steps:80, opt steps:26, total reward:-24.0000, 0.6036267280578613 sec\n",
      "Episode 8324, len12, loss:-87.7022, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5481276512145996 sec\n",
      "Episode 8325, len10, loss:-67.5467, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5488390922546387 sec\n",
      "Episode 8326, len8, loss:-78.5499, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5470788478851318 sec\n",
      "Episode 8327, len10, loss:-70.6224, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5472612380981445 sec\n",
      "Episode 8328, len6, loss:-71.4345, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5477168560028076 sec\n",
      "Episode 8329, len8, loss:-84.0164, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5473275184631348 sec\n",
      "Episode 8330, len10, loss:-63.0985, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5470666885375977 sec\n",
      "Episode 8331, len10, loss:-70.2157, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5475480556488037 sec\n",
      "Episode 8332, len6, loss:-70.3897, fail, steps:80, opt steps:11, total reward:-24.0000, 0.547764778137207 sec\n",
      "Episode 8333, len10, loss:-72.3937, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5464615821838379 sec\n",
      "Episode 8334, len12, loss:-83.5392, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5482845306396484 sec\n",
      "Episode 8335, len6, loss:-68.5299, fail, steps:80, opt steps:11, total reward:-24.0000, 0.548393726348877 sec\n",
      "Episode 8336, len10, loss:-68.1834, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5468175411224365 sec\n",
      "Episode 8337, len8, loss:-85.3652, fail, steps:80, opt steps:15, total reward:-24.0000, 0.6046452522277832 sec\n",
      "Episode 8338, len10, loss:-63.4475, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5475883483886719 sec\n",
      "Episode 8339, len10, loss:-60.7660, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5489399433135986 sec\n",
      "Episode 8340, len6, loss:-67.0681, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5474283695220947 sec\n",
      "Episode 8341, len12, loss:-80.2682, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5482702255249023 sec\n",
      "Episode 8342, len10, loss:-69.9567, fail, steps:80, opt steps:37, total reward:-24.0000, 0.547435998916626 sec\n",
      "Episode 8343, len6, loss:-69.6118, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5475280284881592 sec\n",
      "Episode 8344, len10, loss:-56.4902, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5475242137908936 sec\n",
      "Episode 8345, len10, loss:-69.0837, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5494959354400635 sec\n",
      "Episode 8346, len8, loss:-74.5488, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5481359958648682 sec\n",
      "Episode 8347, len12, loss:-76.8375, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5486245155334473 sec\n",
      "Episode 8348, len12, loss:-81.4715, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5500462055206299 sec\n",
      "Episode 8349, len12, loss:-80.2137, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5485754013061523 sec\n",
      "Episode 8350, len8, loss:-82.5754, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5492253303527832 sec\n",
      "Episode 8351, len8, loss:-82.2044, fail, steps:80, opt steps:26, total reward:-24.0000, 0.6025009155273438 sec\n",
      "Episode 8352, len6, loss:-67.7945, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5481464862823486 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8353, len6, loss:-73.1550, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5470037460327148 sec\n",
      "Episode 8354, len8, loss:-77.9135, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5468029975891113 sec\n",
      "Episode 8355, len12, loss:-84.2489, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5478341579437256 sec\n",
      "Episode 8356, len8, loss:-83.7365, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5481982231140137 sec\n",
      "Episode 8357, len8, loss:-81.3892, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5471787452697754 sec\n",
      "Episode 8358, len12, loss:-96.8323, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5475597381591797 sec\n",
      "Episode 8359, len12, loss:-90.4799, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5476737022399902 sec\n",
      "Episode 8360, len12, loss:-92.6047, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5486917495727539 sec\n",
      "Episode 8361, len6, loss:-72.0032, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5483047962188721 sec\n",
      "Episode 8362, len6, loss:-75.4921, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5474679470062256 sec\n",
      "Episode 8363, len10, loss:-66.5784, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5492849349975586 sec\n",
      "Episode 8364, len6, loss:-72.5497, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5482373237609863 sec\n",
      "Episode 8365, len6, loss:-83.8063, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5975217819213867 sec\n",
      "Episode 8366, len12, loss:-89.4333, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5470144748687744 sec\n",
      "Episode 8367, len6, loss:-74.4051, fail, steps:80, opt steps:7, total reward:-24.0000, 0.547518253326416 sec\n",
      "Episode 8368, len12, loss:-76.7280, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5492303371429443 sec\n",
      "Episode 8369, len6, loss:-74.0735, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5476787090301514 sec\n",
      "Episode 8370, len12, loss:-83.0548, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5486409664154053 sec\n",
      "Episode 8371, len8, loss:-79.6320, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5486636161804199 sec\n",
      "Episode 8372, len10, loss:-78.4515, fail, steps:80, opt steps:42, total reward:-24.7000, 0.5446023941040039 sec\n",
      "Episode 8373, len10, loss:-62.0186, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5486860275268555 sec\n",
      "Episode 8374, len6, loss:-71.6655, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5483191013336182 sec\n",
      "Episode 8375, len12, loss:-84.2858, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5502476692199707 sec\n",
      "Episode 8376, len8, loss:-81.0802, fail, steps:80, opt steps:14, total reward:-24.0000, 0.548337459564209 sec\n",
      "Episode 8377, len10, loss:-62.0211, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5486845970153809 sec\n",
      "Episode 8378, len12, loss:-86.0669, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5495219230651855 sec\n",
      "Episode 8379, len6, loss:-69.3861, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5496163368225098 sec\n",
      "Episode 8380, len10, loss:-76.2732, fail, steps:80, opt steps:52, total reward:-24.7000, 0.5936050415039062 sec\n",
      "Episode 8381, len6, loss:-71.7690, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5486440658569336 sec\n",
      "Episode 8382, len8, loss:-80.0111, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5495092868804932 sec\n",
      "Episode 8383, len10, loss:-64.8086, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5486748218536377 sec\n",
      "Episode 8384, len12, loss:-83.8355, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5498542785644531 sec\n",
      "Episode 8385, len6, loss:-72.6376, fail, steps:80, opt steps:20, total reward:-24.0000, 0.548487663269043 sec\n",
      "Episode 8386, len10, loss:-59.9111, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5495944023132324 sec\n",
      "Episode 8387, len10, loss:-61.7599, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5499634742736816 sec\n",
      "Episode 8388, len6, loss:-72.6168, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5484039783477783 sec\n",
      "Episode 8389, len6, loss:-69.4606, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5498194694519043 sec\n",
      "Episode 8390, len6, loss:-69.9204, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5482280254364014 sec\n",
      "Episode 8391, len8, loss:-83.6822, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5487864017486572 sec\n",
      "Episode 8392, len12, loss:-87.3266, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5542583465576172 sec\n",
      "Episode 8393, len10, loss:-52.3735, fail, steps:80, opt steps:29, total reward:-24.0000, 0.550400972366333 sec\n",
      "Episode 8394, len8, loss:-82.8318, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5494918823242188 sec\n",
      "Episode 8395, len12, loss:-73.7979, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5484590530395508 sec\n",
      "Episode 8396, len12, loss:-79.0183, fail, steps:80, opt steps:36, total reward:-24.0000, 0.598762035369873 sec\n",
      "Episode 8397, len10, loss:-51.3583, fail, steps:80, opt steps:22, total reward:-24.0000, 0.549372673034668 sec\n",
      "Episode 8398, len8, loss:-77.4726, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5485212802886963 sec\n",
      "Episode 8399, len8, loss:-89.9564, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5508246421813965 sec\n",
      "Episode 8400, len12, loss:-71.0833, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5505585670471191 sec\n",
      "Episode 8401, len6, loss:-68.8630, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5499107837677002 sec\n",
      "Episode 8402, len6, loss:-69.3487, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5490577220916748 sec\n",
      "Episode 8403, len6, loss:-70.4644, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5499932765960693 sec\n",
      "Episode 8404, len12, loss:-78.6428, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5496358871459961 sec\n",
      "Episode 8405, len6, loss:-73.1722, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485050678253174 sec\n",
      "Episode 8406, len8, loss:-87.2225, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5478649139404297 sec\n",
      "Episode 8407, len12, loss:-71.4453, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5475437641143799 sec\n",
      "Episode 8408, len10, loss:-49.4349, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5498297214508057 sec\n",
      "Episode 8409, len12, loss:-86.0083, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5467164516448975 sec\n",
      "Episode 8410, len12, loss:-74.2872, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5478971004486084 sec\n",
      "Episode 8411, len12, loss:-84.1732, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5479013919830322 sec\n",
      "Episode 8412, len6, loss:-71.3849, fail, steps:80, opt steps:17, total reward:-24.0000, 0.6018979549407959 sec\n",
      "Episode 8413, len6, loss:-76.6952, fail, steps:80, opt steps:16, total reward:-24.7000, 0.5457141399383545 sec\n",
      "Episode 8414, len12, loss:-78.3644, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5483198165893555 sec\n",
      "Episode 8415, len10, loss:-54.5399, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5483028888702393 sec\n",
      "Episode 8416, len12, loss:-85.9111, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5484604835510254 sec\n",
      "Episode 8417, len8, loss:-83.6311, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5487573146820068 sec\n",
      "Episode 8418, len6, loss:-73.6104, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5492544174194336 sec\n",
      "Episode 8419, len10, loss:-68.4069, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5477085113525391 sec\n",
      "Episode 8420, len10, loss:-56.7568, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5484223365783691 sec\n",
      "Episode 8421, len12, loss:-90.8909, fail, steps:80, opt steps:39, total reward:-24.4000, 0.5387542247772217 sec\n",
      "Episode 8422, len6, loss:-75.1547, fail, steps:80, opt steps:16, total reward:-24.0000, 0.547426700592041 sec\n",
      "Episode 8423, len10, loss:-56.2893, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5476744174957275 sec\n",
      "Episode 8424, len12, loss:-79.4220, fail, steps:80, opt steps:69, total reward:-24.0000, 0.5476601123809814 sec\n",
      "Episode 8425, len12, loss:-84.6911, fail, steps:80, opt steps:35, total reward:-24.0000, 0.6075148582458496 sec\n",
      "Episode 8426, len8, loss:-88.3538, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5490927696228027 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8427, len12, loss:-88.9666, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5477695465087891 sec\n",
      "Episode 8428, len8, loss:-78.3409, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5486772060394287 sec\n",
      "Episode 8429, len10, loss:-79.8651, fail, steps:80, opt steps:18, total reward:-24.7000, 0.5445766448974609 sec\n",
      "Episode 8430, len10, loss:-51.9405, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5477328300476074 sec\n",
      "Episode 8431, len10, loss:-57.8378, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5475192070007324 sec\n",
      "Episode 8432, len12, loss:-76.6191, fail, steps:80, opt steps:65, total reward:-22.7000, 0.5454115867614746 sec\n",
      "Episode 8433, len12, loss:-81.7457, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5479626655578613 sec\n",
      "Episode 8434, len6, loss:-70.0611, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5476047992706299 sec\n",
      "Episode 8435, len8, loss:-76.6287, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5474905967712402 sec\n",
      "Episode 8436, len8, loss:-82.6785, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5477924346923828 sec\n",
      "Episode 8437, len6, loss:-64.4491, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5489156246185303 sec\n",
      "Episode 8438, len10, loss:-60.7713, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5479648113250732 sec\n",
      "Episode 8439, len6, loss:-71.0410, fail, steps:80, opt steps:19, total reward:-24.0000, 0.6052758693695068 sec\n",
      "Episode 8440, len8, loss:-77.4761, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5480575561523438 sec\n",
      "Episode 8441, len8, loss:-85.7066, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5489780902862549 sec\n",
      "Episode 8442, len8, loss:-85.4950, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5472028255462646 sec\n",
      "Episode 8443, len8, loss:-82.7867, fail, steps:80, opt steps:26, total reward:-24.0000, 0.548931360244751 sec\n",
      "Episode 8444, len8, loss:-81.0773, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5483584403991699 sec\n",
      "Episode 8445, len6, loss:-70.1930, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5478293895721436 sec\n",
      "Episode 8446, len10, loss:-57.1369, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5477535724639893 sec\n",
      "Episode 8447, len10, loss:-60.3407, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5477397441864014 sec\n",
      "Episode 8448, len12, loss:-93.8917, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5479552745819092 sec\n",
      "Episode 8449, len8, loss:-78.7935, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5470058917999268 sec\n",
      "Episode 8450, len6, loss:-74.0378, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5481369495391846 sec\n",
      "Episode 8451, len10, loss:-63.3012, fail, steps:80, opt steps:23, total reward:-24.0000, 0.548128604888916 sec\n",
      "Episode 8452, len10, loss:-66.6420, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5480523109436035 sec\n",
      "Episode 8453, len10, loss:-63.1735, fail, steps:80, opt steps:22, total reward:-24.0000, 0.6044471263885498 sec\n",
      "Episode 8454, len10, loss:-63.3756, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5493004322052002 sec\n",
      "Episode 8455, len8, loss:-81.1501, fail, steps:80, opt steps:17, total reward:-24.0000, 0.550255298614502 sec\n",
      "Episode 8456, len12, loss:-98.4829, fail, steps:80, opt steps:29, total reward:-24.7000, 0.5439586639404297 sec\n",
      "Episode 8457, len12, loss:-92.8413, fail, steps:80, opt steps:49, total reward:-24.7000, 0.5432915687561035 sec\n",
      "Episode 8458, len6, loss:-70.7095, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5475213527679443 sec\n",
      "Episode 8459, len8, loss:-83.7726, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5476715564727783 sec\n",
      "Episode 8460, len8, loss:-84.9072, fail, steps:80, opt steps:21, total reward:-24.0000, 0.547766923904419 sec\n",
      "Episode 8461, len8, loss:-81.3798, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5481102466583252 sec\n",
      "Episode 8462, len8, loss:-83.9241, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5488474369049072 sec\n",
      "Episode 8463, len6, loss:-74.0784, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5477426052093506 sec\n",
      "Episode 8464, len12, loss:-85.5929, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5484857559204102 sec\n",
      "Episode 8465, len10, loss:-60.0183, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5490007400512695 sec\n",
      "Episode 8466, len8, loss:-83.0137, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5490872859954834 sec\n",
      "Episode 8467, len12, loss:-102.1181, fail, steps:80, opt steps:35, total reward:-24.0000, 0.602593183517456 sec\n",
      "Episode 8468, len10, loss:-62.3728, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5488684177398682 sec\n",
      "Episode 8469, len8, loss:-81.6131, fail, steps:80, opt steps:15, total reward:-24.0000, 0.54811692237854 sec\n",
      "Episode 8470, len6, loss:-74.3772, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5489101409912109 sec\n",
      "Episode 8471, len12, loss:-95.1502, fail, steps:80, opt steps:68, total reward:-24.0000, 0.5481569766998291 sec\n",
      "Episode 8472, len12, loss:-86.6375, fail, steps:80, opt steps:48, total reward:-24.0000, 0.547520637512207 sec\n",
      "Episode 8473, len8, loss:-84.0795, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5476701259613037 sec\n",
      "Episode 8474, len6, loss:-73.1849, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5476088523864746 sec\n",
      "Episode 8475, len6, loss:-74.6899, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5480012893676758 sec\n",
      "Episode 8476, len10, loss:-65.8493, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5479550361633301 sec\n",
      "Episode 8477, len10, loss:-73.9570, fail, steps:80, opt steps:43, total reward:-24.0000, 0.548332929611206 sec\n",
      "Episode 8478, len12, loss:-92.3925, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5480766296386719 sec\n",
      "Episode 8479, len6, loss:-75.5169, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5479953289031982 sec\n",
      "Episode 8480, len6, loss:-75.6544, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5483243465423584 sec\n",
      "Episode 8481, len6, loss:-75.3365, fail, steps:80, opt steps:3, total reward:-24.0000, 0.6020071506500244 sec\n",
      "Episode 8482, len12, loss:-92.9162, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5484988689422607 sec\n",
      "Episode 8483, len12, loss:-88.5359, fail, steps:80, opt steps:73, total reward:-24.0000, 0.547879695892334 sec\n",
      "Episode 8484, len10, loss:-77.3277, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5488133430480957 sec\n",
      "Episode 8485, len12, loss:-93.5355, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5471217632293701 sec\n",
      "Episode 8486, len8, loss:-80.4453, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5483798980712891 sec\n",
      "Episode 8487, len6, loss:-74.4827, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5493433475494385 sec\n",
      "Episode 8488, len6, loss:-73.9284, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5469574928283691 sec\n",
      "Episode 8489, len12, loss:-94.4043, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5489993095397949 sec\n",
      "Episode 8490, len12, loss:-90.9374, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5483582019805908 sec\n",
      "Episode 8491, len8, loss:-74.7313, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5479438304901123 sec\n",
      "Episode 8492, len12, loss:-95.5159, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5479035377502441 sec\n",
      "Episode 8493, len10, loss:-72.9806, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5480585098266602 sec\n",
      "Episode 8494, len6, loss:-76.7772, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5473461151123047 sec\n",
      "Episode 8495, len6, loss:-69.1520, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5488784313201904 sec\n",
      "Episode 8496, len12, loss:-97.2812, fail, steps:80, opt steps:36, total reward:-24.0000, 0.6014914512634277 sec\n",
      "Episode 8497, len10, loss:-77.2153, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5477163791656494 sec\n",
      "Episode 8498, len10, loss:-72.9894, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5476217269897461 sec\n",
      "Episode 8499, len10, loss:-87.1689, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5483033657073975 sec\n",
      "Episode 8500, len12, loss:-87.3947, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5484237670898438 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8501, len10, loss:-82.7318, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5487141609191895 sec\n",
      "Episode 8502, len10, loss:-79.8991, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5487320423126221 sec\n",
      "Episode 8503, len10, loss:-81.9918, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5488505363464355 sec\n",
      "Episode 8504, len12, loss:-95.9834, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5486526489257812 sec\n",
      "Episode 8505, len6, loss:-75.1008, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5483200550079346 sec\n",
      "Episode 8506, len6, loss:-70.9378, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5482022762298584 sec\n",
      "Episode 8507, len6, loss:-69.0102, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5480968952178955 sec\n",
      "Episode 8508, len6, loss:-71.2985, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5473344326019287 sec\n",
      "Episode 8509, len6, loss:-72.0808, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5478682518005371 sec\n",
      "Episode 8510, len12, loss:-101.0497, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5478363037109375 sec\n",
      "Episode 8511, len12, loss:-91.0861, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5474345684051514 sec\n",
      "Episode 8512, len8, loss:-78.8960, fail, steps:80, opt steps:21, total reward:-24.0000, 0.6012804508209229 sec\n",
      "Episode 8513, len8, loss:-77.9458, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5484387874603271 sec\n",
      "Episode 8514, len8, loss:-74.4070, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5471208095550537 sec\n",
      "Episode 8515, len8, loss:-80.8603, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5474362373352051 sec\n",
      "Episode 8516, len8, loss:-74.1832, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5473182201385498 sec\n",
      "Episode 8517, len8, loss:-76.1244, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5486900806427002 sec\n",
      "Episode 8518, len12, loss:-85.2292, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5491194725036621 sec\n",
      "Episode 8519, len10, loss:-75.0043, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5478634834289551 sec\n",
      "Episode 8520, len8, loss:-78.4612, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5476257801055908 sec\n",
      "Episode 8521, len6, loss:-70.6698, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5474810600280762 sec\n",
      "Episode 8522, len12, loss:-96.8571, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5466480255126953 sec\n",
      "Episode 8523, len8, loss:-73.9983, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5486564636230469 sec\n",
      "Episode 8524, len6, loss:-72.7936, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5485432147979736 sec\n",
      "Episode 8525, len6, loss:-73.2800, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5481524467468262 sec\n",
      "Episode 8526, len12, loss:-91.7102, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5496425628662109 sec\n",
      "Episode 8527, len8, loss:-74.7822, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5483798980712891 sec\n",
      "Episode 8528, len8, loss:-72.0841, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5996403694152832 sec\n",
      "Episode 8529, len6, loss:-67.6705, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5483889579772949 sec\n",
      "Episode 8530, len6, loss:-66.2320, fail, steps:80, opt steps:3, total reward:-24.0000, 0.54892897605896 sec\n",
      "Episode 8531, len8, loss:-76.2105, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5496475696563721 sec\n",
      "Episode 8532, len12, loss:-93.7889, fail, steps:80, opt steps:43, total reward:-24.0000, 0.548863410949707 sec\n",
      "Episode 8533, len6, loss:-73.0258, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5485787391662598 sec\n",
      "Episode 8534, len6, loss:-71.2214, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5484280586242676 sec\n",
      "Episode 8535, len6, loss:-70.0295, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5491213798522949 sec\n",
      "Episode 8536, len10, loss:-78.0615, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5487966537475586 sec\n",
      "Episode 8537, len12, loss:-92.9674, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5466649532318115 sec\n",
      "Episode 8538, len10, loss:-77.5285, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5484790802001953 sec\n",
      "Episode 8539, len10, loss:-83.3150, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5492422580718994 sec\n",
      "Episode 8540, len6, loss:-77.5846, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5479216575622559 sec\n",
      "Episode 8541, len6, loss:-76.4790, fail, steps:80, opt steps:6, total reward:-24.0000, 0.6014688014984131 sec\n",
      "Episode 8542, len10, loss:-86.8358, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5498614311218262 sec\n",
      "Episode 8543, len8, loss:-75.1610, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5487194061279297 sec\n",
      "Episode 8544, len6, loss:-70.8850, fail, steps:80, opt steps:6, total reward:-24.0000, 0.553117036819458 sec\n",
      "Episode 8545, len10, loss:-78.3130, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490174293518066 sec\n",
      "Episode 8546, len6, loss:-69.9260, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5490939617156982 sec\n",
      "Episode 8547, len6, loss:-67.8518, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5507278442382812 sec\n",
      "Episode 8548, len8, loss:-74.7709, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5474624633789062 sec\n",
      "Episode 8549, len12, loss:-88.4762, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5495662689208984 sec\n",
      "Episode 8550, len6, loss:-72.5069, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5478227138519287 sec\n",
      "Episode 8551, len10, loss:-79.3277, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5472004413604736 sec\n",
      "Episode 8552, len12, loss:-94.8679, fail, steps:80, opt steps:57, total reward:-24.0000, 0.548621416091919 sec\n",
      "Episode 8553, len6, loss:-70.8925, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5483074188232422 sec\n",
      "Episode 8554, len10, loss:-86.2813, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5482816696166992 sec\n",
      "Episode 8555, len6, loss:-73.4371, fail, steps:80, opt steps:7, total reward:-24.0000, 0.6047401428222656 sec\n",
      "Episode 8556, len10, loss:-86.8113, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5476193428039551 sec\n",
      "Episode 8557, len8, loss:-81.2079, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5477845668792725 sec\n",
      "Episode 8558, len12, loss:-92.0622, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5489239692687988 sec\n",
      "Episode 8559, len6, loss:-76.0643, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5463521480560303 sec\n",
      "Episode 8560, len8, loss:-78.0447, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5466713905334473 sec\n",
      "Episode 8561, len6, loss:-70.8924, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5484111309051514 sec\n",
      "Episode 8562, len8, loss:-81.9163, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5472846031188965 sec\n",
      "Episode 8563, len12, loss:-90.2923, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5474073886871338 sec\n",
      "Episode 8564, len12, loss:-92.9507, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5484106540679932 sec\n",
      "Episode 8565, len8, loss:-76.3115, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5476977825164795 sec\n",
      "Episode 8566, len12, loss:-101.9776, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5494897365570068 sec\n",
      "Episode 8567, len6, loss:-76.2344, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5490598678588867 sec\n",
      "Episode 8568, len12, loss:-100.8191, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5480983257293701 sec\n",
      "Episode 8569, len12, loss:-93.1163, fail, steps:80, opt steps:57, total reward:-24.0000, 0.6028280258178711 sec\n",
      "Episode 8570, len6, loss:-74.2250, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5468332767486572 sec\n",
      "Episode 8571, len10, loss:-69.3498, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5482175350189209 sec\n",
      "Episode 8572, len6, loss:-72.5415, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5479397773742676 sec\n",
      "Episode 8573, len6, loss:-75.3332, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5463302135467529 sec\n",
      "Episode 8574, len8, loss:-76.7663, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5475037097930908 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8575, len8, loss:-73.2638, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5471630096435547 sec\n",
      "Episode 8576, len10, loss:-75.4065, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5471885204315186 sec\n",
      "Episode 8577, len12, loss:-98.3443, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5477917194366455 sec\n",
      "Episode 8578, len6, loss:-75.8446, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5483951568603516 sec\n",
      "Episode 8579, len6, loss:-71.4767, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5476016998291016 sec\n",
      "Episode 8580, len10, loss:-79.2034, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5487003326416016 sec\n",
      "Episode 8581, len10, loss:-90.7004, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5484061241149902 sec\n",
      "Episode 8582, len8, loss:-79.5092, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5481960773468018 sec\n",
      "Episode 8583, len6, loss:-78.9427, fail, steps:80, opt steps:7, total reward:-24.0000, 0.6015031337738037 sec\n",
      "Episode 8584, len12, loss:-97.0445, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5470695495605469 sec\n",
      "Episode 8585, len10, loss:-76.8924, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5473794937133789 sec\n",
      "Episode 8586, len8, loss:-74.2440, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5465576648712158 sec\n",
      "Episode 8587, len6, loss:-73.3682, fail, steps:80, opt steps:19, total reward:-24.0000, 0.547163724899292 sec\n",
      "Episode 8588, len12, loss:-96.0345, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5474104881286621 sec\n",
      "Episode 8589, len6, loss:-70.7023, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5470278263092041 sec\n",
      "Episode 8590, len10, loss:-76.8959, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5470161437988281 sec\n",
      "Episode 8591, len12, loss:-98.0834, fail, steps:80, opt steps:73, total reward:-24.0000, 0.5480866432189941 sec\n",
      "Episode 8592, len8, loss:-74.9839, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5481009483337402 sec\n",
      "Episode 8593, len10, loss:-73.8768, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5486297607421875 sec\n",
      "Episode 8594, len10, loss:-88.3230, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5478336811065674 sec\n",
      "Episode 8595, len6, loss:-76.2963, fail, steps:80, opt steps:12, total reward:-24.0000, 0.546105146408081 sec\n",
      "Episode 8596, len8, loss:-84.9957, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5490434169769287 sec\n",
      "Episode 8597, len12, loss:-103.9455, fail, steps:80, opt steps:30, total reward:-24.0000, 0.6010656356811523 sec\n",
      "Episode 8598, len6, loss:-71.8631, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5473790168762207 sec\n",
      "Episode 8599, len12, loss:-107.5639, fail, steps:80, opt steps:31, total reward:-24.7000, 0.544140100479126 sec\n",
      "Episode 8600, len10, loss:-71.2383, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5484170913696289 sec\n",
      "Episode 8601, len10, loss:-77.0000, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5473752021789551 sec\n",
      "Episode 8602, len12, loss:-101.1157, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5482466220855713 sec\n",
      "Episode 8603, len8, loss:-78.5804, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5469832420349121 sec\n",
      "Episode 8604, len12, loss:-96.3464, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5472910404205322 sec\n",
      "Episode 8605, len10, loss:-73.7656, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5487575531005859 sec\n",
      "Episode 8606, len8, loss:-78.6800, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5481500625610352 sec\n",
      "Episode 8607, len10, loss:-76.8612, fail, steps:80, opt steps:43, total reward:-24.0000, 0.549339771270752 sec\n",
      "Episode 8608, len12, loss:-95.8879, fail, steps:80, opt steps:42, total reward:-24.0000, 0.547813892364502 sec\n",
      "Episode 8609, len6, loss:-72.8072, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5479512214660645 sec\n",
      "Episode 8610, len12, loss:-95.9567, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5485684871673584 sec\n",
      "Episode 8611, len6, loss:-68.9709, fail, steps:80, opt steps:20, total reward:-24.0000, 0.547896146774292 sec\n",
      "Episode 8612, len6, loss:-75.5721, fail, steps:80, opt steps:13, total reward:-24.0000, 0.6014490127563477 sec\n",
      "Episode 8613, len10, loss:-87.9221, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5474503040313721 sec\n",
      "Episode 8614, len8, loss:-76.3408, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5464859008789062 sec\n",
      "Episode 8615, len8, loss:-73.3304, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5480432510375977 sec\n",
      "Episode 8616, len8, loss:-82.8185, fail, steps:80, opt steps:29, total reward:-24.0000, 0.547476053237915 sec\n",
      "Episode 8617, len6, loss:-76.5064, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5485303401947021 sec\n",
      "Episode 8618, len12, loss:-103.4851, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5492284297943115 sec\n",
      "Episode 8619, len8, loss:-78.2838, fail, steps:80, opt steps:4, total reward:-24.0000, 0.548778772354126 sec\n",
      "Episode 8620, len10, loss:-86.9922, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5501804351806641 sec\n",
      "Episode 8621, len6, loss:-79.0524, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5486197471618652 sec\n",
      "Episode 8622, len10, loss:-84.2871, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5475537776947021 sec\n",
      "Episode 8623, len10, loss:-80.2497, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5477421283721924 sec\n",
      "Episode 8624, len8, loss:-77.5344, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5462214946746826 sec\n",
      "Episode 8625, len10, loss:-84.3343, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5475523471832275 sec\n",
      "Episode 8626, len6, loss:-72.9813, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5468831062316895 sec\n",
      "Episode 8627, len6, loss:-82.1743, fail, steps:80, opt steps:14, total reward:-24.7000, 0.5435268878936768 sec\n",
      "Episode 8628, len10, loss:-74.4158, fail, steps:80, opt steps:8, total reward:-24.0000, 0.6012470722198486 sec\n",
      "Episode 8629, len12, loss:-94.6545, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5487861633300781 sec\n",
      "Episode 8630, len12, loss:-100.1378, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5490634441375732 sec\n",
      "Episode 8631, len10, loss:-81.9708, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5577762126922607 sec\n",
      "Episode 8632, len8, loss:-80.5599, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5490763187408447 sec\n",
      "Episode 8633, len10, loss:-74.7325, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5486044883728027 sec\n",
      "Episode 8634, len6, loss:-80.6639, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5474917888641357 sec\n",
      "Episode 8635, len8, loss:-82.7387, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5475385189056396 sec\n",
      "Episode 8636, len8, loss:-82.5034, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5492429733276367 sec\n",
      "Episode 8637, len10, loss:-77.4523, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5484559535980225 sec\n",
      "Episode 8638, len10, loss:-81.4148, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5469646453857422 sec\n",
      "Episode 8639, len8, loss:-84.2313, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5471093654632568 sec\n",
      "Episode 8640, len8, loss:-79.2445, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5470609664916992 sec\n",
      "Episode 8641, len12, loss:-96.1365, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5476467609405518 sec\n",
      "Episode 8642, len6, loss:-71.8852, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5469250679016113 sec\n",
      "Episode 8643, len8, loss:-78.2422, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5476412773132324 sec\n",
      "Episode 8644, len12, loss:-99.9876, fail, steps:80, opt steps:44, total reward:-24.0000, 0.6044526100158691 sec\n",
      "Episode 8645, len6, loss:-71.5564, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5485265254974365 sec\n",
      "Episode 8646, len10, loss:-80.8909, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5488309860229492 sec\n",
      "Episode 8647, len12, loss:-101.9269, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5492308139801025 sec\n",
      "Episode 8648, len12, loss:-95.9928, fail, steps:80, opt steps:68, total reward:-24.0000, 0.5470666885375977 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8649, len12, loss:-90.4622, fail, steps:80, opt steps:43, total reward:-24.0000, 0.54740309715271 sec\n",
      "Episode 8650, len8, loss:-80.1071, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5469081401824951 sec\n",
      "Episode 8651, len6, loss:-75.9547, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5473442077636719 sec\n",
      "Episode 8652, len10, loss:-84.3560, fail, steps:80, opt steps:48, total reward:-24.0000, 0.546884298324585 sec\n",
      "Episode 8653, len6, loss:-71.6079, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5479283332824707 sec\n",
      "Episode 8654, len10, loss:-82.8048, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5485281944274902 sec\n",
      "Episode 8655, len6, loss:-73.2403, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5515391826629639 sec\n",
      "Episode 8656, len8, loss:-82.7797, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5478167533874512 sec\n",
      "Episode 8657, len10, loss:-88.2146, fail, steps:80, opt steps:21, total reward:-24.0000, 0.602222204208374 sec\n",
      "Episode 8658, len6, loss:-74.3155, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5503365993499756 sec\n",
      "Episode 8659, len8, loss:-90.1889, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5483715534210205 sec\n",
      "Episode 8660, len8, loss:-88.6638, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5484492778778076 sec\n",
      "Episode 8661, len12, loss:-91.1632, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5509941577911377 sec\n",
      "Episode 8662, len12, loss:-95.6605, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5487875938415527 sec\n",
      "Episode 8663, len10, loss:-78.3939, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5481371879577637 sec\n",
      "Episode 8664, len10, loss:-75.9602, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5484833717346191 sec\n",
      "Episode 8665, len8, loss:-87.5602, fail, steps:80, opt steps:24, total reward:-24.7000, 0.5449724197387695 sec\n",
      "Episode 8666, len6, loss:-76.2674, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5469956398010254 sec\n",
      "Episode 8667, len6, loss:-72.5751, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5481748580932617 sec\n",
      "Episode 8668, len12, loss:-88.5361, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5484535694122314 sec\n",
      "Episode 8669, len10, loss:-74.0086, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5480563640594482 sec\n",
      "Episode 8670, len8, loss:-79.7727, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5483133792877197 sec\n",
      "Episode 8671, len8, loss:-84.5144, fail, steps:80, opt steps:31, total reward:-24.0000, 0.6015043258666992 sec\n",
      "Episode 8672, len12, loss:-99.5767, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5490174293518066 sec\n",
      "Episode 8673, len10, loss:-83.9434, fail, steps:80, opt steps:25, total reward:-24.7000, 0.5435607433319092 sec\n",
      "Episode 8674, len12, loss:-84.7888, fail, steps:80, opt steps:63, total reward:-24.0000, 0.547426700592041 sec\n",
      "Episode 8675, len6, loss:-76.5296, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5493180751800537 sec\n",
      "Episode 8676, len10, loss:-73.1248, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5473325252532959 sec\n",
      "Episode 8677, len10, loss:-72.2045, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5482373237609863 sec\n",
      "Episode 8678, len12, loss:-92.1071, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5494697093963623 sec\n",
      "Episode 8679, len12, loss:-95.0373, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5495350360870361 sec\n",
      "Episode 8680, len12, loss:-90.4276, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5486204624176025 sec\n",
      "Episode 8681, len10, loss:-77.3648, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5481891632080078 sec\n",
      "Episode 8682, len8, loss:-78.7000, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5482287406921387 sec\n",
      "Episode 8683, len8, loss:-74.5825, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5487034320831299 sec\n",
      "Episode 8684, len12, loss:-90.9532, fail, steps:80, opt steps:29, total reward:-24.0000, 0.548436164855957 sec\n",
      "Episode 8685, len8, loss:-81.0787, fail, steps:80, opt steps:35, total reward:-24.0000, 0.6001865863800049 sec\n",
      "Episode 8686, len10, loss:-75.8643, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5484528541564941 sec\n",
      "Episode 8687, len8, loss:-74.2169, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5487427711486816 sec\n",
      "Episode 8688, len10, loss:-66.2174, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5484185218811035 sec\n",
      "Episode 8689, len10, loss:-77.9986, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5495738983154297 sec\n",
      "Episode 8690, len8, loss:-74.4360, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5497641563415527 sec\n",
      "Episode 8691, len8, loss:-72.3147, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5480012893676758 sec\n",
      "Episode 8692, len8, loss:-74.8171, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5490503311157227 sec\n",
      "Episode 8693, len8, loss:-79.7058, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5498254299163818 sec\n",
      "Episode 8694, len10, loss:-79.2722, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5492923259735107 sec\n",
      "Episode 8695, len12, loss:-101.4600, fail, steps:80, opt steps:45, total reward:-24.0000, 0.548907995223999 sec\n",
      "Episode 8696, len8, loss:-77.1226, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5480341911315918 sec\n",
      "Episode 8697, len12, loss:-96.4914, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5501630306243896 sec\n",
      "Episode 8698, len8, loss:-82.6931, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5487229824066162 sec\n",
      "Episode 8699, len8, loss:-77.9973, fail, steps:80, opt steps:25, total reward:-24.0000, 0.597747802734375 sec\n",
      "Episode 8700, len12, loss:-94.6556, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5493960380554199 sec\n",
      "Episode 8701, len8, loss:-77.4469, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5485296249389648 sec\n",
      "Episode 8702, len12, loss:-100.6698, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5509612560272217 sec\n",
      "Episode 8703, len10, loss:-76.9542, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5471818447113037 sec\n",
      "Episode 8704, len10, loss:-86.0654, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5487439632415771 sec\n",
      "Episode 8705, len8, loss:-79.8509, fail, steps:80, opt steps:4, total reward:-24.0000, 0.547440767288208 sec\n",
      "Episode 8706, len12, loss:-88.7355, fail, steps:80, opt steps:58, total reward:-24.0000, 0.547544002532959 sec\n",
      "Episode 8707, len10, loss:-94.5826, fail, steps:80, opt steps:44, total reward:-24.7000, 0.543752908706665 sec\n",
      "Episode 8708, len12, loss:-93.5967, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5482606887817383 sec\n",
      "Episode 8709, len6, loss:-71.2671, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485751628875732 sec\n",
      "Episode 8710, len8, loss:-85.0897, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5481867790222168 sec\n",
      "Episode 8711, len8, loss:-76.7884, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5476686954498291 sec\n",
      "Episode 8712, len6, loss:-77.8171, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5481657981872559 sec\n",
      "Episode 8713, len12, loss:-99.1026, fail, steps:80, opt steps:21, total reward:-24.0000, 0.6017231941223145 sec\n",
      "Episode 8714, len8, loss:-75.8783, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5476524829864502 sec\n",
      "Episode 8715, len6, loss:-73.2994, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5472190380096436 sec\n",
      "Episode 8716, len6, loss:-66.5349, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5474898815155029 sec\n",
      "Episode 8717, len6, loss:-70.1104, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5466094017028809 sec\n",
      "Episode 8718, len10, loss:-85.2315, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5476369857788086 sec\n",
      "Episode 8719, len10, loss:-82.8824, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5480411052703857 sec\n",
      "Episode 8720, len10, loss:-77.2743, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5471606254577637 sec\n",
      "Episode 8721, len6, loss:-72.4697, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5492582321166992 sec\n",
      "Episode 8722, len10, loss:-82.5696, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5475080013275146 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8723, len10, loss:-88.1338, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5482275485992432 sec\n",
      "Episode 8724, len8, loss:-81.2507, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5476863384246826 sec\n",
      "Episode 8725, len8, loss:-77.2319, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5479743480682373 sec\n",
      "Episode 8726, len10, loss:-85.3503, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5485942363739014 sec\n",
      "Episode 8727, len10, loss:-80.0183, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5464460849761963 sec\n",
      "Episode 8728, len8, loss:-81.1804, fail, steps:80, opt steps:25, total reward:-24.0000, 0.6024012565612793 sec\n",
      "Episode 8729, len6, loss:-67.3818, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5475747585296631 sec\n",
      "Episode 8730, len12, loss:-93.7038, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5495352745056152 sec\n",
      "Episode 8731, len10, loss:-74.5721, fail, steps:80, opt steps:39, total reward:-24.0000, 0.549217700958252 sec\n",
      "Episode 8732, len8, loss:-81.3732, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5509285926818848 sec\n",
      "Episode 8733, len12, loss:-92.0355, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5482311248779297 sec\n",
      "Episode 8734, len8, loss:-82.5300, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5486001968383789 sec\n",
      "Episode 8735, len12, loss:-96.3424, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5479514598846436 sec\n",
      "Episode 8736, len6, loss:-67.7574, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5475046634674072 sec\n",
      "Episode 8737, len6, loss:-71.5968, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5475716590881348 sec\n",
      "Episode 8738, len10, loss:-80.8333, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5481147766113281 sec\n",
      "Episode 8739, len8, loss:-76.1558, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5480542182922363 sec\n",
      "Episode 8740, len8, loss:-83.4192, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5469341278076172 sec\n",
      "Episode 8741, len10, loss:-73.6382, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5476548671722412 sec\n",
      "Episode 8742, len8, loss:-82.4541, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5491435527801514 sec\n",
      "Episode 8743, len8, loss:-82.0175, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5471768379211426 sec\n",
      "Episode 8744, len12, loss:-100.0578, fail, steps:80, opt steps:32, total reward:-24.0000, 0.6033790111541748 sec\n",
      "Episode 8745, len8, loss:-76.2845, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548710823059082 sec\n",
      "Episode 8746, len10, loss:-83.9640, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5477216243743896 sec\n",
      "Episode 8747, len10, loss:-81.3834, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5483484268188477 sec\n",
      "Episode 8748, len8, loss:-80.6248, fail, steps:80, opt steps:28, total reward:-24.0000, 0.54728102684021 sec\n",
      "Episode 8749, len6, loss:-72.3091, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5468063354492188 sec\n",
      "Episode 8750, len8, loss:-80.9194, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5482213497161865 sec\n",
      "Episode 8751, len6, loss:-71.6694, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5480477809906006 sec\n",
      "Episode 8752, len6, loss:-71.5744, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5487589836120605 sec\n",
      "Episode 8753, len8, loss:-82.1774, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5467789173126221 sec\n",
      "Episode 8754, len12, loss:-98.7230, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5464382171630859 sec\n",
      "Episode 8755, len10, loss:-82.8154, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5477015972137451 sec\n",
      "Episode 8756, len6, loss:-70.1174, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5478935241699219 sec\n",
      "Episode 8757, len6, loss:-67.8082, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5487265586853027 sec\n",
      "Episode 8758, len12, loss:-101.1343, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5472211837768555 sec\n",
      "Episode 8759, len12, loss:-99.7145, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5487959384918213 sec\n",
      "Episode 8760, len10, loss:-87.0049, fail, steps:80, opt steps:40, total reward:-24.0000, 0.601567268371582 sec\n",
      "Episode 8761, len8, loss:-78.9605, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5486321449279785 sec\n",
      "Episode 8762, len12, loss:-102.0685, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5489916801452637 sec\n",
      "Episode 8763, len8, loss:-86.1727, fail, steps:80, opt steps:34, total reward:-24.0000, 0.548532247543335 sec\n",
      "Episode 8764, len10, loss:-87.1196, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5473771095275879 sec\n",
      "Episode 8765, len10, loss:-83.9358, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5489447116851807 sec\n",
      "Episode 8766, len12, loss:-105.6725, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5479340553283691 sec\n",
      "Episode 8767, len8, loss:-76.6273, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5470898151397705 sec\n",
      "Episode 8768, len8, loss:-81.0686, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5479815006256104 sec\n",
      "Episode 8769, len12, loss:-104.5365, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5500226020812988 sec\n",
      "Episode 8770, len12, loss:-94.4722, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5477068424224854 sec\n",
      "Episode 8771, len12, loss:-100.3559, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5483465194702148 sec\n",
      "Episode 8772, len12, loss:-97.3946, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5484468936920166 sec\n",
      "Episode 8773, len8, loss:-75.0806, fail, steps:80, opt steps:12, total reward:-24.0000, 0.6075592041015625 sec\n",
      "Episode 8774, len10, loss:-85.5173, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5488731861114502 sec\n",
      "Episode 8775, len12, loss:-99.9187, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5477588176727295 sec\n",
      "Episode 8776, len8, loss:-83.9820, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5475137233734131 sec\n",
      "Episode 8777, len6, loss:-71.0463, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5480790138244629 sec\n",
      "Episode 8778, len10, loss:-78.1123, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5478935241699219 sec\n",
      "Episode 8779, len10, loss:-89.2368, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5469415187835693 sec\n",
      "Episode 8780, len8, loss:-77.8349, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5486178398132324 sec\n",
      "Episode 8781, len12, loss:-93.8748, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5480189323425293 sec\n",
      "Episode 8782, len6, loss:-71.0174, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5466222763061523 sec\n",
      "Episode 8783, len6, loss:-70.0194, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5472450256347656 sec\n",
      "Episode 8784, len6, loss:-69.6689, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5496213436126709 sec\n",
      "Episode 8785, len6, loss:-69.9075, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5488574504852295 sec\n",
      "Episode 8786, len8, loss:-76.9343, fail, steps:80, opt steps:24, total reward:-24.0000, 0.548490047454834 sec\n",
      "Episode 8787, len6, loss:-75.3797, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5993340015411377 sec\n",
      "Episode 8788, len8, loss:-72.5215, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5491468906402588 sec\n",
      "Episode 8789, len6, loss:-65.4021, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5488948822021484 sec\n",
      "Episode 8790, len12, loss:-97.3943, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5492644309997559 sec\n",
      "Episode 8791, len12, loss:-101.1213, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5489685535430908 sec\n",
      "Episode 8792, len8, loss:-78.0400, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5484013557434082 sec\n",
      "Episode 8793, len12, loss:-106.0979, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5486230850219727 sec\n",
      "Episode 8794, len6, loss:-79.2045, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5484936237335205 sec\n",
      "Episode 8795, len10, loss:-76.1609, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5486812591552734 sec\n",
      "Episode 8796, len12, loss:-97.0412, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5485777854919434 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8797, len10, loss:-87.4438, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5442523956298828 sec\n",
      "Episode 8798, len10, loss:-80.1487, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5475687980651855 sec\n",
      "Episode 8799, len8, loss:-83.4144, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5483736991882324 sec\n",
      "Episode 8800, len6, loss:-71.8694, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5487725734710693 sec\n",
      "Episode 8801, len10, loss:-85.6892, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5990705490112305 sec\n",
      "Episode 8802, len10, loss:-80.4957, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5488283634185791 sec\n",
      "Episode 8803, len10, loss:-72.3115, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5486006736755371 sec\n",
      "Episode 8804, len10, loss:-84.0864, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5488777160644531 sec\n",
      "Episode 8805, len6, loss:-68.4389, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5483005046844482 sec\n",
      "Episode 8806, len8, loss:-80.1898, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5488259792327881 sec\n",
      "Episode 8807, len6, loss:-67.2421, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5487744808197021 sec\n",
      "Episode 8808, len8, loss:-77.8136, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5469629764556885 sec\n",
      "Episode 8809, len8, loss:-78.9858, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5474255084991455 sec\n",
      "Episode 8810, len10, loss:-92.4680, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5493390560150146 sec\n",
      "Episode 8811, len12, loss:-96.4557, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5485475063323975 sec\n",
      "Episode 8812, len6, loss:-66.1344, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5483875274658203 sec\n",
      "Episode 8813, len8, loss:-79.7548, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5495240688323975 sec\n",
      "Episode 8814, len12, loss:-106.7008, fail, steps:80, opt steps:20, total reward:-24.0000, 0.548865795135498 sec\n",
      "Episode 8815, len12, loss:-98.3748, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5990653038024902 sec\n",
      "Episode 8816, len12, loss:-101.4054, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5501656532287598 sec\n",
      "Episode 8817, len12, loss:-99.5777, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5489068031311035 sec\n",
      "Episode 8818, len8, loss:-72.7483, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5483560562133789 sec\n",
      "Episode 8819, len8, loss:-70.1607, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5482919216156006 sec\n",
      "Episode 8820, len12, loss:-100.5826, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5490772724151611 sec\n",
      "Episode 8821, len12, loss:-107.5679, fail, steps:80, opt steps:53, total reward:-24.7000, 0.5440061092376709 sec\n",
      "Episode 8822, len12, loss:-105.7537, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5476651191711426 sec\n",
      "Episode 8823, len8, loss:-75.6710, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5482215881347656 sec\n",
      "Episode 8824, len8, loss:-80.3653, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5485305786132812 sec\n",
      "Episode 8825, len8, loss:-76.3728, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5489516258239746 sec\n",
      "Episode 8826, len8, loss:-75.6143, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5485062599182129 sec\n",
      "Episode 8827, len10, loss:-91.3817, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5565860271453857 sec\n",
      "Episode 8828, len12, loss:-101.9883, fail, steps:80, opt steps:61, total reward:-24.0000, 0.549058198928833 sec\n",
      "Episode 8829, len6, loss:-68.1696, fail, steps:80, opt steps:5, total reward:-24.0000, 0.598442554473877 sec\n",
      "Episode 8830, len10, loss:-95.3586, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5480861663818359 sec\n",
      "Episode 8831, len10, loss:-88.9820, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5483837127685547 sec\n",
      "Episode 8832, len6, loss:-72.2561, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5475437641143799 sec\n",
      "Episode 8833, len10, loss:-82.0638, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5482134819030762 sec\n",
      "Episode 8834, len10, loss:-89.7345, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5478038787841797 sec\n",
      "Episode 8835, len10, loss:-85.0246, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5487101078033447 sec\n",
      "Episode 8836, len8, loss:-76.9869, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5484423637390137 sec\n",
      "Episode 8837, len10, loss:-88.9734, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5482559204101562 sec\n",
      "Episode 8838, len12, loss:-100.0945, fail, steps:80, opt steps:69, total reward:-24.0000, 0.5506336688995361 sec\n",
      "Episode 8839, len12, loss:-104.7764, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5499751567840576 sec\n",
      "Episode 8840, len8, loss:-82.9793, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5483450889587402 sec\n",
      "Episode 8841, len12, loss:-100.1917, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5473265647888184 sec\n",
      "Episode 8842, len8, loss:-74.4106, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5498812198638916 sec\n",
      "Episode 8843, len6, loss:-72.6298, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5495128631591797 sec\n",
      "Episode 8844, len8, loss:-82.5509, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5998270511627197 sec\n",
      "Episode 8845, len12, loss:-107.4530, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5499072074890137 sec\n",
      "Episode 8846, len12, loss:-104.5478, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5486271381378174 sec\n",
      "Episode 8847, len8, loss:-80.3042, fail, steps:80, opt steps:32, total reward:-24.0000, 0.548590898513794 sec\n",
      "Episode 8848, len6, loss:-68.2994, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5501108169555664 sec\n",
      "Episode 8849, len6, loss:-68.4473, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5492923259735107 sec\n",
      "Episode 8850, len10, loss:-92.3856, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5499420166015625 sec\n",
      "Episode 8851, len12, loss:-103.6423, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5487143993377686 sec\n",
      "Episode 8852, len10, loss:-84.9684, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5512440204620361 sec\n",
      "Episode 8853, len8, loss:-83.1212, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5501120090484619 sec\n",
      "Episode 8854, len6, loss:-72.1528, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5500352382659912 sec\n",
      "Episode 8855, len12, loss:-104.6276, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5475311279296875 sec\n",
      "Episode 8856, len12, loss:-109.0560, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5495491027832031 sec\n",
      "Episode 8857, len8, loss:-78.9812, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5491237640380859 sec\n",
      "Episode 8858, len10, loss:-89.3378, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5476250648498535 sec\n",
      "Episode 8859, len6, loss:-67.5197, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5486440658569336 sec\n",
      "Episode 8860, len12, loss:-101.7698, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5991661548614502 sec\n",
      "Episode 8861, len6, loss:-80.3240, fail, steps:80, opt steps:5, total reward:-24.7000, 0.545098066329956 sec\n",
      "Episode 8862, len8, loss:-78.1885, fail, steps:80, opt steps:33, total reward:-24.0000, 0.548128604888916 sec\n",
      "Episode 8863, len6, loss:-68.5920, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5483462810516357 sec\n",
      "Episode 8864, len10, loss:-92.7819, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5485877990722656 sec\n",
      "Episode 8865, len10, loss:-89.6069, fail, steps:80, opt steps:46, total reward:-24.0000, 0.548351526260376 sec\n",
      "Episode 8866, len12, loss:-113.4648, fail, steps:80, opt steps:64, total reward:-24.7000, 0.5451200008392334 sec\n",
      "Episode 8867, len8, loss:-76.6866, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5473284721374512 sec\n",
      "Episode 8868, len10, loss:-83.6069, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5500457286834717 sec\n",
      "Episode 8869, len10, loss:-89.5786, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5480852127075195 sec\n",
      "Episode 8870, len8, loss:-72.9465, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5486924648284912 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8871, len8, loss:-75.5590, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5488986968994141 sec\n",
      "Episode 8872, len6, loss:-74.3088, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5479669570922852 sec\n",
      "Episode 8873, len8, loss:-81.9409, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5484566688537598 sec\n",
      "Episode 8874, len8, loss:-78.5413, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5482316017150879 sec\n",
      "Episode 8875, len10, loss:-83.1363, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5477852821350098 sec\n",
      "Episode 8876, len12, loss:-109.1179, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5993456840515137 sec\n",
      "Episode 8877, len8, loss:-73.1708, fail, steps:80, opt steps:26, total reward:-24.0000, 0.549492597579956 sec\n",
      "Episode 8878, len10, loss:-89.4455, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5493857860565186 sec\n",
      "Episode 8879, len6, loss:-73.9782, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5477533340454102 sec\n",
      "Episode 8880, len8, loss:-74.5620, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5476019382476807 sec\n",
      "Episode 8881, len6, loss:-70.6831, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5483336448669434 sec\n",
      "Episode 8882, len6, loss:-71.0246, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5484921932220459 sec\n",
      "Episode 8883, len8, loss:-69.5632, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5489058494567871 sec\n",
      "Episode 8884, len12, loss:-107.7754, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5495598316192627 sec\n",
      "Episode 8885, len6, loss:-76.0334, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5476887226104736 sec\n",
      "Episode 8886, len12, loss:-98.2925, fail, steps:80, opt steps:52, total reward:-24.0000, 0.548210859298706 sec\n",
      "Episode 8887, len12, loss:-107.9384, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5468342304229736 sec\n",
      "Episode 8888, len12, loss:-101.1392, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5475494861602783 sec\n",
      "Episode 8889, len12, loss:-98.3784, fail, steps:80, opt steps:22, total reward:-24.0000, 0.6026978492736816 sec\n",
      "Episode 8890, len10, loss:-91.0776, fail, steps:80, opt steps:45, total reward:-24.7000, 0.5436937808990479 sec\n",
      "Episode 8891, len8, loss:-76.3627, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5480890274047852 sec\n",
      "Episode 8892, len6, loss:-69.6013, fail, steps:80, opt steps:16, total reward:-24.0000, 0.548734188079834 sec\n",
      "Episode 8893, len8, loss:-78.6832, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5481829643249512 sec\n",
      "Episode 8894, len8, loss:-72.0907, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5488319396972656 sec\n",
      "Episode 8895, len12, loss:-105.4350, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5493898391723633 sec\n",
      "Episode 8896, len10, loss:-87.3505, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5492169857025146 sec\n",
      "Episode 8897, len6, loss:-70.9710, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5487661361694336 sec\n",
      "Episode 8898, len12, loss:-104.8335, fail, steps:80, opt steps:63, total reward:-24.0000, 0.5487558841705322 sec\n",
      "Episode 8899, len12, loss:-104.4084, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5491125583648682 sec\n",
      "Episode 8900, len10, loss:-92.1345, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5493242740631104 sec\n",
      "Episode 8901, len8, loss:-76.4592, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5479185581207275 sec\n",
      "Episode 8902, len8, loss:-79.1347, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5487184524536133 sec\n",
      "Episode 8903, len12, loss:-97.3160, fail, steps:80, opt steps:52, total reward:-24.0000, 0.6016843318939209 sec\n",
      "Episode 8904, len6, loss:-71.5825, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5496711730957031 sec\n",
      "Episode 8905, len6, loss:-69.8139, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5475819110870361 sec\n",
      "Episode 8906, len8, loss:-76.5362, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5498273372650146 sec\n",
      "Episode 8907, len8, loss:-80.4785, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5509898662567139 sec\n",
      "Episode 8908, len10, loss:-98.1364, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5482711791992188 sec\n",
      "Episode 8909, len6, loss:-72.1758, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5494673252105713 sec\n",
      "Episode 8910, len10, loss:-96.8806, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5506339073181152 sec\n",
      "Episode 8911, len6, loss:-63.3140, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5491127967834473 sec\n",
      "Episode 8912, len10, loss:-86.9252, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5486164093017578 sec\n",
      "Episode 8913, len12, loss:-103.4243, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5496165752410889 sec\n",
      "Episode 8914, len10, loss:-90.8831, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5495061874389648 sec\n",
      "Episode 8915, len6, loss:-62.6457, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5488574504852295 sec\n",
      "Episode 8916, len8, loss:-69.1659, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5496478080749512 sec\n",
      "Episode 8917, len10, loss:-94.9386, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5996887683868408 sec\n",
      "Episode 8918, len8, loss:-72.1473, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5504660606384277 sec\n",
      "Episode 8919, len8, loss:-77.5439, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5479979515075684 sec\n",
      "Episode 8920, len6, loss:-67.3320, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5486829280853271 sec\n",
      "Episode 8921, len10, loss:-93.5840, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5482547283172607 sec\n",
      "Episode 8922, len8, loss:-75.3681, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5489506721496582 sec\n",
      "Episode 8923, len10, loss:-94.2321, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5487098693847656 sec\n",
      "Episode 8924, len10, loss:-93.4003, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5501024723052979 sec\n",
      "Episode 8925, len12, loss:-99.8265, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5493855476379395 sec\n",
      "Episode 8926, len12, loss:-102.1486, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5503408908843994 sec\n",
      "Episode 8927, len6, loss:-70.5120, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5490913391113281 sec\n",
      "Episode 8928, len8, loss:-79.6559, fail, steps:80, opt steps:27, total reward:-24.0000, 0.547839879989624 sec\n",
      "Episode 8929, len12, loss:-108.6689, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5504798889160156 sec\n",
      "Episode 8930, len12, loss:-108.6577, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5488240718841553 sec\n",
      "Episode 8931, len10, loss:-93.4902, fail, steps:80, opt steps:44, total reward:-24.0000, 0.6010394096374512 sec\n",
      "Episode 8932, len12, loss:-107.9240, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5502417087554932 sec\n",
      "Episode 8933, len8, loss:-75.0909, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5491747856140137 sec\n",
      "Episode 8934, len10, loss:-94.9091, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5489256381988525 sec\n",
      "Episode 8935, len6, loss:-67.2347, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5480682849884033 sec\n",
      "Episode 8936, len12, loss:-106.6496, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5500729084014893 sec\n",
      "Episode 8937, len6, loss:-68.5407, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5492167472839355 sec\n",
      "Episode 8938, len6, loss:-66.8088, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5479848384857178 sec\n",
      "Episode 8939, len10, loss:-95.6787, fail, steps:80, opt steps:23, total reward:-24.0000, 0.548032283782959 sec\n",
      "Episode 8940, len6, loss:-70.0291, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5489120483398438 sec\n",
      "Episode 8941, len6, loss:-69.0201, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5487337112426758 sec\n",
      "Episode 8942, len12, loss:-104.6348, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5476431846618652 sec\n",
      "Episode 8943, len10, loss:-92.6872, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5510220527648926 sec\n",
      "Episode 8944, len12, loss:-103.1391, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5472800731658936 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8945, len8, loss:-81.0108, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5975382328033447 sec\n",
      "Episode 8946, len6, loss:-71.0237, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5476534366607666 sec\n",
      "Episode 8947, len12, loss:-103.4370, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5494117736816406 sec\n",
      "Episode 8948, len8, loss:-85.1050, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5468721389770508 sec\n",
      "Episode 8949, len12, loss:-106.2333, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5481295585632324 sec\n",
      "Episode 8950, len6, loss:-70.9608, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5475962162017822 sec\n",
      "Episode 8951, len6, loss:-72.6766, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5472598075866699 sec\n",
      "Episode 8952, len8, loss:-78.3645, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5475668907165527 sec\n",
      "Episode 8953, len12, loss:-109.7542, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5482795238494873 sec\n",
      "Episode 8954, len6, loss:-73.3442, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5475902557373047 sec\n",
      "Episode 8955, len12, loss:-109.2707, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5502612590789795 sec\n",
      "Episode 8956, len12, loss:-109.8594, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5472378730773926 sec\n",
      "Episode 8957, len10, loss:-95.5859, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5475423336029053 sec\n",
      "Episode 8958, len8, loss:-82.7234, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5480391979217529 sec\n",
      "Episode 8959, len8, loss:-75.8293, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5475242137908936 sec\n",
      "Episode 8960, len8, loss:-78.1724, fail, steps:80, opt steps:31, total reward:-24.0000, 0.6030499935150146 sec\n",
      "Episode 8961, len8, loss:-75.7278, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5477018356323242 sec\n",
      "Episode 8962, len8, loss:-74.6905, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5485804080963135 sec\n",
      "Episode 8963, len6, loss:-72.4038, fail, steps:80, opt steps:13, total reward:-24.0000, 0.548569917678833 sec\n",
      "Episode 8964, len6, loss:-75.2826, fail, steps:80, opt steps:13, total reward:-24.0000, 0.54775071144104 sec\n",
      "Episode 8965, len8, loss:-78.8748, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5489234924316406 sec\n",
      "Episode 8966, len6, loss:-76.1405, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5491142272949219 sec\n",
      "Episode 8967, len10, loss:-88.6620, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5491623878479004 sec\n",
      "Episode 8968, len12, loss:-108.2863, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5486905574798584 sec\n",
      "Episode 8969, len10, loss:-87.0292, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5496726036071777 sec\n",
      "Episode 8970, len8, loss:-72.6882, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5476107597351074 sec\n",
      "Episode 8971, len12, loss:-99.6973, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5472595691680908 sec\n",
      "Episode 8972, len6, loss:-72.5863, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5496389865875244 sec\n",
      "Episode 8973, len10, loss:-96.7856, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5484046936035156 sec\n",
      "Episode 8974, len12, loss:-96.2825, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5478725433349609 sec\n",
      "Episode 8975, len8, loss:-72.8916, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5495035648345947 sec\n",
      "Episode 8976, len12, loss:-100.6469, fail, steps:80, opt steps:45, total reward:-24.0000, 0.6013932228088379 sec\n",
      "Episode 8977, len12, loss:-105.2569, fail, steps:80, opt steps:39, total reward:-24.0000, 0.549091100692749 sec\n",
      "Episode 8978, len10, loss:-101.0466, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5490045547485352 sec\n",
      "Episode 8979, len12, loss:-102.7257, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5495355129241943 sec\n",
      "Episode 8980, len8, loss:-72.3876, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5487461090087891 sec\n",
      "Episode 8981, len6, loss:-71.2604, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5480015277862549 sec\n",
      "Episode 8982, len12, loss:-104.1623, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5481007099151611 sec\n",
      "Episode 8983, len12, loss:-111.7247, fail, steps:80, opt steps:32, total reward:-24.0000, 0.547466516494751 sec\n",
      "Episode 8984, len6, loss:-70.5499, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5483098030090332 sec\n",
      "Episode 8985, len12, loss:-104.8948, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5481603145599365 sec\n",
      "Episode 8986, len8, loss:-76.1198, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5486907958984375 sec\n",
      "Episode 8987, len8, loss:-76.0158, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5489001274108887 sec\n",
      "Episode 8988, len6, loss:-71.0575, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5433042049407959 sec\n",
      "Episode 8989, len12, loss:-102.9953, fail, steps:80, opt steps:71, total reward:-24.0000, 0.5482962131500244 sec\n",
      "Episode 8990, len8, loss:-74.2159, fail, steps:80, opt steps:17, total reward:-24.0000, 0.548954963684082 sec\n",
      "Episode 8991, len12, loss:-106.4347, fail, steps:80, opt steps:35, total reward:-24.0000, 0.549008846282959 sec\n",
      "Episode 8992, len12, loss:-108.2690, fail, steps:80, opt steps:66, total reward:-24.0000, 0.6040744781494141 sec\n",
      "Episode 8993, len12, loss:-104.5904, fail, steps:80, opt steps:23, total reward:-24.0000, 0.547501802444458 sec\n",
      "Episode 8994, len10, loss:-89.7269, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5483188629150391 sec\n",
      "Episode 8995, len8, loss:-76.6804, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5490498542785645 sec\n",
      "Episode 8996, len8, loss:-76.3998, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5470499992370605 sec\n",
      "Episode 8997, len10, loss:-94.4147, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5493118762969971 sec\n",
      "Episode 8998, len6, loss:-70.6481, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5493955612182617 sec\n",
      "Episode 8999, len10, loss:-97.1659, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5478851795196533 sec\n",
      "Episode 9000, len6, loss:-70.9907, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5472123622894287 sec\n",
      "Checkpoint saved at episode 9000 to /home/mcwave/code/autocode/datasets/rl_sort_transformer_easy/list6_12_transformer3_128_gamma07_step80_v3_merge_2_sorted/ckpt_9000_0.0000_26.24_vs_5.25.pth\n",
      "Learning rate = 0.000083\n",
      "Episode 9001, len10, loss:-91.5095, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5476963520050049 sec\n",
      "Episode 9002, len6, loss:-70.7161, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5486099720001221 sec\n",
      "Episode 9003, len10, loss:-91.4587, fail, steps:80, opt steps:27, total reward:-24.0000, 0.6078677177429199 sec\n",
      "Episode 9004, len10, loss:-88.7214, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5485777854919434 sec\n",
      "Episode 9005, len8, loss:-75.9988, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5507421493530273 sec\n",
      "Episode 9006, len8, loss:-71.6348, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5485837459564209 sec\n",
      "Episode 9007, len6, loss:-68.9277, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5485634803771973 sec\n",
      "Episode 9008, len10, loss:-89.4007, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5487494468688965 sec\n",
      "Episode 9009, len8, loss:-68.5682, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5482983589172363 sec\n",
      "Episode 9010, len10, loss:-91.6038, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5490603446960449 sec\n",
      "Episode 9011, len8, loss:-65.7069, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5475902557373047 sec\n",
      "Episode 9012, len12, loss:-106.2501, fail, steps:80, opt steps:52, total reward:-24.0000, 0.549039363861084 sec\n",
      "Episode 9013, len12, loss:-101.2243, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5482919216156006 sec\n",
      "Episode 9014, len8, loss:-81.8204, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5478153228759766 sec\n",
      "Episode 9015, len12, loss:-102.9185, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5487840175628662 sec\n",
      "Episode 9016, len12, loss:-100.7993, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5500228404998779 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9017, len10, loss:-88.6606, fail, steps:80, opt steps:47, total reward:-24.0000, 0.6013166904449463 sec\n",
      "Episode 9018, len12, loss:-101.7352, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5484890937805176 sec\n",
      "Episode 9019, len12, loss:-112.3984, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5530357360839844 sec\n",
      "Episode 9020, len10, loss:-91.8754, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5492010116577148 sec\n",
      "Episode 9021, len10, loss:-88.9444, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5501148700714111 sec\n",
      "Episode 9022, len12, loss:-102.7531, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5488111972808838 sec\n",
      "Episode 9023, len12, loss:-105.7040, fail, steps:80, opt steps:35, total reward:-24.0000, 0.549358606338501 sec\n",
      "Episode 9024, len6, loss:-67.5439, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5492494106292725 sec\n",
      "Episode 9025, len10, loss:-94.4989, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5501198768615723 sec\n",
      "Episode 9026, len12, loss:-108.2480, fail, steps:80, opt steps:67, total reward:-24.0000, 0.5486893653869629 sec\n",
      "Episode 9027, len12, loss:-105.1776, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5487866401672363 sec\n",
      "Episode 9028, len12, loss:-108.0285, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5506706237792969 sec\n",
      "Episode 9029, len6, loss:-66.8957, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5481903553009033 sec\n",
      "Episode 9030, len8, loss:-68.0970, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5497851371765137 sec\n",
      "Episode 9031, len6, loss:-69.3698, fail, steps:80, opt steps:7, total reward:-24.0000, 0.6043188571929932 sec\n",
      "Episode 9032, len10, loss:-85.1705, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5493934154510498 sec\n",
      "Episode 9033, len6, loss:-70.9225, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5497233867645264 sec\n",
      "Episode 9034, len12, loss:-101.4876, fail, steps:80, opt steps:41, total reward:-24.0000, 0.548630952835083 sec\n",
      "Episode 9035, len10, loss:-78.9636, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5484600067138672 sec\n",
      "Episode 9036, len6, loss:-74.2334, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5480644702911377 sec\n",
      "Episode 9037, len10, loss:-85.7195, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5484561920166016 sec\n",
      "Episode 9038, len8, loss:-64.9899, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5476369857788086 sec\n",
      "Episode 9039, len10, loss:-87.5768, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5490739345550537 sec\n",
      "Episode 9040, len12, loss:-94.5319, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5487215518951416 sec\n",
      "Episode 9041, len8, loss:-63.7060, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5491235256195068 sec\n",
      "Episode 9042, len6, loss:-72.6312, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5478231906890869 sec\n",
      "Episode 9043, len8, loss:-67.5073, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5496461391448975 sec\n",
      "Episode 9044, len12, loss:-92.8880, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5576663017272949 sec\n",
      "Episode 9045, len10, loss:-87.4225, fail, steps:80, opt steps:19, total reward:-24.0000, 0.6002473831176758 sec\n",
      "Episode 9046, len12, loss:-97.0674, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5497086048126221 sec\n",
      "Episode 9047, len10, loss:-80.9858, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5507543087005615 sec\n",
      "Episode 9048, len12, loss:-104.0797, fail, steps:80, opt steps:69, total reward:-24.7000, 0.5443985462188721 sec\n",
      "Episode 9049, len12, loss:-100.3832, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5490713119506836 sec\n",
      "Episode 9050, len10, loss:-85.9797, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5499365329742432 sec\n",
      "Episode 9051, len10, loss:-74.8882, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5486335754394531 sec\n",
      "Episode 9052, len12, loss:-91.3528, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5497493743896484 sec\n",
      "Episode 9053, len8, loss:-70.5639, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5488369464874268 sec\n",
      "Episode 9054, len8, loss:-70.4751, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5485713481903076 sec\n",
      "Episode 9055, len12, loss:-103.7522, fail, steps:80, opt steps:22, total reward:-24.0000, 0.549633264541626 sec\n",
      "Episode 9056, len8, loss:-70.9717, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5495922565460205 sec\n",
      "Episode 9057, len10, loss:-79.2299, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5478589534759521 sec\n",
      "Episode 9058, len6, loss:-67.9852, fail, steps:80, opt steps:10, total reward:-24.0000, 0.547074556350708 sec\n",
      "Episode 9059, len8, loss:-65.4150, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5992169380187988 sec\n",
      "Episode 9060, len6, loss:-67.9120, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5481479167938232 sec\n",
      "Episode 9061, len8, loss:-66.8458, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5490648746490479 sec\n",
      "Episode 9062, len12, loss:-96.2300, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5496907234191895 sec\n",
      "Episode 9063, len10, loss:-91.6851, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5480015277862549 sec\n",
      "Episode 9064, len10, loss:-79.8669, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5470600128173828 sec\n",
      "Episode 9065, len10, loss:-85.1167, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5477733612060547 sec\n",
      "Episode 9066, len12, loss:-96.7097, fail, steps:80, opt steps:31, total reward:-24.0000, 0.547757625579834 sec\n",
      "Episode 9067, len6, loss:-73.1903, fail, steps:80, opt steps:16, total reward:-24.0000, 0.546515941619873 sec\n",
      "Episode 9068, len10, loss:-87.9240, fail, steps:80, opt steps:39, total reward:-24.0000, 0.548332691192627 sec\n",
      "Episode 9069, len10, loss:-83.2856, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5492961406707764 sec\n",
      "Episode 9070, len6, loss:-70.0130, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5479204654693604 sec\n",
      "Episode 9071, len6, loss:-64.8299, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5482454299926758 sec\n",
      "Episode 9072, len12, loss:-107.0923, fail, steps:80, opt steps:54, total reward:-24.0000, 0.547874927520752 sec\n",
      "Episode 9073, len10, loss:-88.8336, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5488533973693848 sec\n",
      "Episode 9074, len12, loss:-91.1954, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5994188785552979 sec\n",
      "Episode 9075, len10, loss:-89.0815, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5488719940185547 sec\n",
      "Episode 9076, len6, loss:-70.8644, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5475912094116211 sec\n",
      "Episode 9077, len6, loss:-71.4561, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5463457107543945 sec\n",
      "Episode 9078, len12, loss:-95.9278, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5475127696990967 sec\n",
      "Episode 9079, len6, loss:-66.9277, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5470242500305176 sec\n",
      "Episode 9080, len12, loss:-96.2480, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5469810962677002 sec\n",
      "Episode 9081, len8, loss:-65.6053, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5478031635284424 sec\n",
      "Episode 9082, len10, loss:-81.5670, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5475912094116211 sec\n",
      "Episode 9083, len10, loss:-81.5622, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5466513633728027 sec\n",
      "Episode 9084, len6, loss:-67.8520, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5477004051208496 sec\n",
      "Episode 9085, len8, loss:-64.2438, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5481963157653809 sec\n",
      "Episode 9086, len10, loss:-81.5211, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5477485656738281 sec\n",
      "Episode 9087, len8, loss:-50.5137, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5465054512023926 sec\n",
      "Episode 9088, len6, loss:-70.3902, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5467982292175293 sec\n",
      "Episode 9089, len12, loss:-94.9397, fail, steps:80, opt steps:74, total reward:-24.0000, 0.5468993186950684 sec\n",
      "Episode 9090, len8, loss:-58.7241, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5999999046325684 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9091, len8, loss:-58.1461, fail, steps:80, opt steps:7, total reward:-24.0000, 0.546682596206665 sec\n",
      "Episode 9092, len8, loss:-56.7643, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5476627349853516 sec\n",
      "Episode 9093, len10, loss:-73.2747, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5479638576507568 sec\n",
      "Episode 9094, len10, loss:-87.2115, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5471506118774414 sec\n",
      "Episode 9095, len10, loss:-81.8091, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5477111339569092 sec\n",
      "Episode 9096, len8, loss:-60.2567, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5467004776000977 sec\n",
      "Episode 9097, len6, loss:-69.9706, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5471482276916504 sec\n",
      "Episode 9098, len8, loss:-54.3561, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5477328300476074 sec\n",
      "Episode 9099, len8, loss:-66.2393, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5423223972320557 sec\n",
      "Episode 9100, len8, loss:-54.9689, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5487949848175049 sec\n",
      "Episode 9101, len10, loss:-80.9452, fail, steps:80, opt steps:45, total reward:-24.0000, 0.548302173614502 sec\n",
      "Episode 9102, len10, loss:-84.9014, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5467541217803955 sec\n",
      "Episode 9103, len10, loss:-74.8697, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5477051734924316 sec\n",
      "Episode 9104, len12, loss:-90.0906, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5485167503356934 sec\n",
      "Episode 9105, len8, loss:-56.7296, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5466127395629883 sec\n",
      "Episode 9106, len6, loss:-72.9407, fail, steps:80, opt steps:15, total reward:-24.0000, 0.6012697219848633 sec\n",
      "Episode 9107, len10, loss:-88.4327, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5479376316070557 sec\n",
      "Episode 9108, len8, loss:-69.6816, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5479373931884766 sec\n",
      "Episode 9109, len10, loss:-77.5902, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5467581748962402 sec\n",
      "Episode 9110, len10, loss:-86.8984, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5483520030975342 sec\n",
      "Episode 9111, len8, loss:-62.4981, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5480172634124756 sec\n",
      "Episode 9112, len12, loss:-103.7452, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5484530925750732 sec\n",
      "Episode 9113, len8, loss:-63.7138, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5462110042572021 sec\n",
      "Episode 9114, len8, loss:-60.1510, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5480606555938721 sec\n",
      "Episode 9115, len8, loss:-55.1660, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5476455688476562 sec\n",
      "Episode 9116, len12, loss:-98.1770, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5473265647888184 sec\n",
      "Episode 9117, len12, loss:-92.1061, fail, steps:80, opt steps:71, total reward:-24.0000, 0.548100471496582 sec\n",
      "Episode 9118, len10, loss:-88.3645, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5473647117614746 sec\n",
      "Episode 9119, len10, loss:-82.8346, fail, steps:80, opt steps:31, total reward:-24.0000, 0.6020970344543457 sec\n",
      "Episode 9120, len6, loss:-70.2548, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5477864742279053 sec\n",
      "Episode 9121, len10, loss:-84.7557, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5481953620910645 sec\n",
      "Episode 9122, len8, loss:-68.4603, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5473906993865967 sec\n",
      "Episode 9123, len12, loss:-104.0889, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5472521781921387 sec\n",
      "Episode 9124, len10, loss:-90.3941, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5477778911590576 sec\n",
      "Episode 9125, len10, loss:-79.6101, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5474913120269775 sec\n",
      "Episode 9126, len8, loss:-70.6886, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5476670265197754 sec\n",
      "Episode 9127, len6, loss:-71.9234, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5475673675537109 sec\n",
      "Episode 9128, len10, loss:-80.7461, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5477044582366943 sec\n",
      "Episode 9129, len10, loss:-80.9551, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5479214191436768 sec\n",
      "Episode 9130, len10, loss:-79.6504, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5475897789001465 sec\n",
      "Episode 9131, len8, loss:-58.6839, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5482549667358398 sec\n",
      "Episode 9132, len8, loss:-50.8114, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490403175354004 sec\n",
      "Episode 9133, len6, loss:-70.6689, fail, steps:80, opt steps:6, total reward:-24.0000, 0.599755048751831 sec\n",
      "Episode 9134, len6, loss:-72.9072, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5478403568267822 sec\n",
      "Episode 9135, len12, loss:-93.0231, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5475184917449951 sec\n",
      "Episode 9136, len10, loss:-79.3367, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5474424362182617 sec\n",
      "Episode 9137, len10, loss:-73.9050, fail, steps:80, opt steps:45, total reward:-24.0000, 0.548743486404419 sec\n",
      "Episode 9138, len10, loss:-77.5183, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5479991436004639 sec\n",
      "Episode 9139, len8, loss:-52.4918, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5486817359924316 sec\n",
      "Episode 9140, len6, loss:-69.5919, fail, steps:80, opt steps:18, total reward:-24.0000, 0.546928882598877 sec\n",
      "Episode 9141, len6, loss:-62.9419, fail, steps:80, opt steps:11, total reward:-24.0000, 0.547229528427124 sec\n",
      "Episode 9142, len12, loss:-88.4814, fail, steps:80, opt steps:26, total reward:-23.7000, 0.5432493686676025 sec\n",
      "Episode 9143, len6, loss:-69.7095, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5473575592041016 sec\n",
      "Episode 9144, len8, loss:-52.8046, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5468156337738037 sec\n",
      "Episode 9145, len10, loss:-75.1147, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5470926761627197 sec\n",
      "Episode 9146, len12, loss:-91.6674, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5473027229309082 sec\n",
      "Episode 9147, len10, loss:-80.9380, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5998818874359131 sec\n",
      "Episode 9148, len10, loss:-78.8568, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5490014553070068 sec\n",
      "Episode 9149, len8, loss:-58.9413, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5479536056518555 sec\n",
      "Episode 9150, len10, loss:-80.0105, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5500583648681641 sec\n",
      "Episode 9151, len12, loss:-88.1115, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5481765270233154 sec\n",
      "Episode 9152, len12, loss:-91.6675, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5484819412231445 sec\n",
      "Episode 9153, len10, loss:-84.3742, fail, steps:80, opt steps:40, total reward:-23.7000, 0.5452861785888672 sec\n",
      "Episode 9154, len12, loss:-101.0199, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5481297969818115 sec\n",
      "Episode 9155, len10, loss:-66.9748, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5488746166229248 sec\n",
      "Episode 9156, len8, loss:-53.7710, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5479216575622559 sec\n",
      "Episode 9157, len10, loss:-74.1906, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5475869178771973 sec\n",
      "Episode 9158, len6, loss:-57.0984, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5482714176177979 sec\n",
      "Episode 9159, len10, loss:-82.4923, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5489420890808105 sec\n",
      "Episode 9160, len12, loss:-91.9660, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5482556819915771 sec\n",
      "Episode 9161, len12, loss:-84.1830, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5990145206451416 sec\n",
      "Episode 9162, len12, loss:-92.1865, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5490710735321045 sec\n",
      "Episode 9163, len12, loss:-96.1695, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5503976345062256 sec\n",
      "Episode 9164, len6, loss:-68.8660, fail, steps:80, opt steps:13, total reward:-24.7000, 0.5446126461029053 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9165, len10, loss:-68.2880, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5492057800292969 sec\n",
      "Episode 9166, len8, loss:-57.2747, fail, steps:80, opt steps:26, total reward:-24.7000, 0.5439012050628662 sec\n",
      "Episode 9167, len12, loss:-86.3248, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5479662418365479 sec\n",
      "Episode 9168, len8, loss:-48.7145, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5494751930236816 sec\n",
      "Episode 9169, len12, loss:-83.8609, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5481777191162109 sec\n",
      "Episode 9170, len12, loss:-77.5865, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5512290000915527 sec\n",
      "Episode 9171, len8, loss:-47.6078, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5478863716125488 sec\n",
      "Episode 9172, len12, loss:-87.9862, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5486898422241211 sec\n",
      "Episode 9173, len12, loss:-87.4879, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5482254028320312 sec\n",
      "Episode 9174, len10, loss:-75.1900, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5478000640869141 sec\n",
      "Episode 9175, len6, loss:-52.0135, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5979270935058594 sec\n",
      "Episode 9176, len10, loss:-81.8489, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5477540493011475 sec\n",
      "Episode 9177, len10, loss:-70.7583, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5479938983917236 sec\n",
      "Episode 9178, len6, loss:-56.4765, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5519816875457764 sec\n",
      "Episode 9179, len10, loss:-68.7462, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5491800308227539 sec\n",
      "Episode 9180, len12, loss:-86.9294, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5488471984863281 sec\n",
      "Episode 9181, len8, loss:-47.8980, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5475485324859619 sec\n",
      "Episode 9182, len6, loss:-53.5263, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5485656261444092 sec\n",
      "Episode 9183, len6, loss:-60.0305, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5489470958709717 sec\n",
      "Episode 9184, len6, loss:-53.0913, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5487613677978516 sec\n",
      "Episode 9185, len12, loss:-87.5765, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5477805137634277 sec\n",
      "Episode 9186, len10, loss:-67.5588, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5495157241821289 sec\n",
      "Episode 9187, len8, loss:-45.0653, fail, steps:80, opt steps:27, total reward:-24.0000, 0.549401044845581 sec\n",
      "Episode 9188, len12, loss:-79.9741, fail, steps:80, opt steps:29, total reward:-24.0000, 0.550408124923706 sec\n",
      "Episode 9189, len8, loss:-54.6077, fail, steps:80, opt steps:21, total reward:-23.7000, 0.5440855026245117 sec\n",
      "Episode 9190, len10, loss:-78.8505, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5978653430938721 sec\n",
      "Episode 9191, len6, loss:-58.9529, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5481719970703125 sec\n",
      "Episode 9192, len6, loss:-63.4792, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5492260456085205 sec\n",
      "Episode 9193, len12, loss:-81.7979, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5483126640319824 sec\n",
      "Episode 9194, len10, loss:-78.0015, fail, steps:80, opt steps:50, total reward:-24.0000, 0.54779052734375 sec\n",
      "Episode 9195, len10, loss:-78.1985, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5476460456848145 sec\n",
      "Episode 9196, len12, loss:-87.2167, fail, steps:80, opt steps:68, total reward:-24.0000, 0.5483603477478027 sec\n",
      "Episode 9197, len12, loss:-85.7975, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5497586727142334 sec\n",
      "Episode 9198, len12, loss:-74.8241, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5492238998413086 sec\n",
      "Episode 9199, len8, loss:-54.2792, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5493426322937012 sec\n",
      "Episode 9200, len10, loss:-82.7820, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5486466884613037 sec\n",
      "Episode 9201, len12, loss:-89.4994, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5484828948974609 sec\n",
      "Episode 9202, len12, loss:-84.5765, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5488061904907227 sec\n",
      "Episode 9203, len10, loss:-82.3462, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5471951961517334 sec\n",
      "Episode 9204, len6, loss:-55.7211, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5492396354675293 sec\n",
      "Episode 9205, len6, loss:-57.2220, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5484282970428467 sec\n",
      "Episode 9206, len6, loss:-59.7578, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5980231761932373 sec\n",
      "Episode 9207, len6, loss:-59.0603, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5476272106170654 sec\n",
      "Episode 9208, len6, loss:-61.8322, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5493927001953125 sec\n",
      "Episode 9209, len10, loss:-68.3572, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5492851734161377 sec\n",
      "Episode 9210, len12, loss:-88.6066, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5494961738586426 sec\n",
      "Episode 9211, len6, loss:-62.8370, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5479412078857422 sec\n",
      "Episode 9212, len6, loss:-67.3317, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5480315685272217 sec\n",
      "Episode 9213, len12, loss:-85.1757, fail, steps:80, opt steps:30, total reward:-24.0000, 0.548109769821167 sec\n",
      "Episode 9214, len8, loss:-52.1290, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5489566326141357 sec\n",
      "Episode 9215, len10, loss:-66.1775, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5516073703765869 sec\n",
      "Episode 9216, len8, loss:-56.0369, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5480365753173828 sec\n",
      "Episode 9217, len10, loss:-68.7016, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5483145713806152 sec\n",
      "Episode 9218, len12, loss:-88.4631, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5485560894012451 sec\n",
      "Episode 9219, len6, loss:-62.0397, fail, steps:80, opt steps:15, total reward:-24.0000, 0.548241138458252 sec\n",
      "Episode 9220, len8, loss:-56.4691, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5473165512084961 sec\n",
      "Episode 9221, len8, loss:-52.1699, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5479779243469238 sec\n",
      "Episode 9222, len6, loss:-61.9243, fail, steps:80, opt steps:10, total reward:-24.0000, 0.597198486328125 sec\n",
      "Episode 9223, len8, loss:-60.5318, fail, steps:80, opt steps:21, total reward:-24.0000, 0.548386812210083 sec\n",
      "Episode 9224, len8, loss:-46.3446, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5492382049560547 sec\n",
      "Episode 9225, len10, loss:-67.7795, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5481686592102051 sec\n",
      "Episode 9226, len6, loss:-61.4135, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5494892597198486 sec\n",
      "Episode 9227, len6, loss:-64.4673, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5492908954620361 sec\n",
      "Episode 9228, len6, loss:-64.0945, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5490036010742188 sec\n",
      "Episode 9229, len12, loss:-80.4941, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5498454570770264 sec\n",
      "Episode 9230, len6, loss:-65.5202, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5494089126586914 sec\n",
      "Episode 9231, len6, loss:-66.2002, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5488243103027344 sec\n",
      "Episode 9232, len10, loss:-72.3398, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5498335361480713 sec\n",
      "Episode 9233, len10, loss:-67.9063, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5492820739746094 sec\n",
      "Episode 9234, len8, loss:-52.5773, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5477945804595947 sec\n",
      "Episode 9235, len10, loss:-68.0004, fail, steps:80, opt steps:31, total reward:-24.0000, 0.6029071807861328 sec\n",
      "Episode 9236, len10, loss:-66.0610, fail, steps:80, opt steps:19, total reward:-24.0000, 0.54905104637146 sec\n",
      "Episode 9237, len8, loss:-62.7027, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5477864742279053 sec\n",
      "Episode 9238, len8, loss:-57.6924, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5470776557922363 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9239, len8, loss:-64.2114, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5483450889587402 sec\n",
      "Episode 9240, len6, loss:-69.1033, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5489420890808105 sec\n",
      "Episode 9241, len12, loss:-88.8686, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5463659763336182 sec\n",
      "Episode 9242, len6, loss:-63.1196, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5478119850158691 sec\n",
      "Episode 9243, len12, loss:-87.9761, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5472569465637207 sec\n",
      "Episode 9244, len10, loss:-67.8154, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5489239692687988 sec\n",
      "Episode 9245, len12, loss:-87.9408, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5474534034729004 sec\n",
      "Episode 9246, len12, loss:-84.6066, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5475368499755859 sec\n",
      "Episode 9247, len10, loss:-62.1574, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5470716953277588 sec\n",
      "Episode 9248, len10, loss:-67.3701, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5478518009185791 sec\n",
      "Episode 9249, len12, loss:-86.5646, fail, steps:80, opt steps:24, total reward:-24.0000, 0.6019175052642822 sec\n",
      "Episode 9250, len8, loss:-48.1183, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5475718975067139 sec\n",
      "Episode 9251, len10, loss:-67.7783, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5469658374786377 sec\n",
      "Episode 9252, len6, loss:-67.3918, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5476341247558594 sec\n",
      "Episode 9253, len10, loss:-69.2949, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5469777584075928 sec\n",
      "Episode 9254, len10, loss:-65.0224, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5479862689971924 sec\n",
      "Episode 9255, len10, loss:-77.0527, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5487771034240723 sec\n",
      "Episode 9256, len10, loss:-60.3643, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5470967292785645 sec\n",
      "Episode 9257, len10, loss:-68.9408, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5472407341003418 sec\n",
      "Episode 9258, len12, loss:-81.4862, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5476772785186768 sec\n",
      "Episode 9259, len12, loss:-79.5531, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5489327907562256 sec\n",
      "Episode 9260, len12, loss:-97.0935, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5484557151794434 sec\n",
      "Episode 9261, len6, loss:-67.6588, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5518858432769775 sec\n",
      "Episode 9262, len12, loss:-87.5730, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5575506687164307 sec\n",
      "Episode 9263, len12, loss:-86.1026, fail, steps:80, opt steps:62, total reward:-24.0000, 0.5999283790588379 sec\n",
      "Episode 9264, len8, loss:-60.8707, fail, steps:80, opt steps:12, total reward:-24.0000, 0.554746150970459 sec\n",
      "Episode 9265, len6, loss:-68.7504, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5485682487487793 sec\n",
      "Episode 9266, len8, loss:-62.0129, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5490984916687012 sec\n",
      "Episode 9267, len10, loss:-76.5667, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5488929748535156 sec\n",
      "Episode 9268, len6, loss:-62.5551, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5495526790618896 sec\n",
      "Episode 9269, len10, loss:-76.4782, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5490908622741699 sec\n",
      "Episode 9270, len12, loss:-79.6710, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5502285957336426 sec\n",
      "Episode 9271, len10, loss:-75.7724, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5483009815216064 sec\n",
      "Episode 9272, len6, loss:-64.2740, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5503406524658203 sec\n",
      "Episode 9273, len12, loss:-85.6028, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5499114990234375 sec\n",
      "Episode 9274, len10, loss:-73.0005, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5497632026672363 sec\n",
      "Episode 9275, len12, loss:-77.0812, fail, steps:80, opt steps:33, total reward:-24.0000, 0.548865795135498 sec\n",
      "Episode 9276, len10, loss:-73.3326, fail, steps:80, opt steps:37, total reward:-24.0000, 0.549877405166626 sec\n",
      "Episode 9277, len8, loss:-53.2418, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5999712944030762 sec\n",
      "Episode 9278, len8, loss:-58.0534, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5491328239440918 sec\n",
      "Episode 9279, len12, loss:-91.4760, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5492682456970215 sec\n",
      "Episode 9280, len8, loss:-61.1405, fail, steps:80, opt steps:26, total reward:-24.0000, 0.549818754196167 sec\n",
      "Episode 9281, len6, loss:-65.4784, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5492227077484131 sec\n",
      "Episode 9282, len12, loss:-91.8614, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5484275817871094 sec\n",
      "Episode 9283, len6, loss:-58.9772, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5493264198303223 sec\n",
      "Episode 9284, len12, loss:-88.5372, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5513656139373779 sec\n",
      "Episode 9285, len12, loss:-96.6550, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5494630336761475 sec\n",
      "Episode 9286, len12, loss:-88.5783, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5486140251159668 sec\n",
      "Episode 9287, len6, loss:-57.3274, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5497050285339355 sec\n",
      "Episode 9288, len10, loss:-76.6322, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5502464771270752 sec\n",
      "Episode 9289, len12, loss:-81.2829, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5498144626617432 sec\n",
      "Episode 9290, len6, loss:-63.6250, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5494389533996582 sec\n",
      "Episode 9291, len6, loss:-53.3578, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5982189178466797 sec\n",
      "Episode 9292, len12, loss:-85.7604, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5498735904693604 sec\n",
      "Episode 9293, len8, loss:-60.8656, fail, steps:80, opt steps:4, total reward:-24.0000, 0.5493865013122559 sec\n",
      "Episode 9294, len8, loss:-58.5505, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5480630397796631 sec\n",
      "Episode 9295, len8, loss:-57.9331, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5496091842651367 sec\n",
      "Episode 9296, len10, loss:-68.9704, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5495123863220215 sec\n",
      "Episode 9297, len6, loss:-60.8137, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5496129989624023 sec\n",
      "Episode 9298, len10, loss:-76.3117, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5490972995758057 sec\n",
      "Episode 9299, len8, loss:-56.9654, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5485601425170898 sec\n",
      "Episode 9300, len10, loss:-68.5742, fail, steps:80, opt steps:45, total reward:-24.0000, 0.549424409866333 sec\n",
      "Episode 9301, len6, loss:-54.6022, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5488338470458984 sec\n",
      "Episode 9302, len10, loss:-74.4629, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5489749908447266 sec\n",
      "Episode 9303, len10, loss:-84.5769, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5496063232421875 sec\n",
      "Episode 9304, len8, loss:-57.6356, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5487158298492432 sec\n",
      "Episode 9305, len12, loss:-96.7918, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5493311882019043 sec\n",
      "Episode 9306, len6, loss:-46.9081, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5990135669708252 sec\n",
      "Episode 9307, len8, loss:-67.2946, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5484230518341064 sec\n",
      "Episode 9308, len8, loss:-61.7389, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5481619834899902 sec\n",
      "Episode 9309, len8, loss:-59.5147, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5479159355163574 sec\n",
      "Episode 9310, len6, loss:-55.2149, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5496609210968018 sec\n",
      "Episode 9311, len8, loss:-58.5404, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5481290817260742 sec\n",
      "Episode 9312, len6, loss:-51.3571, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5486865043640137 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9313, len6, loss:-56.5076, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5498075485229492 sec\n",
      "Episode 9314, len6, loss:-65.1668, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5493898391723633 sec\n",
      "Episode 9315, len12, loss:-92.6836, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5502676963806152 sec\n",
      "Episode 9316, len12, loss:-84.5342, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5522515773773193 sec\n",
      "Episode 9317, len8, loss:-62.4798, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5486783981323242 sec\n",
      "Episode 9318, len12, loss:-93.5731, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5492582321166992 sec\n",
      "Episode 9319, len10, loss:-73.7647, fail, steps:80, opt steps:30, total reward:-24.0000, 0.549903392791748 sec\n",
      "Episode 9320, len12, loss:-94.9444, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5485670566558838 sec\n",
      "Episode 9321, len10, loss:-81.4955, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5491704940795898 sec\n",
      "Episode 9322, len6, loss:-75.9128, fail, steps:80, opt steps:6, total reward:-24.7000, 0.5944743156433105 sec\n",
      "Episode 9323, len12, loss:-91.6495, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5477735996246338 sec\n",
      "Episode 9324, len10, loss:-79.0561, fail, steps:80, opt steps:5, total reward:-24.0000, 0.549560546875 sec\n",
      "Episode 9325, len12, loss:-90.8157, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5490729808807373 sec\n",
      "Episode 9326, len10, loss:-72.1568, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5483052730560303 sec\n",
      "Episode 9327, len10, loss:-81.6975, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5492324829101562 sec\n",
      "Episode 9328, len6, loss:-61.6976, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5490896701812744 sec\n",
      "Episode 9329, len10, loss:-79.1315, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5483970642089844 sec\n",
      "Episode 9330, len8, loss:-61.9850, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5487256050109863 sec\n",
      "Episode 9331, len6, loss:-63.3434, fail, steps:80, opt steps:17, total reward:-24.0000, 0.550020694732666 sec\n",
      "Episode 9332, len10, loss:-81.7965, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5489025115966797 sec\n",
      "Episode 9333, len8, loss:-71.3287, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5493683815002441 sec\n",
      "Episode 9334, len6, loss:-57.5781, fail, steps:80, opt steps:13, total reward:-24.0000, 0.548987627029419 sec\n",
      "Episode 9335, len12, loss:-88.0964, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5495991706848145 sec\n",
      "Episode 9336, len12, loss:-93.5869, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5495705604553223 sec\n",
      "Episode 9337, len10, loss:-74.8163, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5484375953674316 sec\n",
      "Episode 9338, len10, loss:-66.4167, fail, steps:80, opt steps:32, total reward:-24.0000, 0.6002070903778076 sec\n",
      "Episode 9339, len12, loss:-91.9562, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5498671531677246 sec\n",
      "Episode 9340, len12, loss:-97.3488, fail, steps:80, opt steps:50, total reward:-24.0000, 0.549823522567749 sec\n",
      "Episode 9341, len12, loss:-87.4391, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5491876602172852 sec\n",
      "Episode 9342, len8, loss:-69.6426, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5497558116912842 sec\n",
      "Episode 9343, len12, loss:-94.5516, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5489847660064697 sec\n",
      "Episode 9344, len12, loss:-94.9456, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5499029159545898 sec\n",
      "Episode 9345, len6, loss:-62.3274, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5493628978729248 sec\n",
      "Episode 9346, len10, loss:-75.9189, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5504453182220459 sec\n",
      "Episode 9347, len6, loss:-58.0378, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5493693351745605 sec\n",
      "Episode 9348, len12, loss:-92.3180, fail, steps:80, opt steps:19, total reward:-24.0000, 0.550762414932251 sec\n",
      "Episode 9349, len12, loss:-98.7222, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5486886501312256 sec\n",
      "Episode 9350, len8, loss:-63.2582, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5492763519287109 sec\n",
      "Episode 9351, len6, loss:-58.5030, fail, steps:80, opt steps:5, total reward:-24.0000, 0.6016905307769775 sec\n",
      "Episode 9352, len6, loss:-51.4657, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5497715473175049 sec\n",
      "Episode 9353, len10, loss:-66.6033, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5489063262939453 sec\n",
      "Episode 9354, len6, loss:-57.9382, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5495491027832031 sec\n",
      "Episode 9355, len10, loss:-74.3224, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5493144989013672 sec\n",
      "Episode 9356, len12, loss:-88.3278, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5490779876708984 sec\n",
      "Episode 9357, len12, loss:-89.5463, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5502040386199951 sec\n",
      "Episode 9358, len8, loss:-68.0402, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5494544506072998 sec\n",
      "Episode 9359, len6, loss:-59.4028, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5499200820922852 sec\n",
      "Episode 9360, len8, loss:-70.3694, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5483253002166748 sec\n",
      "Episode 9361, len10, loss:-67.6248, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5503928661346436 sec\n",
      "Episode 9362, len10, loss:-79.7081, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5496013164520264 sec\n",
      "Episode 9363, len10, loss:-72.1318, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5480329990386963 sec\n",
      "Episode 9364, len10, loss:-71.9331, fail, steps:80, opt steps:16, total reward:-24.0000, 0.549274206161499 sec\n",
      "Episode 9365, len6, loss:-58.8492, fail, steps:80, opt steps:6, total reward:-24.0000, 0.6019139289855957 sec\n",
      "Episode 9366, len10, loss:-75.9845, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5486776828765869 sec\n",
      "Episode 9367, len10, loss:-71.9374, fail, steps:80, opt steps:33, total reward:-24.0000, 0.549612283706665 sec\n",
      "Episode 9368, len12, loss:-94.5468, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5504169464111328 sec\n",
      "Episode 9369, len12, loss:-94.5393, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5508592128753662 sec\n",
      "Episode 9370, len6, loss:-60.1861, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5481867790222168 sec\n",
      "Episode 9371, len8, loss:-69.6549, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5482664108276367 sec\n",
      "Episode 9372, len8, loss:-63.1643, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5487933158874512 sec\n",
      "Episode 9373, len8, loss:-64.6296, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5499894618988037 sec\n",
      "Episode 9374, len12, loss:-93.0939, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5499119758605957 sec\n",
      "Episode 9375, len6, loss:-59.4445, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5488693714141846 sec\n",
      "Episode 9376, len10, loss:-83.8010, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5495564937591553 sec\n",
      "Episode 9377, len10, loss:-75.5314, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5505125522613525 sec\n",
      "Episode 9378, len8, loss:-65.0075, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5500354766845703 sec\n",
      "Episode 9379, len10, loss:-78.1226, fail, steps:80, opt steps:40, total reward:-24.0000, 0.6009728908538818 sec\n",
      "Episode 9380, len8, loss:-64.0671, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5492300987243652 sec\n",
      "Episode 9381, len6, loss:-63.1315, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5493311882019043 sec\n",
      "Episode 9382, len10, loss:-72.2112, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5505485534667969 sec\n",
      "Episode 9383, len12, loss:-96.5188, fail, steps:80, opt steps:30, total reward:-24.7000, 0.5433547496795654 sec\n",
      "Episode 9384, len10, loss:-74.6976, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5478119850158691 sec\n",
      "Episode 9385, len10, loss:-83.8993, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5491454601287842 sec\n",
      "Episode 9386, len12, loss:-94.2126, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5495340824127197 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9387, len6, loss:-67.1418, fail, steps:80, opt steps:18, total reward:-24.0000, 0.549415111541748 sec\n",
      "Episode 9388, len8, loss:-65.1539, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5490615367889404 sec\n",
      "Episode 9389, len8, loss:-65.2800, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5492618083953857 sec\n",
      "Episode 9390, len8, loss:-67.3769, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5497896671295166 sec\n",
      "Episode 9391, len12, loss:-94.2161, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5503518581390381 sec\n",
      "Episode 9392, len12, loss:-92.5490, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5498349666595459 sec\n",
      "Episode 9393, len10, loss:-84.8150, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5991272926330566 sec\n",
      "Episode 9394, len12, loss:-93.6168, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5490455627441406 sec\n",
      "Episode 9395, len10, loss:-75.1177, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5498042106628418 sec\n",
      "Episode 9396, len6, loss:-68.9901, fail, steps:80, opt steps:15, total reward:-24.7000, 0.544633150100708 sec\n",
      "Episode 9397, len10, loss:-79.7290, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5490295886993408 sec\n",
      "Episode 9398, len12, loss:-95.1262, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5493457317352295 sec\n",
      "Episode 9399, len8, loss:-66.5119, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5487155914306641 sec\n",
      "Episode 9400, len6, loss:-58.0682, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5495684146881104 sec\n",
      "Episode 9401, len6, loss:-66.2495, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5485587120056152 sec\n",
      "Episode 9402, len12, loss:-96.3920, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5497679710388184 sec\n",
      "Episode 9403, len10, loss:-87.1924, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5491032600402832 sec\n",
      "Episode 9404, len10, loss:-76.6009, fail, steps:80, opt steps:47, total reward:-24.0000, 0.549424409866333 sec\n",
      "Episode 9405, len8, loss:-72.9933, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5494775772094727 sec\n",
      "Episode 9406, len6, loss:-66.6207, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5488288402557373 sec\n",
      "Episode 9407, len10, loss:-68.8421, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5973889827728271 sec\n",
      "Episode 9408, len12, loss:-91.8203, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5488672256469727 sec\n",
      "Episode 9409, len6, loss:-63.2540, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5502541065216064 sec\n",
      "Episode 9410, len6, loss:-63.5135, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5491492748260498 sec\n",
      "Episode 9411, len8, loss:-68.2963, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5494318008422852 sec\n",
      "Episode 9412, len10, loss:-79.1505, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5482950210571289 sec\n",
      "Episode 9413, len10, loss:-78.6747, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5482406616210938 sec\n",
      "Episode 9414, len12, loss:-93.5922, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5491995811462402 sec\n",
      "Episode 9415, len6, loss:-64.2181, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5481469631195068 sec\n",
      "Episode 9416, len10, loss:-74.0936, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5495505332946777 sec\n",
      "Episode 9417, len8, loss:-66.9651, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5496325492858887 sec\n",
      "Episode 9418, len8, loss:-63.0228, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5495181083679199 sec\n",
      "Episode 9419, len6, loss:-64.8200, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5499000549316406 sec\n",
      "Episode 9420, len12, loss:-98.5910, fail, steps:80, opt steps:46, total reward:-24.0000, 0.549187421798706 sec\n",
      "Episode 9421, len6, loss:-64.8269, fail, steps:80, opt steps:16, total reward:-24.0000, 0.550403356552124 sec\n",
      "Episode 9422, len10, loss:-78.9626, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5982270240783691 sec\n",
      "Episode 9423, len8, loss:-80.7547, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5481326580047607 sec\n",
      "Episode 9424, len12, loss:-94.0882, fail, steps:80, opt steps:58, total reward:-24.0000, 0.548206090927124 sec\n",
      "Episode 9425, len8, loss:-77.7728, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5481398105621338 sec\n",
      "Episode 9426, len6, loss:-73.4821, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5505845546722412 sec\n",
      "Episode 9427, len12, loss:-101.1836, fail, steps:80, opt steps:66, total reward:-24.0000, 0.550145149230957 sec\n",
      "Episode 9428, len8, loss:-81.8702, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5483956336975098 sec\n",
      "Episode 9429, len10, loss:-87.5188, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5486137866973877 sec\n",
      "Episode 9430, len10, loss:-82.0821, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5500071048736572 sec\n",
      "Episode 9431, len12, loss:-98.5949, fail, steps:80, opt steps:56, total reward:-24.0000, 0.5494546890258789 sec\n",
      "Episode 9432, len10, loss:-79.3758, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5498025417327881 sec\n",
      "Episode 9433, len12, loss:-97.0113, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5489151477813721 sec\n",
      "Episode 9434, len6, loss:-61.9601, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5503287315368652 sec\n",
      "Episode 9435, len12, loss:-91.0837, fail, steps:80, opt steps:27, total reward:-24.0000, 0.549689769744873 sec\n",
      "Episode 9436, len6, loss:-72.3484, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5497937202453613 sec\n",
      "Episode 9437, len12, loss:-96.3681, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5488700866699219 sec\n",
      "Episode 9438, len12, loss:-96.2085, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5993762016296387 sec\n",
      "Episode 9439, len6, loss:-71.1260, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5491347312927246 sec\n",
      "Episode 9440, len6, loss:-68.6125, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5493147373199463 sec\n",
      "Episode 9441, len6, loss:-67.6382, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5480554103851318 sec\n",
      "Episode 9442, len6, loss:-70.9888, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5493977069854736 sec\n",
      "Episode 9443, len8, loss:-76.4933, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5489261150360107 sec\n",
      "Episode 9444, len6, loss:-74.9710, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5471324920654297 sec\n",
      "Episode 9445, len10, loss:-79.8706, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5502262115478516 sec\n",
      "Episode 9446, len8, loss:-78.6569, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5489120483398438 sec\n",
      "Episode 9447, len12, loss:-102.2805, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5475592613220215 sec\n",
      "Episode 9448, len10, loss:-79.7157, fail, steps:80, opt steps:38, total reward:-24.0000, 0.5501039028167725 sec\n",
      "Episode 9449, len6, loss:-73.3741, fail, steps:80, opt steps:13, total reward:-24.0000, 0.54905104637146 sec\n",
      "Episode 9450, len8, loss:-74.0933, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5498313903808594 sec\n",
      "Episode 9451, len8, loss:-81.1603, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5479638576507568 sec\n",
      "Episode 9452, len12, loss:-96.7540, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5485243797302246 sec\n",
      "Episode 9453, len12, loss:-97.3482, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5509049892425537 sec\n",
      "Episode 9454, len10, loss:-76.5789, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5999469757080078 sec\n",
      "Episode 9455, len8, loss:-83.6882, fail, steps:80, opt steps:22, total reward:-24.0000, 0.549663782119751 sec\n",
      "Episode 9456, len8, loss:-79.4105, fail, steps:80, opt steps:9, total reward:-24.0000, 0.5484194755554199 sec\n",
      "Episode 9457, len10, loss:-85.7021, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5490865707397461 sec\n",
      "Episode 9458, len6, loss:-83.2783, fail, steps:80, opt steps:19, total reward:-24.7000, 0.5452063083648682 sec\n",
      "Episode 9459, len8, loss:-79.9542, fail, steps:80, opt steps:33, total reward:-24.0000, 0.549126148223877 sec\n",
      "Episode 9460, len12, loss:-95.4792, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5486733913421631 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9461, len6, loss:-62.6229, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5490968227386475 sec\n",
      "Episode 9462, len6, loss:-66.4396, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5479621887207031 sec\n",
      "Episode 9463, len8, loss:-79.9018, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5488436222076416 sec\n",
      "Episode 9464, len12, loss:-98.5797, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5498039722442627 sec\n",
      "Episode 9465, len8, loss:-80.8389, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5476560592651367 sec\n",
      "Episode 9466, len12, loss:-96.0468, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5495026111602783 sec\n",
      "Episode 9467, len6, loss:-72.2680, fail, steps:80, opt steps:8, total reward:-24.0000, 0.6084494590759277 sec\n",
      "Episode 9468, len6, loss:-66.2114, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5488338470458984 sec\n",
      "Episode 9469, len8, loss:-77.7566, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5498971939086914 sec\n",
      "Episode 9470, len8, loss:-78.3676, fail, steps:80, opt steps:27, total reward:-24.0000, 0.5476875305175781 sec\n",
      "Episode 9471, len8, loss:-81.6584, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5484673976898193 sec\n",
      "Episode 9472, len8, loss:-79.8391, fail, steps:80, opt steps:29, total reward:-24.0000, 0.549767255783081 sec\n",
      "Episode 9473, len6, loss:-69.7402, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5492279529571533 sec\n",
      "Episode 9474, len12, loss:-101.9528, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5485599040985107 sec\n",
      "Episode 9475, len8, loss:-74.9350, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5491223335266113 sec\n",
      "Episode 9476, len12, loss:-96.5608, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5492379665374756 sec\n",
      "Episode 9477, len6, loss:-64.0950, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5477349758148193 sec\n",
      "Episode 9478, len6, loss:-62.5478, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5495820045471191 sec\n",
      "Episode 9479, len6, loss:-65.9687, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5605502128601074 sec\n",
      "Episode 9480, len10, loss:-79.2334, fail, steps:80, opt steps:55, total reward:-24.0000, 0.5490930080413818 sec\n",
      "Episode 9481, len8, loss:-82.6198, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5995364189147949 sec\n",
      "Episode 9482, len12, loss:-97.4747, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5491256713867188 sec\n",
      "Episode 9483, len6, loss:-68.0192, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5472204685211182 sec\n",
      "Episode 9484, len6, loss:-69.7278, fail, steps:80, opt steps:3, total reward:-24.0000, 0.6034433841705322 sec\n",
      "Episode 9485, len8, loss:-84.6548, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5495576858520508 sec\n",
      "Episode 9486, len8, loss:-79.2618, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5497639179229736 sec\n",
      "Episode 9487, len8, loss:-82.8685, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5508840084075928 sec\n",
      "Episode 9488, len10, loss:-83.3448, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5505640506744385 sec\n",
      "Episode 9489, len12, loss:-94.8092, fail, steps:80, opt steps:71, total reward:-24.0000, 0.5484030246734619 sec\n",
      "Episode 9490, len12, loss:-98.8602, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5509912967681885 sec\n",
      "Episode 9491, len10, loss:-78.0247, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5492086410522461 sec\n",
      "Episode 9492, len10, loss:-78.1544, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5488393306732178 sec\n",
      "Episode 9493, len10, loss:-83.6443, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5493118762969971 sec\n",
      "Episode 9494, len6, loss:-62.3123, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5500986576080322 sec\n",
      "Episode 9495, len10, loss:-86.3234, fail, steps:80, opt steps:29, total reward:-24.0000, 0.6021008491516113 sec\n",
      "Episode 9496, len6, loss:-72.6820, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5490741729736328 sec\n",
      "Episode 9497, len12, loss:-101.8246, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5494368076324463 sec\n",
      "Episode 9498, len12, loss:-96.9908, fail, steps:80, opt steps:57, total reward:-24.0000, 0.5505282878875732 sec\n",
      "Episode 9499, len12, loss:-100.2214, fail, steps:80, opt steps:58, total reward:-24.0000, 0.549720048904419 sec\n",
      "Episode 9500, len10, loss:-85.0572, fail, steps:80, opt steps:26, total reward:-24.0000, 0.54982590675354 sec\n",
      "Episode 9501, len10, loss:-80.7320, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5498902797698975 sec\n",
      "Episode 9502, len10, loss:-79.1576, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5495355129241943 sec\n",
      "Episode 9503, len12, loss:-97.4294, fail, steps:80, opt steps:59, total reward:-24.0000, 0.5497093200683594 sec\n",
      "Episode 9504, len10, loss:-86.2031, fail, steps:80, opt steps:29, total reward:-24.0000, 0.549828052520752 sec\n",
      "Episode 9505, len8, loss:-75.5068, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5477795600891113 sec\n",
      "Episode 9506, len12, loss:-105.3388, fail, steps:80, opt steps:65, total reward:-24.7000, 0.5445129871368408 sec\n",
      "Episode 9507, len6, loss:-64.1619, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5477919578552246 sec\n",
      "Episode 9508, len8, loss:-77.0929, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5493283271789551 sec\n",
      "Episode 9509, len8, loss:-75.6219, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5998439788818359 sec\n",
      "Episode 9510, len8, loss:-80.2069, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5490286350250244 sec\n",
      "Episode 9511, len6, loss:-64.8481, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5493934154510498 sec\n",
      "Episode 9512, len12, loss:-90.7043, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5475258827209473 sec\n",
      "Episode 9513, len8, loss:-78.5403, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5485050678253174 sec\n",
      "Episode 9514, len12, loss:-103.7847, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5485541820526123 sec\n",
      "Episode 9515, len6, loss:-61.8074, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5478112697601318 sec\n",
      "Episode 9516, len10, loss:-79.4893, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5494935512542725 sec\n",
      "Episode 9517, len10, loss:-82.1580, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5486595630645752 sec\n",
      "Episode 9518, len12, loss:-94.3811, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5485744476318359 sec\n",
      "Episode 9519, len8, loss:-77.6765, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5501365661621094 sec\n",
      "Episode 9520, len6, loss:-66.9149, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5502839088439941 sec\n",
      "Episode 9521, len12, loss:-94.0826, fail, steps:80, opt steps:48, total reward:-24.0000, 0.5485002994537354 sec\n",
      "Episode 9522, len6, loss:-73.8651, fail, steps:80, opt steps:10, total reward:-24.0000, 0.549114465713501 sec\n",
      "Episode 9523, len12, loss:-96.5864, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5987453460693359 sec\n",
      "Episode 9524, len12, loss:-91.8199, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5489859580993652 sec\n",
      "Episode 9525, len8, loss:-81.4696, fail, steps:80, opt steps:6, total reward:-24.0000, 0.549332857131958 sec\n",
      "Episode 9526, len12, loss:-102.8136, fail, steps:80, opt steps:42, total reward:-24.0000, 0.5488016605377197 sec\n",
      "Episode 9527, len10, loss:-81.8275, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5495269298553467 sec\n",
      "Episode 9528, len12, loss:-89.6408, fail, steps:80, opt steps:48, total reward:-24.0000, 0.552739143371582 sec\n",
      "Episode 9529, len8, loss:-84.6158, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5487155914306641 sec\n",
      "Episode 9530, len10, loss:-82.7699, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5502874851226807 sec\n",
      "Episode 9531, len8, loss:-79.8891, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5501294136047363 sec\n",
      "Episode 9532, len6, loss:-71.8602, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5489368438720703 sec\n",
      "Episode 9533, len8, loss:-86.5180, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5493481159210205 sec\n",
      "Episode 9534, len6, loss:-66.8574, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5476589202880859 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9535, len6, loss:-69.5729, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5482919216156006 sec\n",
      "Episode 9536, len8, loss:-80.8893, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5476925373077393 sec\n",
      "Episode 9537, len8, loss:-84.0956, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5483133792877197 sec\n",
      "Episode 9538, len12, loss:-98.3269, fail, steps:80, opt steps:27, total reward:-24.0000, 0.6020145416259766 sec\n",
      "Episode 9539, len12, loss:-98.3498, fail, steps:80, opt steps:45, total reward:-24.0000, 0.549663782119751 sec\n",
      "Episode 9540, len12, loss:-89.6790, fail, steps:80, opt steps:39, total reward:-24.0000, 0.549778938293457 sec\n",
      "Episode 9541, len8, loss:-80.8639, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5498337745666504 sec\n",
      "Episode 9542, len6, loss:-68.5859, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5484983921051025 sec\n",
      "Episode 9543, len10, loss:-79.8361, fail, steps:80, opt steps:40, total reward:-24.0000, 0.5484788417816162 sec\n",
      "Episode 9544, len12, loss:-97.1977, fail, steps:80, opt steps:73, total reward:-24.0000, 0.5498120784759521 sec\n",
      "Episode 9545, len8, loss:-81.8592, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5493700504302979 sec\n",
      "Episode 9546, len10, loss:-79.2325, fail, steps:80, opt steps:45, total reward:-24.0000, 0.54892897605896 sec\n",
      "Episode 9547, len6, loss:-67.2169, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5481328964233398 sec\n",
      "Episode 9548, len8, loss:-83.3237, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5492770671844482 sec\n",
      "Episode 9549, len12, loss:-100.7235, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5490343570709229 sec\n",
      "Episode 9550, len10, loss:-74.1165, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5489623546600342 sec\n",
      "Episode 9551, len8, loss:-84.1128, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5481081008911133 sec\n",
      "Episode 9552, len12, loss:-88.6126, fail, steps:80, opt steps:73, total reward:-24.0000, 0.5494189262390137 sec\n",
      "Episode 9553, len12, loss:-96.0885, fail, steps:80, opt steps:65, total reward:-24.0000, 0.548811674118042 sec\n",
      "Episode 9554, len10, loss:-73.8979, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5980961322784424 sec\n",
      "Episode 9555, len12, loss:-95.5159, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5492475032806396 sec\n",
      "Episode 9556, len6, loss:-62.6337, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5485742092132568 sec\n",
      "Episode 9557, len8, loss:-78.2789, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5497720241546631 sec\n",
      "Episode 9558, len6, loss:-66.4279, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5496988296508789 sec\n",
      "Episode 9559, len6, loss:-65.4239, fail, steps:80, opt steps:8, total reward:-24.0000, 0.54775071144104 sec\n",
      "Episode 9560, len6, loss:-72.6871, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5489954948425293 sec\n",
      "Episode 9561, len12, loss:-86.6165, fail, steps:80, opt steps:27, total reward:-24.0000, 0.548583984375 sec\n",
      "Episode 9562, len6, loss:-66.2690, fail, steps:80, opt steps:21, total reward:-24.0000, 0.548757791519165 sec\n",
      "Episode 9563, len8, loss:-79.4060, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5489315986633301 sec\n",
      "Episode 9564, len8, loss:-82.5053, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5477480888366699 sec\n",
      "Episode 9565, len10, loss:-88.8923, fail, steps:80, opt steps:38, total reward:-24.7000, 0.5438799858093262 sec\n",
      "Episode 9566, len6, loss:-72.9134, fail, steps:80, opt steps:5, total reward:-24.7000, 0.5444891452789307 sec\n",
      "Episode 9567, len10, loss:-76.8006, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5484275817871094 sec\n",
      "Episode 9568, len12, loss:-93.9110, fail, steps:80, opt steps:61, total reward:-24.0000, 0.5482940673828125 sec\n",
      "Episode 9569, len10, loss:-78.9608, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5478765964508057 sec\n",
      "Episode 9570, len8, loss:-82.5638, fail, steps:80, opt steps:28, total reward:-24.0000, 0.604651689529419 sec\n",
      "Episode 9571, len6, loss:-71.9328, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5501172542572021 sec\n",
      "Episode 9572, len12, loss:-87.2703, fail, steps:80, opt steps:36, total reward:-24.0000, 0.5492315292358398 sec\n",
      "Episode 9573, len6, loss:-67.6892, fail, steps:80, opt steps:8, total reward:-24.0000, 0.5483095645904541 sec\n",
      "Episode 9574, len12, loss:-87.5687, fail, steps:80, opt steps:53, total reward:-24.0000, 0.5506207942962646 sec\n",
      "Episode 9575, len8, loss:-77.4386, fail, steps:80, opt steps:19, total reward:-24.0000, 0.548715353012085 sec\n",
      "Episode 9576, len8, loss:-88.2971, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5500335693359375 sec\n",
      "Episode 9577, len6, loss:-74.6811, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5497152805328369 sec\n",
      "Episode 9578, len8, loss:-80.8592, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5495870113372803 sec\n",
      "Episode 9579, len6, loss:-63.2936, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5480785369873047 sec\n",
      "Episode 9580, len10, loss:-79.4449, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5485048294067383 sec\n",
      "Episode 9581, len12, loss:-87.7672, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5503032207489014 sec\n",
      "Episode 9582, len6, loss:-68.0672, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5496633052825928 sec\n",
      "Episode 9583, len8, loss:-87.2468, fail, steps:80, opt steps:27, total reward:-24.0000, 0.603905200958252 sec\n",
      "Episode 9584, len10, loss:-69.4340, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5493474006652832 sec\n",
      "Episode 9585, len8, loss:-81.6353, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5483367443084717 sec\n",
      "Episode 9586, len6, loss:-68.0057, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5497856140136719 sec\n",
      "Episode 9587, len10, loss:-61.6647, fail, steps:80, opt steps:37, total reward:-24.0000, 0.550656795501709 sec\n",
      "Episode 9588, len8, loss:-81.7301, fail, steps:80, opt steps:20, total reward:-24.0000, 0.549588680267334 sec\n",
      "Episode 9589, len10, loss:-62.1479, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5490598678588867 sec\n",
      "Episode 9590, len6, loss:-63.7844, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5498466491699219 sec\n",
      "Episode 9591, len12, loss:-94.9171, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5484023094177246 sec\n",
      "Episode 9592, len10, loss:-68.8539, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5493583679199219 sec\n",
      "Episode 9593, len8, loss:-80.4292, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5491650104522705 sec\n",
      "Episode 9594, len12, loss:-95.2122, fail, steps:80, opt steps:23, total reward:-24.0000, 0.548875093460083 sec\n",
      "Episode 9595, len12, loss:-87.2035, fail, steps:80, opt steps:58, total reward:-24.0000, 0.5502731800079346 sec\n",
      "Episode 9596, len12, loss:-82.9356, fail, steps:80, opt steps:38, total reward:-24.0000, 0.54927659034729 sec\n",
      "Episode 9597, len6, loss:-56.5511, fail, steps:80, opt steps:12, total reward:-22.7000, 0.5978631973266602 sec\n",
      "Episode 9598, len10, loss:-59.5656, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5487017631530762 sec\n",
      "Episode 9599, len8, loss:-81.9495, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5495116710662842 sec\n",
      "Episode 9600, len12, loss:-89.8685, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5488741397857666 sec\n",
      "Episode 9601, len8, loss:-83.2909, fail, steps:80, opt steps:11, total reward:-24.0000, 0.5485010147094727 sec\n",
      "Episode 9602, len6, loss:-66.7728, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5484201908111572 sec\n",
      "Episode 9603, len10, loss:-64.9060, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5491507053375244 sec\n",
      "Episode 9604, len6, loss:-66.1656, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5502002239227295 sec\n",
      "Episode 9605, len12, loss:-85.9564, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5482478141784668 sec\n",
      "Episode 9606, len8, loss:-82.1083, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5495462417602539 sec\n",
      "Episode 9607, len6, loss:-67.7386, fail, steps:80, opt steps:10, total reward:-24.0000, 0.548574686050415 sec\n",
      "Episode 9608, len6, loss:-75.3549, fail, steps:80, opt steps:5, total reward:-24.0000, 0.548882246017456 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9609, len8, loss:-87.3165, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5485682487487793 sec\n",
      "Episode 9610, len10, loss:-68.0228, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5494711399078369 sec\n",
      "Episode 9611, len6, loss:-78.3972, fail, steps:80, opt steps:6, total reward:-24.0000, 0.6005358695983887 sec\n",
      "Episode 9612, len8, loss:-81.7795, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5489494800567627 sec\n",
      "Episode 9613, len12, loss:-87.2926, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5496606826782227 sec\n",
      "Episode 9614, len10, loss:-67.9152, fail, steps:80, opt steps:50, total reward:-24.0000, 0.5494701862335205 sec\n",
      "Episode 9615, len12, loss:-82.5935, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5496838092803955 sec\n",
      "Episode 9616, len8, loss:-83.9777, fail, steps:80, opt steps:21, total reward:-24.0000, 0.54953932762146 sec\n",
      "Episode 9617, len12, loss:-80.9382, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5478622913360596 sec\n",
      "Episode 9618, len12, loss:-95.2568, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5487532615661621 sec\n",
      "Episode 9619, len12, loss:-85.0062, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5504300594329834 sec\n",
      "Episode 9620, len12, loss:-83.5677, fail, steps:80, opt steps:66, total reward:-24.0000, 0.5491223335266113 sec\n",
      "Episode 9621, len6, loss:-75.6816, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5497512817382812 sec\n",
      "Episode 9622, len8, loss:-79.1722, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5491325855255127 sec\n",
      "Episode 9623, len6, loss:-68.9158, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5490536689758301 sec\n",
      "Episode 9624, len10, loss:-69.3256, fail, steps:80, opt steps:33, total reward:-24.0000, 0.5490684509277344 sec\n",
      "Episode 9625, len8, loss:-80.6141, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5989062786102295 sec\n",
      "Episode 9626, len6, loss:-77.8670, fail, steps:80, opt steps:13, total reward:-24.0000, 0.5476295948028564 sec\n",
      "Episode 9627, len6, loss:-68.7333, fail, steps:80, opt steps:5, total reward:-24.0000, 0.5480754375457764 sec\n",
      "Episode 9628, len12, loss:-93.7750, fail, steps:80, opt steps:41, total reward:-24.0000, 0.5490527153015137 sec\n",
      "Episode 9629, len6, loss:-69.5204, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5489552021026611 sec\n",
      "Episode 9630, len10, loss:-69.4852, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5483353137969971 sec\n",
      "Episode 9631, len10, loss:-62.1898, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5502879619598389 sec\n",
      "Episode 9632, len12, loss:-72.0233, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5496649742126465 sec\n",
      "Episode 9633, len6, loss:-72.4956, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5491611957550049 sec\n",
      "Episode 9634, len10, loss:-62.0134, fail, steps:80, opt steps:35, total reward:-24.0000, 0.5493581295013428 sec\n",
      "Episode 9635, len10, loss:-60.1705, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5485339164733887 sec\n",
      "Episode 9636, len12, loss:-83.5509, fail, steps:80, opt steps:34, total reward:-24.0000, 0.5498738288879395 sec\n",
      "Episode 9637, len10, loss:-65.5670, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5498943328857422 sec\n",
      "Episode 9638, len6, loss:-73.7071, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5486476421356201 sec\n",
      "Episode 9639, len8, loss:-80.1216, fail, steps:80, opt steps:25, total reward:-24.0000, 0.599921464920044 sec\n",
      "Episode 9640, len6, loss:-73.1553, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5495767593383789 sec\n",
      "Episode 9641, len8, loss:-78.8374, fail, steps:80, opt steps:30, total reward:-24.0000, 0.5485985279083252 sec\n",
      "Episode 9642, len8, loss:-86.4103, fail, steps:80, opt steps:17, total reward:-24.0000, 0.54917311668396 sec\n",
      "Episode 9643, len12, loss:-74.9693, fail, steps:80, opt steps:45, total reward:-24.0000, 0.5482399463653564 sec\n",
      "Episode 9644, len6, loss:-71.0822, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5499248504638672 sec\n",
      "Episode 9645, len10, loss:-61.3712, fail, steps:80, opt steps:37, total reward:-24.0000, 0.5488665103912354 sec\n",
      "Episode 9646, len12, loss:-77.8023, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5492794513702393 sec\n",
      "Episode 9647, len12, loss:-81.9928, fail, steps:80, opt steps:49, total reward:-24.0000, 0.5500180721282959 sec\n",
      "Episode 9648, len8, loss:-85.1350, fail, steps:80, opt steps:22, total reward:-24.0000, 0.5511784553527832 sec\n",
      "Episode 9649, len6, loss:-82.2509, fail, steps:80, opt steps:7, total reward:-24.7000, 0.5453982353210449 sec\n",
      "Episode 9650, len10, loss:-62.8706, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5480766296386719 sec\n",
      "Episode 9651, len10, loss:-62.4576, fail, steps:80, opt steps:36, total reward:-24.0000, 0.548231840133667 sec\n",
      "Episode 9652, len10, loss:-63.7643, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5492763519287109 sec\n",
      "Episode 9653, len6, loss:-77.1908, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5484907627105713 sec\n",
      "Episode 9654, len8, loss:-71.6946, fail, steps:80, opt steps:21, total reward:-24.0000, 0.6004805564880371 sec\n",
      "Episode 9655, len12, loss:-80.8720, fail, steps:80, opt steps:64, total reward:-24.0000, 0.5497622489929199 sec\n",
      "Episode 9656, len12, loss:-70.9914, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5490531921386719 sec\n",
      "Episode 9657, len10, loss:-55.6815, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5489969253540039 sec\n",
      "Episode 9658, len10, loss:-50.5655, fail, steps:80, opt steps:25, total reward:-24.0000, 0.5488662719726562 sec\n",
      "Episode 9659, len6, loss:-74.4716, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5483675003051758 sec\n",
      "Episode 9660, len6, loss:-70.7503, fail, steps:80, opt steps:5, total reward:-24.0000, 0.549072265625 sec\n",
      "Episode 9661, len6, loss:-65.5429, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5483288764953613 sec\n",
      "Episode 9662, len12, loss:-76.4744, fail, steps:80, opt steps:54, total reward:-24.0000, 0.5477697849273682 sec\n",
      "Episode 9663, len12, loss:-74.2146, fail, steps:80, opt steps:32, total reward:-24.0000, 0.547874927520752 sec\n",
      "Episode 9664, len6, loss:-70.1859, fail, steps:80, opt steps:3, total reward:-24.0000, 0.5476648807525635 sec\n",
      "Episode 9665, len12, loss:-69.3881, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5498800277709961 sec\n",
      "Episode 9666, len6, loss:-70.9916, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5479669570922852 sec\n",
      "Episode 9667, len8, loss:-78.6986, fail, steps:80, opt steps:7, total reward:-24.0000, 0.5478372573852539 sec\n",
      "Episode 9668, len10, loss:-48.9129, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5480606555938721 sec\n",
      "Episode 9669, len10, loss:-63.2745, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5495669841766357 sec\n",
      "Episode 9670, len12, loss:-73.8740, fail, steps:80, opt steps:47, total reward:-24.0000, 0.5974726676940918 sec\n",
      "Episode 9671, len10, loss:-42.0978, fail, steps:80, opt steps:31, total reward:-24.0000, 0.5499589443206787 sec\n",
      "Episode 9672, len8, loss:-74.8725, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5485649108886719 sec\n",
      "Episode 9673, len8, loss:-77.6599, fail, steps:80, opt steps:19, total reward:-24.0000, 0.548790454864502 sec\n",
      "Episode 9674, len10, loss:-43.8173, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5501158237457275 sec\n",
      "Episode 9675, len12, loss:-77.9372, fail, steps:80, opt steps:65, total reward:-24.0000, 0.5500156879425049 sec\n",
      "Episode 9676, len8, loss:-70.6876, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5493087768554688 sec\n",
      "Episode 9677, len8, loss:-77.7345, fail, steps:80, opt steps:24, total reward:-24.0000, 0.5485720634460449 sec\n",
      "Episode 9678, len12, loss:-68.8081, fail, steps:80, opt steps:23, total reward:-24.0000, 0.5488579273223877 sec\n",
      "Episode 9679, len12, loss:-79.3321, fail, steps:80, opt steps:32, total reward:-24.0000, 0.5498654842376709 sec\n",
      "Episode 9680, len10, loss:-42.2500, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5486886501312256 sec\n",
      "Episode 9681, len6, loss:-73.8572, fail, steps:80, opt steps:17, total reward:-24.0000, 0.5483710765838623 sec\n",
      "Episode 9682, len12, loss:-75.9994, fail, steps:80, opt steps:39, total reward:-24.0000, 0.549309492111206 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9683, len8, loss:-80.7658, fail, steps:80, opt steps:16, total reward:-24.0000, 0.5487136840820312 sec\n",
      "Episode 9684, len10, loss:-42.1427, fail, steps:80, opt steps:26, total reward:-24.7000, 0.542837381362915 sec\n",
      "Episode 9685, len12, loss:-74.9879, fail, steps:80, opt steps:46, total reward:-24.0000, 0.5474638938903809 sec\n",
      "Episode 9686, len12, loss:-74.0822, fail, steps:80, opt steps:49, total reward:-24.0000, 0.6040084362030029 sec\n",
      "Episode 9687, len10, loss:-52.2078, fail, steps:80, opt steps:43, total reward:-24.0000, 0.5476045608520508 sec\n",
      "Episode 9688, len10, loss:-45.6956, fail, steps:80, opt steps:25, total reward:-24.0000, 0.548677921295166 sec\n",
      "Episode 9689, len12, loss:-77.2155, fail, steps:80, opt steps:66, total reward:-24.0000, 0.548525333404541 sec\n",
      "Episode 9690, len8, loss:-79.7834, fail, steps:80, opt steps:26, total reward:-24.0000, 0.5481340885162354 sec\n",
      "Episode 9691, len12, loss:-66.8403, fail, steps:80, opt steps:29, total reward:-24.0000, 0.5478990077972412 sec\n",
      "Episode 9692, len12, loss:-71.9803, fail, steps:80, opt steps:51, total reward:-24.0000, 0.5482323169708252 sec\n",
      "Episode 9693, len6, loss:-69.7912, fail, steps:80, opt steps:6, total reward:-24.0000, 0.5473036766052246 sec\n",
      "Episode 9694, len12, loss:-85.4821, fail, steps:80, opt steps:52, total reward:-24.0000, 0.5611617565155029 sec\n",
      "Episode 9695, len6, loss:-71.2687, fail, steps:80, opt steps:15, total reward:-24.0000, 0.547522783279419 sec\n",
      "Episode 9696, len8, loss:-79.4253, fail, steps:80, opt steps:21, total reward:-24.0000, 0.5483157634735107 sec\n",
      "Episode 9697, len6, loss:-75.6297, fail, steps:80, opt steps:12, total reward:-24.0000, 0.5485880374908447 sec\n",
      "Episode 9698, len6, loss:-77.8004, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5476727485656738 sec\n",
      "Episode 9699, len12, loss:-77.7064, fail, steps:80, opt steps:44, total reward:-24.0000, 0.607154130935669 sec\n",
      "Episode 9700, len8, loss:-76.8077, fail, steps:80, opt steps:18, total reward:-24.0000, 0.5481822490692139 sec\n",
      "Episode 9701, len12, loss:-79.4663, fail, steps:80, opt steps:60, total reward:-24.0000, 0.5506656169891357 sec\n",
      "Episode 9702, len6, loss:-73.1121, fail, steps:80, opt steps:10, total reward:-24.0000, 0.5469663143157959 sec\n",
      "Episode 9703, len6, loss:-70.9730, fail, steps:80, opt steps:15, total reward:-24.0000, 0.5478904247283936 sec\n",
      "Episode 9704, len10, loss:-55.1059, fail, steps:80, opt steps:39, total reward:-24.0000, 0.5485105514526367 sec\n",
      "Episode 9705, len10, loss:-54.7809, fail, steps:80, opt steps:28, total reward:-24.0000, 0.547816276550293 sec\n",
      "Episode 9706, len10, loss:-62.1464, fail, steps:80, opt steps:28, total reward:-24.0000, 0.5467424392700195 sec\n",
      "Episode 9707, len12, loss:-86.5350, fail, steps:80, opt steps:44, total reward:-24.0000, 0.5482985973358154 sec\n",
      "Episode 9708, len6, loss:-74.3155, fail, steps:80, opt steps:20, total reward:-24.0000, 0.5479578971862793 sec\n",
      "Episode 9709, len8, loss:-82.4048, fail, steps:80, opt steps:14, total reward:-24.0000, 0.5479145050048828 sec\n",
      "Episode 9710, len6, loss:-74.5507, fail, steps:80, opt steps:19, total reward:-24.0000, 0.5463049411773682 sec\n"
     ]
    }
   ],
   "source": [
    "def compute_bellman_returns(raw_rewards, gamma):\n",
    "    bellman_returns = []\n",
    "    R = 0\n",
    "    for r in raw_rewards[::-1]:\n",
    "        R = r + gamma * R\n",
    "        bellman_returns.insert(0, R)\n",
    "    return bellman_returns\n",
    "\n",
    "# Training Loop\n",
    "def train(verbose=False):\n",
    "    # Removed torch.autograd.set_detect_anomaly(True)\n",
    "    vocab_size = len(vocab)\n",
    "    model = TransformerModel(vocab_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)  # Reduced learning rate\n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=LR_SCHEDULER_GAMMA)\n",
    "    \n",
    "    # Optionally, load a checkpoint\n",
    "    #checkpoint_path = os.path.join(OUTPUT_DIR, \"ckpt_199000_1.0000_13.37.pth\")\n",
    "    #load_checkpoint(checkpoint_path, model, optimizer)\n",
    "\n",
    "    episode_cnt = 0\n",
    "    total_reward = 0.0\n",
    "    num_successes = 0\n",
    "    success_step_cnts = []\n",
    "    optimal_step_cnts = []\n",
    "    \n",
    "    for episode in range(NUM_EPISODES):\n",
    "        t1 = time.time()\n",
    "        model.train()  # Set model to training mode\n",
    "        env = SortingEnv()\n",
    "        initial_token_id, current_list = env.reset()\n",
    "        input_tokens = [initial_token_id]\n",
    "        log_probs = []\n",
    "        rewards = []\n",
    "        comparisons = []\n",
    "        steps = 0\n",
    "        \n",
    "        state = 'expect_action'\n",
    "        done = False\n",
    "        success = False\n",
    "\n",
    "        while not done: #and len(input_tokens) < env.max_steps:\n",
    "            if verbose:\n",
    "                print(decode(input_tokens, inv_vocab))\n",
    "                print(env.get_list())\n",
    "                print(comparisons)\n",
    "            # Prepare input tensor\n",
    "            input_seq = torch.tensor(input_tokens, dtype=torch.long, device=device).unsqueeze(1)  # (seq_len, batch_size)\n",
    "            # Get model output\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n",
    "                output = model(input_seq)  # (seq_len, batch_size, vocab_size)\n",
    "                # Get logits for the last token\n",
    "                logits = output[-1, 0, :]  # (vocab_size)\n",
    "\n",
    "                # Check for NaNs in logits\n",
    "                if torch.isnan(logits).any():\n",
    "                    print(f\"Episode {episode}, NaNs in logits before masking.\")\n",
    "                    break\n",
    "\n",
    "                # Get valid tokens based on state\n",
    "                def get_valid_tokens(state):\n",
    "                    action_tokens = [vocab['Comparison'], vocab['Swap']]\n",
    "                    index_tokens = [vocab[str(i)] for i in range(env.length)]\n",
    "                    if state == 'expect_action':\n",
    "                        return action_tokens\n",
    "                    elif state == 'expect_index1':\n",
    "                        return index_tokens[:-1]\n",
    "                    elif state == 'expect_index2':\n",
    "                        return [x for x in index_tokens if x > input_tokens[-1]]\n",
    "                    else:\n",
    "                        # Handle unexpected states by defaulting to expect_action\n",
    "                        return action_tokens\n",
    "\n",
    "                valid_token_ids = get_valid_tokens(state)\n",
    "\n",
    "                # Ensure valid_token_ids are within the vocab range\n",
    "                if any(idx >= vocab_size or idx < 0 for idx in valid_token_ids):\n",
    "                    print(f\"Episode {episode}, invalid indices in valid_token_ids: {valid_token_ids}\")\n",
    "                    break\n",
    "\n",
    "                # Mask invalid tokens\n",
    "                mask_value = -1e9  # Use a large negative value instead of -inf\n",
    "                mask = torch.full_like(logits, mask_value).to(device)\n",
    "                mask[valid_token_ids] = 0\n",
    "                masked_logits = logits + mask\n",
    "\n",
    "                # Sample action. Have some chance to randomly pick a valid action.\n",
    "                eps_threshold = EPS_END + (EPS_START - EPS_END) * np.exp(-1.0 * episode / EPS_DECAY)\n",
    "                if random.random() < eps_threshold:\n",
    "                    masked_logits = masked_logits / 6\n",
    "\n",
    "                # Check for NaNs in masked_logits\n",
    "                if torch.isnan(masked_logits).any():\n",
    "                    print(f\"Episode {episode}, NaNs in masked_logits after masking.\")\n",
    "                    break\n",
    "\n",
    "                # Compute probabilities\n",
    "                probs = F.softmax(masked_logits, dim=0)\n",
    "\n",
    "                # Check for NaNs in probs\n",
    "                if torch.isnan(probs).any():\n",
    "                    print(f\"Episode {episode}, NaNs in probs after softmax.\")\n",
    "                    break\n",
    "\n",
    "                try:\n",
    "                    m = torch.distributions.Categorical(probs)\n",
    "                    action_token = m.sample()\n",
    "                    log_prob = m.log_prob(action_token)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Episode {episode}, error in sampling action: {e}\")\n",
    "                    break\n",
    "\n",
    "            log_probs.append(log_prob)\n",
    "            input_tokens.append(action_token.item())\n",
    "\n",
    "            action = action_token.item()\n",
    "            reward = 0.0\n",
    "            if state == 'expect_action':\n",
    "                if action == vocab['Comparison']:\n",
    "                    state = 'expect_index1'\n",
    "                elif action == vocab['Swap']:\n",
    "                    if env.indices is None:\n",
    "                        reward = INVALID_ACTION_REWARD\n",
    "                        rewards.append(reward)\n",
    "                        done = True\n",
    "                        continue\n",
    "                    action_tokens = [vocab['Swap']]\n",
    "                    response_token, reward, done, current_list = env.step(action_tokens)\n",
    "                    steps += 1\n",
    "                    if done and reward == SUCCESS_REWARD:\n",
    "                        success = True\n",
    "                        if episode % 50 == 0:\n",
    "                            print(\"Original:\", env.get_original_list())\n",
    "                            print(decode(input_tokens, inv_vocab))\n",
    "                    if verbose:\n",
    "                        print(\"Reward:\", reward)\n",
    "                    state = 'expect_action'\n",
    "                else:\n",
    "                    reward = INVALID_ACTION_REWARD\n",
    "                    done = True\n",
    "            elif state == 'expect_index1':\n",
    "                index1_token = action_token\n",
    "                state = 'expect_index2'\n",
    "            elif state == 'expect_index2':\n",
    "                index2_token = action_token\n",
    "                action_tokens = [vocab['Comparison'], index1_token.item(), index2_token.item()]\n",
    "                comparisons.append((int(inv_vocab[index1_token.item()]), \n",
    "                                    int(inv_vocab[index2_token.item()])))\n",
    "                response_token, reward, done, current_list = env.step(action_tokens)\n",
    "                steps += 1\n",
    "                if done and reward == SUCCESS_REWARD:\n",
    "                    success = True\n",
    "                else:\n",
    "                    reward += COMPARISON_ENTROPY_MULTIPLIER * compute_min_delta_entropy(comparisons)\n",
    "                if verbose:\n",
    "                    print(\"Reward:\", reward)\n",
    "                if response_token is not None:\n",
    "                    input_tokens.append(response_token)\n",
    "                state = 'expect_action'\n",
    "            else:\n",
    "                reward = INVALID_ACTION_REWARD\n",
    "                done = True\n",
    "\n",
    "            rewards.append(reward)\n",
    "        #\n",
    "        # Post processing of each episode\n",
    "        success_rewards = [0.0] * len(rewards)\n",
    "        if success: \n",
    "            num_successes += 1\n",
    "            success_rewards[-1] = SUCCESS_REWARD\n",
    "            success_step_cnts.append(steps)\n",
    "            optimal_step_cnts.append(env.get_optimal_steps())\n",
    "        #\n",
    "        assert len(log_probs) == len(rewards), \"log_probs and returns have different sizes!\"\n",
    "\n",
    "        if len(log_probs) == 0:\n",
    "            continue  # Skip if no actions were taken\n",
    "\n",
    "        # Compute returns and loss within autocast\n",
    "        with torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n",
    "            # Compute returns\n",
    "            returns1 = compute_bellman_returns(rewards, SHORTTERM_GAMMA)\n",
    "            returns2 = compute_bellman_returns(success_rewards, LONGTERM_GAMMA)\n",
    "            returns = torch.tensor(np.array(returns1) + np.array(returns2)).to(device)\n",
    "\n",
    "            # Check for NaNs in returns\n",
    "            if torch.isnan(returns).any():\n",
    "                print(f\"Episode {episode}, NaNs in returns.\")\n",
    "                continue\n",
    "\n",
    "            # Compute loss\n",
    "            loss = 0\n",
    "            for log_prob, R in zip(log_probs, returns):\n",
    "                loss -= log_prob * R\n",
    "\n",
    "            # Check for NaNs in loss\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"Episode {episode}, NaN in loss.\")\n",
    "                continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        episode_cnt += 1\n",
    "        total_reward += sum(rewards)\n",
    "        t2 = time.time()\n",
    "        if episode % 1 == 0:\n",
    "            print(f\"Episode {episode}, len{env.get_list_len()}, loss:{loss.item():.4f}, {'succeed' if success else 'fail'}, steps:{steps}, opt steps:{env.get_optimal_steps()}, total reward:{sum(rewards):.4f}, {t2-t1} sec\")\n",
    "            \n",
    "        # Save checkpoint\n",
    "        if episode > 0 and episode % EPISODES_SAVE == 0:\n",
    "            avg_reward = total_reward / episode_cnt\n",
    "            #assert len(success_step_cnts) == num_successes\n",
    "            success_rate = num_successes / episode_cnt\n",
    "            avg_steps = sum(success_step_cnts) / (len(success_step_cnts) + 0.001)\n",
    "            avg_optimal_steps = sum(optimal_step_cnts) / len(optimal_step_cnts)\n",
    "            episode_cnt = 0\n",
    "            total_reward = 0.0\n",
    "            num_successes = 0\n",
    "            total_steps = 0\n",
    "            save_checkpoint(model, optimizer, episode, OUTPUT_DIR, f\"ckpt_{episode}_{success_rate:.4f}_{avg_steps:.2f}_vs_{avg_optimal_steps:.2f}.pth\")\n",
    "            #\n",
    "            # Reduce the lr\n",
    "            scheduler.step()\n",
    "            # Optionally, log the learning rate\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            print(f\"Learning rate = {current_lr:.6f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train(verbose=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "axiom",
   "language": "python",
   "name": "axiom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
