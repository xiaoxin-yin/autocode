{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ba0d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import math\n",
    "import random\n",
    "\n",
    "NUM_POSITIONS = 16\n",
    "\n",
    "MIN_LIST_LEN = 4\n",
    "MAX_LIST_LEN = 4\n",
    "MAX_STEPS = 40\n",
    "\n",
    "SUCCESS_REWARD = 0.5\n",
    "STEP_REWARD = -0.3\n",
    "COMPARISON_ENTROPY_MULTIPLIER = -0.00\n",
    "SWAP_REWARD = 1.0\n",
    "INVALID_ACTION_REWARD = -10.0\n",
    "LONGTERM_GAMMA = 0.99\n",
    "SHORTTERM_GAMMA = 0.7\n",
    "\n",
    "EPS_START = 0.5\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "LR_SCHEDULER_GAMMA = 0.93\n",
    "NUM_EPISODES = 100000\n",
    "EPISODES_SAVE = 1000\n",
    "OUTPUT_DIR = '/home/mcwave/code/autocode/datasets/rl_sort_transformer_curriculum/list4_transformer4_192_gamma07_step40_v1'\n",
    "\n",
    "# Define the vocabulary\n",
    "vocab = {\n",
    "    'Comparison': 0,\n",
    "    'Swap': 1,\n",
    "    'less': 2,\n",
    "    'equal': 3,\n",
    "    'more': 4,\n",
    "    '0': 5,\n",
    "    '1': 6,\n",
    "    '2': 7,\n",
    "    '3': 8,\n",
    "    '4': 9,\n",
    "    '5': 10,\n",
    "    '6': 11,\n",
    "    '7': 12,\n",
    "    '8': 13,\n",
    "    '9': 14,\n",
    "    '10': 15,\n",
    "    '11': 16,\n",
    "    '12': 17,\n",
    "    '13': 18,\n",
    "    '14': 19,\n",
    "    '15': 20,\n",
    "    'len1': 21,\n",
    "    'len2': 22,\n",
    "    'len3': 23,\n",
    "    'len4': 24,\n",
    "    'len5': 25,\n",
    "    'len6': 26,\n",
    "    'len7': 27,\n",
    "    'len8': 28,\n",
    "    'len9': 29,\n",
    "    'len10': 30,\n",
    "    'len11': 31,\n",
    "    'len12': 32,\n",
    "    'len13': 33,\n",
    "    'len14': 34,\n",
    "    'len15': 35,\n",
    "    'len16': 36,\n",
    "    'start0': 37,\n",
    "    'start1': 38,\n",
    "    'start2': 39,\n",
    "    'start3': 40,\n",
    "    'start4': 41,\n",
    "    'start5': 42,\n",
    "    'start6': 43,\n",
    "    'start7': 44,\n",
    "    'start8': 45,\n",
    "    'start9': 46,\n",
    "    'start10': 47,\n",
    "    'start11': 48,\n",
    "    'start12': 49,\n",
    "    'start13': 50,\n",
    "    'start14': 51,\n",
    "    'start15': 52,\n",
    "}\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "def compute_entropy(N, alpha=1):\n",
    "    K = 2**N\n",
    "    values = np.arange(K)\n",
    "    unnormalized_probs = np.exp(-alpha * values)\n",
    "    Z = unnormalized_probs.sum()\n",
    "    probs = unnormalized_probs / Z\n",
    "    return values, -np.log2(probs)\n",
    "\n",
    "_, int_entropy = compute_entropy(4)\n",
    "\n",
    "def get_entropy_of_integer(x):\n",
    "    x = min(15, abs(x))\n",
    "    return int_entropy[x]\n",
    "\n",
    "def compute_min_delta_entropy(comparisons):\n",
    "    # Initialize the result list to store minDelta values\n",
    "    min_delta = None\n",
    "\n",
    "    # Iterate through each pair in the comparisons list\n",
    "    i = len(comparisons) - 1\n",
    "    xi, yi = comparisons[i]\n",
    "    if i == 0:\n",
    "        # For i = 0, use the first case directly\n",
    "        min_delta = (xi, min(yi, yi - xi), 0)\n",
    "    else:\n",
    "        # For i > 0, compute all possible options and select the minimal one\n",
    "        options = []\n",
    "\n",
    "        # Simple Entropy\n",
    "        simple_entropy = (xi, min(yi, yi - xi), 0)\n",
    "        options.append(simple_entropy)\n",
    "\n",
    "        # First Delta Entropy\n",
    "        xi_prev, yi_prev = comparisons[i - 1]\n",
    "        first_delta_entropy = (xi - xi_prev, yi - yi_prev, 0)\n",
    "        options.append(first_delta_entropy)\n",
    "\n",
    "        # Second Delta Entropy (only valid for i > 1)\n",
    "        if i > 1:\n",
    "            xi_prev2, yi_prev2 = comparisons[i - 2]\n",
    "            second_delta_entropy = (\n",
    "                (xi - xi_prev) - (xi_prev - xi_prev2),\n",
    "                (yi - yi_prev) - (yi_prev - yi_prev2),\n",
    "                0,\n",
    "            )\n",
    "            options.append(second_delta_entropy)\n",
    "\n",
    "        # Arbitrary Position Entropy (only valid for i > 1)\n",
    "        for j in range(i):\n",
    "            xj, yj = comparisons[j]\n",
    "            arbitrary_position_entropy = (\n",
    "                xi - xj,\n",
    "                yi - yj,\n",
    "                min(j, i - j),\n",
    "            )\n",
    "            options.append(arbitrary_position_entropy)\n",
    "\n",
    "        # Find the option with the minimal sum\n",
    "        min_delta = min(options, key=lambda t: sum([get_entropy_of_integer(x) for x in t]))\n",
    "\n",
    "    entropy = sum([get_entropy_of_integer(x) for x in min_delta])\n",
    "    if len(comparisons) == 1:\n",
    "        return 3 * entropy\n",
    "    else:\n",
    "        return entropy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the environment\n",
    "class SortingEnv:\n",
    "    def __init__(self):\n",
    "        self.max_steps = MAX_STEPS\n",
    "\n",
    "    def reset(self):\n",
    "        self.length = random.randint(MIN_LIST_LEN, MAX_LIST_LEN)\n",
    "        self.list = [random.randint(1, 100) for _ in range(self.length)]\n",
    "        while self.list == sorted(self.list):\n",
    "            self.list = [random.randint(1, 100) for _ in range(self.length)]\n",
    "        self.indices = None\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        length_token = 'len{}'.format(self.length)\n",
    "        return vocab[length_token], self.list.copy()\n",
    "    \n",
    "    def get_list(self):\n",
    "        return self.list\n",
    "    \n",
    "    def get_length(self):\n",
    "        return self.length\n",
    "\n",
    "    def step(self, action_tokens):\n",
    "        action = action_tokens[0]\n",
    "        reward = -0.01  # default penalty\n",
    "        response_token = None\n",
    "\n",
    "        if action == vocab['Comparison']:\n",
    "            if len(action_tokens) != 3:\n",
    "                print(\"Error! Comparison without 2 indices!\")\n",
    "                reward = INVALID_ACTION_REWARD\n",
    "                self.done = True\n",
    "                return response_token, reward, self.done, self.list.copy()\n",
    "            index1 = action_tokens[1] - vocab['0']\n",
    "            index2 = action_tokens[2] - vocab['0']\n",
    "            if index1 < 0 or index1 >= self.length or index2 < 0 or index2 >= self.length:\n",
    "                print(f\"Error! Comparison with invalid indices {index1} {index2}\")\n",
    "                reward = INVALID_ACTION_REWARD\n",
    "                self.done = True\n",
    "                return response_token, reward, self.done, self.list.copy()\n",
    "            self.indices = (index1, index2)\n",
    "            if self.list[index1] < self.list[index2]:\n",
    "                response_token = vocab['less']\n",
    "                reward = STEP_REWARD\n",
    "            elif self.list[index1] == self.list[index2]:\n",
    "                response_token = vocab['equal']\n",
    "                reward = STEP_REWARD * 2\n",
    "            else:\n",
    "                response_token = vocab['more']\n",
    "                reward = STEP_REWARD\n",
    "        elif action == vocab['Swap']:\n",
    "            if self.indices is None:\n",
    "                reward = INVALID_ACTION_REWARD\n",
    "                self.done = True\n",
    "                return response_token, reward, self.done, self.list.copy()\n",
    "            index1, index2 = self.indices\n",
    "            prev_list = self.list.copy()\n",
    "            self.list[index1], self.list[index2] = self.list[index2], self.list[index1]\n",
    "            if self.list == sorted(self.list):\n",
    "                reward = SUCCESS_REWARD\n",
    "                self.done = True\n",
    "            #elif prev_list[index1] > prev_list[index2] and self.list[index1] <= self.list[index2]:\n",
    "            #    reward = 0.1\n",
    "            elif (index1 < index2 and prev_list[index1] > prev_list[index2] and self.list[index1] <= self.list[index2]) or \\\n",
    "                (index1 > index2 and prev_list[index1] < prev_list[index2] and self.list[index1] >= self.list[index2]):\n",
    "                reward = SWAP_REWARD\n",
    "            elif (index1 < index2 and prev_list[index1] < prev_list[index2] and self.list[index1] >= self.list[index2]) or \\\n",
    "                (index1 > index2 and prev_list[index1] > prev_list[index2] and self.list[index1] <= self.list[index2]):\n",
    "                reward = -SWAP_REWARD\n",
    "            else:\n",
    "                reward = STEP_REWARD\n",
    "            self.indices = None\n",
    "        else:\n",
    "            reward = INVALID_ACTION_REWARD\n",
    "            self.done = True\n",
    "\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= self.max_steps:\n",
    "            self.done = True\n",
    "        return response_token, reward, self.done, self.list.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d0cf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding for Transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # (max_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # Even indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # Odd indices\n",
    "        pe = pe.unsqueeze(1)  # (max_len, 1, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Transformer Model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=192, nhead=8, num_layers=4):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.decoder = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.embedding.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "def decode(input_tokens, inv_vocab):\n",
    "    return ' '.join([inv_vocab[x] for x in input_tokens])\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, episode, folder, filename):\n",
    "    \"\"\"\n",
    "    Save the model and optimizer state to the designated filepath.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to save.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer whose state to save.\n",
    "        episode (int): The current episode number.\n",
    "        filepath (str): The path where to save the checkpoint.\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    # Save the checkpoint\n",
    "    torch.save({\n",
    "        'episode': episode,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, filepath)\n",
    "    print(f\"Checkpoint saved at episode {episode} to {filepath}\")\n",
    "\n",
    "def load_checkpoint(filepath, model, optimizer):\n",
    "    \"\"\"\n",
    "    Load the model and optimizer state from the designated filepath.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path from where to load the checkpoint.\n",
    "        model (nn.Module): The model into which to load the state_dict.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer into which to load the state.\n",
    "\n",
    "    Returns:\n",
    "        int: The episode number to resume from.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(filepath):\n",
    "        checkpoint = torch.load(filepath, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        episode = checkpoint['episode']\n",
    "        print(f\"Checkpoint loaded from {filepath}, resuming from episode {episode}\")\n",
    "        return episode\n",
    "    else:\n",
    "        print(f\"No checkpoint found at {filepath}, starting from scratch.\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a13cca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from /home/mcwave/code/autocode/datasets/rl_sort_transformer_curriculum/list2_transformer4_192_gamma07_step10_v1/ckpt_10000_1.0000_4.00.pth, resuming from episode 10000\n",
      "Episode 0, loss:-9.2804, fail, steps:5, total reward:-11.3000, 0.38872671127319336 sec\n",
      "Episode 1, loss:-4.3093, fail, steps:5, total reward:-9.3000, 0.01579427719116211 sec\n",
      "Episode 2, loss:-9.4230, fail, steps:5, total reward:-11.3000, 0.013831377029418945 sec\n",
      "Episode 3, loss:-9.1705, fail, steps:5, total reward:-11.3000, 0.013719558715820312 sec\n",
      "Episode 4, loss:-2.7957, fail, steps:5, total reward:-9.3000, 0.013746976852416992 sec\n",
      "Episode 5, loss:-8.9026, fail, steps:5, total reward:-9.3000, 0.013704299926757812 sec\n",
      "Episode 6, loss:-4.4113, fail, steps:5, total reward:-11.3000, 0.013674020767211914 sec\n",
      "Episode 7, loss:-5.9139, fail, steps:5, total reward:-9.3000, 0.01370692253112793 sec\n",
      "Episode 8, loss:-9.5696, fail, steps:5, total reward:-9.3000, 0.01372671127319336 sec\n",
      "Episode 9, loss:-7.9788, fail, steps:5, total reward:-9.3000, 0.013653993606567383 sec\n",
      "Episode 10, loss:-9.3516, fail, steps:5, total reward:-9.3000, 0.013649940490722656 sec\n",
      "Episode 11, loss:-9.9664, fail, steps:5, total reward:-11.3000, 0.01367950439453125 sec\n",
      "Episode 12, loss:-1.6635, fail, steps:5, total reward:-11.3000, 0.013730049133300781 sec\n",
      "Episode 13, loss:-3.3704, fail, steps:5, total reward:-11.3000, 0.013729333877563477 sec\n",
      "Episode 14, loss:-1.5864, fail, steps:5, total reward:-10.9000, 0.013644218444824219 sec\n",
      "Episode 15, loss:-3.5591, fail, steps:8, total reward:-9.6000, 0.022718429565429688 sec\n",
      "Episode 16, loss:-20.2993, fail, steps:26, total reward:-14.1000, 0.07324743270874023 sec\n",
      "Episode 17, loss:-33.3932, fail, steps:29, total reward:-10.4000, 0.07562398910522461 sec\n",
      "Episode 18, loss:-0.0368, fail, steps:29, total reward:-1.7000, 0.07381057739257812 sec\n",
      "Episode 19, loss:1.2415, succeed, steps:4, total reward:0.2000, 0.013024091720581055 sec\n",
      "Episode 20, loss:0.6015, fail, steps:29, total reward:-1.7000, 0.0712432861328125 sec\n",
      "Episode 21, loss:-2.0646, fail, steps:29, total reward:-1.7000, 0.07246875762939453 sec\n",
      "Episode 22, loss:-0.7326, fail, steps:29, total reward:-1.7000, 0.07347702980041504 sec\n",
      "Episode 23, loss:-0.8317, fail, steps:30, total reward:0.3000, 0.07599449157714844 sec\n",
      "Episode 24, loss:-0.2040, fail, steps:29, total reward:-0.7000, 0.07332086563110352 sec\n",
      "Episode 25, loss:-1.5720, fail, steps:29, total reward:-1.7000, 0.0740196704864502 sec\n",
      "Episode 26, loss:-0.4463, fail, steps:30, total reward:0.3000, 0.07553291320800781 sec\n",
      "Episode 27, loss:-3.7934, fail, steps:29, total reward:-1.7000, 0.07340288162231445 sec\n",
      "Episode 28, loss:5.7829, succeed, steps:22, total reward:1.7000, 0.056893110275268555 sec\n",
      "Episode 29, loss:-1.7014, fail, steps:29, total reward:-0.7000, 0.07289338111877441 sec\n",
      "Episode 30, loss:1.9275, succeed, steps:13, total reward:-0.7000, 0.03430509567260742 sec\n",
      "Episode 31, loss:3.6115, succeed, steps:15, total reward:1.3000, 0.03857421875 sec\n",
      "Episode 32, loss:-4.0174, fail, steps:29, total reward:-1.7000, 0.07241225242614746 sec\n",
      "Episode 33, loss:-0.1057, fail, steps:30, total reward:0.3000, 0.07501435279846191 sec\n",
      "Episode 34, loss:-3.0373, fail, steps:29, total reward:-1.7000, 0.07329940795898438 sec\n",
      "Episode 35, loss:0.4685, succeed, steps:4, total reward:0.2000, 0.012809038162231445 sec\n",
      "Episode 36, loss:-3.0587, fail, steps:29, total reward:-1.7000, 0.07170820236206055 sec\n",
      "Episode 37, loss:3.3751, succeed, steps:20, total reward:-0.3000, 0.050985097885131836 sec\n",
      "Episode 38, loss:-2.1061, fail, steps:29, total reward:-0.7000, 0.07205319404602051 sec\n",
      "Episode 39, loss:-3.6923, fail, steps:29, total reward:-2.7000, 0.07297110557556152 sec\n",
      "Episode 40, loss:-2.5125, fail, steps:29, total reward:-0.7000, 0.07356071472167969 sec\n",
      "Episode 41, loss:3.2254, succeed, steps:8, total reward:0.9000, 0.022648334503173828 sec\n",
      "Episode 42, loss:-2.8994, fail, steps:29, total reward:-1.7000, 0.0713493824005127 sec\n",
      "Episode 43, loss:-3.0234, fail, steps:29, total reward:-2.3000, 0.07346653938293457 sec\n",
      "Episode 44, loss:-0.6331, fail, steps:29, total reward:-0.7000, 0.07701635360717773 sec\n",
      "Episode 45, loss:-2.6239, fail, steps:29, total reward:-1.7000, 0.07330703735351562 sec\n",
      "Episode 46, loss:-2.9327, fail, steps:29, total reward:-2.3000, 0.07361674308776855 sec\n",
      "Episode 47, loss:-3.6162, fail, steps:29, total reward:-2.7000, 0.07367205619812012 sec\n",
      "Episode 48, loss:-5.1524, fail, steps:29, total reward:-2.7000, 0.07374048233032227 sec\n",
      "Episode 49, loss:1.0755, succeed, steps:4, total reward:0.2000, 0.012781858444213867 sec\n",
      "Episode 50, loss:5.6983, succeed, steps:19, total reward:2.0000, 0.04723501205444336 sec\n",
      "Episode 51, loss:-2.6760, fail, steps:29, total reward:-1.0000, 0.0720672607421875 sec\n",
      "Episode 52, loss:-3.0506, fail, steps:29, total reward:-2.7000, 0.07279849052429199 sec\n",
      "Episode 53, loss:-3.3309, fail, steps:29, total reward:-2.7000, 0.07306957244873047 sec\n",
      "Episode 54, loss:-1.6090, fail, steps:30, total reward:0.3000, 0.0758826732635498 sec\n",
      "Episode 55, loss:5.1575, succeed, steps:29, total reward:2.1000, 0.07327604293823242 sec\n",
      "Episode 56, loss:3.0805, succeed, steps:17, total reward:0.0000, 0.044168710708618164 sec\n",
      "Episode 57, loss:-3.5666, fail, steps:29, total reward:-2.3000, 0.0725393295288086 sec\n",
      "Episode 58, loss:2.4162, succeed, steps:14, total reward:0.3000, 0.03732657432556152 sec\n",
      "Episode 59, loss:-0.9746, fail, steps:30, total reward:0.3000, 0.07446742057800293 sec\n",
      "Episode 60, loss:0.2187, fail, steps:29, total reward:-1.7000, 0.07268786430358887 sec\n",
      "Episode 61, loss:-3.1504, fail, steps:29, total reward:-1.7000, 0.07380151748657227 sec\n",
      "Episode 62, loss:1.3881, fail, steps:30, total reward:1.6000, 0.07573151588439941 sec\n",
      "Episode 63, loss:-9.9779, fail, steps:29, total reward:-2.7000, 0.0734255313873291 sec\n",
      "Episode 64, loss:-2.8780, fail, steps:29, total reward:-1.7000, 0.07365703582763672 sec\n",
      "Episode 65, loss:0.6683, succeed, steps:4, total reward:0.2000, 0.013054370880126953 sec\n",
      "Episode 66, loss:-0.5852, fail, steps:29, total reward:-0.7000, 0.07102084159851074 sec\n",
      "Episode 67, loss:-4.3858, fail, steps:29, total reward:-1.7000, 0.07245969772338867 sec\n",
      "Episode 68, loss:2.5078, succeed, steps:26, total reward:-0.9000, 0.06623601913452148 sec\n",
      "Episode 69, loss:4.4112, succeed, steps:27, total reward:0.1000, 0.0676419734954834 sec\n",
      "Episode 70, loss:1.0967, fail, steps:30, total reward:0.3000, 0.07517647743225098 sec\n",
      "Episode 71, loss:-1.2451, fail, steps:30, total reward:0.6000, 0.07643604278564453 sec\n",
      "Episode 72, loss:-0.5842, fail, steps:30, total reward:0.3000, 0.07609748840332031 sec\n",
      "Episode 73, loss:2.5178, succeed, steps:20, total reward:-0.3000, 0.05150628089904785 sec\n",
      "Episode 74, loss:2.1373, succeed, steps:14, total reward:0.3000, 0.03653836250305176 sec\n",
      "Episode 75, loss:-1.8794, fail, steps:29, total reward:-1.7000, 0.07274031639099121 sec\n",
      "Episode 76, loss:-0.4010, fail, steps:30, total reward:0.3000, 0.07861804962158203 sec\n",
      "Episode 77, loss:4.0348, succeed, steps:25, total reward:1.4000, 0.06500244140625 sec\n",
      "Episode 78, loss:0.9324, succeed, steps:7, total reward:-0.1000, 0.02034449577331543 sec\n",
      "Episode 79, loss:-1.9129, fail, steps:29, total reward:-0.7000, 0.07314610481262207 sec\n",
      "Episode 80, loss:1.0056, succeed, steps:7, total reward:-0.1000, 0.020107746124267578 sec\n",
      "Episode 81, loss:-1.8092, fail, steps:29, total reward:-0.7000, 0.07250022888183594 sec\n",
      "Episode 82, loss:3.0839, succeed, steps:18, total reward:1.0000, 0.04683375358581543 sec\n",
      "Episode 83, loss:0.4028, succeed, steps:4, total reward:0.2000, 0.012349843978881836 sec\n",
      "Episode 84, loss:3.5769, succeed, steps:15, total reward:1.3000, 0.0384974479675293 sec\n",
      "Episode 85, loss:1.0232, fail, steps:30, total reward:1.6000, 0.07579278945922852 sec\n",
      "Episode 86, loss:-1.4936, fail, steps:29, total reward:-1.7000, 0.07428145408630371 sec\n",
      "Episode 87, loss:3.1475, succeed, steps:26, total reward:-0.9000, 0.06705260276794434 sec\n",
      "Episode 88, loss:-0.8103, fail, steps:30, total reward:1.6000, 0.07732820510864258 sec\n",
      "Episode 89, loss:-3.1048, fail, steps:29, total reward:-1.7000, 0.07464814186096191 sec\n",
      "Episode 90, loss:1.9117, succeed, steps:8, total reward:0.9000, 0.02243185043334961 sec\n",
      "Episode 91, loss:2.1928, succeed, steps:23, total reward:-0.6000, 0.057164907455444336 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 92, loss:-0.2066, fail, steps:30, total reward:1.6000, 0.07510733604431152 sec\n",
      "Episode 93, loss:-1.8699, fail, steps:29, total reward:-0.7000, 0.0731196403503418 sec\n",
      "Episode 94, loss:1.5858, succeed, steps:16, total reward:-1.0000, 0.0972754955291748 sec\n",
      "Episode 95, loss:-3.1116, fail, steps:29, total reward:-1.7000, 0.0740506649017334 sec\n",
      "Episode 96, loss:-1.8908, fail, steps:29, total reward:-0.7000, 0.07322478294372559 sec\n",
      "Episode 97, loss:3.7184, succeed, steps:27, total reward:0.1000, 0.06854963302612305 sec\n",
      "Episode 98, loss:-4.2276, fail, steps:29, total reward:-2.7000, 0.0734870433807373 sec\n",
      "Episode 99, loss:-2.7220, fail, steps:29, total reward:-0.7000, 0.07335662841796875 sec\n",
      "len4 start12 Comparison 12 13 less Comparison 14 15 more Swap\n",
      "Episode 100, loss:0.9348, succeed, steps:7, total reward:-0.1000, 0.02003026008605957 sec\n",
      "Episode 101, loss:5.1438, succeed, steps:18, total reward:1.0000, 0.04533100128173828 sec\n",
      "Episode 102, loss:2.0073, succeed, steps:17, total reward:-0.6000, 0.043604373931884766 sec\n",
      "Episode 103, loss:-0.1105, fail, steps:30, total reward:0.3000, 0.07552337646484375 sec\n",
      "Episode 104, loss:3.6872, succeed, steps:15, total reward:1.3000, 0.0394749641418457 sec\n",
      "Episode 105, loss:-3.0300, fail, steps:29, total reward:-0.7000, 0.07204508781433105 sec\n",
      "Episode 106, loss:-2.9991, fail, steps:29, total reward:-0.7000, 0.07266521453857422 sec\n",
      "Episode 107, loss:-1.8228, fail, steps:30, total reward:0.3000, 0.07615423202514648 sec\n",
      "Episode 108, loss:0.9972, succeed, steps:7, total reward:-0.1000, 0.020465373992919922 sec\n",
      "Episode 109, loss:-5.6556, fail, steps:29, total reward:-2.7000, 0.07154965400695801 sec\n",
      "Episode 110, loss:-4.7009, fail, steps:30, total reward:-2.4000, 0.07612895965576172 sec\n",
      "Episode 111, loss:-2.6322, fail, steps:31, total reward:-1.4000, 0.11687231063842773 sec\n",
      "Episode 112, loss:-4.1534, fail, steps:31, total reward:-1.4000, 0.0779569149017334 sec\n",
      "Episode 113, loss:-12.1935, fail, steps:17, total reward:-11.2000, 0.04459118843078613 sec\n",
      "Episode 114, loss:-12.3105, fail, steps:5, total reward:-9.3000, 0.014746665954589844 sec\n",
      "Episode 115, loss:-10.9204, fail, steps:9, total reward:-10.6000, 0.023433685302734375 sec\n",
      "Episode 116, loss:-4.2345, fail, steps:5, total reward:-9.3000, 0.013921499252319336 sec\n",
      "Episode 117, loss:-4.0642, fail, steps:5, total reward:-9.3000, 0.013848543167114258 sec\n",
      "Episode 118, loss:-19.9296, fail, steps:13, total reward:-9.9000, 0.03310823440551758 sec\n",
      "Episode 119, loss:-7.5157, fail, steps:17, total reward:-11.2000, 0.04259514808654785 sec\n",
      "Episode 120, loss:-3.5411, fail, steps:17, total reward:-9.2000, 0.04291653633117676 sec\n",
      "Episode 121, loss:1.8794, succeed, steps:8, total reward:0.9000, 0.021553993225097656 sec\n",
      "Episode 122, loss:-5.6809, fail, steps:31, total reward:-3.4000, 0.07605576515197754 sec\n",
      "Episode 123, loss:-2.4059, fail, steps:31, total reward:-3.4000, 0.0788884162902832 sec\n",
      "Episode 124, loss:-5.8420, fail, steps:31, total reward:-5.4000, 0.07840681076049805 sec\n",
      "Episode 125, loss:5.0167, succeed, steps:20, total reward:1.0000, 0.05115842819213867 sec\n",
      "Episode 126, loss:-4.2762, fail, steps:31, total reward:-3.4000, 0.07791733741760254 sec\n",
      "Episode 127, loss:-2.0012, fail, steps:31, total reward:-1.4000, 0.0782780647277832 sec\n",
      "Episode 128, loss:-5.1097, fail, steps:31, total reward:-3.4000, 0.07839131355285645 sec\n",
      "Episode 129, loss:-6.3137, fail, steps:31, total reward:-5.4000, 0.07876777648925781 sec\n",
      "Episode 130, loss:-4.1553, fail, steps:30, total reward:-3.4000, 0.07644295692443848 sec\n",
      "Episode 131, loss:-4.0934, fail, steps:30, total reward:-2.4000, 0.0756845474243164 sec\n",
      "Episode 132, loss:0.8124, succeed, steps:15, total reward:-0.7000, 0.03963279724121094 sec\n",
      "Episode 133, loss:-1.7487, fail, steps:30, total reward:-0.4000, 0.07546615600585938 sec\n",
      "Episode 134, loss:-0.5199, fail, steps:30, total reward:0.6000, 0.07556438446044922 sec\n",
      "Episode 135, loss:-1.0200, fail, steps:30, total reward:0.3000, 0.07572197914123535 sec\n",
      "Episode 136, loss:1.9939, succeed, steps:11, total reward:0.6000, 0.029845237731933594 sec\n",
      "Episode 137, loss:-2.8107, fail, steps:29, total reward:-1.7000, 0.07254433631896973 sec\n",
      "Episode 138, loss:-4.9470, fail, steps:30, total reward:-1.7000, 0.07523846626281738 sec\n",
      "Episode 139, loss:-4.1641, fail, steps:29, total reward:-2.7000, 0.07342910766601562 sec\n",
      "Episode 140, loss:0.2561, fail, steps:30, total reward:0.3000, 0.0762016773223877 sec\n",
      "Episode 141, loss:4.2659, succeed, steps:18, total reward:1.0000, 0.04698920249938965 sec\n",
      "Episode 142, loss:-2.8745, fail, steps:29, total reward:-1.7000, 0.07234501838684082 sec\n",
      "Episode 143, loss:3.0261, succeed, steps:14, total reward:0.3000, 0.03695988655090332 sec\n",
      "Episode 144, loss:0.1570, fail, steps:30, total reward:1.6000, 0.0749046802520752 sec\n",
      "Episode 145, loss:0.8328, succeed, steps:7, total reward:-0.1000, 0.02006697654724121 sec\n",
      "Episode 146, loss:-3.3164, fail, steps:29, total reward:-1.7000, 0.07356643676757812 sec\n",
      "Episode 147, loss:2.1553, succeed, steps:11, total reward:0.6000, 0.03057384490966797 sec\n",
      "Episode 148, loss:-1.6520, fail, steps:29, total reward:-1.7000, 0.0732114315032959 sec\n",
      "Episode 149, loss:1.3397, succeed, steps:8, total reward:0.9000, 0.02314448356628418 sec\n",
      "Episode 150, loss:2.8296, succeed, steps:19, total reward:2.0000, 0.04837489128112793 sec\n",
      "Episode 151, loss:6.0852, succeed, steps:18, total reward:1.0000, 0.04654812812805176 sec\n",
      "Episode 152, loss:2.2024, succeed, steps:29, total reward:-1.2000, 0.07354736328125 sec\n",
      "Episode 153, loss:0.9614, succeed, steps:10, total reward:-0.7000, 0.027751445770263672 sec\n",
      "Episode 154, loss:-3.3250, fail, steps:29, total reward:-0.7000, 0.0738222599029541 sec\n",
      "Episode 155, loss:4.5467, succeed, steps:25, total reward:1.4000, 0.06324267387390137 sec\n",
      "Episode 156, loss:2.9702, succeed, steps:15, total reward:1.0000, 0.03901028633117676 sec\n",
      "Episode 157, loss:0.4679, fail, steps:30, total reward:1.6000, 0.07476806640625 sec\n",
      "Episode 158, loss:5.9198, succeed, steps:23, total reward:2.7000, 0.05923748016357422 sec\n",
      "Episode 159, loss:0.4923, succeed, steps:4, total reward:0.2000, 0.012503385543823242 sec\n",
      "Episode 160, loss:0.6579, fail, steps:30, total reward:1.6000, 0.07349228858947754 sec\n",
      "Episode 161, loss:3.8312, succeed, steps:18, total reward:1.0000, 0.04585695266723633 sec\n",
      "Episode 162, loss:-4.6585, fail, steps:29, total reward:-0.7000, 0.07262873649597168 sec\n",
      "Episode 163, loss:-0.5468, fail, steps:30, total reward:0.3000, 0.07528257369995117 sec\n",
      "Episode 164, loss:0.8186, succeed, steps:7, total reward:-0.1000, 0.020058155059814453 sec\n",
      "Episode 165, loss:5.2364, succeed, steps:19, total reward:2.0000, 0.04754209518432617 sec\n",
      "Episode 166, loss:-0.5488, fail, steps:30, total reward:0.3000, 0.07487726211547852 sec\n",
      "Episode 167, loss:1.5984, succeed, steps:10, total reward:-0.4000, 0.027321815490722656 sec\n",
      "Episode 168, loss:-1.1518, fail, steps:29, total reward:-0.7000, 0.07140922546386719 sec\n",
      "Episode 169, loss:3.7769, succeed, steps:19, total reward:2.0000, 0.04853343963623047 sec\n",
      "Episode 170, loss:-2.1935, fail, steps:29, total reward:-1.7000, 0.07293200492858887 sec\n",
      "Episode 171, loss:0.9988, succeed, steps:7, total reward:-0.1000, 0.020412445068359375 sec\n",
      "Episode 172, loss:2.3574, succeed, steps:28, total reward:-2.2000, 0.06935930252075195 sec\n",
      "Episode 173, loss:0.8416, succeed, steps:10, total reward:-0.4000, 0.02691960334777832 sec\n",
      "Episode 174, loss:5.4488, succeed, steps:22, total reward:1.7000, 0.05481386184692383 sec\n",
      "Episode 175, loss:-3.7291, fail, steps:29, total reward:-0.7000, 0.07283210754394531 sec\n",
      "Episode 176, loss:-3.0931, fail, steps:29, total reward:-1.7000, 0.07298827171325684 sec\n",
      "Episode 177, loss:-1.2030, fail, steps:30, total reward:0.3000, 0.07534217834472656 sec\n",
      "Episode 178, loss:-1.7057, fail, steps:29, total reward:-0.7000, 0.07385778427124023 sec\n",
      "Episode 179, loss:-1.4695, fail, steps:29, total reward:-0.7000, 0.07355499267578125 sec\n",
      "Episode 180, loss:-0.7331, fail, steps:29, total reward:-0.7000, 0.07304573059082031 sec\n",
      "Episode 181, loss:2.9181, succeed, steps:17, total reward:0.0000, 0.044389963150024414 sec\n",
      "Episode 182, loss:2.0596, succeed, steps:14, total reward:0.3000, 0.0370180606842041 sec\n",
      "Episode 183, loss:3.6195, succeed, steps:15, total reward:1.3000, 0.038626670837402344 sec\n",
      "Episode 184, loss:-1.2717, fail, steps:29, total reward:-0.7000, 0.07421207427978516 sec\n",
      "Episode 185, loss:-2.5307, fail, steps:29, total reward:-1.7000, 0.07523918151855469 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 186, loss:-1.4531, fail, steps:29, total reward:-0.7000, 0.07362842559814453 sec\n",
      "Episode 187, loss:2.1969, fail, steps:30, total reward:1.6000, 0.07557535171508789 sec\n",
      "Episode 188, loss:1.2408, succeed, steps:7, total reward:-0.1000, 0.02017688751220703 sec\n",
      "Episode 189, loss:-3.9033, fail, steps:29, total reward:-1.7000, 0.07183122634887695 sec\n",
      "Episode 190, loss:2.2697, succeed, steps:14, total reward:0.3000, 0.03707265853881836 sec\n",
      "Episode 191, loss:-3.5910, fail, steps:29, total reward:-1.7000, 0.07191252708435059 sec\n",
      "Episode 192, loss:3.9258, succeed, steps:25, total reward:1.4000, 0.06312346458435059 sec\n",
      "Episode 193, loss:-3.3953, fail, steps:29, total reward:-0.7000, 0.07341837882995605 sec\n",
      "Episode 194, loss:0.2298, succeed, steps:4, total reward:0.2000, 0.012944459915161133 sec\n",
      "Episode 195, loss:-0.8398, fail, steps:30, total reward:0.3000, 0.07360219955444336 sec\n",
      "Episode 196, loss:-0.1020, fail, steps:30, total reward:0.3000, 0.07484555244445801 sec\n",
      "Episode 197, loss:0.9932, succeed, steps:10, total reward:-0.4000, 0.02737712860107422 sec\n",
      "Episode 198, loss:0.5568, succeed, steps:4, total reward:0.2000, 0.012210845947265625 sec\n",
      "Episode 199, loss:3.6238, succeed, steps:19, total reward:2.0000, 0.04714465141296387 sec\n",
      "len4 start12 Comparison 13 14 more Swap Comparison 14 15 more Swap Comparison 14 15 less Comparison 14 15 less Swap Comparison 13 15 more Swap Comparison 14 15 more Swap\n",
      "Episode 200, loss:4.2024, succeed, steps:23, total reward:0.7000, 0.057080745697021484 sec\n",
      "Episode 201, loss:-2.1852, fail, steps:29, total reward:-1.7000, 0.07199764251708984 sec\n",
      "Episode 202, loss:3.7819, succeed, steps:24, total reward:0.4000, 0.06155586242675781 sec\n",
      "Episode 203, loss:2.7665, succeed, steps:29, total reward:-1.2000, 0.07287979125976562 sec\n",
      "Episode 204, loss:-1.6711, fail, steps:29, total reward:-0.7000, 0.0730290412902832 sec\n",
      "Episode 205, loss:-0.9061, fail, steps:30, total reward:0.3000, 0.07633352279663086 sec\n",
      "Episode 206, loss:1.6113, succeed, steps:11, total reward:0.6000, 0.029976844787597656 sec\n",
      "Episode 207, loss:-3.0739, fail, steps:29, total reward:-1.7000, 0.07218599319458008 sec\n",
      "Episode 208, loss:-0.5912, fail, steps:30, total reward:0.3000, 0.07497739791870117 sec\n",
      "Episode 209, loss:-1.3678, fail, steps:29, total reward:-0.7000, 0.07382464408874512 sec\n",
      "Episode 210, loss:-2.1832, fail, steps:29, total reward:-0.7000, 0.0733485221862793 sec\n",
      "Episode 211, loss:-2.2582, fail, steps:30, total reward:-1.7000, 0.07560944557189941 sec\n",
      "Episode 212, loss:0.9043, succeed, steps:7, total reward:-0.1000, 0.020123004913330078 sec\n",
      "Episode 213, loss:-2.5079, fail, steps:29, total reward:-0.7000, 0.07213830947875977 sec\n",
      "Episode 214, loss:1.8125, succeed, steps:28, total reward:-2.2000, 0.07022333145141602 sec\n",
      "Episode 215, loss:-2.3645, fail, steps:29, total reward:-2.7000, 0.07269167900085449 sec\n",
      "Episode 216, loss:2.9792, succeed, steps:14, total reward:0.3000, 0.03678464889526367 sec\n",
      "Episode 217, loss:-2.4713, fail, steps:29, total reward:-1.7000, 0.07264375686645508 sec\n",
      "Episode 218, loss:-4.9572, fail, steps:29, total reward:-2.7000, 0.0726473331451416 sec\n",
      "Episode 219, loss:-0.6058, fail, steps:30, total reward:0.3000, 0.0792856216430664 sec\n",
      "Episode 220, loss:-1.4178, fail, steps:29, total reward:-0.7000, 0.07452178001403809 sec\n",
      "Episode 221, loss:2.0441, succeed, steps:14, total reward:0.3000, 0.03743624687194824 sec\n",
      "Episode 222, loss:-2.8809, fail, steps:29, total reward:-1.7000, 0.07204151153564453 sec\n",
      "Episode 223, loss:-3.3929, fail, steps:29, total reward:-2.7000, 0.07286834716796875 sec\n",
      "Episode 224, loss:-0.7047, fail, steps:30, total reward:0.6000, 0.07598590850830078 sec\n",
      "Episode 225, loss:-2.8786, fail, steps:30, total reward:-1.7000, 0.07597899436950684 sec\n",
      "Episode 226, loss:-1.1827, fail, steps:29, total reward:-0.7000, 0.07317471504211426 sec\n",
      "Episode 227, loss:0.9421, succeed, steps:7, total reward:-0.1000, 0.02017831802368164 sec\n",
      "Episode 228, loss:-1.2193, fail, steps:30, total reward:-1.4000, 0.07443785667419434 sec\n",
      "Episode 229, loss:-3.2710, fail, steps:29, total reward:-2.7000, 0.07292699813842773 sec\n",
      "Episode 230, loss:-1.2514, fail, steps:30, total reward:-0.4000, 0.07542634010314941 sec\n",
      "Episode 231, loss:0.8345, fail, steps:30, total reward:0.6000, 0.07624292373657227 sec\n",
      "Episode 232, loss:-0.1835, fail, steps:29, total reward:-1.7000, 0.07334518432617188 sec\n",
      "Episode 233, loss:-3.9894, fail, steps:30, total reward:-1.7000, 0.07527875900268555 sec\n",
      "Episode 234, loss:-2.7954, fail, steps:29, total reward:-2.7000, 0.07390093803405762 sec\n",
      "Episode 235, loss:-1.7234, fail, steps:30, total reward:-0.4000, 0.07588505744934082 sec\n",
      "Episode 236, loss:4.0235, succeed, steps:30, total reward:-0.9000, 0.07546854019165039 sec\n",
      "Episode 237, loss:1.1081, succeed, steps:10, total reward:-0.4000, 0.027512311935424805 sec\n",
      "Episode 238, loss:-1.3043, fail, steps:30, total reward:0.3000, 0.07491135597229004 sec\n",
      "Episode 239, loss:0.2908, fail, steps:30, total reward:0.3000, 0.07534050941467285 sec\n",
      "Episode 240, loss:-2.0561, fail, steps:29, total reward:-1.7000, 0.07322430610656738 sec\n",
      "Episode 241, loss:3.1043, succeed, steps:15, total reward:1.3000, 0.0395359992980957 sec\n",
      "Episode 242, loss:2.5672, succeed, steps:17, total reward:0.0000, 0.04382157325744629 sec\n",
      "Episode 243, loss:1.1683, succeed, steps:4, total reward:0.2000, 0.012267112731933594 sec\n",
      "Episode 244, loss:-0.2530, fail, steps:30, total reward:0.6000, 0.073272705078125 sec\n",
      "Episode 245, loss:-0.7045, fail, steps:30, total reward:0.6000, 0.07509994506835938 sec\n",
      "Episode 246, loss:-3.2491, fail, steps:29, total reward:-1.7000, 0.07381153106689453 sec\n",
      "Episode 247, loss:-2.1009, fail, steps:29, total reward:-0.7000, 0.07327842712402344 sec\n",
      "Episode 248, loss:-2.2711, fail, steps:29, total reward:-0.7000, 0.07332992553710938 sec\n",
      "Episode 249, loss:1.0865, succeed, steps:8, total reward:0.9000, 0.022591829299926758 sec\n",
      "Episode 250, loss:1.8327, succeed, steps:22, total reward:-1.6000, 0.05649757385253906 sec\n",
      "Episode 251, loss:-0.8908, fail, steps:30, total reward:0.3000, 0.07714462280273438 sec\n",
      "Episode 252, loss:2.3164, succeed, steps:11, total reward:0.6000, 0.030942440032958984 sec\n",
      "Episode 253, loss:-0.2196, fail, steps:30, total reward:0.3000, 0.07655215263366699 sec\n",
      "Episode 254, loss:-1.8278, fail, steps:30, total reward:0.3000, 0.07593274116516113 sec\n",
      "Episode 255, loss:0.0455, fail, steps:29, total reward:-0.7000, 0.07309985160827637 sec\n",
      "Episode 256, loss:3.8711, succeed, steps:27, total reward:0.1000, 0.0687708854675293 sec\n",
      "Episode 257, loss:2.6769, succeed, steps:20, total reward:-0.3000, 0.0513148307800293 sec\n",
      "Episode 258, loss:-1.7583, fail, steps:29, total reward:-0.7000, 0.07303261756896973 sec\n",
      "Episode 259, loss:2.9863, succeed, steps:17, total reward:0.0000, 0.04409027099609375 sec\n",
      "Episode 260, loss:0.1975, succeed, steps:4, total reward:0.2000, 0.01224970817565918 sec\n",
      "Episode 261, loss:4.6290, succeed, steps:27, total reward:0.1000, 0.0662238597869873 sec\n",
      "Episode 262, loss:3.8721, succeed, steps:11, total reward:0.6000, 0.029121875762939453 sec\n",
      "Episode 263, loss:-10.6469, fail, steps:29, total reward:-2.7000, 0.0719454288482666 sec\n",
      "Episode 264, loss:2.2002, succeed, steps:20, total reward:-0.3000, 0.05104708671569824 sec\n",
      "Episode 265, loss:-0.8807, fail, steps:30, total reward:0.3000, 0.07473421096801758 sec\n",
      "Episode 266, loss:-1.8419, fail, steps:29, total reward:-0.7000, 0.0727698802947998 sec\n",
      "Episode 267, loss:1.0213, succeed, steps:10, total reward:-0.4000, 0.028021812438964844 sec\n",
      "Episode 268, loss:-2.0251, fail, steps:29, total reward:-0.7000, 0.07171964645385742 sec\n",
      "Episode 269, loss:1.1146, succeed, steps:7, total reward:-0.1000, 0.01964855194091797 sec\n",
      "Episode 270, loss:-2.1319, fail, steps:30, total reward:0.3000, 0.07352709770202637 sec\n",
      "Episode 271, loss:3.3730, succeed, steps:16, total reward:2.3000, 0.0418238639831543 sec\n",
      "Episode 272, loss:6.2308, succeed, steps:22, total reward:1.7000, 0.05530261993408203 sec\n",
      "Episode 273, loss:-1.9292, fail, steps:30, total reward:0.3000, 0.07458662986755371 sec\n",
      "Episode 274, loss:2.2172, succeed, steps:11, total reward:0.6000, 0.02974700927734375 sec\n",
      "Episode 275, loss:0.5244, fail, steps:30, total reward:1.6000, 0.07482385635375977 sec\n",
      "Episode 276, loss:1.0476, succeed, steps:4, total reward:0.2000, 0.012689352035522461 sec\n",
      "Episode 277, loss:5.5728, succeed, steps:26, total reward:2.4000, 0.06378340721130371 sec\n",
      "Episode 278, loss:-3.3336, fail, steps:29, total reward:-1.7000, 0.07213211059570312 sec\n",
      "Episode 279, loss:2.1501, succeed, steps:11, total reward:0.6000, 0.02956414222717285 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 280, loss:1.8143, succeed, steps:16, total reward:-1.0000, 0.04113173484802246 sec\n",
      "Episode 281, loss:-2.3233, fail, steps:30, total reward:-1.7000, 0.07416558265686035 sec\n",
      "Episode 282, loss:-0.4072, fail, steps:30, total reward:0.3000, 0.07516789436340332 sec\n",
      "Episode 283, loss:-1.7628, fail, steps:29, total reward:-1.3000, 0.07352209091186523 sec\n",
      "Episode 284, loss:-7.3939, fail, steps:30, total reward:-1.7000, 0.07564473152160645 sec\n",
      "Episode 285, loss:-3.0759, fail, steps:29, total reward:-1.7000, 0.07319068908691406 sec\n",
      "Episode 286, loss:1.9485, succeed, steps:23, total reward:-0.6000, 0.058994293212890625 sec\n",
      "Episode 287, loss:-2.1270, fail, steps:29, total reward:-0.7000, 0.07394599914550781 sec\n",
      "Episode 288, loss:0.9905, fail, steps:30, total reward:2.6000, 0.07893872261047363 sec\n",
      "Episode 289, loss:-2.1770, fail, steps:29, total reward:-0.7000, 0.07396245002746582 sec\n",
      "Episode 290, loss:-3.0745, fail, steps:29, total reward:-0.7000, 0.07377910614013672 sec\n",
      "Episode 291, loss:0.9332, succeed, steps:7, total reward:-0.1000, 0.020119428634643555 sec\n",
      "Episode 292, loss:-0.4245, fail, steps:30, total reward:0.3000, 0.07379555702209473 sec\n",
      "Episode 293, loss:4.8799, succeed, steps:26, total reward:2.4000, 0.06577181816101074 sec\n",
      "Episode 294, loss:-2.0275, fail, steps:29, total reward:-0.7000, 0.07284951210021973 sec\n",
      "Episode 295, loss:-2.6925, fail, steps:29, total reward:-1.7000, 0.07308316230773926 sec\n",
      "Episode 296, loss:-0.0226, fail, steps:29, total reward:-0.7000, 0.07365012168884277 sec\n",
      "Episode 297, loss:-1.7157, fail, steps:29, total reward:-0.7000, 0.07320141792297363 sec\n",
      "Episode 298, loss:0.7949, succeed, steps:7, total reward:-0.1000, 0.02008223533630371 sec\n",
      "Episode 299, loss:-4.0384, fail, steps:29, total reward:-2.7000, 0.07152438163757324 sec\n",
      "len4 start0 Comparison 1 2 more Swap Comparison 2 3 more Swap Comparison 0 2 more Swap\n",
      "Episode 300, loss:2.9544, succeed, steps:12, total reward:1.6000, 0.031766653060913086 sec\n",
      "Episode 301, loss:1.0503, succeed, steps:4, total reward:0.2000, 0.012449979782104492 sec\n",
      "Episode 302, loss:0.2674, fail, steps:30, total reward:1.6000, 0.0731661319732666 sec\n",
      "Episode 303, loss:-2.2890, fail, steps:29, total reward:-0.7000, 0.0724639892578125 sec\n",
      "Episode 304, loss:-1.4071, fail, steps:29, total reward:-1.7000, 0.07355546951293945 sec\n",
      "Episode 305, loss:-1.4464, fail, steps:29, total reward:-0.7000, 0.07317900657653809 sec\n",
      "Episode 306, loss:2.1771, succeed, steps:12, total reward:1.6000, 0.031999826431274414 sec\n",
      "Episode 307, loss:-1.3870, fail, steps:30, total reward:0.3000, 0.07408523559570312 sec\n",
      "Episode 308, loss:2.5575, succeed, steps:23, total reward:-0.6000, 0.059007883071899414 sec\n",
      "Episode 309, loss:-1.2487, fail, steps:29, total reward:-0.7000, 0.0726156234741211 sec\n",
      "Episode 310, loss:4.5895, succeed, steps:19, total reward:2.0000, 0.048684120178222656 sec\n",
      "Episode 311, loss:-1.8953, fail, steps:29, total reward:-1.3000, 0.07221150398254395 sec\n",
      "Episode 312, loss:-2.1675, fail, steps:29, total reward:-1.7000, 0.07340002059936523 sec\n",
      "Episode 313, loss:2.9260, succeed, steps:23, total reward:-0.6000, 0.05896162986755371 sec\n",
      "Episode 314, loss:3.4888, succeed, steps:14, total reward:0.3000, 0.036406517028808594 sec\n",
      "Episode 315, loss:-1.2179, fail, steps:29, total reward:-0.7000, 0.07182478904724121 sec\n",
      "Episode 316, loss:4.6844, succeed, steps:22, total reward:1.7000, 0.056055307388305664 sec\n",
      "Episode 317, loss:3.3773, succeed, steps:21, total reward:0.7000, 0.05348706245422363 sec\n",
      "Episode 318, loss:-1.7140, fail, steps:29, total reward:-0.7000, 0.07229375839233398 sec\n",
      "Episode 319, loss:3.7039, succeed, steps:18, total reward:1.0000, 0.046491384506225586 sec\n",
      "Episode 320, loss:-2.0017, fail, steps:29, total reward:-0.7000, 0.07286548614501953 sec\n",
      "Episode 321, loss:1.9088, succeed, steps:17, total reward:-0.3000, 0.044055938720703125 sec\n",
      "Episode 322, loss:3.4497, succeed, steps:12, total reward:1.6000, 0.03228163719177246 sec\n",
      "Episode 323, loss:0.5127, succeed, steps:7, total reward:-0.1000, 0.019894838333129883 sec\n",
      "Episode 324, loss:-1.2616, fail, steps:30, total reward:0.3000, 0.07652807235717773 sec\n",
      "Episode 325, loss:2.4404, succeed, steps:11, total reward:0.6000, 0.030376195907592773 sec\n",
      "Episode 326, loss:2.6224, succeed, steps:17, total reward:0.0000, 0.04350733757019043 sec\n",
      "Episode 327, loss:1.0928, succeed, steps:7, total reward:-0.1000, 0.01906561851501465 sec\n",
      "Episode 328, loss:3.8423, succeed, steps:21, total reward:0.7000, 0.05186653137207031 sec\n",
      "Episode 329, loss:3.9463, succeed, steps:21, total reward:0.7000, 0.05258989334106445 sec\n",
      "Episode 330, loss:-2.6990, fail, steps:29, total reward:-1.7000, 0.0726933479309082 sec\n",
      "Episode 331, loss:0.5273, succeed, steps:4, total reward:0.2000, 0.012774467468261719 sec\n",
      "Episode 332, loss:-0.6177, fail, steps:30, total reward:1.3000, 0.07316184043884277 sec\n",
      "Episode 333, loss:-0.9098, fail, steps:29, total reward:-0.7000, 0.07256865501403809 sec\n",
      "Episode 334, loss:8.4049, succeed, steps:25, total reward:1.4000, 0.06381940841674805 sec\n",
      "Episode 335, loss:3.6311, succeed, steps:14, total reward:0.3000, 0.036774635314941406 sec\n",
      "Episode 336, loss:-0.6725, fail, steps:30, total reward:0.3000, 0.07395339012145996 sec\n",
      "Episode 337, loss:3.9006, succeed, steps:15, total reward:1.3000, 0.03914928436279297 sec\n",
      "Episode 338, loss:0.2844, fail, steps:30, total reward:0.3000, 0.07480883598327637 sec\n",
      "Episode 339, loss:-2.8942, fail, steps:29, total reward:-1.7000, 0.07268762588500977 sec\n",
      "Episode 340, loss:3.0111, succeed, steps:12, total reward:1.6000, 0.032018184661865234 sec\n",
      "Episode 341, loss:2.9824, succeed, steps:24, total reward:0.4000, 0.05966043472290039 sec\n",
      "Episode 342, loss:2.8936, succeed, steps:26, total reward:-0.9000, 0.06539130210876465 sec\n",
      "Episode 343, loss:1.3902, succeed, steps:8, total reward:0.9000, 0.022480010986328125 sec\n",
      "Episode 344, loss:5.3537, succeed, steps:22, total reward:1.7000, 0.054627418518066406 sec\n",
      "Episode 345, loss:-1.2681, fail, steps:29, total reward:-0.7000, 0.07184457778930664 sec\n",
      "Episode 346, loss:2.9938, succeed, steps:20, total reward:-0.3000, 0.051511526107788086 sec\n",
      "Episode 347, loss:-1.4218, fail, steps:29, total reward:-0.7000, 0.07253551483154297 sec\n",
      "Episode 348, loss:-1.1455, fail, steps:29, total reward:-0.7000, 0.07293558120727539 sec\n",
      "Episode 349, loss:-1.7661, fail, steps:29, total reward:-0.7000, 0.07351493835449219 sec\n",
      "Episode 350, loss:-2.7534, fail, steps:29, total reward:-0.7000, 0.07304787635803223 sec\n",
      "Episode 351, loss:-0.1908, fail, steps:29, total reward:-0.7000, 0.07304072380065918 sec\n",
      "Episode 352, loss:0.6220, succeed, steps:4, total reward:0.2000, 0.012739419937133789 sec\n",
      "Episode 353, loss:1.3997, succeed, steps:4, total reward:0.2000, 0.011551141738891602 sec\n",
      "Episode 354, loss:2.8208, succeed, steps:17, total reward:0.0000, 0.04250502586364746 sec\n",
      "Episode 355, loss:-2.9373, fail, steps:29, total reward:-1.7000, 0.07155084609985352 sec\n",
      "Episode 356, loss:5.6143, succeed, steps:22, total reward:1.7000, 0.05562758445739746 sec\n",
      "Episode 357, loss:-2.0859, fail, steps:29, total reward:-0.7000, 0.07239723205566406 sec\n",
      "Episode 358, loss:2.8129, succeed, steps:26, total reward:-0.9000, 0.06600737571716309 sec\n",
      "Episode 359, loss:3.6237, succeed, steps:17, total reward:0.0000, 0.044060468673706055 sec\n",
      "Episode 360, loss:-1.1864, fail, steps:29, total reward:-0.7000, 0.07213854789733887 sec\n",
      "Episode 361, loss:3.8857, succeed, steps:15, total reward:1.3000, 0.04085803031921387 sec\n",
      "Episode 362, loss:3.8723, succeed, steps:21, total reward:0.7000, 0.05531573295593262 sec\n",
      "Episode 363, loss:-4.3381, fail, steps:29, total reward:-2.7000, 0.07419157028198242 sec\n",
      "Episode 364, loss:1.7255, succeed, steps:8, total reward:0.9000, 0.022783756256103516 sec\n",
      "Episode 365, loss:1.1237, succeed, steps:10, total reward:-0.4000, 0.026555776596069336 sec\n",
      "Episode 366, loss:-0.4705, fail, steps:30, total reward:0.3000, 0.07493734359741211 sec\n",
      "Episode 367, loss:4.0051, succeed, steps:18, total reward:1.0000, 0.04760909080505371 sec\n",
      "Episode 368, loss:4.3506, succeed, steps:24, total reward:0.4000, 0.06149768829345703 sec\n",
      "Episode 369, loss:3.6571, succeed, steps:28, total reward:1.1000, 0.07126545906066895 sec\n",
      "Episode 370, loss:-0.7386, fail, steps:30, total reward:0.3000, 0.07732748985290527 sec\n",
      "Episode 371, loss:4.1044, succeed, steps:18, total reward:1.0000, 0.04784202575683594 sec\n",
      "Episode 372, loss:-1.5026, fail, steps:29, total reward:-0.7000, 0.07388043403625488 sec\n",
      "Episode 373, loss:6.4316, succeed, steps:25, total reward:1.4000, 0.06434106826782227 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 374, loss:-0.7457, fail, steps:30, total reward:0.3000, 0.07776570320129395 sec\n",
      "Episode 375, loss:-4.0257, fail, steps:29, total reward:-1.7000, 0.07508134841918945 sec\n",
      "Episode 376, loss:-0.7929, fail, steps:30, total reward:0.3000, 0.07738709449768066 sec\n",
      "Episode 377, loss:0.9418, succeed, steps:7, total reward:-0.1000, 0.02057337760925293 sec\n",
      "Episode 378, loss:-2.1812, fail, steps:29, total reward:-0.7000, 0.07352662086486816 sec\n",
      "Episode 379, loss:1.8831, succeed, steps:11, total reward:0.6000, 0.03010869026184082 sec\n",
      "Episode 380, loss:0.1342, fail, steps:30, total reward:1.6000, 0.07465696334838867 sec\n",
      "Episode 381, loss:3.2881, succeed, steps:29, total reward:-1.2000, 0.07274794578552246 sec\n",
      "Episode 382, loss:0.3111, fail, steps:30, total reward:1.6000, 0.07620501518249512 sec\n",
      "Episode 383, loss:-2.0053, fail, steps:29, total reward:-0.7000, 0.07328414916992188 sec\n",
      "Episode 384, loss:1.3262, succeed, steps:13, total reward:-0.7000, 0.03463625907897949 sec\n",
      "Episode 385, loss:2.0842, succeed, steps:11, total reward:0.6000, 0.028608322143554688 sec\n",
      "Episode 386, loss:-1.4446, fail, steps:30, total reward:0.3000, 0.07418632507324219 sec\n",
      "Episode 387, loss:-2.4799, fail, steps:29, total reward:-0.7000, 0.07280540466308594 sec\n",
      "Episode 388, loss:1.8367, succeed, steps:11, total reward:0.3000, 0.029595136642456055 sec\n",
      "Episode 389, loss:-2.2642, fail, steps:29, total reward:-0.7000, 0.0717628002166748 sec\n",
      "Episode 390, loss:-3.7641, fail, steps:29, total reward:-1.7000, 0.07307195663452148 sec\n",
      "Episode 391, loss:4.4753, succeed, steps:27, total reward:0.1000, 0.0681450366973877 sec\n",
      "Episode 392, loss:-1.9279, fail, steps:29, total reward:-0.7000, 0.07285451889038086 sec\n",
      "Episode 393, loss:0.5625, fail, steps:30, total reward:1.6000, 0.07601356506347656 sec\n",
      "Episode 394, loss:-2.8383, fail, steps:29, total reward:-0.7000, 0.07398724555969238 sec\n",
      "Episode 395, loss:-4.9922, fail, steps:29, total reward:-2.7000, 0.07662653923034668 sec\n",
      "Episode 396, loss:0.1023, fail, steps:30, total reward:1.6000, 0.07729625701904297 sec\n",
      "Episode 397, loss:5.3313, succeed, steps:26, total reward:2.4000, 0.0663306713104248 sec\n",
      "Episode 398, loss:-2.0637, fail, steps:29, total reward:-0.7000, 0.07310318946838379 sec\n",
      "Episode 399, loss:2.8836, succeed, steps:17, total reward:0.0000, 0.04413247108459473 sec\n",
      "len4 start4 Comparison 4 5 more Swap\n",
      "Episode 400, loss:0.6045, succeed, steps:4, total reward:0.2000, 0.012255668640136719 sec\n",
      "Episode 401, loss:4.4747, succeed, steps:15, total reward:1.3000, 0.03801441192626953 sec\n",
      "Episode 402, loss:0.2803, fail, steps:30, total reward:1.6000, 0.07364726066589355 sec\n",
      "Episode 403, loss:2.5793, succeed, steps:20, total reward:-0.3000, 0.050933837890625 sec\n",
      "Episode 404, loss:2.0130, succeed, steps:11, total reward:0.6000, 0.028964996337890625 sec\n",
      "Episode 405, loss:1.3304, succeed, steps:10, total reward:-0.4000, 0.026245832443237305 sec\n",
      "Episode 406, loss:1.1506, succeed, steps:13, total reward:-0.7000, 0.03335857391357422 sec\n",
      "Episode 407, loss:4.6269, succeed, steps:21, total reward:0.7000, 0.05220818519592285 sec\n",
      "Episode 408, loss:5.3222, succeed, steps:22, total reward:1.7000, 0.055029869079589844 sec\n",
      "Episode 409, loss:1.5774, succeed, steps:16, total reward:-1.0000, 0.04108452796936035 sec\n",
      "Episode 410, loss:-1.9553, fail, steps:29, total reward:-0.7000, 0.07258033752441406 sec\n",
      "Episode 411, loss:5.8529, succeed, steps:29, total reward:2.1000, 0.07265377044677734 sec\n",
      "Episode 412, loss:-4.6043, fail, steps:29, total reward:-2.7000, 0.07283759117126465 sec\n",
      "Episode 413, loss:-1.4806, fail, steps:30, total reward:0.3000, 0.07580089569091797 sec\n",
      "Episode 414, loss:1.4479, succeed, steps:10, total reward:-0.4000, 0.027418851852416992 sec\n",
      "Episode 415, loss:-2.4790, fail, steps:29, total reward:-0.7000, 0.07188153266906738 sec\n",
      "Episode 416, loss:-1.9207, fail, steps:29, total reward:-0.7000, 0.07238268852233887 sec\n",
      "Episode 417, loss:3.1665, succeed, steps:18, total reward:1.0000, 0.04704022407531738 sec\n",
      "Episode 418, loss:0.7827, fail, steps:30, total reward:1.6000, 0.07651996612548828 sec\n",
      "Episode 419, loss:0.5207, fail, steps:30, total reward:1.6000, 0.07693004608154297 sec\n",
      "Episode 420, loss:5.9037, succeed, steps:28, total reward:1.1000, 0.07282185554504395 sec\n",
      "Episode 421, loss:2.5201, succeed, steps:20, total reward:-0.3000, 0.05245375633239746 sec\n",
      "Episode 422, loss:4.4804, succeed, steps:25, total reward:1.4000, 0.06425309181213379 sec\n",
      "Episode 423, loss:6.4596, succeed, steps:19, total reward:2.0000, 0.049509286880493164 sec\n",
      "Episode 424, loss:6.0683, succeed, steps:29, total reward:2.1000, 0.0743112564086914 sec\n",
      "Episode 425, loss:2.5949, succeed, steps:12, total reward:1.6000, 0.03253459930419922 sec\n",
      "Episode 426, loss:2.0215, succeed, steps:29, total reward:-1.5000, 0.0729837417602539 sec\n",
      "Episode 427, loss:3.9349, succeed, steps:27, total reward:0.1000, 0.06782126426696777 sec\n",
      "Episode 428, loss:4.1955, succeed, steps:24, total reward:0.4000, 0.06168484687805176 sec\n",
      "Episode 429, loss:3.1253, succeed, steps:26, total reward:-0.9000, 0.06551265716552734 sec\n",
      "Episode 430, loss:2.5948, succeed, steps:8, total reward:0.9000, 0.022144079208374023 sec\n",
      "Episode 431, loss:-0.0150, fail, steps:30, total reward:1.6000, 0.0749809741973877 sec\n",
      "Episode 432, loss:2.4772, succeed, steps:14, total reward:0.3000, 0.038442373275756836 sec\n",
      "Episode 433, loss:-2.5356, fail, steps:29, total reward:-0.7000, 0.07324385643005371 sec\n",
      "Episode 434, loss:1.7262, succeed, steps:8, total reward:0.9000, 0.0222780704498291 sec\n",
      "Episode 435, loss:-3.3135, fail, steps:29, total reward:-0.7000, 0.0714578628540039 sec\n",
      "Episode 436, loss:-0.3061, fail, steps:30, total reward:1.6000, 0.07603216171264648 sec\n",
      "Episode 437, loss:2.5586, succeed, steps:20, total reward:-0.3000, 0.05149435997009277 sec\n",
      "Episode 438, loss:-2.7015, fail, steps:29, total reward:-0.7000, 0.07204174995422363 sec\n",
      "Episode 439, loss:-0.7044, fail, steps:30, total reward:0.3000, 0.0751805305480957 sec\n",
      "Episode 440, loss:-0.9175, fail, steps:30, total reward:0.3000, 0.07619404792785645 sec\n",
      "Episode 441, loss:1.0354, succeed, steps:4, total reward:0.2000, 0.012884855270385742 sec\n",
      "Episode 442, loss:-3.8201, fail, steps:29, total reward:-1.9000, 0.07092499732971191 sec\n",
      "Episode 443, loss:4.9666, succeed, steps:28, total reward:1.1000, 0.0700533390045166 sec\n",
      "Episode 444, loss:1.9211, succeed, steps:10, total reward:-0.4000, 0.02718806266784668 sec\n",
      "Episode 445, loss:6.8050, succeed, steps:28, total reward:1.1000, 0.06982588768005371 sec\n",
      "Episode 446, loss:2.6540, succeed, steps:17, total reward:0.0000, 0.04403543472290039 sec\n",
      "Episode 447, loss:1.4118, succeed, steps:13, total reward:-0.7000, 0.03373312950134277 sec\n",
      "Episode 448, loss:-1.1189, fail, steps:30, total reward:0.3000, 0.07391667366027832 sec\n",
      "Episode 449, loss:-1.2697, fail, steps:30, total reward:0.3000, 0.07575035095214844 sec\n",
      "Episode 450, loss:5.8965, succeed, steps:29, total reward:2.1000, 0.07305431365966797 sec\n",
      "Episode 451, loss:3.4057, succeed, steps:24, total reward:0.4000, 0.06084942817687988 sec\n",
      "Episode 452, loss:-2.2049, fail, steps:29, total reward:-0.7000, 0.0736856460571289 sec\n",
      "Episode 453, loss:2.0307, succeed, steps:17, total reward:0.0000, 0.04442191123962402 sec\n",
      "Episode 454, loss:-2.1597, fail, steps:29, total reward:-0.7000, 0.07215476036071777 sec\n",
      "Episode 455, loss:3.9205, succeed, steps:19, total reward:2.0000, 0.04868793487548828 sec\n",
      "Episode 456, loss:2.7239, succeed, steps:20, total reward:-0.3000, 0.051096439361572266 sec\n",
      "Episode 457, loss:0.4753, fail, steps:30, total reward:1.6000, 0.0751638412475586 sec\n",
      "Episode 458, loss:3.8790, succeed, steps:24, total reward:0.4000, 0.06088089942932129 sec\n",
      "Episode 459, loss:2.4749, succeed, steps:14, total reward:0.3000, 0.03660154342651367 sec\n",
      "Episode 460, loss:2.1016, succeed, steps:26, total reward:-0.9000, 0.06560993194580078 sec\n",
      "Episode 461, loss:-2.0187, fail, steps:29, total reward:-0.7000, 0.07250165939331055 sec\n",
      "Episode 462, loss:-1.0005, fail, steps:30, total reward:0.3000, 0.07533073425292969 sec\n",
      "Episode 463, loss:1.5611, succeed, steps:16, total reward:-1.0000, 0.041986942291259766 sec\n",
      "Episode 464, loss:4.6303, succeed, steps:22, total reward:1.7000, 0.05582404136657715 sec\n",
      "Episode 465, loss:1.7056, succeed, steps:16, total reward:-1.0000, 0.041361331939697266 sec\n",
      "Episode 466, loss:-3.8164, fail, steps:29, total reward:-2.7000, 0.07195591926574707 sec\n",
      "Episode 467, loss:3.5669, succeed, steps:24, total reward:0.4000, 0.06341195106506348 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 468, loss:1.1614, fail, steps:30, total reward:1.6000, 0.07706904411315918 sec\n",
      "Episode 469, loss:-0.8164, fail, steps:30, total reward:0.3000, 0.07538366317749023 sec\n",
      "Episode 470, loss:-1.3172, fail, steps:30, total reward:0.3000, 0.07551717758178711 sec\n",
      "Episode 471, loss:-0.7945, fail, steps:30, total reward:0.3000, 0.0760962963104248 sec\n",
      "Episode 472, loss:2.6481, succeed, steps:11, total reward:0.6000, 0.02998971939086914 sec\n",
      "Episode 473, loss:5.5572, succeed, steps:23, total reward:2.7000, 0.05740785598754883 sec\n",
      "Episode 474, loss:3.0053, succeed, steps:18, total reward:1.0000, 0.04576230049133301 sec\n",
      "Episode 475, loss:3.6467, succeed, steps:23, total reward:-0.6000, 0.05762887001037598 sec\n",
      "Episode 476, loss:-2.8106, fail, steps:29, total reward:-1.7000, 0.07290196418762207 sec\n",
      "Episode 477, loss:-4.4476, fail, steps:29, total reward:-1.7000, 0.0730433464050293 sec\n",
      "Episode 478, loss:2.8107, succeed, steps:18, total reward:1.0000, 0.04644513130187988 sec\n",
      "Episode 479, loss:3.8464, succeed, steps:16, total reward:2.3000, 0.04113960266113281 sec\n",
      "Episode 480, loss:-1.0851, fail, steps:30, total reward:0.3000, 0.07482314109802246 sec\n",
      "Episode 481, loss:2.4243, succeed, steps:14, total reward:0.3000, 0.03677248954772949 sec\n",
      "Episode 482, loss:3.8983, succeed, steps:22, total reward:1.7000, 0.05495882034301758 sec\n",
      "Episode 483, loss:-2.1963, fail, steps:29, total reward:-0.7000, 0.07205533981323242 sec\n",
      "Episode 484, loss:2.6815, succeed, steps:8, total reward:0.9000, 0.02241969108581543 sec\n",
      "Episode 485, loss:4.7800, succeed, steps:28, total reward:1.1000, 0.06963753700256348 sec\n",
      "Episode 486, loss:2.6701, succeed, steps:8, total reward:0.9000, 0.022046804428100586 sec\n",
      "Episode 487, loss:0.6587, succeed, steps:4, total reward:0.2000, 0.011683464050292969 sec\n",
      "Episode 488, loss:-1.6847, fail, steps:29, total reward:-0.7000, 0.0706179141998291 sec\n",
      "Episode 489, loss:3.7971, succeed, steps:14, total reward:0.3000, 0.03642535209655762 sec\n",
      "Episode 490, loss:-0.8446, fail, steps:30, total reward:0.3000, 0.07455182075500488 sec\n",
      "Episode 491, loss:3.0107, succeed, steps:20, total reward:-0.3000, 0.05118703842163086 sec\n",
      "Episode 492, loss:-3.6216, fail, steps:29, total reward:-1.7000, 0.07233738899230957 sec\n",
      "Episode 493, loss:3.3567, succeed, steps:15, total reward:1.3000, 0.03909015655517578 sec\n",
      "Episode 494, loss:-1.1030, fail, steps:30, total reward:0.3000, 0.07488751411437988 sec\n",
      "Episode 495, loss:0.9971, succeed, steps:7, total reward:-0.1000, 0.019974231719970703 sec\n",
      "Episode 496, loss:2.9491, succeed, steps:20, total reward:-0.3000, 0.04973959922790527 sec\n",
      "Episode 497, loss:2.3967, succeed, steps:12, total reward:1.6000, 0.03119802474975586 sec\n",
      "Episode 498, loss:-3.3860, fail, steps:29, total reward:-1.3000, 0.07138752937316895 sec\n",
      "Episode 499, loss:4.4480, succeed, steps:22, total reward:1.7000, 0.056386470794677734 sec\n",
      "len4 start8 Comparison 10 11 less Comparison 8 9 less Comparison 9 10 more Swap Comparison 10 11 more Swap\n",
      "Episode 500, loss:2.4143, succeed, steps:14, total reward:0.3000, 0.03643012046813965 sec\n",
      "Episode 501, loss:3.9155, succeed, steps:21, total reward:0.7000, 0.05261564254760742 sec\n",
      "Episode 502, loss:4.5441, succeed, steps:22, total reward:1.7000, 0.05526614189147949 sec\n",
      "Episode 503, loss:4.1078, succeed, steps:18, total reward:1.0000, 0.04592704772949219 sec\n",
      "Episode 504, loss:-3.0977, fail, steps:29, total reward:-1.7000, 0.07259607315063477 sec\n",
      "Episode 505, loss:0.9725, succeed, steps:20, total reward:-0.6000, 0.052958011627197266 sec\n",
      "Episode 506, loss:-2.1636, fail, steps:29, total reward:-0.7000, 0.07477712631225586 sec\n",
      "Episode 507, loss:-1.2640, fail, steps:29, total reward:-0.7000, 0.0732426643371582 sec\n",
      "Episode 508, loss:2.2619, succeed, steps:23, total reward:-0.6000, 0.05891919136047363 sec\n",
      "Episode 509, loss:0.6481, succeed, steps:4, total reward:0.2000, 0.012557268142700195 sec\n",
      "Episode 510, loss:0.7053, fail, steps:30, total reward:1.6000, 0.07329654693603516 sec\n",
      "Episode 511, loss:2.5244, succeed, steps:14, total reward:0.3000, 0.0364682674407959 sec\n",
      "Episode 512, loss:2.4630, succeed, steps:15, total reward:1.3000, 0.03849315643310547 sec\n",
      "Episode 513, loss:1.7231, succeed, steps:28, total reward:-2.2000, 0.06948304176330566 sec\n",
      "Episode 514, loss:3.7781, succeed, steps:24, total reward:0.4000, 0.06104564666748047 sec\n",
      "Episode 515, loss:2.2452, succeed, steps:17, total reward:0.0000, 0.0437772274017334 sec\n",
      "Episode 516, loss:3.4386, succeed, steps:15, total reward:1.3000, 0.03883647918701172 sec\n",
      "Episode 517, loss:0.0341, fail, steps:30, total reward:0.3000, 0.0742959976196289 sec\n",
      "Episode 518, loss:5.0146, succeed, steps:24, total reward:0.4000, 0.06078505516052246 sec\n",
      "Episode 519, loss:2.2777, succeed, steps:20, total reward:-0.3000, 0.05096793174743652 sec\n",
      "Episode 520, loss:0.9328, succeed, steps:10, total reward:-0.4000, 0.0269927978515625 sec\n",
      "Episode 521, loss:-3.0682, fail, steps:29, total reward:-1.7000, 0.0715327262878418 sec\n",
      "Episode 522, loss:2.7072, succeed, steps:26, total reward:-0.9000, 0.06515932083129883 sec\n",
      "Episode 523, loss:1.1609, succeed, steps:10, total reward:-0.4000, 0.026942729949951172 sec\n",
      "Episode 524, loss:-0.1141, fail, steps:30, total reward:0.3000, 0.07540512084960938 sec\n",
      "Episode 525, loss:-0.8435, fail, steps:29, total reward:-0.7000, 0.0728003978729248 sec\n",
      "Episode 526, loss:-5.9840, fail, steps:29, total reward:-2.7000, 0.07296967506408691 sec\n",
      "Episode 527, loss:4.8877, succeed, steps:22, total reward:1.7000, 0.05643296241760254 sec\n",
      "Episode 528, loss:-0.3291, fail, steps:30, total reward:0.3000, 0.07532906532287598 sec\n",
      "Episode 529, loss:-2.4834, fail, steps:29, total reward:-1.7000, 0.07267928123474121 sec\n",
      "Episode 530, loss:1.2240, succeed, steps:10, total reward:-0.4000, 0.027205944061279297 sec\n",
      "Episode 531, loss:4.5934, succeed, steps:27, total reward:0.1000, 0.06776905059814453 sec\n",
      "Episode 532, loss:3.0069, succeed, steps:18, total reward:1.0000, 0.046137332916259766 sec\n",
      "Episode 533, loss:-0.8749, fail, steps:30, total reward:0.3000, 0.07439351081848145 sec\n",
      "Episode 534, loss:0.4017, fail, steps:30, total reward:1.6000, 0.07541871070861816 sec\n",
      "Episode 535, loss:-0.3727, fail, steps:30, total reward:0.3000, 0.07648682594299316 sec\n",
      "Episode 536, loss:3.9337, succeed, steps:25, total reward:1.4000, 0.06362271308898926 sec\n",
      "Episode 537, loss:2.5722, succeed, steps:20, total reward:-0.3000, 0.05109858512878418 sec\n",
      "Episode 538, loss:-1.7474, fail, steps:29, total reward:-0.7000, 0.07247757911682129 sec\n",
      "Episode 539, loss:-4.1926, fail, steps:29, total reward:-2.7000, 0.07376527786254883 sec\n",
      "Episode 540, loss:-1.5868, fail, steps:29, total reward:-0.7000, 0.0752115249633789 sec\n",
      "Episode 541, loss:-0.1220, fail, steps:30, total reward:1.6000, 0.07869815826416016 sec\n",
      "Episode 542, loss:0.9081, succeed, steps:7, total reward:-0.1000, 0.020186185836791992 sec\n",
      "Episode 543, loss:-3.4513, fail, steps:29, total reward:-1.7000, 0.07204866409301758 sec\n",
      "Episode 544, loss:-1.3914, fail, steps:29, total reward:-0.7000, 0.07234907150268555 sec\n",
      "Episode 545, loss:5.0630, succeed, steps:27, total reward:0.1000, 0.0679318904876709 sec\n",
      "Episode 546, loss:3.5711, succeed, steps:26, total reward:-0.9000, 0.06600069999694824 sec\n",
      "Episode 547, loss:-1.2596, fail, steps:30, total reward:0.3000, 0.07522320747375488 sec\n",
      "Episode 548, loss:-4.4035, fail, steps:29, total reward:-2.7000, 0.07293105125427246 sec\n",
      "Episode 549, loss:4.0588, succeed, steps:25, total reward:1.4000, 0.06354761123657227 sec\n",
      "Episode 550, loss:1.5075, succeed, steps:8, total reward:0.9000, 0.022372007369995117 sec\n",
      "Episode 551, loss:0.9347, succeed, steps:7, total reward:-0.1000, 0.018874645233154297 sec\n",
      "Episode 552, loss:2.8837, succeed, steps:23, total reward:-0.6000, 0.05662989616394043 sec\n",
      "Episode 553, loss:3.6700, succeed, steps:22, total reward:1.7000, 0.05509519577026367 sec\n",
      "Episode 554, loss:-2.0880, fail, steps:29, total reward:-0.7000, 0.07263517379760742 sec\n",
      "Episode 555, loss:4.6621, succeed, steps:28, total reward:1.1000, 0.07011032104492188 sec\n",
      "Episode 556, loss:2.9394, succeed, steps:11, total reward:0.6000, 0.02964496612548828 sec\n",
      "Episode 557, loss:-2.8577, fail, steps:29, total reward:-1.7000, 0.07135462760925293 sec\n",
      "Episode 558, loss:-3.7796, fail, steps:29, total reward:-1.7000, 0.07308077812194824 sec\n",
      "Episode 559, loss:4.2614, succeed, steps:19, total reward:2.0000, 0.048882484436035156 sec\n",
      "Episode 560, loss:1.6476, succeed, steps:11, total reward:0.6000, 0.029134511947631836 sec\n",
      "Episode 561, loss:3.4868, succeed, steps:24, total reward:0.4000, 0.05960226058959961 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 562, loss:-2.3500, fail, steps:29, total reward:-0.7000, 0.07272791862487793 sec\n",
      "Episode 563, loss:-2.3089, fail, steps:29, total reward:-0.7000, 0.07284832000732422 sec\n",
      "Episode 564, loss:3.3567, succeed, steps:18, total reward:1.0000, 0.04632925987243652 sec\n",
      "Episode 565, loss:5.2701, succeed, steps:29, total reward:2.1000, 0.07216835021972656 sec\n",
      "Episode 566, loss:4.1271, succeed, steps:28, total reward:1.1000, 0.0706326961517334 sec\n",
      "Episode 567, loss:2.1323, succeed, steps:20, total reward:-0.3000, 0.051609039306640625 sec\n",
      "Episode 568, loss:-0.5695, fail, steps:29, total reward:-0.7000, 0.07244086265563965 sec\n",
      "Episode 569, loss:2.1466, succeed, steps:17, total reward:0.0000, 0.04417586326599121 sec\n",
      "Episode 570, loss:2.6694, succeed, steps:20, total reward:-0.3000, 0.050981760025024414 sec\n",
      "Episode 571, loss:5.8342, succeed, steps:29, total reward:2.1000, 0.07204937934875488 sec\n",
      "Episode 572, loss:2.3506, succeed, steps:20, total reward:-0.3000, 0.05108022689819336 sec\n",
      "Episode 573, loss:1.5002, succeed, steps:19, total reward:-1.3000, 0.04837322235107422 sec\n",
      "Episode 574, loss:2.7270, succeed, steps:18, total reward:1.0000, 0.04628777503967285 sec\n",
      "Episode 575, loss:-2.2327, fail, steps:30, total reward:0.3000, 0.07448315620422363 sec\n",
      "Episode 576, loss:0.2030, fail, steps:30, total reward:1.6000, 0.07867717742919922 sec\n",
      "Episode 577, loss:-1.2710, fail, steps:30, total reward:0.3000, 0.07794952392578125 sec\n",
      "Episode 578, loss:0.7664, fail, steps:30, total reward:1.6000, 0.07718443870544434 sec\n",
      "Episode 579, loss:1.3484, succeed, steps:10, total reward:-0.4000, 0.02733612060546875 sec\n",
      "Episode 580, loss:5.1618, succeed, steps:22, total reward:1.7000, 0.05591940879821777 sec\n",
      "Episode 581, loss:-2.5949, fail, steps:29, total reward:-0.7000, 0.07213449478149414 sec\n",
      "Episode 582, loss:-1.7703, fail, steps:30, total reward:0.3000, 0.0751492977142334 sec\n",
      "Episode 583, loss:-2.3911, fail, steps:29, total reward:-1.7000, 0.07281780242919922 sec\n",
      "Episode 584, loss:2.3802, succeed, steps:21, total reward:0.7000, 0.053792715072631836 sec\n",
      "Episode 585, loss:-0.8989, fail, steps:29, total reward:-0.7000, 0.07265162467956543 sec\n",
      "Episode 586, loss:3.0126, succeed, steps:23, total reward:-0.6000, 0.058341264724731445 sec\n",
      "Episode 587, loss:2.4057, succeed, steps:20, total reward:-0.3000, 0.050962209701538086 sec\n",
      "Episode 588, loss:1.2431, fail, steps:30, total reward:2.6000, 0.07521915435791016 sec\n",
      "Episode 589, loss:3.3522, succeed, steps:16, total reward:2.3000, 0.041918039321899414 sec\n",
      "Episode 590, loss:4.1649, succeed, steps:23, total reward:-0.6000, 0.0577239990234375 sec\n",
      "Episode 591, loss:-2.3435, fail, steps:29, total reward:-1.7000, 0.0723729133605957 sec\n",
      "Episode 592, loss:-3.7418, fail, steps:29, total reward:-2.7000, 0.07348990440368652 sec\n",
      "Episode 593, loss:1.8711, succeed, steps:8, total reward:0.9000, 0.022517681121826172 sec\n",
      "Episode 594, loss:0.4967, succeed, steps:4, total reward:0.2000, 0.011769771575927734 sec\n",
      "Episode 595, loss:3.9579, succeed, steps:18, total reward:1.0000, 0.04450488090515137 sec\n",
      "Episode 596, loss:-0.4387, fail, steps:30, total reward:0.3000, 0.0738682746887207 sec\n",
      "Episode 597, loss:-0.4189, fail, steps:30, total reward:0.6000, 0.07575821876525879 sec\n",
      "Episode 598, loss:3.2467, succeed, steps:15, total reward:1.3000, 0.03962850570678711 sec\n",
      "Episode 599, loss:1.0363, succeed, steps:4, total reward:0.2000, 0.012138605117797852 sec\n",
      "Episode 600, loss:-0.8938, fail, steps:29, total reward:-0.7000, 0.07086014747619629 sec\n",
      "Episode 601, loss:-1.7289, fail, steps:29, total reward:-0.7000, 0.07244324684143066 sec\n",
      "Episode 602, loss:-2.4880, fail, steps:29, total reward:-0.7000, 0.07304096221923828 sec\n",
      "Episode 603, loss:-1.0954, fail, steps:29, total reward:-0.7000, 0.07295393943786621 sec\n",
      "Episode 604, loss:3.7680, succeed, steps:17, total reward:0.0000, 0.044019222259521484 sec\n",
      "Episode 605, loss:-1.3755, fail, steps:29, total reward:-0.7000, 0.07209920883178711 sec\n",
      "Episode 606, loss:-1.6911, fail, steps:29, total reward:-0.7000, 0.07330727577209473 sec\n",
      "Episode 607, loss:-1.3533, fail, steps:30, total reward:0.6000, 0.07530450820922852 sec\n",
      "Episode 608, loss:0.6532, fail, steps:30, total reward:1.6000, 0.07541084289550781 sec\n",
      "Episode 609, loss:-2.4444, fail, steps:29, total reward:-1.7000, 0.07380032539367676 sec\n",
      "Episode 610, loss:1.0594, succeed, steps:7, total reward:-0.1000, 0.021100997924804688 sec\n",
      "Episode 611, loss:-0.9475, fail, steps:29, total reward:-0.7000, 0.07465195655822754 sec\n",
      "Episode 612, loss:-1.1044, fail, steps:30, total reward:0.3000, 0.0765535831451416 sec\n",
      "Episode 613, loss:-2.7610, fail, steps:29, total reward:-0.7000, 0.07367968559265137 sec\n",
      "Episode 614, loss:1.3575, succeed, steps:13, total reward:-0.7000, 0.03462076187133789 sec\n",
      "Episode 615, loss:-2.3517, fail, steps:29, total reward:-0.7000, 0.07163238525390625 sec\n",
      "Episode 616, loss:-1.6401, fail, steps:29, total reward:-0.7000, 0.07243704795837402 sec\n",
      "Episode 617, loss:-2.8107, fail, steps:29, total reward:-1.3000, 0.07344412803649902 sec\n",
      "Episode 618, loss:1.8981, succeed, steps:11, total reward:0.6000, 0.029691219329833984 sec\n",
      "Episode 619, loss:1.6735, fail, steps:30, total reward:1.6000, 0.0739901065826416 sec\n",
      "Episode 620, loss:1.3033, succeed, steps:13, total reward:-0.7000, 0.034314632415771484 sec\n",
      "Episode 621, loss:4.3486, succeed, steps:25, total reward:1.4000, 0.06228184700012207 sec\n",
      "Episode 622, loss:-1.9009, fail, steps:29, total reward:-0.7000, 0.07239460945129395 sec\n",
      "Episode 623, loss:0.5868, succeed, steps:4, total reward:0.2000, 0.012651443481445312 sec\n",
      "Episode 624, loss:-5.5259, fail, steps:29, total reward:-2.3000, 0.07097220420837402 sec\n",
      "Episode 625, loss:3.7550, succeed, steps:15, total reward:1.3000, 0.03860759735107422 sec\n",
      "Episode 626, loss:-1.9482, fail, steps:29, total reward:-2.0000, 0.07188224792480469 sec\n",
      "Episode 627, loss:-1.1660, fail, steps:30, total reward:0.3000, 0.07484626770019531 sec\n",
      "Episode 628, loss:0.7359, succeed, steps:4, total reward:0.2000, 0.01264643669128418 sec\n",
      "Episode 629, loss:1.8954, succeed, steps:26, total reward:-0.9000, 0.06384491920471191 sec\n",
      "Episode 630, loss:1.4019, succeed, steps:10, total reward:-0.4000, 0.026584386825561523 sec\n",
      "Episode 631, loss:0.5379, succeed, steps:4, total reward:0.2000, 0.01174020767211914 sec\n",
      "Episode 632, loss:-1.8251, fail, steps:29, total reward:-0.7000, 0.07113170623779297 sec\n",
      "Episode 633, loss:-1.1417, fail, steps:29, total reward:-0.7000, 0.0720522403717041 sec\n",
      "Episode 634, loss:3.6599, succeed, steps:22, total reward:1.7000, 0.055986881256103516 sec\n",
      "Episode 635, loss:3.2175, succeed, steps:17, total reward:0.0000, 0.04361152648925781 sec\n",
      "Episode 636, loss:-3.2928, fail, steps:29, total reward:-0.7000, 0.0732569694519043 sec\n",
      "Episode 637, loss:5.2421, succeed, steps:29, total reward:2.1000, 0.07286858558654785 sec\n",
      "Episode 638, loss:2.6991, succeed, steps:12, total reward:1.6000, 0.03199434280395508 sec\n",
      "Episode 639, loss:-2.3315, fail, steps:29, total reward:-0.7000, 0.07159066200256348 sec\n",
      "Episode 640, loss:1.2534, succeed, steps:10, total reward:-0.4000, 0.027190446853637695 sec\n",
      "Episode 641, loss:2.6618, succeed, steps:23, total reward:-0.6000, 0.0574495792388916 sec\n",
      "Episode 642, loss:0.3474, fail, steps:29, total reward:-0.7000, 0.07202458381652832 sec\n",
      "Episode 643, loss:2.4500, succeed, steps:20, total reward:-0.3000, 0.05101966857910156 sec\n",
      "Episode 644, loss:2.9852, succeed, steps:27, total reward:0.1000, 0.06768608093261719 sec\n",
      "Episode 645, loss:-3.5256, fail, steps:29, total reward:-1.7000, 0.07257652282714844 sec\n",
      "Episode 646, loss:-1.8299, fail, steps:30, total reward:0.3000, 0.07515406608581543 sec\n",
      "Episode 647, loss:-1.5205, fail, steps:30, total reward:1.6000, 0.07903552055358887 sec\n",
      "Episode 648, loss:1.8317, succeed, steps:14, total reward:0.3000, 0.03823137283325195 sec\n",
      "Episode 649, loss:0.8269, fail, steps:30, total reward:1.6000, 0.07603025436401367 sec\n",
      "Episode 650, loss:-1.6524, fail, steps:30, total reward:0.3000, 0.07657909393310547 sec\n",
      "Episode 651, loss:-1.0712, fail, steps:30, total reward:0.3000, 0.07794880867004395 sec\n",
      "Episode 652, loss:2.1512, succeed, steps:11, total reward:0.6000, 0.030473947525024414 sec\n",
      "Episode 653, loss:0.9962, succeed, steps:4, total reward:0.2000, 0.01224064826965332 sec\n",
      "Episode 654, loss:0.4664, fail, steps:30, total reward:0.3000, 0.0747218132019043 sec\n",
      "Episode 655, loss:-2.3450, fail, steps:29, total reward:-1.0000, 0.07325124740600586 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 656, loss:-1.5504, fail, steps:29, total reward:-0.7000, 0.07320904731750488 sec\n",
      "Episode 657, loss:-3.5791, fail, steps:29, total reward:-1.7000, 0.07306289672851562 sec\n",
      "Episode 658, loss:1.2397, succeed, steps:11, total reward:0.6000, 0.02978038787841797 sec\n",
      "Episode 659, loss:4.5812, succeed, steps:18, total reward:1.0000, 0.04530215263366699 sec\n",
      "Episode 660, loss:-0.5520, fail, steps:29, total reward:-0.7000, 0.07191634178161621 sec\n",
      "Episode 661, loss:4.9966, succeed, steps:18, total reward:1.0000, 0.04649686813354492 sec\n",
      "Episode 662, loss:-3.4979, fail, steps:29, total reward:-1.7000, 0.07214021682739258 sec\n",
      "Episode 663, loss:2.9678, succeed, steps:16, total reward:2.3000, 0.041426658630371094 sec\n",
      "Episode 664, loss:4.5689, succeed, steps:21, total reward:0.7000, 0.05326390266418457 sec\n",
      "Episode 665, loss:-0.5730, fail, steps:30, total reward:0.3000, 0.07449483871459961 sec\n",
      "Episode 666, loss:2.5920, succeed, steps:15, total reward:1.3000, 0.039379119873046875 sec\n",
      "Episode 667, loss:2.3620, succeed, steps:29, total reward:-1.2000, 0.07196450233459473 sec\n",
      "Episode 668, loss:-3.6347, fail, steps:29, total reward:-2.7000, 0.07300996780395508 sec\n",
      "Episode 669, loss:-1.3675, fail, steps:30, total reward:0.3000, 0.07560157775878906 sec\n",
      "Episode 670, loss:4.5232, succeed, steps:21, total reward:0.7000, 0.053888559341430664 sec\n",
      "Episode 671, loss:1.2175, succeed, steps:7, total reward:-0.1000, 0.019664764404296875 sec\n",
      "Episode 672, loss:3.7507, succeed, steps:18, total reward:1.0000, 0.044814348220825195 sec\n",
      "Episode 673, loss:-3.8209, fail, steps:29, total reward:-2.7000, 0.07201051712036133 sec\n",
      "Episode 674, loss:-1.5498, fail, steps:30, total reward:0.3000, 0.07529020309448242 sec\n",
      "Episode 675, loss:-1.3374, fail, steps:29, total reward:-0.7000, 0.07268953323364258 sec\n",
      "Episode 676, loss:-1.9722, fail, steps:29, total reward:-0.7000, 0.07380437850952148 sec\n",
      "Episode 677, loss:-0.6724, fail, steps:30, total reward:0.3000, 0.07557058334350586 sec\n",
      "Episode 678, loss:-4.5392, fail, steps:29, total reward:-2.7000, 0.07313942909240723 sec\n",
      "Episode 679, loss:-2.4831, fail, steps:29, total reward:-0.7000, 0.07368636131286621 sec\n",
      "Episode 680, loss:-0.7111, fail, steps:30, total reward:1.6000, 0.07563543319702148 sec\n",
      "Episode 681, loss:2.0123, succeed, steps:18, total reward:1.0000, 0.04883408546447754 sec\n",
      "Episode 682, loss:-5.6175, fail, steps:29, total reward:-3.9000, 0.07474255561828613 sec\n",
      "Episode 683, loss:2.5183, succeed, steps:26, total reward:-0.9000, 0.06598544120788574 sec\n",
      "Episode 684, loss:-5.2211, fail, steps:29, total reward:-2.7000, 0.07290530204772949 sec\n",
      "Episode 685, loss:-3.6044, fail, steps:29, total reward:-2.7000, 0.0731508731842041 sec\n",
      "Episode 686, loss:-3.0116, fail, steps:29, total reward:-0.7000, 0.07347893714904785 sec\n",
      "Episode 687, loss:2.1004, succeed, steps:17, total reward:0.0000, 0.044976234436035156 sec\n",
      "Episode 688, loss:3.5035, succeed, steps:19, total reward:2.0000, 0.04823708534240723 sec\n",
      "Episode 689, loss:2.2252, succeed, steps:23, total reward:-0.6000, 0.05766153335571289 sec\n",
      "Episode 690, loss:-0.5471, fail, steps:29, total reward:-0.7000, 0.07264423370361328 sec\n",
      "Episode 691, loss:-3.7451, fail, steps:29, total reward:-1.7000, 0.07307100296020508 sec\n",
      "Episode 692, loss:3.5009, succeed, steps:24, total reward:0.1000, 0.06082296371459961 sec\n",
      "Episode 693, loss:-2.9252, fail, steps:29, total reward:-2.7000, 0.07269001007080078 sec\n",
      "Episode 694, loss:-1.1680, fail, steps:29, total reward:-1.7000, 0.07282423973083496 sec\n",
      "Episode 695, loss:2.8688, succeed, steps:14, total reward:0.3000, 0.037087202072143555 sec\n",
      "Episode 696, loss:1.0128, succeed, steps:11, total reward:0.3000, 0.0288848876953125 sec\n",
      "Episode 697, loss:-1.3974, fail, steps:30, total reward:-0.3000, 0.07418131828308105 sec\n",
      "Episode 698, loss:2.8898, succeed, steps:26, total reward:-0.9000, 0.06550097465515137 sec\n",
      "Episode 699, loss:2.9627, succeed, steps:11, total reward:0.6000, 0.029293537139892578 sec\n",
      "Episode 700, loss:-1.2084, fail, steps:30, total reward:0.3000, 0.07383418083190918 sec\n",
      "Episode 701, loss:4.3064, succeed, steps:18, total reward:1.0000, 0.04697871208190918 sec\n",
      "Episode 702, loss:2.3439, succeed, steps:15, total reward:1.3000, 0.038611412048339844 sec\n",
      "Episode 703, loss:-0.2395, fail, steps:30, total reward:1.6000, 0.07402706146240234 sec\n",
      "Episode 704, loss:1.6205, succeed, steps:14, total reward:0.3000, 0.03648877143859863 sec\n",
      "Episode 705, loss:-1.0805, fail, steps:29, total reward:-0.7000, 0.07201313972473145 sec\n",
      "Episode 706, loss:1.2177, fail, steps:30, total reward:1.6000, 0.07504677772521973 sec\n",
      "Episode 707, loss:2.3679, succeed, steps:18, total reward:1.0000, 0.04672980308532715 sec\n",
      "Episode 708, loss:2.8021, succeed, steps:15, total reward:1.3000, 0.03865361213684082 sec\n",
      "Episode 709, loss:-1.0870, fail, steps:29, total reward:-0.7000, 0.07192683219909668 sec\n",
      "Episode 710, loss:2.9004, succeed, steps:24, total reward:0.4000, 0.06092500686645508 sec\n",
      "Episode 711, loss:0.9159, succeed, steps:8, total reward:0.9000, 0.022024154663085938 sec\n",
      "Episode 712, loss:4.7125, succeed, steps:29, total reward:2.1000, 0.07128334045410156 sec\n",
      "Episode 713, loss:4.5659, succeed, steps:27, total reward:0.1000, 0.06799983978271484 sec\n",
      "Episode 714, loss:1.3007, succeed, steps:16, total reward:-1.0000, 0.04158496856689453 sec\n",
      "Episode 715, loss:1.1130, succeed, steps:11, total reward:0.6000, 0.029018640518188477 sec\n",
      "Episode 716, loss:2.2865, succeed, steps:12, total reward:1.6000, 0.030792713165283203 sec\n",
      "Episode 717, loss:2.3042, succeed, steps:26, total reward:-0.9000, 0.06586575508117676 sec\n",
      "Episode 718, loss:4.2396, succeed, steps:16, total reward:2.3000, 0.04304170608520508 sec\n",
      "Episode 719, loss:0.9317, succeed, steps:7, total reward:-0.1000, 0.019832134246826172 sec\n",
      "Episode 720, loss:1.1013, succeed, steps:13, total reward:-0.7000, 0.03395724296569824 sec\n",
      "Episode 721, loss:1.1498, fail, steps:30, total reward:1.6000, 0.07545590400695801 sec\n",
      "Episode 722, loss:4.7529, succeed, steps:23, total reward:-0.6000, 0.05913662910461426 sec\n",
      "Episode 723, loss:1.3379, succeed, steps:14, total reward:0.3000, 0.037824153900146484 sec\n",
      "Episode 724, loss:4.1497, succeed, steps:21, total reward:0.7000, 0.052728891372680664 sec\n",
      "Episode 725, loss:6.9295, succeed, steps:30, total reward:3.1000, 0.07435321807861328 sec\n",
      "Episode 726, loss:1.9462, succeed, steps:20, total reward:-0.3000, 0.051116943359375 sec\n",
      "Episode 727, loss:-2.5605, fail, steps:29, total reward:-0.7000, 0.07342863082885742 sec\n",
      "Episode 728, loss:2.4167, succeed, steps:11, total reward:0.6000, 0.029837608337402344 sec\n",
      "Episode 729, loss:-1.3546, fail, steps:30, total reward:0.3000, 0.07395815849304199 sec\n",
      "Episode 730, loss:7.7992, succeed, steps:28, total reward:1.1000, 0.07013797760009766 sec\n",
      "Episode 731, loss:0.4962, fail, steps:30, total reward:0.3000, 0.07584643363952637 sec\n",
      "Episode 732, loss:1.2417, fail, steps:30, total reward:1.6000, 0.0756223201751709 sec\n",
      "Episode 733, loss:1.4364, succeed, steps:16, total reward:-1.0000, 0.04178261756896973 sec\n",
      "Episode 734, loss:-3.6492, fail, steps:29, total reward:-1.7000, 0.07264828681945801 sec\n",
      "Episode 735, loss:2.3781, succeed, steps:24, total reward:0.4000, 0.06106138229370117 sec\n",
      "Episode 736, loss:-0.9800, fail, steps:29, total reward:-0.7000, 0.07270312309265137 sec\n",
      "Episode 737, loss:-2.0587, fail, steps:30, total reward:0.3000, 0.07550430297851562 sec\n",
      "Episode 738, loss:0.1953, succeed, steps:4, total reward:0.2000, 0.012940168380737305 sec\n",
      "Episode 739, loss:3.0181, succeed, steps:18, total reward:1.0000, 0.04531121253967285 sec\n",
      "Episode 740, loss:-1.4203, fail, steps:29, total reward:-0.7000, 0.07182097434997559 sec\n",
      "Episode 741, loss:0.1780, fail, steps:30, total reward:0.3000, 0.07487821578979492 sec\n",
      "Episode 742, loss:0.1986, fail, steps:30, total reward:1.6000, 0.09564805030822754 sec\n",
      "Episode 743, loss:-1.4568, fail, steps:29, total reward:-0.7000, 0.07438278198242188 sec\n",
      "Episode 744, loss:3.6195, succeed, steps:20, total reward:-0.3000, 0.10498881340026855 sec\n",
      "Episode 745, loss:-3.4766, fail, steps:29, total reward:-0.7000, 0.07393431663513184 sec\n",
      "Episode 746, loss:-0.5142, fail, steps:30, total reward:0.3000, 0.0753626823425293 sec\n",
      "Episode 747, loss:2.7368, succeed, steps:24, total reward:0.4000, 0.06119680404663086 sec\n",
      "Episode 748, loss:4.1275, succeed, steps:24, total reward:0.4000, 0.0606231689453125 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 749, loss:-3.9465, fail, steps:30, total reward:-0.9000, 0.07551264762878418 sec\n",
      "Episode 750, loss:2.4204, succeed, steps:20, total reward:-0.3000, 0.05136394500732422 sec\n",
      "Episode 751, loss:0.6912, succeed, steps:4, total reward:0.2000, 0.01251220703125 sec\n",
      "Episode 752, loss:-1.1329, fail, steps:30, total reward:0.3000, 0.07680392265319824 sec\n",
      "Episode 753, loss:-3.9943, fail, steps:29, total reward:-1.7000, 0.07473444938659668 sec\n",
      "Episode 754, loss:-1.5921, fail, steps:29, total reward:-0.7000, 0.07464861869812012 sec\n",
      "Episode 755, loss:-2.9351, fail, steps:29, total reward:-1.7000, 0.07431674003601074 sec\n",
      "Episode 756, loss:-1.8469, fail, steps:29, total reward:-0.7000, 0.07509279251098633 sec\n",
      "Episode 757, loss:3.4220, succeed, steps:19, total reward:2.0000, 0.05009627342224121 sec\n",
      "Episode 758, loss:-1.8687, fail, steps:29, total reward:-0.7000, 0.07309103012084961 sec\n",
      "Episode 759, loss:3.2700, succeed, steps:24, total reward:-0.5000, 0.06082296371459961 sec\n",
      "Episode 760, loss:-1.4731, fail, steps:29, total reward:-0.7000, 0.07345914840698242 sec\n",
      "Episode 761, loss:-2.3130, fail, steps:29, total reward:-1.7000, 0.07287883758544922 sec\n",
      "Episode 762, loss:-0.2439, fail, steps:30, total reward:0.3000, 0.07564187049865723 sec\n",
      "Episode 763, loss:1.0447, succeed, steps:10, total reward:-0.4000, 0.027283668518066406 sec\n",
      "Episode 764, loss:3.5480, succeed, steps:15, total reward:1.3000, 0.03845810890197754 sec\n",
      "Episode 765, loss:2.3976, succeed, steps:12, total reward:1.6000, 0.03117966651916504 sec\n",
      "Episode 766, loss:3.9237, succeed, steps:15, total reward:1.3000, 0.03803706169128418 sec\n",
      "Episode 767, loss:-5.2012, fail, steps:29, total reward:-1.7000, 0.07138943672180176 sec\n",
      "Episode 768, loss:2.4986, succeed, steps:20, total reward:-0.3000, 0.05089616775512695 sec\n",
      "Episode 769, loss:0.5173, fail, steps:29, total reward:-1.0000, 0.07323932647705078 sec\n",
      "Episode 770, loss:4.3850, succeed, steps:28, total reward:1.1000, 0.07035136222839355 sec\n",
      "Episode 771, loss:1.9282, succeed, steps:19, total reward:-1.3000, 0.0488286018371582 sec\n",
      "Episode 772, loss:-3.2827, fail, steps:29, total reward:-1.7000, 0.07219958305358887 sec\n",
      "Episode 773, loss:0.4971, succeed, steps:4, total reward:0.2000, 0.012768745422363281 sec\n",
      "Episode 774, loss:1.5422, fail, steps:30, total reward:1.6000, 0.07331514358520508 sec\n",
      "Episode 775, loss:3.6049, succeed, steps:27, total reward:0.1000, 0.06734395027160645 sec\n",
      "Episode 776, loss:-1.9033, fail, steps:29, total reward:-1.7000, 0.07286262512207031 sec\n",
      "Episode 777, loss:4.0773, succeed, steps:22, total reward:1.7000, 0.05605673789978027 sec\n",
      "Episode 778, loss:1.6850, succeed, steps:11, total reward:0.6000, 0.02943134307861328 sec\n",
      "Episode 779, loss:-2.3876, fail, steps:29, total reward:-2.7000, 0.0713813304901123 sec\n",
      "Episode 780, loss:0.4834, succeed, steps:4, total reward:0.2000, 0.012433290481567383 sec\n",
      "Episode 781, loss:2.7433, succeed, steps:17, total reward:0.0000, 0.04259943962097168 sec\n",
      "Episode 782, loss:1.4070, succeed, steps:25, total reward:-1.9000, 0.062111854553222656 sec\n",
      "Episode 783, loss:-0.8968, fail, steps:30, total reward:0.3000, 0.07573246955871582 sec\n",
      "Episode 784, loss:-2.3725, fail, steps:29, total reward:-0.7000, 0.07320451736450195 sec\n",
      "Episode 785, loss:3.3940, succeed, steps:15, total reward:1.3000, 0.03921008110046387 sec\n",
      "Episode 786, loss:1.9024, succeed, steps:25, total reward:-1.9000, 0.0625145435333252 sec\n",
      "Episode 787, loss:-1.2780, fail, steps:29, total reward:-0.7000, 0.07493329048156738 sec\n",
      "Episode 788, loss:3.9739, succeed, steps:25, total reward:1.4000, 0.06630063056945801 sec\n",
      "Episode 789, loss:-0.8533, fail, steps:29, total reward:-0.7000, 0.07425951957702637 sec\n",
      "Episode 790, loss:1.2363, succeed, steps:13, total reward:-0.7000, 0.03501725196838379 sec\n",
      "Episode 791, loss:-3.7852, fail, steps:29, total reward:-1.7000, 0.07346940040588379 sec\n",
      "Episode 792, loss:4.9230, succeed, steps:28, total reward:1.1000, 0.0724802017211914 sec\n",
      "Episode 793, loss:-1.2140, fail, steps:29, total reward:-0.7000, 0.07460379600524902 sec\n",
      "Episode 794, loss:2.5077, succeed, steps:14, total reward:0.3000, 0.03757500648498535 sec\n",
      "Episode 795, loss:-2.2630, fail, steps:29, total reward:-0.7000, 0.07345700263977051 sec\n",
      "Episode 796, loss:1.0615, succeed, steps:13, total reward:-0.7000, 0.03499197959899902 sec\n",
      "Episode 797, loss:1.0140, succeed, steps:7, total reward:-0.1000, 0.019710302352905273 sec\n",
      "Episode 798, loss:5.8940, succeed, steps:11, total reward:0.6000, 0.028779983520507812 sec\n",
      "Episode 799, loss:4.9293, succeed, steps:29, total reward:2.1000, 0.07224369049072266 sec\n",
      "len4 start4 Comparison 4 5 less Comparison 6 7 more Swap\n",
      "Episode 800, loss:0.6753, succeed, steps:7, total reward:-0.1000, 0.019963502883911133 sec\n",
      "Episode 801, loss:-0.9665, fail, steps:29, total reward:-0.7000, 0.07375741004943848 sec\n",
      "Episode 802, loss:-1.1738, fail, steps:29, total reward:-0.7000, 0.07338881492614746 sec\n",
      "Episode 803, loss:-2.2988, fail, steps:29, total reward:-2.7000, 0.0728294849395752 sec\n",
      "Episode 804, loss:-1.5048, fail, steps:29, total reward:-0.7000, 0.07350349426269531 sec\n",
      "Episode 805, loss:3.6437, succeed, steps:24, total reward:0.4000, 0.06132078170776367 sec\n",
      "Episode 806, loss:1.2517, succeed, steps:13, total reward:-0.7000, 0.034108638763427734 sec\n",
      "Episode 807, loss:-1.2510, fail, steps:29, total reward:-0.7000, 0.07157278060913086 sec\n",
      "Episode 808, loss:-1.2523, fail, steps:30, total reward:0.3000, 0.0756676197052002 sec\n",
      "Episode 809, loss:-3.2030, fail, steps:29, total reward:-2.7000, 0.07321000099182129 sec\n",
      "Episode 810, loss:-3.4080, fail, steps:29, total reward:-1.7000, 0.07297515869140625 sec\n",
      "Episode 811, loss:0.6375, fail, steps:30, total reward:1.6000, 0.07593011856079102 sec\n",
      "Episode 812, loss:1.7868, succeed, steps:11, total reward:0.6000, 0.03011798858642578 sec\n",
      "Episode 813, loss:-3.0664, fail, steps:29, total reward:-1.7000, 0.07184505462646484 sec\n",
      "Episode 814, loss:-2.0570, fail, steps:29, total reward:-0.7000, 0.07245993614196777 sec\n",
      "Episode 815, loss:3.2106, succeed, steps:29, total reward:-1.2000, 0.07430696487426758 sec\n",
      "Episode 816, loss:6.6916, succeed, steps:29, total reward:2.1000, 0.07315397262573242 sec\n",
      "Episode 817, loss:1.1780, succeed, steps:13, total reward:-0.7000, 0.03447771072387695 sec\n",
      "Episode 818, loss:1.1026, succeed, steps:19, total reward:-1.3000, 0.0479588508605957 sec\n",
      "Episode 819, loss:1.0536, fail, steps:30, total reward:2.6000, 0.07467365264892578 sec\n",
      "Episode 820, loss:5.7872, succeed, steps:27, total reward:0.1000, 0.06815147399902344 sec\n",
      "Episode 821, loss:-2.1421, fail, steps:29, total reward:-0.7000, 0.07444024085998535 sec\n",
      "Episode 822, loss:-1.2499, fail, steps:29, total reward:-0.7000, 0.07597517967224121 sec\n",
      "Episode 823, loss:0.7583, succeed, steps:4, total reward:0.2000, 0.013156414031982422 sec\n",
      "Episode 824, loss:4.3608, succeed, steps:25, total reward:1.4000, 0.06153273582458496 sec\n",
      "Episode 825, loss:0.8840, fail, steps:30, total reward:1.6000, 0.07438087463378906 sec\n",
      "Episode 826, loss:5.4157, succeed, steps:29, total reward:2.1000, 0.07341742515563965 sec\n",
      "Episode 827, loss:2.7810, succeed, steps:14, total reward:0.3000, 0.03707122802734375 sec\n",
      "Episode 828, loss:-1.6439, fail, steps:29, total reward:-0.7000, 0.07186293601989746 sec\n",
      "Episode 829, loss:4.1945, succeed, steps:25, total reward:1.4000, 0.06269216537475586 sec\n",
      "Episode 830, loss:6.0554, succeed, steps:26, total reward:2.4000, 0.0664517879486084 sec\n",
      "Episode 831, loss:1.5727, succeed, steps:8, total reward:0.9000, 0.022331953048706055 sec\n",
      "Episode 832, loss:-4.0645, fail, steps:29, total reward:-1.7000, 0.0713188648223877 sec\n",
      "Episode 833, loss:-2.7969, fail, steps:29, total reward:-0.7000, 0.07227540016174316 sec\n",
      "Episode 834, loss:2.3158, succeed, steps:23, total reward:-0.6000, 0.05891847610473633 sec\n",
      "Episode 835, loss:-3.9527, fail, steps:29, total reward:-2.7000, 0.07256746292114258 sec\n",
      "Episode 836, loss:-2.4712, fail, steps:29, total reward:-0.7000, 0.07294392585754395 sec\n",
      "Episode 837, loss:0.4658, fail, steps:30, total reward:1.6000, 0.07571196556091309 sec\n",
      "Episode 838, loss:4.2275, succeed, steps:18, total reward:1.0000, 0.046994924545288086 sec\n",
      "Episode 839, loss:-0.9525, fail, steps:30, total reward:0.3000, 0.07458257675170898 sec\n",
      "Episode 840, loss:-1.7757, fail, steps:30, total reward:0.3000, 0.07523894309997559 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 841, loss:2.6955, succeed, steps:21, total reward:0.7000, 0.05435776710510254 sec\n",
      "Episode 842, loss:-1.6845, fail, steps:29, total reward:-0.7000, 0.07266736030578613 sec\n",
      "Episode 843, loss:-5.1395, fail, steps:29, total reward:-2.7000, 0.07293367385864258 sec\n",
      "Episode 844, loss:-0.2155, fail, steps:30, total reward:1.6000, 0.07591867446899414 sec\n",
      "Episode 845, loss:-1.1622, fail, steps:29, total reward:-0.7000, 0.07319021224975586 sec\n",
      "Episode 846, loss:3.1752, succeed, steps:27, total reward:0.1000, 0.06812810897827148 sec\n",
      "Episode 847, loss:-1.0997, fail, steps:29, total reward:-0.7000, 0.07332897186279297 sec\n",
      "Episode 848, loss:3.4422, succeed, steps:11, total reward:0.6000, 0.029901981353759766 sec\n",
      "Episode 849, loss:2.1726, succeed, steps:20, total reward:-0.3000, 0.05026721954345703 sec\n",
      "Episode 850, loss:1.7917, fail, steps:30, total reward:1.6000, 0.07425999641418457 sec\n",
      "Episode 851, loss:-1.0569, fail, steps:30, total reward:0.3000, 0.07551074028015137 sec\n",
      "Episode 852, loss:-1.9132, fail, steps:29, total reward:-0.7000, 0.07325577735900879 sec\n",
      "Episode 853, loss:-1.5267, fail, steps:30, total reward:0.3000, 0.07538580894470215 sec\n",
      "Episode 854, loss:4.3852, succeed, steps:22, total reward:1.7000, 0.05952024459838867 sec\n",
      "Episode 855, loss:-0.7607, fail, steps:30, total reward:0.3000, 0.0767056941986084 sec\n",
      "Episode 856, loss:-1.1148, fail, steps:29, total reward:-0.7000, 0.07443857192993164 sec\n",
      "Episode 857, loss:-0.8631, fail, steps:30, total reward:0.0000, 0.076171875 sec\n",
      "Episode 858, loss:3.5768, succeed, steps:12, total reward:1.6000, 0.032393455505371094 sec\n",
      "Episode 859, loss:0.8141, succeed, steps:8, total reward:0.9000, 0.021698474884033203 sec\n",
      "Episode 860, loss:-1.3217, fail, steps:30, total reward:0.3000, 0.0732877254486084 sec\n",
      "Episode 861, loss:-1.9985, fail, steps:29, total reward:-2.7000, 0.07237982749938965 sec\n",
      "Episode 862, loss:1.4077, succeed, steps:16, total reward:-1.0000, 0.04215073585510254 sec\n",
      "Episode 863, loss:1.7677, succeed, steps:14, total reward:0.3000, 0.036225080490112305 sec\n",
      "Episode 864, loss:2.0068, succeed, steps:14, total reward:0.3000, 0.03599357604980469 sec\n",
      "Episode 865, loss:-0.4146, fail, steps:29, total reward:-0.7000, 0.0717763900756836 sec\n",
      "Episode 866, loss:-2.2886, fail, steps:29, total reward:-0.7000, 0.07311892509460449 sec\n",
      "Episode 867, loss:2.1956, succeed, steps:17, total reward:0.0000, 0.04427480697631836 sec\n",
      "Episode 868, loss:2.0322, succeed, steps:14, total reward:0.3000, 0.036237239837646484 sec\n",
      "Episode 869, loss:5.7657, succeed, steps:26, total reward:2.4000, 0.06446433067321777 sec\n",
      "Episode 870, loss:-0.7337, fail, steps:30, total reward:0.3000, 0.07540082931518555 sec\n",
      "Episode 871, loss:0.3919, succeed, steps:4, total reward:0.2000, 0.01282811164855957 sec\n",
      "Episode 872, loss:4.7007, succeed, steps:24, total reward:0.4000, 0.05899453163146973 sec\n",
      "Episode 873, loss:-1.4045, fail, steps:29, total reward:-0.7000, 0.07199239730834961 sec\n",
      "Episode 874, loss:0.5260, succeed, steps:4, total reward:0.2000, 0.012581825256347656 sec\n",
      "Episode 875, loss:2.9973, succeed, steps:17, total reward:0.0000, 0.04229307174682617 sec\n",
      "Episode 876, loss:-2.7600, fail, steps:29, total reward:-0.7000, 0.07197022438049316 sec\n",
      "Episode 877, loss:1.9576, succeed, steps:17, total reward:0.0000, 0.04388785362243652 sec\n",
      "Episode 878, loss:5.3167, succeed, steps:27, total reward:0.1000, 0.06708097457885742 sec\n",
      "Episode 879, loss:0.7166, fail, steps:30, total reward:1.6000, 0.07475900650024414 sec\n",
      "Episode 880, loss:3.0438, succeed, steps:21, total reward:0.7000, 0.054915666580200195 sec\n",
      "Episode 881, loss:4.3607, succeed, steps:20, total reward:3.0000, 0.05205512046813965 sec\n",
      "Episode 882, loss:-3.0429, fail, steps:29, total reward:-1.7000, 0.07356095314025879 sec\n",
      "Episode 883, loss:2.4774, succeed, steps:15, total reward:1.3000, 0.039894819259643555 sec\n",
      "Episode 884, loss:-2.5309, fail, steps:29, total reward:-0.7000, 0.07381892204284668 sec\n",
      "Episode 885, loss:1.7605, succeed, steps:12, total reward:1.6000, 0.0326075553894043 sec\n",
      "Episode 886, loss:4.4350, succeed, steps:24, total reward:0.4000, 0.06092953681945801 sec\n",
      "Episode 887, loss:4.2326, succeed, steps:28, total reward:1.1000, 0.07124519348144531 sec\n",
      "Episode 888, loss:4.5648, succeed, steps:22, total reward:1.7000, 0.05755877494812012 sec\n",
      "Episode 889, loss:2.4299, succeed, steps:15, total reward:1.3000, 0.03980398178100586 sec\n",
      "Episode 890, loss:-1.3924, fail, steps:29, total reward:-0.7000, 0.0731360912322998 sec\n",
      "Episode 891, loss:3.5570, succeed, steps:21, total reward:0.7000, 0.055484771728515625 sec\n",
      "Episode 892, loss:2.2256, succeed, steps:23, total reward:-0.6000, 0.060518741607666016 sec\n",
      "Episode 893, loss:-0.0304, fail, steps:30, total reward:0.3000, 0.0768275260925293 sec\n",
      "Episode 894, loss:-1.5781, fail, steps:29, total reward:-0.7000, 0.07430267333984375 sec\n",
      "Episode 895, loss:-1.0083, fail, steps:30, total reward:0.3000, 0.07604193687438965 sec\n",
      "Episode 896, loss:3.2070, succeed, steps:18, total reward:1.0000, 0.04667973518371582 sec\n",
      "Episode 897, loss:3.1390, succeed, steps:20, total reward:-0.3000, 0.05060172080993652 sec\n",
      "Episode 898, loss:2.3651, succeed, steps:24, total reward:0.4000, 0.06011962890625 sec\n",
      "Episode 899, loss:3.5310, succeed, steps:18, total reward:1.0000, 0.046141624450683594 sec\n",
      "len4 start4 Comparison 5 6 less Comparison 6 7 more Swap Comparison 5 6 more Swap Comparison 4 7 less Comparison 4 5 more Swap Comparison 5 6 more Swap\n",
      "Episode 900, loss:4.7903, succeed, steps:22, total reward:1.7000, 0.05552411079406738 sec\n",
      "Episode 901, loss:-1.0239, fail, steps:30, total reward:0.3000, 0.07458639144897461 sec\n",
      "Episode 902, loss:4.2399, succeed, steps:24, total reward:0.4000, 0.06077003479003906 sec\n",
      "Episode 903, loss:-1.7283, fail, steps:30, total reward:0.3000, 0.07593464851379395 sec\n",
      "Episode 904, loss:4.2253, succeed, steps:28, total reward:1.1000, 0.07054352760314941 sec\n",
      "Episode 905, loss:-1.0601, fail, steps:29, total reward:-0.7000, 0.0731043815612793 sec\n",
      "Episode 906, loss:6.8439, succeed, steps:26, total reward:2.4000, 0.066314697265625 sec\n",
      "Episode 907, loss:-4.2433, fail, steps:29, total reward:-2.7000, 0.07303452491760254 sec\n",
      "Episode 908, loss:2.0882, succeed, steps:14, total reward:0.3000, 0.03694415092468262 sec\n",
      "Episode 909, loss:2.0499, succeed, steps:14, total reward:0.3000, 0.03608059883117676 sec\n",
      "Episode 910, loss:-1.0927, fail, steps:29, total reward:-1.7000, 0.07236933708190918 sec\n",
      "Episode 911, loss:4.0590, succeed, steps:28, total reward:1.1000, 0.07044053077697754 sec\n",
      "Episode 912, loss:2.4667, succeed, steps:8, total reward:0.9000, 0.02231740951538086 sec\n",
      "Episode 913, loss:-3.3064, fail, steps:29, total reward:-1.7000, 0.07133316993713379 sec\n",
      "Episode 914, loss:3.0301, succeed, steps:12, total reward:1.6000, 0.03168654441833496 sec\n",
      "Episode 915, loss:-2.2382, fail, steps:29, total reward:-2.7000, 0.0719459056854248 sec\n",
      "Episode 916, loss:2.5274, succeed, steps:15, total reward:1.3000, 0.038977861404418945 sec\n",
      "Episode 917, loss:-2.0249, fail, steps:29, total reward:-0.7000, 0.07217693328857422 sec\n",
      "Episode 918, loss:1.6649, succeed, steps:25, total reward:-1.9000, 0.06289124488830566 sec\n",
      "Episode 919, loss:-0.8201, fail, steps:30, total reward:0.3000, 0.07591676712036133 sec\n",
      "Episode 920, loss:-0.8658, fail, steps:30, total reward:0.3000, 0.07545924186706543 sec\n",
      "Episode 921, loss:-3.6663, fail, steps:29, total reward:-1.7000, 0.0731356143951416 sec\n",
      "Episode 922, loss:-0.4354, fail, steps:29, total reward:-0.7000, 0.07366061210632324 sec\n",
      "Episode 923, loss:3.3144, succeed, steps:15, total reward:1.3000, 0.039461374282836914 sec\n",
      "Episode 924, loss:2.6099, succeed, steps:26, total reward:-0.9000, 0.06500077247619629 sec\n",
      "Episode 925, loss:-1.8117, fail, steps:29, total reward:-1.7000, 0.07501935958862305 sec\n",
      "Episode 926, loss:3.2059, succeed, steps:18, total reward:1.0000, 0.04868340492248535 sec\n",
      "Episode 927, loss:-0.6791, fail, steps:30, total reward:0.3000, 0.07511496543884277 sec\n",
      "Episode 928, loss:3.1306, succeed, steps:27, total reward:0.1000, 0.06791448593139648 sec\n",
      "Episode 929, loss:0.2937, succeed, steps:4, total reward:0.2000, 0.012639522552490234 sec\n",
      "Episode 930, loss:5.3320, succeed, steps:22, total reward:1.7000, 0.054582834243774414 sec\n",
      "Episode 931, loss:-1.6601, fail, steps:29, total reward:-0.7000, 0.0718069076538086 sec\n",
      "Episode 932, loss:2.2314, succeed, steps:17, total reward:0.0000, 0.04383063316345215 sec\n",
      "Episode 933, loss:-3.4756, fail, steps:29, total reward:-1.7000, 0.07214641571044922 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 934, loss:-1.0321, fail, steps:29, total reward:-0.7000, 0.07310247421264648 sec\n",
      "Episode 935, loss:3.3177, succeed, steps:23, total reward:-0.6000, 0.05852198600769043 sec\n",
      "Episode 936, loss:1.9639, succeed, steps:17, total reward:0.0000, 0.04394340515136719 sec\n",
      "Episode 937, loss:-3.1290, fail, steps:29, total reward:-1.7000, 0.07201290130615234 sec\n",
      "Episode 938, loss:3.6690, succeed, steps:21, total reward:0.7000, 0.05382084846496582 sec\n",
      "Episode 939, loss:2.7267, succeed, steps:21, total reward:0.7000, 0.05332779884338379 sec\n",
      "Episode 940, loss:-1.1301, fail, steps:29, total reward:-0.7000, 0.07239818572998047 sec\n",
      "Episode 941, loss:-3.4873, fail, steps:29, total reward:-1.7000, 0.07308697700500488 sec\n",
      "Episode 942, loss:2.4983, succeed, steps:15, total reward:1.3000, 0.039762258529663086 sec\n",
      "Episode 943, loss:-2.5849, fail, steps:29, total reward:-1.7000, 0.07241582870483398 sec\n",
      "Episode 944, loss:-2.2789, fail, steps:29, total reward:-0.7000, 0.07254552841186523 sec\n",
      "Episode 945, loss:-1.6818, fail, steps:29, total reward:-0.7000, 0.07317638397216797 sec\n",
      "Episode 946, loss:3.4136, succeed, steps:18, total reward:1.0000, 0.0465388298034668 sec\n",
      "Episode 947, loss:3.1562, succeed, steps:27, total reward:-0.5000, 0.0675206184387207 sec\n",
      "Episode 948, loss:-2.5740, fail, steps:29, total reward:-0.7000, 0.07265639305114746 sec\n",
      "Episode 949, loss:3.4117, succeed, steps:18, total reward:1.0000, 0.047059059143066406 sec\n",
      "Episode 950, loss:-1.0409, fail, steps:29, total reward:-0.7000, 0.07221436500549316 sec\n",
      "Episode 951, loss:2.6333, succeed, steps:23, total reward:-0.6000, 0.05845308303833008 sec\n",
      "Episode 952, loss:-0.9045, fail, steps:30, total reward:0.3000, 0.07528018951416016 sec\n",
      "Episode 953, loss:-0.5261, fail, steps:30, total reward:0.3000, 0.07536053657531738 sec\n",
      "Episode 954, loss:-1.1924, fail, steps:30, total reward:0.3000, 0.0754389762878418 sec\n",
      "Episode 955, loss:2.2443, succeed, steps:20, total reward:-0.3000, 0.05197906494140625 sec\n",
      "Episode 956, loss:2.5477, succeed, steps:15, total reward:1.3000, 0.03910017013549805 sec\n",
      "Episode 957, loss:2.3007, succeed, steps:17, total reward:0.0000, 0.04310941696166992 sec\n",
      "Episode 958, loss:3.4859, succeed, steps:28, total reward:1.1000, 0.06943035125732422 sec\n",
      "Episode 959, loss:-2.4830, fail, steps:29, total reward:-0.7000, 0.07509756088256836 sec\n",
      "Episode 960, loss:-2.4739, fail, steps:30, total reward:0.3000, 0.07915639877319336 sec\n",
      "Episode 961, loss:4.6331, succeed, steps:28, total reward:1.1000, 0.07240724563598633 sec\n",
      "Episode 962, loss:3.3324, succeed, steps:15, total reward:1.3000, 0.03966927528381348 sec\n",
      "Episode 963, loss:-1.6410, fail, steps:29, total reward:-1.7000, 0.0723426342010498 sec\n",
      "Episode 964, loss:2.7051, succeed, steps:18, total reward:1.0000, 0.046363115310668945 sec\n",
      "Episode 965, loss:-1.6230, fail, steps:30, total reward:0.3000, 0.07468605041503906 sec\n",
      "Episode 966, loss:1.2454, succeed, steps:8, total reward:0.9000, 0.022346973419189453 sec\n",
      "Episode 967, loss:-1.1452, fail, steps:30, total reward:0.3000, 0.07394838333129883 sec\n",
      "Episode 968, loss:-2.6647, fail, steps:29, total reward:-1.7000, 0.07290911674499512 sec\n",
      "Episode 969, loss:2.8870, succeed, steps:12, total reward:1.6000, 0.03213620185852051 sec\n",
      "Episode 970, loss:2.2674, succeed, steps:14, total reward:0.3000, 0.03586173057556152 sec\n",
      "Episode 971, loss:1.9362, succeed, steps:8, total reward:0.9000, 0.021416187286376953 sec\n",
      "Episode 972, loss:3.9605, succeed, steps:27, total reward:0.1000, 0.06652188301086426 sec\n",
      "Episode 973, loss:-0.7993, fail, steps:30, total reward:0.3000, 0.07457280158996582 sec\n",
      "Episode 974, loss:3.7184, succeed, steps:24, total reward:0.4000, 0.06099581718444824 sec\n",
      "Episode 975, loss:-0.1796, fail, steps:29, total reward:-0.7000, 0.07258772850036621 sec\n",
      "Episode 976, loss:-4.1078, fail, steps:29, total reward:-2.7000, 0.07322430610656738 sec\n",
      "Episode 977, loss:-2.6251, fail, steps:29, total reward:-2.7000, 0.07315301895141602 sec\n",
      "Episode 978, loss:2.0955, succeed, steps:26, total reward:-1.5000, 0.06641387939453125 sec\n",
      "Episode 979, loss:2.2846, succeed, steps:28, total reward:-2.2000, 0.07071948051452637 sec\n",
      "Episode 980, loss:5.4935, succeed, steps:23, total reward:2.7000, 0.058640480041503906 sec\n",
      "Episode 981, loss:0.9382, succeed, steps:7, total reward:-0.1000, 0.01994180679321289 sec\n",
      "Episode 982, loss:2.8039, succeed, steps:26, total reward:-0.9000, 0.06475424766540527 sec\n",
      "Episode 983, loss:-0.7685, fail, steps:30, total reward:0.3000, 0.07467031478881836 sec\n",
      "Episode 984, loss:-0.5379, fail, steps:30, total reward:0.3000, 0.07515478134155273 sec\n",
      "Episode 985, loss:-1.6413, fail, steps:29, total reward:-0.7000, 0.07338237762451172 sec\n",
      "Episode 986, loss:4.6925, succeed, steps:25, total reward:1.4000, 0.06367707252502441 sec\n",
      "Episode 987, loss:1.1905, succeed, steps:19, total reward:-1.3000, 0.048699140548706055 sec\n",
      "Episode 988, loss:-1.0738, fail, steps:30, total reward:0.3000, 0.07465124130249023 sec\n",
      "Episode 989, loss:1.1763, fail, steps:30, total reward:1.6000, 0.07593989372253418 sec\n",
      "Episode 990, loss:2.2287, succeed, steps:23, total reward:-0.6000, 0.05902862548828125 sec\n",
      "Episode 991, loss:2.0317, succeed, steps:17, total reward:0.0000, 0.043901681900024414 sec\n",
      "Episode 992, loss:2.8105, succeed, steps:21, total reward:0.7000, 0.05298304557800293 sec\n",
      "Episode 993, loss:-1.4203, fail, steps:29, total reward:-0.7000, 0.07387137413024902 sec\n",
      "Episode 994, loss:3.2379, succeed, steps:12, total reward:1.6000, 0.033510684967041016 sec\n",
      "Episode 995, loss:5.3698, succeed, steps:22, total reward:1.7000, 0.05708813667297363 sec\n",
      "Episode 996, loss:2.6968, succeed, steps:11, total reward:0.6000, 0.02987957000732422 sec\n",
      "Episode 997, loss:-1.8686, fail, steps:29, total reward:-1.7000, 0.07300782203674316 sec\n",
      "Episode 998, loss:2.8944, succeed, steps:29, total reward:-1.2000, 0.07496857643127441 sec\n",
      "Episode 999, loss:3.8630, succeed, steps:24, total reward:0.4000, 0.06211113929748535 sec\n",
      "Checkpoint saved at episode 1000 to /home/mcwave/code/autocode/datasets/rl_sort_transformer_curriculum/list4_transformer4_192_gamma07_step40_v1/ckpt_1000_0.4870_22.97.pth\n",
      "Learning rate = 0.000048\n",
      "Episode 1000, loss:-1.1846, fail, steps:30, total reward:0.3000, 0.10863804817199707 sec\n",
      "Episode 1001, loss:-3.1771, fail, steps:29, total reward:-1.7000, 0.07489776611328125 sec\n",
      "Episode 1002, loss:1.5549, succeed, steps:11, total reward:0.6000, 0.02988290786743164 sec\n",
      "Episode 1003, loss:0.3579, fail, steps:30, total reward:1.6000, 0.07394218444824219 sec\n",
      "Episode 1004, loss:-4.8051, fail, steps:29, total reward:-1.7000, 0.07258033752441406 sec\n",
      "Episode 1005, loss:2.0163, succeed, steps:14, total reward:0.0000, 0.03739643096923828 sec\n",
      "Episode 1006, loss:0.9125, succeed, steps:7, total reward:-0.1000, 0.019406557083129883 sec\n",
      "Episode 1007, loss:2.2935, succeed, steps:17, total reward:0.0000, 0.04243803024291992 sec\n",
      "Episode 1008, loss:3.4482, succeed, steps:24, total reward:0.4000, 0.059372663497924805 sec\n",
      "Episode 1009, loss:-3.3964, fail, steps:29, total reward:-2.7000, 0.07221508026123047 sec\n",
      "Episode 1010, loss:3.0964, succeed, steps:21, total reward:0.7000, 0.0541682243347168 sec\n",
      "Episode 1011, loss:1.2180, succeed, steps:8, total reward:0.9000, 0.022278785705566406 sec\n",
      "Episode 1012, loss:-1.4557, fail, steps:29, total reward:-1.7000, 0.07114434242248535 sec\n",
      "Episode 1013, loss:-1.8537, fail, steps:29, total reward:-0.7000, 0.07248759269714355 sec\n",
      "Episode 1014, loss:1.8490, succeed, steps:14, total reward:0.3000, 0.037149906158447266 sec\n",
      "Episode 1015, loss:4.5739, succeed, steps:25, total reward:1.4000, 0.062496185302734375 sec\n",
      "Episode 1016, loss:-1.0562, fail, steps:29, total reward:-0.7000, 0.0728003978729248 sec\n",
      "Episode 1017, loss:5.2235, succeed, steps:27, total reward:0.1000, 0.06838393211364746 sec\n",
      "Episode 1018, loss:4.4173, succeed, steps:27, total reward:3.4000, 0.06841063499450684 sec\n",
      "Episode 1019, loss:1.4423, succeed, steps:13, total reward:-0.7000, 0.03458595275878906 sec\n",
      "Episode 1020, loss:2.3143, succeed, steps:11, total reward:0.6000, 0.028750896453857422 sec\n",
      "Episode 1021, loss:2.9777, succeed, steps:18, total reward:1.0000, 0.04502272605895996 sec\n",
      "Episode 1022, loss:2.3982, succeed, steps:18, total reward:1.0000, 0.04562115669250488 sec\n",
      "Episode 1023, loss:-1.0501, fail, steps:29, total reward:-0.7000, 0.07164120674133301 sec\n",
      "Episode 1024, loss:1.1964, succeed, steps:7, total reward:-0.1000, 0.019713640213012695 sec\n",
      "Episode 1025, loss:-4.0603, fail, steps:29, total reward:-2.7000, 0.0711514949798584 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1026, loss:-0.3105, fail, steps:29, total reward:-0.7000, 0.07290101051330566 sec\n",
      "Episode 1027, loss:-1.2838, fail, steps:30, total reward:0.3000, 0.07694172859191895 sec\n",
      "Episode 1028, loss:2.1782, succeed, steps:17, total reward:0.0000, 0.04504871368408203 sec\n",
      "Episode 1029, loss:4.2378, succeed, steps:24, total reward:0.4000, 0.06122183799743652 sec\n",
      "Episode 1030, loss:1.7242, succeed, steps:17, total reward:0.0000, 0.04499244689941406 sec\n",
      "Episode 1031, loss:-1.8024, fail, steps:29, total reward:-0.7000, 0.07557463645935059 sec\n",
      "Episode 1032, loss:3.2325, succeed, steps:12, total reward:1.6000, 0.032470703125 sec\n",
      "Episode 1033, loss:0.7062, fail, steps:30, total reward:1.6000, 0.07582306861877441 sec\n",
      "Episode 1034, loss:-3.6504, fail, steps:29, total reward:-1.7000, 0.07485485076904297 sec\n",
      "Episode 1035, loss:4.8963, succeed, steps:18, total reward:1.0000, 0.047556400299072266 sec\n",
      "Episode 1036, loss:-2.4479, fail, steps:29, total reward:-1.7000, 0.0735330581665039 sec\n",
      "Episode 1037, loss:-0.8122, fail, steps:30, total reward:0.3000, 0.07694172859191895 sec\n",
      "Episode 1038, loss:0.9205, succeed, steps:10, total reward:-0.4000, 0.028168916702270508 sec\n",
      "Episode 1039, loss:5.2649, succeed, steps:29, total reward:2.1000, 0.0717172622680664 sec\n",
      "Episode 1040, loss:0.9445, succeed, steps:7, total reward:-0.1000, 0.01970362663269043 sec\n",
      "Episode 1041, loss:3.1680, succeed, steps:29, total reward:-1.2000, 0.07115888595581055 sec\n",
      "Episode 1042, loss:-1.1438, fail, steps:29, total reward:-1.7000, 0.07270002365112305 sec\n",
      "Episode 1043, loss:1.1739, succeed, steps:7, total reward:-0.1000, 0.020407438278198242 sec\n",
      "Episode 1044, loss:-0.8811, fail, steps:30, total reward:0.3000, 0.07360529899597168 sec\n",
      "Episode 1045, loss:-0.0327, fail, steps:30, total reward:1.6000, 0.07471656799316406 sec\n",
      "Episode 1046, loss:2.5952, succeed, steps:17, total reward:0.0000, 0.0445256233215332 sec\n",
      "Episode 1047, loss:3.6021, succeed, steps:20, total reward:-0.3000, 0.05070900917053223 sec\n",
      "Episode 1048, loss:2.4462, succeed, steps:20, total reward:-0.3000, 0.05051445960998535 sec\n",
      "Episode 1049, loss:0.0749, fail, steps:30, total reward:0.3000, 0.07442378997802734 sec\n",
      "Episode 1050, loss:3.3395, succeed, steps:25, total reward:1.4000, 0.0639333724975586 sec\n",
      "Episode 1051, loss:1.7173, succeed, steps:11, total reward:0.6000, 0.029550552368164062 sec\n",
      "Episode 1052, loss:1.4008, succeed, steps:7, total reward:-0.1000, 0.018986225128173828 sec\n",
      "Episode 1053, loss:0.7009, succeed, steps:4, total reward:0.2000, 0.011607885360717773 sec\n",
      "Episode 1054, loss:-0.8907, fail, steps:29, total reward:-0.7000, 0.07054376602172852 sec\n",
      "Episode 1055, loss:0.6468, fail, steps:30, total reward:1.6000, 0.07491374015808105 sec\n",
      "Episode 1056, loss:-0.5826, fail, steps:29, total reward:-0.7000, 0.07301592826843262 sec\n",
      "Episode 1057, loss:-2.8168, fail, steps:30, total reward:0.3000, 0.07528948783874512 sec\n",
      "Episode 1058, loss:2.1564, succeed, steps:22, total reward:-1.6000, 0.0567784309387207 sec\n",
      "Episode 1059, loss:4.2292, succeed, steps:21, total reward:0.7000, 0.05354595184326172 sec\n",
      "Episode 1060, loss:3.8565, succeed, steps:15, total reward:1.3000, 0.03855133056640625 sec\n",
      "Episode 1061, loss:3.5576, succeed, steps:21, total reward:0.4000, 0.05294036865234375 sec\n",
      "Episode 1062, loss:-4.6291, fail, steps:29, total reward:-1.7000, 0.07247042655944824 sec\n",
      "Episode 1063, loss:1.2965, succeed, steps:25, total reward:-1.9000, 0.06317257881164551 sec\n",
      "Episode 1064, loss:1.7635, succeed, steps:8, total reward:0.9000, 0.022031068801879883 sec\n",
      "Episode 1065, loss:1.0895, succeed, steps:7, total reward:-0.1000, 0.018867969512939453 sec\n",
      "Episode 1066, loss:3.5838, succeed, steps:27, total reward:0.1000, 0.06601905822753906 sec\n",
      "Episode 1067, loss:5.2449, succeed, steps:21, total reward:0.7000, 0.05321192741394043 sec\n",
      "Episode 1068, loss:0.5383, succeed, steps:4, total reward:0.2000, 0.012482166290283203 sec\n",
      "Episode 1069, loss:0.5590, succeed, steps:4, total reward:0.2000, 0.011426687240600586 sec\n",
      "Episode 1070, loss:0.6213, fail, steps:30, total reward:1.6000, 0.07480812072753906 sec\n",
      "Episode 1071, loss:1.6446, succeed, steps:13, total reward:-0.7000, 0.03580188751220703 sec\n",
      "Episode 1072, loss:0.6948, succeed, steps:7, total reward:-0.1000, 0.01973271369934082 sec\n",
      "Episode 1073, loss:-2.4223, fail, steps:29, total reward:-1.7000, 0.07321524620056152 sec\n",
      "Episode 1074, loss:-0.5223, fail, steps:30, total reward:0.3000, 0.07631564140319824 sec\n",
      "Episode 1075, loss:1.9699, succeed, steps:17, total reward:0.0000, 0.04506945610046387 sec\n",
      "Episode 1076, loss:2.9219, succeed, steps:27, total reward:0.1000, 0.06856513023376465 sec\n",
      "Episode 1077, loss:0.5487, succeed, steps:4, total reward:0.2000, 0.013050317764282227 sec\n",
      "Episode 1078, loss:-0.8284, fail, steps:29, total reward:-0.7000, 0.07236027717590332 sec\n",
      "Episode 1079, loss:3.8657, succeed, steps:16, total reward:2.3000, 0.04210996627807617 sec\n",
      "Episode 1080, loss:1.2447, succeed, steps:4, total reward:0.2000, 0.012393712997436523 sec\n",
      "Episode 1081, loss:4.6371, succeed, steps:23, total reward:2.7000, 0.05762529373168945 sec\n",
      "Episode 1082, loss:2.4374, succeed, steps:15, total reward:1.3000, 0.03983020782470703 sec\n",
      "Episode 1083, loss:-1.5849, fail, steps:29, total reward:-0.7000, 0.07293486595153809 sec\n",
      "Episode 1084, loss:-2.9297, fail, steps:29, total reward:-2.7000, 0.07392477989196777 sec\n",
      "Episode 1085, loss:2.5694, succeed, steps:17, total reward:0.0000, 0.044976234436035156 sec\n",
      "Episode 1086, loss:-0.8081, fail, steps:30, total reward:0.3000, 0.07493734359741211 sec\n",
      "Episode 1087, loss:-2.0881, fail, steps:29, total reward:-1.7000, 0.07267141342163086 sec\n",
      "Episode 1088, loss:-2.1550, fail, steps:29, total reward:-2.7000, 0.07313776016235352 sec\n",
      "Episode 1089, loss:3.6420, succeed, steps:28, total reward:0.5000, 0.07246756553649902 sec\n",
      "Episode 1090, loss:-1.1133, fail, steps:30, total reward:0.3000, 0.0759744644165039 sec\n",
      "Episode 1091, loss:3.5449, succeed, steps:18, total reward:1.0000, 0.04674720764160156 sec\n",
      "Episode 1092, loss:-3.8212, fail, steps:29, total reward:-1.7000, 0.07236075401306152 sec\n",
      "Episode 1093, loss:3.8805, succeed, steps:27, total reward:0.1000, 0.06859207153320312 sec\n",
      "Episode 1094, loss:-1.7311, fail, steps:30, total reward:0.3000, 0.07555150985717773 sec\n",
      "Episode 1095, loss:-1.1926, fail, steps:30, total reward:0.3000, 0.07556414604187012 sec\n",
      "Episode 1096, loss:-2.7519, fail, steps:29, total reward:-0.7000, 0.07375311851501465 sec\n",
      "Episode 1097, loss:-1.7466, fail, steps:30, total reward:0.3000, 0.07716488838195801 sec\n",
      "Episode 1098, loss:-0.7749, fail, steps:30, total reward:0.3000, 0.07585668563842773 sec\n",
      "Episode 1099, loss:2.1238, succeed, steps:24, total reward:0.4000, 0.06180739402770996 sec\n",
      "len4 start8 Comparison 10 11 less Comparison 10 11 less Comparison 10 11 less Comparison 9 10 less Comparison 8 9 more Swap\n",
      "Episode 1100, loss:2.0308, succeed, steps:16, total reward:-1.0000, 0.04202747344970703 sec\n",
      "Episode 1101, loss:3.4493, succeed, steps:18, total reward:1.0000, 0.0457611083984375 sec\n",
      "Episode 1102, loss:-2.4587, fail, steps:29, total reward:-1.7000, 0.07178449630737305 sec\n",
      "Episode 1103, loss:-1.5319, fail, steps:29, total reward:-0.7000, 0.07333612442016602 sec\n",
      "Episode 1104, loss:-0.4495, fail, steps:30, total reward:0.3000, 0.07560563087463379 sec\n",
      "Episode 1105, loss:2.7128, succeed, steps:18, total reward:1.0000, 0.0485227108001709 sec\n",
      "Episode 1106, loss:1.8569, succeed, steps:20, total reward:-0.3000, 0.05207061767578125 sec\n",
      "Episode 1107, loss:-0.5162, fail, steps:30, total reward:0.3000, 0.07524514198303223 sec\n",
      "Episode 1108, loss:-1.3896, fail, steps:29, total reward:-0.7000, 0.07294631004333496 sec\n",
      "Episode 1109, loss:2.3783, succeed, steps:23, total reward:-0.6000, 0.05841398239135742 sec\n",
      "Episode 1110, loss:3.5685, succeed, steps:24, total reward:0.4000, 0.060476064682006836 sec\n",
      "Episode 1111, loss:-0.3334, fail, steps:30, total reward:0.3000, 0.07529807090759277 sec\n",
      "Episode 1112, loss:5.4238, succeed, steps:30, total reward:3.1000, 0.07562017440795898 sec\n",
      "Episode 1113, loss:4.9279, succeed, steps:25, total reward:1.4000, 0.06350350379943848 sec\n",
      "Episode 1114, loss:2.8444, succeed, steps:20, total reward:-0.3000, 0.05096793174743652 sec\n",
      "Episode 1115, loss:3.6324, succeed, steps:21, total reward:0.7000, 0.05347847938537598 sec\n",
      "Episode 1116, loss:3.0240, succeed, steps:21, total reward:0.7000, 0.05317878723144531 sec\n",
      "Episode 1117, loss:1.4557, succeed, steps:13, total reward:-0.7000, 0.03390216827392578 sec\n",
      "Episode 1118, loss:3.2228, succeed, steps:24, total reward:0.4000, 0.0598452091217041 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1119, loss:-1.4578, fail, steps:29, total reward:-0.7000, 0.07248783111572266 sec\n",
      "Episode 1120, loss:4.1063, succeed, steps:24, total reward:0.4000, 0.0609743595123291 sec\n",
      "Episode 1121, loss:0.0975, fail, steps:30, total reward:1.6000, 0.07558584213256836 sec\n",
      "Episode 1122, loss:-3.0790, fail, steps:29, total reward:-1.7000, 0.07341980934143066 sec\n",
      "Episode 1123, loss:-1.4337, fail, steps:29, total reward:-0.7000, 0.0735468864440918 sec\n",
      "Episode 1124, loss:-2.0979, fail, steps:29, total reward:-1.7000, 0.07298851013183594 sec\n",
      "Episode 1125, loss:-1.3624, fail, steps:29, total reward:-0.7000, 0.07358050346374512 sec\n",
      "Episode 1126, loss:-2.1942, fail, steps:29, total reward:-1.7000, 0.07322812080383301 sec\n",
      "Episode 1127, loss:-0.7195, fail, steps:30, total reward:1.6000, 0.07540535926818848 sec\n",
      "Episode 1128, loss:1.3366, succeed, steps:4, total reward:0.2000, 0.012821674346923828 sec\n",
      "Episode 1129, loss:-0.4595, fail, steps:30, total reward:0.3000, 0.07400298118591309 sec\n",
      "Episode 1130, loss:2.7366, succeed, steps:14, total reward:0.3000, 0.036884307861328125 sec\n",
      "Episode 1131, loss:2.3461, succeed, steps:17, total reward:0.0000, 0.043066978454589844 sec\n",
      "Episode 1132, loss:2.3396, succeed, steps:26, total reward:-0.9000, 0.06445479393005371 sec\n",
      "Episode 1133, loss:3.2952, succeed, steps:18, total reward:1.0000, 0.0460050106048584 sec\n",
      "Episode 1134, loss:-3.6709, fail, steps:29, total reward:-0.7000, 0.07247281074523926 sec\n",
      "Episode 1135, loss:2.8820, succeed, steps:8, total reward:0.9000, 0.02234029769897461 sec\n",
      "Episode 1136, loss:2.6712, succeed, steps:27, total reward:0.1000, 0.06639742851257324 sec\n",
      "Episode 1137, loss:3.4731, succeed, steps:22, total reward:1.7000, 0.05558133125305176 sec\n",
      "Episode 1138, loss:-3.3101, fail, steps:29, total reward:-0.7000, 0.07291030883789062 sec\n",
      "Episode 1139, loss:-1.7064, fail, steps:29, total reward:-0.7000, 0.07544112205505371 sec\n",
      "Episode 1140, loss:2.0810, succeed, steps:8, total reward:0.9000, 0.023036479949951172 sec\n",
      "Episode 1141, loss:1.7885, succeed, steps:26, total reward:-0.9000, 0.06579923629760742 sec\n",
      "Episode 1142, loss:-2.1935, fail, steps:29, total reward:-1.7000, 0.07418251037597656 sec\n",
      "Episode 1143, loss:-1.0780, fail, steps:30, total reward:0.3000, 0.07681655883789062 sec\n",
      "Episode 1144, loss:-2.0794, fail, steps:29, total reward:-0.7000, 0.07423233985900879 sec\n",
      "Episode 1145, loss:1.8275, succeed, steps:12, total reward:1.6000, 0.032758474349975586 sec\n",
      "Episode 1146, loss:-0.1031, fail, steps:30, total reward:0.3000, 0.07606196403503418 sec\n",
      "Episode 1147, loss:0.6764, fail, steps:30, total reward:1.6000, 0.07673025131225586 sec\n",
      "Episode 1148, loss:1.1670, succeed, steps:10, total reward:-0.4000, 0.02788519859313965 sec\n",
      "Episode 1149, loss:-0.2624, fail, steps:30, total reward:0.3000, 0.07553577423095703 sec\n",
      "Episode 1150, loss:0.8578, succeed, steps:10, total reward:-0.4000, 0.028007030487060547 sec\n",
      "Episode 1151, loss:3.4624, succeed, steps:27, total reward:0.1000, 0.06817245483398438 sec\n",
      "Episode 1152, loss:2.5436, succeed, steps:18, total reward:1.0000, 0.046935081481933594 sec\n",
      "Episode 1153, loss:3.2284, succeed, steps:27, total reward:0.1000, 0.0685124397277832 sec\n",
      "Episode 1154, loss:0.9880, succeed, steps:11, total reward:0.6000, 0.030522584915161133 sec\n",
      "Episode 1155, loss:-1.8497, fail, steps:29, total reward:-0.7000, 0.0734248161315918 sec\n",
      "Episode 1156, loss:2.8654, succeed, steps:16, total reward:2.3000, 0.04221320152282715 sec\n",
      "Episode 1157, loss:-1.3362, fail, steps:29, total reward:-1.7000, 0.0734400749206543 sec\n",
      "Episode 1158, loss:2.7514, succeed, steps:18, total reward:1.0000, 0.047443389892578125 sec\n",
      "Episode 1159, loss:1.8517, succeed, steps:16, total reward:-1.0000, 0.04099249839782715 sec\n",
      "Episode 1160, loss:1.9649, succeed, steps:20, total reward:-0.3000, 0.05029034614562988 sec\n",
      "Episode 1161, loss:2.1444, succeed, steps:23, total reward:-0.6000, 0.057299137115478516 sec\n",
      "Episode 1162, loss:-0.5690, fail, steps:30, total reward:0.3000, 0.07540488243103027 sec\n",
      "Episode 1163, loss:2.6232, succeed, steps:11, total reward:0.6000, 0.02985095977783203 sec\n",
      "Episode 1164, loss:0.9460, succeed, steps:7, total reward:-0.1000, 0.01904010772705078 sec\n",
      "Episode 1165, loss:4.9546, succeed, steps:19, total reward:2.0000, 0.04712200164794922 sec\n",
      "Episode 1166, loss:-2.0936, fail, steps:29, total reward:-0.7000, 0.07161760330200195 sec\n",
      "Episode 1167, loss:3.7750, succeed, steps:22, total reward:1.7000, 0.05631399154663086 sec\n",
      "Episode 1168, loss:1.8886, succeed, steps:10, total reward:-0.4000, 0.027045011520385742 sec\n",
      "Episode 1169, loss:-2.1040, fail, steps:29, total reward:-1.7000, 0.07124876976013184 sec\n",
      "Episode 1170, loss:-1.9480, fail, steps:29, total reward:-0.7000, 0.07227230072021484 sec\n",
      "Episode 1171, loss:-0.7624, fail, steps:30, total reward:0.3000, 0.07596325874328613 sec\n",
      "Episode 1172, loss:3.8449, succeed, steps:28, total reward:1.1000, 0.07085561752319336 sec\n",
      "Episode 1173, loss:2.8957, succeed, steps:16, total reward:2.3000, 0.041749000549316406 sec\n",
      "Episode 1174, loss:4.9231, succeed, steps:12, total reward:1.6000, 0.03131890296936035 sec\n",
      "Episode 1175, loss:6.2053, succeed, steps:20, total reward:3.0000, 0.05033087730407715 sec\n",
      "Episode 1176, loss:0.4291, fail, steps:30, total reward:1.6000, 0.07523727416992188 sec\n",
      "Episode 1177, loss:5.5148, succeed, steps:29, total reward:2.1000, 0.07631087303161621 sec\n",
      "Episode 1178, loss:-1.4702, fail, steps:29, total reward:-0.7000, 0.07442378997802734 sec\n",
      "Episode 1179, loss:1.2147, succeed, steps:13, total reward:-0.7000, 0.03520941734313965 sec\n",
      "Episode 1180, loss:-0.2790, fail, steps:30, total reward:0.3000, 0.07637667655944824 sec\n",
      "Episode 1181, loss:3.4896, succeed, steps:19, total reward:2.0000, 0.04977011680603027 sec\n",
      "Episode 1182, loss:-1.2878, fail, steps:30, total reward:0.3000, 0.0759890079498291 sec\n",
      "Episode 1183, loss:-1.1872, fail, steps:29, total reward:-0.7000, 0.07577133178710938 sec\n",
      "Episode 1184, loss:-0.1953, fail, steps:30, total reward:0.3000, 0.07590937614440918 sec\n",
      "Episode 1185, loss:0.6942, succeed, steps:7, total reward:-0.1000, 0.020122528076171875 sec\n",
      "Episode 1186, loss:-2.4343, fail, steps:29, total reward:-0.7000, 0.07157349586486816 sec\n",
      "Episode 1187, loss:1.0478, succeed, steps:10, total reward:-0.4000, 0.026929378509521484 sec\n",
      "Episode 1188, loss:0.7608, succeed, steps:4, total reward:0.2000, 0.012094259262084961 sec\n",
      "Episode 1189, loss:1.9165, succeed, steps:25, total reward:-1.9000, 0.06142687797546387 sec\n",
      "Episode 1190, loss:0.4952, succeed, steps:4, total reward:0.2000, 0.012208938598632812 sec\n",
      "Episode 1191, loss:3.4774, succeed, steps:28, total reward:1.1000, 0.06835770606994629 sec\n",
      "Episode 1192, loss:1.2227, succeed, steps:8, total reward:0.9000, 0.021722078323364258 sec\n",
      "Episode 1193, loss:1.0944, succeed, steps:7, total reward:-0.1000, 0.01870274543762207 sec\n",
      "Episode 1194, loss:5.6597, succeed, steps:28, total reward:1.1000, 0.0691986083984375 sec\n",
      "Episode 1195, loss:-2.8891, fail, steps:29, total reward:-1.7000, 0.07235908508300781 sec\n",
      "Episode 1196, loss:3.6350, succeed, steps:28, total reward:1.1000, 0.07046031951904297 sec\n",
      "Episode 1197, loss:-1.3419, fail, steps:29, total reward:-1.7000, 0.07332515716552734 sec\n",
      "Episode 1198, loss:1.2661, succeed, steps:11, total reward:0.6000, 0.02983689308166504 sec\n",
      "Episode 1199, loss:5.2820, succeed, steps:28, total reward:1.1000, 0.06912088394165039 sec\n",
      "Episode 1200, loss:-0.4853, fail, steps:30, total reward:0.3000, 0.07503342628479004 sec\n",
      "Episode 1201, loss:-2.1573, fail, steps:29, total reward:-2.7000, 0.07426571846008301 sec\n",
      "Episode 1202, loss:-1.5209, fail, steps:30, total reward:0.3000, 0.07579779624938965 sec\n",
      "Episode 1203, loss:3.5919, succeed, steps:21, total reward:0.7000, 0.053727149963378906 sec\n",
      "Episode 1204, loss:-0.9697, fail, steps:30, total reward:0.3000, 0.07537460327148438 sec\n",
      "Episode 1205, loss:0.2496, succeed, steps:4, total reward:0.2000, 0.013063669204711914 sec\n",
      "Episode 1206, loss:3.5123, succeed, steps:25, total reward:1.4000, 0.06127667427062988 sec\n",
      "Episode 1207, loss:2.9503, succeed, steps:21, total reward:0.7000, 0.05289721488952637 sec\n",
      "Episode 1208, loss:-1.9102, fail, steps:30, total reward:0.3000, 0.07480525970458984 sec\n",
      "Episode 1209, loss:0.2357, fail, steps:30, total reward:1.6000, 0.07549214363098145 sec\n",
      "Episode 1210, loss:1.2737, succeed, steps:10, total reward:-0.4000, 0.027314424514770508 sec\n",
      "Episode 1211, loss:-0.0632, fail, steps:30, total reward:0.3000, 0.07379341125488281 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1212, loss:4.8203, succeed, steps:24, total reward:0.4000, 0.06160593032836914 sec\n",
      "Episode 1213, loss:1.6840, succeed, steps:17, total reward:0.0000, 0.0438532829284668 sec\n",
      "Episode 1214, loss:4.1061, succeed, steps:28, total reward:1.1000, 0.0728297233581543 sec\n",
      "Episode 1215, loss:1.0112, succeed, steps:8, total reward:0.9000, 0.02280712127685547 sec\n",
      "Episode 1216, loss:5.6217, succeed, steps:26, total reward:2.4000, 0.06570792198181152 sec\n",
      "Episode 1217, loss:2.8365, succeed, steps:18, total reward:1.0000, 0.047112226486206055 sec\n",
      "Episode 1218, loss:2.0887, fail, steps:30, total reward:2.6000, 0.07596921920776367 sec\n",
      "Episode 1219, loss:-1.2821, fail, steps:29, total reward:-0.7000, 0.07421183586120605 sec\n",
      "Episode 1220, loss:-0.9838, fail, steps:29, total reward:-0.7000, 0.07483696937561035 sec\n",
      "Episode 1221, loss:-1.8483, fail, steps:29, total reward:-0.7000, 0.0747830867767334 sec\n",
      "Episode 1222, loss:1.1651, succeed, steps:11, total reward:0.6000, 0.030338525772094727 sec\n",
      "Episode 1223, loss:2.1202, succeed, steps:17, total reward:0.0000, 0.04408669471740723 sec\n",
      "Episode 1224, loss:2.8195, succeed, steps:20, total reward:-0.3000, 0.05148506164550781 sec\n",
      "Episode 1225, loss:5.2243, succeed, steps:30, total reward:3.1000, 0.07640218734741211 sec\n",
      "Episode 1226, loss:-2.0208, fail, steps:29, total reward:-0.7000, 0.07491350173950195 sec\n",
      "Episode 1227, loss:1.4436, fail, steps:30, total reward:2.6000, 0.07760763168334961 sec\n",
      "Episode 1228, loss:-2.7505, fail, steps:29, total reward:-2.7000, 0.07481789588928223 sec\n",
      "Episode 1229, loss:-2.9031, fail, steps:29, total reward:-1.7000, 0.07478523254394531 sec\n",
      "Episode 1230, loss:1.3685, succeed, steps:11, total reward:0.6000, 0.03032660484313965 sec\n",
      "Episode 1231, loss:2.3656, succeed, steps:15, total reward:1.3000, 0.03950786590576172 sec\n",
      "Episode 1232, loss:1.3337, succeed, steps:10, total reward:-0.4000, 0.02712869644165039 sec\n",
      "Episode 1233, loss:4.5721, succeed, steps:25, total reward:1.4000, 0.06166958808898926 sec\n",
      "Episode 1234, loss:-1.3066, fail, steps:30, total reward:0.3000, 0.07441091537475586 sec\n",
      "Episode 1235, loss:-0.6965, fail, steps:30, total reward:0.3000, 0.07561373710632324 sec\n",
      "Episode 1236, loss:2.9206, succeed, steps:18, total reward:1.0000, 0.04674267768859863 sec\n",
      "Episode 1237, loss:-1.7876, fail, steps:29, total reward:-0.7000, 0.07220005989074707 sec\n",
      "Episode 1238, loss:2.4948, succeed, steps:24, total reward:0.4000, 0.06062674522399902 sec\n",
      "Episode 1239, loss:4.4635, succeed, steps:28, total reward:1.1000, 0.07050609588623047 sec\n",
      "Episode 1240, loss:-1.5225, fail, steps:29, total reward:-0.7000, 0.07303690910339355 sec\n",
      "Episode 1241, loss:-5.0143, fail, steps:29, total reward:-1.7000, 0.07296943664550781 sec\n",
      "Episode 1242, loss:4.0892, succeed, steps:26, total reward:-0.9000, 0.06653857231140137 sec\n",
      "Episode 1243, loss:0.0125, fail, steps:30, total reward:1.6000, 0.07557439804077148 sec\n",
      "Episode 1244, loss:-2.0144, fail, steps:30, total reward:0.3000, 0.07578516006469727 sec\n",
      "Episode 1245, loss:5.4177, succeed, steps:19, total reward:2.0000, 0.04940032958984375 sec\n",
      "Episode 1246, loss:2.2529, succeed, steps:17, total reward:0.0000, 0.04401063919067383 sec\n",
      "Episode 1247, loss:0.5389, fail, steps:30, total reward:1.6000, 0.07490777969360352 sec\n",
      "Episode 1248, loss:-1.7841, fail, steps:30, total reward:0.3000, 0.07804298400878906 sec\n",
      "Episode 1249, loss:3.4511, succeed, steps:24, total reward:0.4000, 0.06298375129699707 sec\n",
      "Episode 1250, loss:-1.5508, fail, steps:30, total reward:0.3000, 0.07689118385314941 sec\n",
      "Episode 1251, loss:2.9007, succeed, steps:21, total reward:0.7000, 0.05475139617919922 sec\n",
      "Episode 1252, loss:-3.6191, fail, steps:29, total reward:-1.7000, 0.07457089424133301 sec\n",
      "Episode 1253, loss:1.0049, succeed, steps:11, total reward:0.6000, 0.030519962310791016 sec\n",
      "Episode 1254, loss:2.2628, succeed, steps:17, total reward:0.0000, 0.04394888877868652 sec\n",
      "Episode 1255, loss:3.0427, succeed, steps:15, total reward:1.3000, 0.03923511505126953 sec\n",
      "Episode 1256, loss:0.4305, succeed, steps:4, total reward:0.2000, 0.012201309204101562 sec\n",
      "Episode 1257, loss:-2.4638, fail, steps:29, total reward:-0.7000, 0.07228231430053711 sec\n",
      "Episode 1258, loss:5.2747, succeed, steps:22, total reward:1.7000, 0.05693984031677246 sec\n",
      "Episode 1259, loss:2.4051, succeed, steps:17, total reward:-0.3000, 0.044596195220947266 sec\n",
      "Episode 1260, loss:1.5931, succeed, steps:14, total reward:0.3000, 0.036783456802368164 sec\n",
      "Episode 1261, loss:2.0983, succeed, steps:11, total reward:0.6000, 0.02917027473449707 sec\n",
      "Episode 1262, loss:0.7405, fail, steps:30, total reward:1.6000, 0.0752713680267334 sec\n",
      "Episode 1263, loss:2.4631, succeed, steps:27, total reward:0.1000, 0.06981968879699707 sec\n",
      "Episode 1264, loss:0.5078, succeed, steps:4, total reward:0.2000, 0.012818336486816406 sec\n",
      "Episode 1265, loss:-3.5936, fail, steps:29, total reward:-1.7000, 0.07119369506835938 sec\n",
      "Episode 1266, loss:3.6278, succeed, steps:27, total reward:0.1000, 0.06744241714477539 sec\n",
      "Episode 1267, loss:-2.5578, fail, steps:29, total reward:-1.7000, 0.07324671745300293 sec\n",
      "Episode 1268, loss:1.5019, succeed, steps:11, total reward:0.6000, 0.029616355895996094 sec\n",
      "Episode 1269, loss:5.7842, succeed, steps:22, total reward:1.7000, 0.0550994873046875 sec\n",
      "Episode 1270, loss:0.3475, succeed, steps:4, total reward:0.2000, 0.012159109115600586 sec\n",
      "Episode 1271, loss:1.3121, succeed, steps:25, total reward:-1.9000, 0.06115102767944336 sec\n",
      "Episode 1272, loss:0.2312, succeed, steps:4, total reward:0.2000, 0.012192249298095703 sec\n",
      "Episode 1273, loss:2.2246, succeed, steps:15, total reward:1.3000, 0.03784513473510742 sec\n",
      "Episode 1274, loss:-1.2862, fail, steps:29, total reward:-0.7000, 0.07117986679077148 sec\n",
      "Episode 1275, loss:2.3901, succeed, steps:19, total reward:2.0000, 0.04842710494995117 sec\n",
      "Episode 1276, loss:-0.0732, fail, steps:30, total reward:0.3000, 0.0743556022644043 sec\n",
      "Episode 1277, loss:-0.7277, fail, steps:29, total reward:-0.7000, 0.07341432571411133 sec\n",
      "Episode 1278, loss:1.6320, succeed, steps:17, total reward:0.0000, 0.044115543365478516 sec\n",
      "Episode 1279, loss:2.2552, succeed, steps:12, total reward:1.6000, 0.0314791202545166 sec\n",
      "Episode 1280, loss:0.0746, succeed, steps:4, total reward:0.2000, 0.011887788772583008 sec\n",
      "Episode 1281, loss:1.8818, succeed, steps:11, total reward:0.6000, 0.028052806854248047 sec\n",
      "Episode 1282, loss:2.4029, succeed, steps:20, total reward:-0.3000, 0.0493769645690918 sec\n",
      "Episode 1283, loss:-0.1091, fail, steps:29, total reward:-0.7000, 0.07195186614990234 sec\n",
      "Episode 1284, loss:-0.3633, fail, steps:30, total reward:0.3000, 0.07550501823425293 sec\n",
      "Episode 1285, loss:4.8887, succeed, steps:27, total reward:0.1000, 0.06798338890075684 sec\n",
      "Episode 1286, loss:1.1774, succeed, steps:13, total reward:-0.7000, 0.03433060646057129 sec\n",
      "Episode 1287, loss:-1.8698, fail, steps:29, total reward:-0.7000, 0.07235884666442871 sec\n",
      "Episode 1288, loss:-0.7195, fail, steps:30, total reward:0.3000, 0.07770800590515137 sec\n",
      "Episode 1289, loss:-10.3523, fail, steps:30, total reward:-1.7000, 0.07777070999145508 sec\n",
      "Episode 1290, loss:-1.6210, fail, steps:29, total reward:-0.7000, 0.07372021675109863 sec\n",
      "Episode 1291, loss:-1.2209, fail, steps:30, total reward:0.3000, 0.07559919357299805 sec\n",
      "Episode 1292, loss:-1.3240, fail, steps:29, total reward:-0.7000, 0.07318472862243652 sec\n",
      "Episode 1293, loss:2.2580, succeed, steps:25, total reward:-1.9000, 0.06399273872375488 sec\n",
      "Episode 1294, loss:3.1879, succeed, steps:28, total reward:1.1000, 0.07120871543884277 sec\n",
      "Episode 1295, loss:2.3523, succeed, steps:21, total reward:0.7000, 0.05420565605163574 sec\n",
      "Episode 1296, loss:-2.0117, fail, steps:29, total reward:-1.7000, 0.07253694534301758 sec\n",
      "Episode 1297, loss:-3.0088, fail, steps:29, total reward:-2.7000, 0.073394775390625 sec\n",
      "Episode 1298, loss:0.9189, succeed, steps:4, total reward:0.2000, 0.012938261032104492 sec\n",
      "Episode 1299, loss:-1.3774, fail, steps:29, total reward:-1.7000, 0.07092785835266113 sec\n",
      "Episode 1300, loss:-0.6968, fail, steps:29, total reward:-0.7000, 0.07402944564819336 sec\n",
      "Episode 1301, loss:-2.2959, fail, steps:29, total reward:-0.7000, 0.07322931289672852 sec\n",
      "Episode 1302, loss:-3.5364, fail, steps:29, total reward:-1.0000, 0.07312440872192383 sec\n",
      "Episode 1303, loss:-1.4902, fail, steps:29, total reward:-0.7000, 0.07284402847290039 sec\n",
      "Episode 1304, loss:1.4770, succeed, steps:12, total reward:1.6000, 0.031969547271728516 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1305, loss:1.0334, succeed, steps:13, total reward:-0.7000, 0.03406882286071777 sec\n",
      "Episode 1306, loss:1.9907, succeed, steps:11, total reward:0.6000, 0.0288088321685791 sec\n",
      "Episode 1307, loss:-3.9379, fail, steps:29, total reward:-1.7000, 0.07101988792419434 sec\n",
      "Episode 1308, loss:2.2517, succeed, steps:26, total reward:-0.9000, 0.06523704528808594 sec\n",
      "Episode 1309, loss:4.7157, succeed, steps:29, total reward:2.1000, 0.0732264518737793 sec\n",
      "Episode 1310, loss:5.2270, succeed, steps:30, total reward:3.1000, 0.07526135444641113 sec\n",
      "Episode 1311, loss:0.7260, succeed, steps:8, total reward:0.9000, 0.022476911544799805 sec\n",
      "Episode 1312, loss:2.6994, succeed, steps:21, total reward:0.7000, 0.052118539810180664 sec\n",
      "Episode 1313, loss:2.8364, succeed, steps:18, total reward:1.0000, 0.0457000732421875 sec\n",
      "Episode 1314, loss:0.4993, succeed, steps:7, total reward:-0.1000, 0.019649982452392578 sec\n",
      "Episode 1315, loss:-1.9223, fail, steps:29, total reward:-0.7000, 0.07091379165649414 sec\n",
      "Episode 1316, loss:-1.5397, fail, steps:29, total reward:-0.7000, 0.07220029830932617 sec\n",
      "Episode 1317, loss:4.4274, succeed, steps:18, total reward:1.0000, 0.04657459259033203 sec\n",
      "Episode 1318, loss:1.0180, succeed, steps:14, total reward:0.3000, 0.03662872314453125 sec\n",
      "Episode 1319, loss:-0.3589, fail, steps:30, total reward:0.3000, 0.07421302795410156 sec\n",
      "Episode 1320, loss:3.2070, succeed, steps:21, total reward:0.7000, 0.05325675010681152 sec\n",
      "Episode 1321, loss:-1.8325, fail, steps:29, total reward:-0.7000, 0.07216668128967285 sec\n",
      "Episode 1322, loss:1.6758, succeed, steps:14, total reward:0.3000, 0.03721284866333008 sec\n",
      "Episode 1323, loss:-1.8183, fail, steps:29, total reward:-1.7000, 0.07339644432067871 sec\n",
      "Episode 1324, loss:3.7058, succeed, steps:19, total reward:2.0000, 0.050446271896362305 sec\n",
      "Episode 1325, loss:1.1851, succeed, steps:13, total reward:-0.7000, 0.03525209426879883 sec\n",
      "Episode 1326, loss:2.1224, succeed, steps:21, total reward:0.7000, 0.05409073829650879 sec\n",
      "Episode 1327, loss:-2.9153, fail, steps:29, total reward:-0.7000, 0.07370758056640625 sec\n",
      "Episode 1328, loss:1.1354, succeed, steps:20, total reward:-0.3000, 0.05232048034667969 sec\n",
      "Episode 1329, loss:-2.5900, fail, steps:29, total reward:-0.7000, 0.07387995719909668 sec\n",
      "Episode 1330, loss:0.2264, succeed, steps:7, total reward:-0.1000, 0.020719528198242188 sec\n",
      "Episode 1331, loss:6.2926, succeed, steps:23, total reward:2.7000, 0.058388471603393555 sec\n",
      "Episode 1332, loss:-0.8180, fail, steps:30, total reward:0.3000, 0.07633781433105469 sec\n",
      "Episode 1333, loss:0.0109, succeed, steps:4, total reward:0.2000, 0.01276540756225586 sec\n",
      "Episode 1334, loss:-1.2720, fail, steps:29, total reward:-0.7000, 0.07242560386657715 sec\n",
      "Episode 1335, loss:-1.5062, fail, steps:30, total reward:0.3000, 0.07651376724243164 sec\n",
      "Episode 1336, loss:1.0830, succeed, steps:10, total reward:-0.4000, 0.02774643898010254 sec\n",
      "Episode 1337, loss:3.3036, succeed, steps:18, total reward:1.0000, 0.04620051383972168 sec\n",
      "Episode 1338, loss:-1.4232, fail, steps:29, total reward:-1.7000, 0.07375812530517578 sec\n",
      "Episode 1339, loss:-2.5480, fail, steps:29, total reward:-0.7000, 0.07408666610717773 sec\n",
      "Episode 1340, loss:-0.4777, fail, steps:30, total reward:0.3000, 0.07548236846923828 sec\n",
      "Episode 1341, loss:-1.3716, fail, steps:30, total reward:0.3000, 0.07612013816833496 sec\n",
      "Episode 1342, loss:-1.7009, fail, steps:30, total reward:0.3000, 0.07575321197509766 sec\n",
      "Episode 1343, loss:1.7661, succeed, steps:17, total reward:0.0000, 0.044069766998291016 sec\n",
      "Episode 1344, loss:1.7214, succeed, steps:20, total reward:-0.3000, 0.05058693885803223 sec\n",
      "Episode 1345, loss:-2.0507, fail, steps:29, total reward:-0.7000, 0.07273221015930176 sec\n",
      "Episode 1346, loss:3.2092, succeed, steps:18, total reward:1.0000, 0.04630851745605469 sec\n",
      "Episode 1347, loss:0.2959, succeed, steps:7, total reward:-0.1000, 0.019483566284179688 sec\n",
      "Episode 1348, loss:-1.9052, fail, steps:29, total reward:-2.7000, 0.07136130332946777 sec\n",
      "Episode 1349, loss:1.0156, succeed, steps:10, total reward:-0.4000, 0.02691173553466797 sec\n",
      "Episode 1350, loss:2.3099, succeed, steps:19, total reward:2.0000, 0.04771280288696289 sec\n",
      "Episode 1351, loss:2.5320, succeed, steps:20, total reward:-0.3000, 0.05043172836303711 sec\n",
      "Episode 1352, loss:1.7957, succeed, steps:28, total reward:-2.2000, 0.06965255737304688 sec\n",
      "Episode 1353, loss:-2.7145, fail, steps:29, total reward:-0.7000, 0.07240009307861328 sec\n",
      "Episode 1354, loss:0.8291, succeed, steps:10, total reward:-0.4000, 0.02762889862060547 sec\n",
      "Episode 1355, loss:4.4738, succeed, steps:27, total reward:0.1000, 0.06676936149597168 sec\n",
      "Episode 1356, loss:0.0292, fail, steps:30, total reward:0.3000, 0.07471799850463867 sec\n",
      "Episode 1357, loss:2.7791, succeed, steps:21, total reward:0.7000, 0.053649187088012695 sec\n",
      "Episode 1358, loss:-0.3920, fail, steps:30, total reward:0.3000, 0.07534623146057129 sec\n",
      "Episode 1359, loss:0.8533, succeed, steps:10, total reward:-0.4000, 0.027248382568359375 sec\n",
      "Episode 1360, loss:-1.8745, fail, steps:29, total reward:-0.7000, 0.07275199890136719 sec\n",
      "Episode 1361, loss:2.9382, succeed, steps:22, total reward:1.7000, 0.0583949089050293 sec\n",
      "Episode 1362, loss:1.1272, succeed, steps:10, total reward:-0.4000, 0.027957677841186523 sec\n",
      "Episode 1363, loss:1.0823, succeed, steps:4, total reward:0.2000, 0.012115716934204102 sec\n",
      "Episode 1364, loss:2.4752, succeed, steps:18, total reward:1.0000, 0.04603767395019531 sec\n",
      "Episode 1365, loss:3.3698, succeed, steps:27, total reward:0.1000, 0.06801557540893555 sec\n",
      "Episode 1366, loss:0.1964, fail, steps:30, total reward:1.6000, 0.07642197608947754 sec\n",
      "Episode 1367, loss:-3.5451, fail, steps:29, total reward:-1.7000, 0.07463598251342773 sec\n",
      "Episode 1368, loss:-2.2858, fail, steps:29, total reward:-0.7000, 0.07472515106201172 sec\n",
      "Episode 1369, loss:-3.5237, fail, steps:29, total reward:-1.0000, 0.07434225082397461 sec\n",
      "Episode 1370, loss:0.9741, succeed, steps:8, total reward:0.9000, 0.022510766983032227 sec\n",
      "Episode 1371, loss:2.2392, succeed, steps:14, total reward:0.3000, 0.03590583801269531 sec\n",
      "Episode 1372, loss:1.5033, succeed, steps:11, total reward:0.6000, 0.028786659240722656 sec\n",
      "Episode 1373, loss:2.8340, succeed, steps:27, total reward:0.1000, 0.06611180305480957 sec\n",
      "Episode 1374, loss:1.7230, succeed, steps:16, total reward:-1.0000, 0.04136466979980469 sec\n",
      "Episode 1375, loss:0.8189, fail, steps:30, total reward:2.6000, 0.07477760314941406 sec\n",
      "Episode 1376, loss:1.2101, succeed, steps:10, total reward:-0.4000, 0.027330398559570312 sec\n",
      "Episode 1377, loss:-2.3528, fail, steps:29, total reward:-1.7000, 0.07178664207458496 sec\n",
      "Episode 1378, loss:3.1520, succeed, steps:23, total reward:-0.6000, 0.05808687210083008 sec\n",
      "Episode 1379, loss:-1.7282, fail, steps:29, total reward:-0.7000, 0.07276391983032227 sec\n",
      "Episode 1380, loss:0.0310, succeed, steps:4, total reward:0.2000, 0.012876510620117188 sec\n",
      "Episode 1381, loss:2.7450, succeed, steps:22, total reward:1.7000, 0.05424785614013672 sec\n",
      "Episode 1382, loss:1.1061, fail, steps:30, total reward:2.6000, 0.07419133186340332 sec\n",
      "Episode 1383, loss:-0.8684, fail, steps:30, total reward:0.3000, 0.07557845115661621 sec\n",
      "Episode 1384, loss:0.5512, fail, steps:30, total reward:2.6000, 0.07571029663085938 sec\n",
      "Episode 1385, loss:2.0959, succeed, steps:18, total reward:1.0000, 0.046488046646118164 sec\n",
      "Episode 1386, loss:1.2689, succeed, steps:15, total reward:1.3000, 0.03884458541870117 sec\n",
      "Episode 1387, loss:4.1953, succeed, steps:27, total reward:0.1000, 0.06696772575378418 sec\n",
      "Episode 1388, loss:0.2077, succeed, steps:8, total reward:0.9000, 0.022303342819213867 sec\n",
      "Episode 1389, loss:-2.2422, fail, steps:29, total reward:-1.7000, 0.07126903533935547 sec\n",
      "Episode 1390, loss:-1.9618, fail, steps:29, total reward:-1.7000, 0.07246112823486328 sec\n",
      "Episode 1391, loss:3.2816, succeed, steps:19, total reward:2.0000, 0.04918932914733887 sec\n",
      "Episode 1392, loss:-1.7894, fail, steps:29, total reward:-0.7000, 0.07228422164916992 sec\n",
      "Episode 1393, loss:4.5084, succeed, steps:28, total reward:1.1000, 0.07021117210388184 sec\n",
      "Episode 1394, loss:3.5406, succeed, steps:28, total reward:1.1000, 0.07104897499084473 sec\n",
      "Episode 1395, loss:4.1381, succeed, steps:22, total reward:1.7000, 0.05619621276855469 sec\n",
      "Episode 1396, loss:3.7145, succeed, steps:14, total reward:0.3000, 0.0363311767578125 sec\n",
      "Episode 1397, loss:2.6658, succeed, steps:26, total reward:2.4000, 0.06445813179016113 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1398, loss:3.6549, succeed, steps:29, total reward:2.1000, 0.07599639892578125 sec\n",
      "Episode 1399, loss:1.2298, succeed, steps:10, total reward:-0.4000, 0.029070138931274414 sec\n",
      "len4 start4 Comparison 4 5 more Swap Comparison 6 7 less Comparison 5 6 more Swap Comparison 6 7 more Swap Comparison 4 5 more Swap\n",
      "Episode 1400, loss:2.5641, succeed, steps:19, total reward:2.0000, 0.10238981246948242 sec\n",
      "Episode 1401, loss:2.9685, succeed, steps:27, total reward:0.1000, 0.06739473342895508 sec\n",
      "Episode 1402, loss:3.6765, succeed, steps:27, total reward:-0.5000, 0.06847500801086426 sec\n",
      "Episode 1403, loss:7.0937, succeed, steps:26, total reward:2.4000, 0.06560945510864258 sec\n",
      "Episode 1404, loss:0.3337, succeed, steps:8, total reward:0.9000, 0.02236628532409668 sec\n",
      "Episode 1405, loss:1.5281, succeed, steps:10, total reward:-0.4000, 0.0261380672454834 sec\n",
      "Episode 1406, loss:-1.3458, fail, steps:29, total reward:-0.7000, 0.07112383842468262 sec\n",
      "Episode 1407, loss:1.8863, succeed, steps:14, total reward:0.3000, 0.037215232849121094 sec\n",
      "Episode 1408, loss:-1.0807, fail, steps:29, total reward:-0.7000, 0.07173681259155273 sec\n",
      "Episode 1409, loss:3.1591, succeed, steps:22, total reward:1.7000, 0.055848121643066406 sec\n",
      "Episode 1410, loss:-1.4167, fail, steps:30, total reward:1.3000, 0.07538747787475586 sec\n",
      "Episode 1411, loss:1.5345, succeed, steps:14, total reward:0.3000, 0.03702044486999512 sec\n",
      "Episode 1412, loss:1.3072, succeed, steps:4, total reward:0.2000, 0.012227773666381836 sec\n",
      "Episode 1413, loss:-1.5378, fail, steps:29, total reward:-0.7000, 0.07086920738220215 sec\n",
      "Episode 1414, loss:0.8759, fail, steps:30, total reward:1.6000, 0.0747382640838623 sec\n",
      "Episode 1415, loss:3.6914, succeed, steps:28, total reward:1.1000, 0.07127857208251953 sec\n",
      "Episode 1416, loss:2.5311, succeed, steps:27, total reward:0.1000, 0.06801223754882812 sec\n",
      "Episode 1417, loss:0.7988, succeed, steps:11, total reward:0.6000, 0.029477596282958984 sec\n",
      "Episode 1418, loss:4.0736, succeed, steps:24, total reward:0.4000, 0.059587717056274414 sec\n",
      "Episode 1419, loss:2.3384, succeed, steps:16, total reward:2.3000, 0.04109907150268555 sec\n",
      "Episode 1420, loss:-0.6488, fail, steps:29, total reward:-0.7000, 0.0724172592163086 sec\n",
      "Episode 1421, loss:1.5602, succeed, steps:14, total reward:0.3000, 0.03670549392700195 sec\n",
      "Episode 1422, loss:-1.1910, fail, steps:30, total reward:0.3000, 0.07392001152038574 sec\n",
      "Episode 1423, loss:2.5602, succeed, steps:17, total reward:0.0000, 0.044068098068237305 sec\n",
      "Episode 1424, loss:2.1784, succeed, steps:21, total reward:0.7000, 0.05373859405517578 sec\n",
      "Episode 1425, loss:2.5339, succeed, steps:26, total reward:-0.9000, 0.06497025489807129 sec\n",
      "Episode 1426, loss:1.1229, succeed, steps:17, total reward:0.0000, 0.04365277290344238 sec\n",
      "Episode 1427, loss:1.9388, succeed, steps:24, total reward:0.4000, 0.06016969680786133 sec\n",
      "Episode 1428, loss:-1.7667, fail, steps:29, total reward:-1.7000, 0.07337808609008789 sec\n",
      "Episode 1429, loss:2.0505, succeed, steps:20, total reward:-0.3000, 0.05169486999511719 sec\n",
      "Episode 1430, loss:-0.3767, fail, steps:30, total reward:0.3000, 0.07483315467834473 sec\n",
      "Episode 1431, loss:0.6084, succeed, steps:7, total reward:-0.1000, 0.019805431365966797 sec\n",
      "Episode 1432, loss:-0.8421, fail, steps:29, total reward:-0.7000, 0.07175040245056152 sec\n",
      "Episode 1433, loss:-0.5318, fail, steps:30, total reward:0.3000, 0.0751950740814209 sec\n",
      "Episode 1434, loss:0.8871, succeed, steps:12, total reward:1.6000, 0.03191661834716797 sec\n",
      "Episode 1435, loss:0.7033, fail, steps:30, total reward:1.6000, 0.07694101333618164 sec\n",
      "Episode 1436, loss:-0.0094, fail, steps:30, total reward:0.3000, 0.0773782730102539 sec\n",
      "Episode 1437, loss:-2.1549, fail, steps:29, total reward:-0.7000, 0.07318997383117676 sec\n",
      "Episode 1438, loss:5.3436, succeed, steps:18, total reward:1.0000, 0.04669928550720215 sec\n",
      "Episode 1439, loss:0.1351, fail, steps:30, total reward:1.6000, 0.07469439506530762 sec\n",
      "Episode 1440, loss:0.0222, succeed, steps:4, total reward:0.2000, 0.01285552978515625 sec\n",
      "Episode 1441, loss:0.3226, succeed, steps:7, total reward:-0.1000, 0.01886582374572754 sec\n",
      "Episode 1442, loss:-2.2987, fail, steps:29, total reward:-0.7000, 0.07091450691223145 sec\n",
      "Episode 1443, loss:-1.0792, fail, steps:29, total reward:-0.7000, 0.07237458229064941 sec\n",
      "Episode 1444, loss:-1.4474, fail, steps:29, total reward:-1.7000, 0.07330107688903809 sec\n",
      "Episode 1445, loss:2.3704, succeed, steps:15, total reward:1.3000, 0.03941512107849121 sec\n",
      "Episode 1446, loss:-58.3630, fail, steps:5, total reward:-9.3000, 0.01459193229675293 sec\n",
      "Episode 1447, loss:0.8524, succeed, steps:14, total reward:0.3000, 0.03534126281738281 sec\n",
      "Episode 1448, loss:1.6629, succeed, steps:12, total reward:1.6000, 0.030727863311767578 sec\n",
      "Episode 1449, loss:0.7630, fail, steps:30, total reward:0.3000, 0.07380342483520508 sec\n",
      "Episode 1450, loss:1.3946, succeed, steps:20, total reward:-0.3000, 0.051542043685913086 sec\n",
      "Episode 1451, loss:1.4784, succeed, steps:22, total reward:1.7000, 0.055786848068237305 sec\n",
      "Episode 1452, loss:-1.4863, fail, steps:30, total reward:0.3000, 0.07461094856262207 sec\n",
      "Episode 1453, loss:2.1642, succeed, steps:12, total reward:1.6000, 0.03195595741271973 sec\n",
      "Episode 1454, loss:1.2051, succeed, steps:18, total reward:1.0000, 0.0461573600769043 sec\n",
      "Episode 1455, loss:3.2196, succeed, steps:27, total reward:0.1000, 0.06725406646728516 sec\n",
      "Episode 1456, loss:-1.3602, fail, steps:29, total reward:-1.0000, 0.07280731201171875 sec\n",
      "Episode 1457, loss:1.7161, succeed, steps:27, total reward:0.1000, 0.06886458396911621 sec\n",
      "Episode 1458, loss:5.6608, succeed, steps:22, total reward:1.7000, 0.056298255920410156 sec\n",
      "Episode 1459, loss:1.9533, succeed, steps:23, total reward:-0.6000, 0.05846095085144043 sec\n",
      "Episode 1460, loss:-1.2974, fail, steps:29, total reward:-1.7000, 0.07295870780944824 sec\n",
      "Episode 1461, loss:0.0090, succeed, steps:4, total reward:0.2000, 0.012742757797241211 sec\n",
      "Episode 1462, loss:1.8171, succeed, steps:15, total reward:1.3000, 0.03817129135131836 sec\n",
      "Episode 1463, loss:1.9001, succeed, steps:20, total reward:-0.3000, 0.050012826919555664 sec\n",
      "Episode 1464, loss:2.1269, succeed, steps:24, total reward:0.4000, 0.060033321380615234 sec\n",
      "Episode 1465, loss:2.0105, succeed, steps:7, total reward:-0.1000, 0.019385099411010742 sec\n",
      "Episode 1466, loss:-0.3449, fail, steps:30, total reward:1.6000, 0.07396602630615234 sec\n",
      "Episode 1467, loss:2.7129, succeed, steps:25, total reward:1.4000, 0.06314706802368164 sec\n",
      "Episode 1468, loss:-0.6966, fail, steps:29, total reward:-0.7000, 0.0726315975189209 sec\n",
      "Episode 1469, loss:2.0214, succeed, steps:23, total reward:-0.6000, 0.05858922004699707 sec\n",
      "Episode 1470, loss:0.7827, succeed, steps:8, total reward:0.9000, 0.022529125213623047 sec\n",
      "Episode 1471, loss:-1.8006, fail, steps:29, total reward:-0.7000, 0.07159972190856934 sec\n",
      "Episode 1472, loss:-1.1266, fail, steps:30, total reward:0.3000, 0.07522439956665039 sec\n",
      "Episode 1473, loss:1.0443, succeed, steps:17, total reward:0.0000, 0.04482579231262207 sec\n",
      "Episode 1474, loss:-0.4760, fail, steps:30, total reward:1.0000, 0.07866811752319336 sec\n",
      "Episode 1475, loss:2.5852, succeed, steps:19, total reward:2.0000, 0.049236297607421875 sec\n",
      "Episode 1476, loss:1.9669, succeed, steps:21, total reward:0.7000, 0.053055524826049805 sec\n",
      "Episode 1477, loss:0.2702, succeed, steps:7, total reward:-0.1000, 0.019475221633911133 sec\n",
      "Episode 1478, loss:-2.7314, fail, steps:29, total reward:-1.7000, 0.07149028778076172 sec\n",
      "Episode 1479, loss:3.0894, succeed, steps:19, total reward:2.0000, 0.049141883850097656 sec\n",
      "Episode 1480, loss:0.0740, succeed, steps:7, total reward:-0.1000, 0.01944446563720703 sec\n",
      "Episode 1481, loss:-3.3638, fail, steps:29, total reward:-2.7000, 0.07128334045410156 sec\n",
      "Episode 1482, loss:0.4943, fail, steps:30, total reward:0.3000, 0.07476091384887695 sec\n",
      "Episode 1483, loss:1.9547, succeed, steps:19, total reward:2.0000, 0.04942727088928223 sec\n",
      "Episode 1484, loss:-2.1721, fail, steps:29, total reward:-1.7000, 0.07234621047973633 sec\n",
      "Episode 1485, loss:1.5324, fail, steps:30, total reward:1.6000, 0.07527375221252441 sec\n",
      "Episode 1486, loss:-0.2536, fail, steps:29, total reward:-0.7000, 0.0736243724822998 sec\n",
      "Episode 1487, loss:1.6778, succeed, steps:18, total reward:1.0000, 0.0468447208404541 sec\n",
      "Episode 1488, loss:-1.0578, fail, steps:30, total reward:0.3000, 0.07502412796020508 sec\n",
      "Episode 1489, loss:1.3193, succeed, steps:8, total reward:0.9000, 0.0223238468170166 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1490, loss:-1.5332, fail, steps:29, total reward:-1.7000, 0.07188200950622559 sec\n",
      "Episode 1491, loss:1.6391, succeed, steps:16, total reward:2.3000, 0.04165196418762207 sec\n",
      "Episode 1492, loss:1.8754, succeed, steps:4, total reward:0.2000, 0.012044906616210938 sec\n",
      "Episode 1493, loss:-1.9861, fail, steps:29, total reward:-1.7000, 0.07104825973510742 sec\n",
      "Episode 1494, loss:0.8144, fail, steps:30, total reward:1.6000, 0.0747673511505127 sec\n",
      "Episode 1495, loss:-1.1371, fail, steps:29, total reward:-2.7000, 0.07308006286621094 sec\n",
      "Episode 1496, loss:3.6105, succeed, steps:27, total reward:0.1000, 0.06830167770385742 sec\n",
      "Episode 1497, loss:3.8185, succeed, steps:29, total reward:2.1000, 0.07283139228820801 sec\n",
      "Episode 1498, loss:3.4449, succeed, steps:22, total reward:1.7000, 0.05621004104614258 sec\n",
      "Episode 1499, loss:2.5673, succeed, steps:15, total reward:1.3000, 0.039524078369140625 sec\n",
      "len4 start4 Comparison 4 5 less Comparison 6 7 more Swap\n",
      "Episode 1500, loss:0.7581, succeed, steps:7, total reward:-0.1000, 0.01934194564819336 sec\n",
      "Episode 1501, loss:-0.1631, fail, steps:30, total reward:0.3000, 0.07351255416870117 sec\n",
      "Episode 1502, loss:-2.1962, fail, steps:30, total reward:1.6000, 0.0751180648803711 sec\n",
      "Episode 1503, loss:-0.8314, fail, steps:29, total reward:-0.7000, 0.07398700714111328 sec\n",
      "Episode 1504, loss:-1.4693, fail, steps:29, total reward:-0.7000, 0.07309722900390625 sec\n",
      "Episode 1505, loss:4.2101, succeed, steps:27, total reward:0.1000, 0.06851673126220703 sec\n",
      "Episode 1506, loss:1.5153, succeed, steps:26, total reward:-0.9000, 0.06656050682067871 sec\n",
      "Episode 1507, loss:1.3509, succeed, steps:13, total reward:-0.7000, 0.03447365760803223 sec\n",
      "Episode 1508, loss:0.9697, fail, steps:29, total reward:-0.7000, 0.0722506046295166 sec\n",
      "Episode 1509, loss:3.6782, succeed, steps:28, total reward:1.1000, 0.0724494457244873 sec\n",
      "Episode 1510, loss:2.8593, succeed, steps:26, total reward:-0.9000, 0.06856727600097656 sec\n",
      "Episode 1511, loss:0.2888, succeed, steps:8, total reward:0.9000, 0.022548198699951172 sec\n",
      "Episode 1512, loss:1.1462, succeed, steps:29, total reward:-1.2000, 0.0715482234954834 sec\n",
      "Episode 1513, loss:2.8503, succeed, steps:19, total reward:2.0000, 0.04865741729736328 sec\n",
      "Episode 1514, loss:2.4130, succeed, steps:21, total reward:0.7000, 0.053087472915649414 sec\n",
      "Episode 1515, loss:-0.1568, fail, steps:30, total reward:1.6000, 0.07547497749328613 sec\n",
      "Episode 1516, loss:-2.0123, fail, steps:29, total reward:-1.7000, 0.07323122024536133 sec\n",
      "Episode 1517, loss:3.9233, succeed, steps:29, total reward:2.1000, 0.07316470146179199 sec\n",
      "Episode 1518, loss:2.1950, succeed, steps:17, total reward:0.0000, 0.04450535774230957 sec\n",
      "Episode 1519, loss:-1.9615, fail, steps:30, total reward:0.3000, 0.07535839080810547 sec\n",
      "Episode 1520, loss:1.0236, fail, steps:30, total reward:2.6000, 0.0754704475402832 sec\n",
      "Episode 1521, loss:-2.8663, fail, steps:29, total reward:-1.3000, 0.07319331169128418 sec\n",
      "Episode 1522, loss:-40.7956, fail, steps:1, total reward:-10.0000, 0.005285739898681641 sec\n",
      "Episode 1523, loss:1.8326, succeed, steps:11, total reward:0.6000, 0.027835607528686523 sec\n",
      "Episode 1524, loss:0.8723, succeed, steps:13, total reward:-0.7000, 0.03342604637145996 sec\n",
      "Episode 1525, loss:-1.6312, fail, steps:29, total reward:-1.7000, 0.07149434089660645 sec\n",
      "Episode 1526, loss:1.6490, succeed, steps:21, total reward:0.7000, 0.05332350730895996 sec\n",
      "Episode 1527, loss:2.3050, succeed, steps:21, total reward:0.7000, 0.05313730239868164 sec\n",
      "Episode 1528, loss:1.5800, succeed, steps:14, total reward:0.3000, 0.036835670471191406 sec\n",
      "Episode 1529, loss:5.9296, succeed, steps:22, total reward:1.7000, 0.055175065994262695 sec\n",
      "Episode 1530, loss:2.3387, succeed, steps:29, total reward:-1.2000, 0.07253360748291016 sec\n",
      "Episode 1531, loss:3.8886, succeed, steps:28, total reward:1.1000, 0.07055854797363281 sec\n",
      "Episode 1532, loss:2.0016, succeed, steps:12, total reward:1.6000, 0.032489776611328125 sec\n",
      "Episode 1533, loss:0.6446, succeed, steps:7, total reward:-0.1000, 0.019152164459228516 sec\n",
      "Episode 1534, loss:0.6146, succeed, steps:11, total reward:0.6000, 0.02820134162902832 sec\n",
      "Episode 1535, loss:-2.5949, fail, steps:29, total reward:-1.7000, 0.07136917114257812 sec\n",
      "Episode 1536, loss:-2.0606, fail, steps:30, total reward:0.3000, 0.07489895820617676 sec\n",
      "Episode 1537, loss:2.1635, succeed, steps:25, total reward:1.4000, 0.06400299072265625 sec\n",
      "Episode 1538, loss:-1.5601, fail, steps:30, total reward:0.3000, 0.07527732849121094 sec\n",
      "Episode 1539, loss:-1.4626, fail, steps:30, total reward:0.3000, 0.0755758285522461 sec\n",
      "Episode 1540, loss:-3.6589, fail, steps:29, total reward:-1.7000, 0.07383966445922852 sec\n",
      "Episode 1541, loss:3.0404, succeed, steps:8, total reward:0.9000, 0.02277207374572754 sec\n",
      "Episode 1542, loss:0.7634, succeed, steps:14, total reward:0.3000, 0.03579258918762207 sec\n",
      "Episode 1543, loss:2.6706, succeed, steps:15, total reward:1.3000, 0.038213253021240234 sec\n",
      "Episode 1544, loss:-1.7082, fail, steps:30, total reward:0.3000, 0.07402944564819336 sec\n",
      "Episode 1545, loss:3.2041, succeed, steps:18, total reward:1.0000, 0.04672098159790039 sec\n",
      "Episode 1546, loss:5.9636, succeed, steps:26, total reward:2.4000, 0.06501173973083496 sec\n",
      "Episode 1547, loss:1.6425, succeed, steps:26, total reward:-0.9000, 0.0679471492767334 sec\n",
      "Episode 1548, loss:2.3337, succeed, steps:24, total reward:0.4000, 0.06246495246887207 sec\n",
      "Episode 1549, loss:1.8811, succeed, steps:24, total reward:0.4000, 0.06094837188720703 sec\n",
      "Episode 1550, loss:0.2902, succeed, steps:7, total reward:-0.1000, 0.0196993350982666 sec\n",
      "Episode 1551, loss:3.4824, succeed, steps:27, total reward:0.1000, 0.06627225875854492 sec\n",
      "Episode 1552, loss:-2.1888, fail, steps:29, total reward:-1.7000, 0.07253551483154297 sec\n",
      "Episode 1553, loss:-2.2897, fail, steps:29, total reward:-1.7000, 0.07353949546813965 sec\n",
      "Episode 1554, loss:1.2624, succeed, steps:22, total reward:-1.6000, 0.05676388740539551 sec\n",
      "Episode 1555, loss:1.7465, fail, steps:30, total reward:2.6000, 0.07488012313842773 sec\n",
      "Episode 1556, loss:4.4933, succeed, steps:23, total reward:2.7000, 0.05899500846862793 sec\n",
      "Episode 1557, loss:4.7710, succeed, steps:28, total reward:1.1000, 0.07088470458984375 sec\n",
      "Episode 1558, loss:3.5196, succeed, steps:29, total reward:2.1000, 0.07297658920288086 sec\n",
      "Episode 1559, loss:-2.2175, fail, steps:30, total reward:0.3000, 0.0754845142364502 sec\n",
      "Episode 1560, loss:2.2298, succeed, steps:21, total reward:0.7000, 0.05456733703613281 sec\n",
      "Episode 1561, loss:0.7587, succeed, steps:17, total reward:0.0000, 0.044063568115234375 sec\n",
      "Episode 1562, loss:0.0104, succeed, steps:4, total reward:0.2000, 0.012010335922241211 sec\n",
      "Episode 1563, loss:2.2970, succeed, steps:17, total reward:0.0000, 0.04217886924743652 sec\n",
      "Episode 1564, loss:1.0424, succeed, steps:4, total reward:0.2000, 0.011876583099365234 sec\n",
      "Episode 1565, loss:0.7266, succeed, steps:13, total reward:-0.7000, 0.03270387649536133 sec\n",
      "Episode 1566, loss:3.5984, succeed, steps:24, total reward:0.4000, 0.05948519706726074 sec\n",
      "Episode 1567, loss:1.8252, succeed, steps:21, total reward:0.7000, 0.05313611030578613 sec\n",
      "Episode 1568, loss:1.5622, succeed, steps:29, total reward:-1.2000, 0.07219696044921875 sec\n",
      "Episode 1569, loss:0.1063, succeed, steps:7, total reward:-0.1000, 0.019696712493896484 sec\n",
      "Episode 1570, loss:0.3832, fail, steps:30, total reward:1.6000, 0.07431149482727051 sec\n",
      "Episode 1571, loss:-0.7442, fail, steps:30, total reward:0.3000, 0.07506203651428223 sec\n",
      "Episode 1572, loss:1.2243, succeed, steps:14, total reward:0.3000, 0.03689408302307129 sec\n",
      "Episode 1573, loss:0.0066, succeed, steps:4, total reward:0.2000, 0.012017250061035156 sec\n",
      "Episode 1574, loss:-1.8009, fail, steps:29, total reward:-1.7000, 0.07086920738220215 sec\n",
      "Episode 1575, loss:1.2026, succeed, steps:15, total reward:1.3000, 0.03957104682922363 sec\n",
      "Episode 1576, loss:-0.8738, fail, steps:29, total reward:-0.7000, 0.07193374633789062 sec\n",
      "Episode 1577, loss:0.8818, succeed, steps:20, total reward:-0.3000, 0.051122188568115234 sec\n",
      "Episode 1578, loss:-0.8224, fail, steps:29, total reward:-0.7000, 0.07229971885681152 sec\n",
      "Episode 1579, loss:2.2642, succeed, steps:4, total reward:0.2000, 0.013148069381713867 sec\n",
      "Episode 1580, loss:2.4254, succeed, steps:22, total reward:1.7000, 0.054552316665649414 sec\n",
      "Episode 1581, loss:-0.9008, fail, steps:29, total reward:-1.7000, 0.07179594039916992 sec\n",
      "Episode 1582, loss:0.8616, succeed, steps:11, total reward:0.6000, 0.029462099075317383 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1583, loss:1.7815, succeed, steps:24, total reward:0.4000, 0.059880971908569336 sec\n",
      "Episode 1584, loss:-0.4625, fail, steps:30, total reward:0.3000, 0.0745553970336914 sec\n",
      "Episode 1585, loss:-1.1295, fail, steps:29, total reward:-1.7000, 0.07373571395874023 sec\n",
      "Episode 1586, loss:2.4357, succeed, steps:26, total reward:-0.9000, 0.06912541389465332 sec\n",
      "Episode 1587, loss:0.3949, succeed, steps:8, total reward:0.9000, 0.022960424423217773 sec\n",
      "Episode 1588, loss:0.2241, succeed, steps:4, total reward:0.2000, 0.011725425720214844 sec\n",
      "Episode 1589, loss:0.4375, succeed, steps:12, total reward:1.6000, 0.030435800552368164 sec\n",
      "Episode 1590, loss:2.4270, succeed, steps:27, total reward:0.1000, 0.06632161140441895 sec\n",
      "Episode 1591, loss:1.7889, succeed, steps:21, total reward:0.7000, 0.05326080322265625 sec\n",
      "Episode 1592, loss:0.0812, fail, steps:30, total reward:1.6000, 0.0754086971282959 sec\n",
      "Episode 1593, loss:1.3747, succeed, steps:20, total reward:-0.3000, 0.051189422607421875 sec\n",
      "Episode 1594, loss:-0.6496, fail, steps:29, total reward:-0.7000, 0.07258725166320801 sec\n",
      "Episode 1595, loss:1.8555, succeed, steps:20, total reward:-0.3000, 0.05124664306640625 sec\n",
      "Episode 1596, loss:1.5906, succeed, steps:17, total reward:0.0000, 0.04392647743225098 sec\n",
      "Episode 1597, loss:-0.5393, fail, steps:29, total reward:-1.7000, 0.07218575477600098 sec\n",
      "Episode 1598, loss:-1.5762, fail, steps:29, total reward:-1.7000, 0.07275223731994629 sec\n",
      "Episode 1599, loss:8.0108, succeed, steps:22, total reward:1.7000, 0.056220293045043945 sec\n",
      "Episode 1600, loss:-1.4351, fail, steps:30, total reward:0.3000, 0.07546544075012207 sec\n",
      "Episode 1601, loss:1.7185, succeed, steps:14, total reward:0.3000, 0.03680229187011719 sec\n",
      "Episode 1602, loss:3.7679, succeed, steps:24, total reward:0.4000, 0.05960893630981445 sec\n",
      "Episode 1603, loss:1.0332, succeed, steps:20, total reward:-0.3000, 0.05097556114196777 sec\n",
      "Episode 1604, loss:3.8394, succeed, steps:18, total reward:1.0000, 0.04632830619812012 sec\n",
      "Episode 1605, loss:1.4261, fail, steps:30, total reward:2.6000, 0.07447648048400879 sec\n",
      "Episode 1606, loss:1.4848, succeed, steps:22, total reward:1.7000, 0.05590057373046875 sec\n",
      "Episode 1607, loss:0.1990, succeed, steps:4, total reward:0.2000, 0.012301206588745117 sec\n",
      "Episode 1608, loss:-1.1092, fail, steps:30, total reward:0.3000, 0.07411742210388184 sec\n",
      "Episode 1609, loss:0.0352, succeed, steps:4, total reward:0.2000, 0.012561321258544922 sec\n",
      "Episode 1610, loss:-1.4123, fail, steps:30, total reward:0.3000, 0.07322001457214355 sec\n",
      "Episode 1611, loss:-1.8298, fail, steps:29, total reward:-0.7000, 0.07254481315612793 sec\n",
      "Episode 1612, loss:2.0050, succeed, steps:12, total reward:1.6000, 0.03193831443786621 sec\n",
      "Episode 1613, loss:0.8825, succeed, steps:24, total reward:0.4000, 0.059990882873535156 sec\n",
      "Episode 1614, loss:1.8705, succeed, steps:18, total reward:1.0000, 0.046219825744628906 sec\n",
      "Episode 1615, loss:4.2682, succeed, steps:22, total reward:1.4000, 0.055362701416015625 sec\n",
      "Episode 1616, loss:3.3317, succeed, steps:21, total reward:0.7000, 0.05290627479553223 sec\n",
      "Episode 1617, loss:1.9743, succeed, steps:20, total reward:-0.3000, 0.051291465759277344 sec\n",
      "Episode 1618, loss:1.6912, succeed, steps:24, total reward:0.4000, 0.06054520606994629 sec\n",
      "Episode 1619, loss:-1.3986, fail, steps:30, total reward:0.3000, 0.07470703125 sec\n",
      "Episode 1620, loss:-1.1660, fail, steps:29, total reward:-1.3000, 0.0735330581665039 sec\n",
      "Episode 1621, loss:-0.8332, fail, steps:29, total reward:-0.7000, 0.07345199584960938 sec\n",
      "Episode 1622, loss:1.2704, succeed, steps:17, total reward:0.0000, 0.043974876403808594 sec\n",
      "Episode 1623, loss:0.0145, succeed, steps:4, total reward:0.2000, 0.012293577194213867 sec\n",
      "Episode 1624, loss:0.1482, succeed, steps:7, total reward:-0.1000, 0.018575429916381836 sec\n",
      "Episode 1625, loss:-1.5800, fail, steps:29, total reward:-1.7000, 0.08354496955871582 sec\n",
      "Episode 1626, loss:0.6375, succeed, steps:4, total reward:0.2000, 0.01592731475830078 sec\n",
      "Episode 1627, loss:0.0664, succeed, steps:8, total reward:0.9000, 0.02589702606201172 sec\n",
      "Episode 1628, loss:-1.2556, fail, steps:30, total reward:0.3000, 0.0734109878540039 sec\n",
      "Episode 1629, loss:1.0587, succeed, steps:12, total reward:1.6000, 0.03152346611022949 sec\n",
      "Episode 1630, loss:0.6181, succeed, steps:7, total reward:-0.1000, 0.01901102066040039 sec\n",
      "Episode 1631, loss:0.2134, succeed, steps:7, total reward:-0.1000, 0.018599987030029297 sec\n",
      "Episode 1632, loss:-4.4563, fail, steps:29, total reward:-1.7000, 0.07156634330749512 sec\n",
      "Episode 1633, loss:1.2469, succeed, steps:26, total reward:-0.9000, 0.06534337997436523 sec\n",
      "Episode 1634, loss:3.4141, succeed, steps:22, total reward:1.7000, 0.05570244789123535 sec\n",
      "Episode 1635, loss:0.4480, succeed, steps:16, total reward:-1.0000, 0.04125785827636719 sec\n",
      "Episode 1636, loss:0.9746, succeed, steps:21, total reward:0.7000, 0.05298566818237305 sec\n",
      "Episode 1637, loss:2.6624, succeed, steps:25, total reward:1.4000, 0.06252193450927734 sec\n",
      "Episode 1638, loss:1.7254, succeed, steps:23, total reward:-0.6000, 0.05807781219482422 sec\n",
      "Episode 1639, loss:-0.4635, fail, steps:30, total reward:0.3000, 0.07467770576477051 sec\n",
      "Episode 1640, loss:-1.3798, fail, steps:29, total reward:-0.7000, 0.07358312606811523 sec\n",
      "Episode 1641, loss:0.6369, succeed, steps:14, total reward:0.3000, 0.03700709342956543 sec\n",
      "Episode 1642, loss:-1.6167, fail, steps:29, total reward:-0.7000, 0.07209467887878418 sec\n",
      "Episode 1643, loss:-1.6521, fail, steps:29, total reward:-0.7000, 0.07273983955383301 sec\n",
      "Episode 1644, loss:0.2457, succeed, steps:8, total reward:0.9000, 0.022825956344604492 sec\n",
      "Episode 1645, loss:-0.4044, fail, steps:29, total reward:-0.7000, 0.07172155380249023 sec\n",
      "Episode 1646, loss:0.6577, succeed, steps:11, total reward:0.6000, 0.0293734073638916 sec\n",
      "Episode 1647, loss:-0.9831, fail, steps:29, total reward:-0.7000, 0.07128214836120605 sec\n",
      "Episode 1648, loss:0.7401, succeed, steps:11, total reward:0.6000, 0.029648303985595703 sec\n",
      "Episode 1649, loss:-4.1064, fail, steps:30, total reward:0.6000, 0.07408881187438965 sec\n",
      "Episode 1650, loss:-1.1267, fail, steps:30, total reward:0.3000, 0.07480001449584961 sec\n",
      "Episode 1651, loss:1.6136, succeed, steps:14, total reward:0.3000, 0.036963462829589844 sec\n",
      "Episode 1652, loss:1.7793, succeed, steps:21, total reward:0.7000, 0.05336141586303711 sec\n",
      "Episode 1653, loss:-2.4682, fail, steps:30, total reward:0.3000, 0.07443618774414062 sec\n",
      "Episode 1654, loss:0.1290, succeed, steps:4, total reward:0.2000, 0.012580394744873047 sec\n",
      "Episode 1655, loss:2.4907, succeed, steps:23, total reward:2.7000, 0.05672812461853027 sec\n",
      "Episode 1656, loss:1.7366, succeed, steps:18, total reward:1.0000, 0.04561924934387207 sec\n",
      "Episode 1657, loss:-0.2914, fail, steps:30, total reward:1.6000, 0.07457947731018066 sec\n",
      "Episode 1658, loss:3.9008, succeed, steps:22, total reward:1.7000, 0.05603933334350586 sec\n",
      "Episode 1659, loss:-1.3049, fail, steps:29, total reward:-1.0000, 0.07206034660339355 sec\n",
      "Episode 1660, loss:0.2410, succeed, steps:8, total reward:0.9000, 0.02231574058532715 sec\n",
      "Episode 1661, loss:3.1349, succeed, steps:20, total reward:-0.3000, 0.05005025863647461 sec\n",
      "Episode 1662, loss:0.2283, fail, steps:30, total reward:0.3000, 0.07447314262390137 sec\n",
      "Episode 1663, loss:1.7416, succeed, steps:23, total reward:-0.6000, 0.05835103988647461 sec\n",
      "Episode 1664, loss:1.3613, succeed, steps:25, total reward:-1.9000, 0.06459307670593262 sec\n",
      "Episode 1665, loss:0.4323, succeed, steps:8, total reward:0.9000, 0.023736238479614258 sec\n",
      "Episode 1666, loss:-1.0631, fail, steps:29, total reward:-0.7000, 0.0742483139038086 sec\n",
      "Episode 1667, loss:-0.1973, fail, steps:29, total reward:-0.7000, 0.07412505149841309 sec\n",
      "Episode 1668, loss:-0.5156, fail, steps:30, total reward:0.3000, 0.0774075984954834 sec\n",
      "Episode 1669, loss:-2.4638, fail, steps:29, total reward:-1.7000, 0.07474398612976074 sec\n",
      "Episode 1670, loss:0.3815, succeed, steps:7, total reward:-0.1000, 0.02047443389892578 sec\n",
      "Episode 1671, loss:2.3727, succeed, steps:18, total reward:1.0000, 0.045879364013671875 sec\n",
      "Episode 1672, loss:6.3720, succeed, steps:24, total reward:0.4000, 0.0612797737121582 sec\n",
      "Episode 1673, loss:-2.8775, fail, steps:29, total reward:-1.7000, 0.07394099235534668 sec\n",
      "Episode 1674, loss:1.1886, succeed, steps:4, total reward:0.2000, 0.012760639190673828 sec\n",
      "Episode 1675, loss:-1.4291, fail, steps:30, total reward:0.3000, 0.07488846778869629 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1676, loss:-0.5796, fail, steps:30, total reward:0.3000, 0.07696890830993652 sec\n",
      "Episode 1677, loss:2.1914, succeed, steps:15, total reward:1.3000, 0.03929853439331055 sec\n",
      "Episode 1678, loss:0.9034, succeed, steps:16, total reward:-1.0000, 0.04094552993774414 sec\n",
      "Episode 1679, loss:-0.1724, fail, steps:30, total reward:1.6000, 0.07412838935852051 sec\n",
      "Episode 1680, loss:-1.5691, fail, steps:29, total reward:-0.7000, 0.07319259643554688 sec\n",
      "Episode 1681, loss:3.3445, succeed, steps:22, total reward:1.7000, 0.056169986724853516 sec\n",
      "Episode 1682, loss:0.4751, succeed, steps:15, total reward:1.3000, 0.03878641128540039 sec\n",
      "Episode 1683, loss:2.1084, succeed, steps:11, total reward:0.6000, 0.028850793838500977 sec\n",
      "Episode 1684, loss:-2.5286, fail, steps:29, total reward:-0.7000, 0.07139396667480469 sec\n",
      "Episode 1685, loss:3.2356, succeed, steps:29, total reward:2.1000, 0.07276344299316406 sec\n",
      "Episode 1686, loss:1.1234, succeed, steps:7, total reward:-0.1000, 0.01999640464782715 sec\n",
      "Episode 1687, loss:1.6138, succeed, steps:12, total reward:1.6000, 0.030698299407958984 sec\n",
      "Episode 1688, loss:1.3508, succeed, steps:22, total reward:1.7000, 0.054444074630737305 sec\n",
      "Episode 1689, loss:-0.1296, fail, steps:30, total reward:1.6000, 0.07422876358032227 sec\n",
      "Episode 1690, loss:1.5492, succeed, steps:25, total reward:-1.9000, 0.0640254020690918 sec\n",
      "Episode 1691, loss:3.6484, succeed, steps:24, total reward:0.4000, 0.06069135665893555 sec\n",
      "Episode 1692, loss:0.6733, succeed, steps:7, total reward:-0.1000, 0.019687414169311523 sec\n",
      "Episode 1693, loss:1.0486, succeed, steps:11, total reward:0.6000, 0.028165817260742188 sec\n",
      "Episode 1694, loss:-1.8797, fail, steps:29, total reward:-1.7000, 0.071075439453125 sec\n",
      "Episode 1695, loss:1.3545, succeed, steps:25, total reward:-1.9000, 0.06393599510192871 sec\n",
      "Episode 1696, loss:1.2420, succeed, steps:15, total reward:1.3000, 0.03921103477478027 sec\n",
      "Episode 1697, loss:-1.9883, fail, steps:29, total reward:-0.7000, 0.07164263725280762 sec\n",
      "Episode 1698, loss:2.0481, succeed, steps:17, total reward:0.0000, 0.043868303298950195 sec\n",
      "Episode 1699, loss:0.1325, fail, steps:29, total reward:-0.7000, 0.07254743576049805 sec\n",
      "len4 start8 Comparison 8 9 less Comparison 9 10 less Comparison 9 10 less Comparison 9 10 less Comparison 9 10 less Comparison 9 10 less Comparison 9 10 less Comparison 10 11 more Swap\n",
      "Episode 1700, loss:0.9165, succeed, steps:25, total reward:-1.9000, 0.06313323974609375 sec\n",
      "Episode 1701, loss:2.0907, succeed, steps:20, total reward:-0.3000, 0.05100512504577637 sec\n",
      "Episode 1702, loss:-1.8439, fail, steps:29, total reward:-0.7000, 0.07387685775756836 sec\n",
      "Episode 1703, loss:-1.3259, fail, steps:29, total reward:-0.7000, 0.07623457908630371 sec\n",
      "Episode 1704, loss:6.0535, succeed, steps:15, total reward:1.3000, 0.0393369197845459 sec\n",
      "Episode 1705, loss:2.1339, succeed, steps:19, total reward:2.0000, 0.04837918281555176 sec\n",
      "Episode 1706, loss:0.5946, succeed, steps:12, total reward:1.6000, 0.031297922134399414 sec\n",
      "Episode 1707, loss:-0.1648, fail, steps:30, total reward:1.6000, 0.07416987419128418 sec\n",
      "Episode 1708, loss:0.0036, succeed, steps:4, total reward:0.2000, 0.012590408325195312 sec\n",
      "Episode 1709, loss:0.1437, succeed, steps:7, total reward:-0.1000, 0.01876354217529297 sec\n",
      "Episode 1710, loss:1.4240, succeed, steps:18, total reward:1.0000, 0.04460000991821289 sec\n",
      "Episode 1711, loss:-1.4064, fail, steps:30, total reward:0.3000, 0.0739278793334961 sec\n",
      "Episode 1712, loss:3.1454, succeed, steps:24, total reward:0.4000, 0.06084704399108887 sec\n",
      "Episode 1713, loss:3.3559, succeed, steps:15, total reward:1.3000, 0.039433956146240234 sec\n",
      "Episode 1714, loss:-0.8421, fail, steps:30, total reward:1.6000, 0.07464098930358887 sec\n",
      "Episode 1715, loss:1.9976, succeed, steps:24, total reward:0.4000, 0.06083059310913086 sec\n",
      "Episode 1716, loss:-2.2226, fail, steps:29, total reward:-1.7000, 0.07296442985534668 sec\n",
      "Episode 1717, loss:0.3699, succeed, steps:7, total reward:-0.1000, 0.020375728607177734 sec\n",
      "Episode 1718, loss:0.5726, succeed, steps:10, total reward:-0.4000, 0.026099681854248047 sec\n",
      "Episode 1719, loss:-0.9820, fail, steps:29, total reward:-0.7000, 0.07104182243347168 sec\n",
      "Episode 1720, loss:-0.0456, fail, steps:30, total reward:1.6000, 0.07501363754272461 sec\n",
      "Episode 1721, loss:0.1422, fail, steps:30, total reward:1.6000, 0.07606029510498047 sec\n",
      "Episode 1722, loss:3.1188, succeed, steps:26, total reward:2.4000, 0.06613349914550781 sec\n",
      "Episode 1723, loss:0.8011, succeed, steps:18, total reward:0.7000, 0.04644656181335449 sec\n",
      "Episode 1724, loss:-2.1397, fail, steps:30, total reward:0.3000, 0.07481884956359863 sec\n",
      "Episode 1725, loss:1.4203, succeed, steps:28, total reward:1.1000, 0.07122063636779785 sec\n",
      "Episode 1726, loss:-1.7112, fail, steps:30, total reward:0.3000, 0.07558679580688477 sec\n",
      "Episode 1727, loss:3.4794, succeed, steps:27, total reward:0.1000, 0.06864047050476074 sec\n",
      "Episode 1728, loss:-0.1395, fail, steps:29, total reward:-0.7000, 0.07369780540466309 sec\n",
      "Episode 1729, loss:-0.4127, fail, steps:29, total reward:-0.7000, 0.07326579093933105 sec\n",
      "Episode 1730, loss:0.0838, succeed, steps:4, total reward:0.2000, 0.012659072875976562 sec\n",
      "Episode 1731, loss:0.1912, succeed, steps:8, total reward:0.9000, 0.021121740341186523 sec\n",
      "Episode 1732, loss:-1.8942, fail, steps:29, total reward:-1.7000, 0.07101750373840332 sec\n",
      "Episode 1733, loss:-0.0393, fail, steps:29, total reward:-0.7000, 0.07296919822692871 sec\n",
      "Episode 1734, loss:2.0618, succeed, steps:21, total reward:0.7000, 0.05361580848693848 sec\n",
      "Episode 1735, loss:2.0813, succeed, steps:17, total reward:0.0000, 0.04359602928161621 sec\n",
      "Episode 1736, loss:-2.1957, fail, steps:29, total reward:-1.7000, 0.07206010818481445 sec\n",
      "Episode 1737, loss:2.6560, succeed, steps:16, total reward:2.3000, 0.0417935848236084 sec\n",
      "Episode 1738, loss:-1.7560, fail, steps:29, total reward:-2.7000, 0.07240796089172363 sec\n",
      "Episode 1739, loss:1.0353, succeed, steps:26, total reward:-0.9000, 0.06642365455627441 sec\n",
      "Episode 1740, loss:2.0065, succeed, steps:24, total reward:0.4000, 0.06329870223999023 sec\n",
      "Episode 1741, loss:0.6976, succeed, steps:20, total reward:-0.3000, 0.052107810974121094 sec\n",
      "Episode 1742, loss:4.9400, succeed, steps:16, total reward:2.3000, 0.041117191314697266 sec\n",
      "Episode 1743, loss:0.0711, succeed, steps:4, total reward:0.2000, 0.012016773223876953 sec\n",
      "Episode 1744, loss:1.9934, succeed, steps:14, total reward:0.3000, 0.03516840934753418 sec\n",
      "Episode 1745, loss:0.5644, succeed, steps:15, total reward:1.3000, 0.03784584999084473 sec\n",
      "Episode 1746, loss:1.8496, succeed, steps:26, total reward:-0.9000, 0.06485819816589355 sec\n",
      "Episode 1747, loss:2.4307, succeed, steps:25, total reward:1.4000, 0.06303858757019043 sec\n",
      "Episode 1748, loss:3.5649, succeed, steps:22, total reward:1.7000, 0.05586075782775879 sec\n",
      "Episode 1749, loss:-1.2193, fail, steps:29, total reward:-0.7000, 0.07242798805236816 sec\n",
      "Episode 1750, loss:-0.8733, fail, steps:29, total reward:-0.7000, 0.07400965690612793 sec\n",
      "Episode 1751, loss:3.7564, succeed, steps:27, total reward:0.1000, 0.06868147850036621 sec\n",
      "Episode 1752, loss:0.0300, succeed, steps:8, total reward:0.9000, 0.022380828857421875 sec\n",
      "Episode 1753, loss:1.9990, succeed, steps:12, total reward:1.6000, 0.03087759017944336 sec\n",
      "Episode 1754, loss:-1.2770, fail, steps:29, total reward:-0.7000, 0.0713188648223877 sec\n",
      "Episode 1755, loss:0.0697, fail, steps:29, total reward:-0.7000, 0.07293272018432617 sec\n",
      "Episode 1756, loss:0.0507, succeed, steps:11, total reward:0.6000, 0.029779434204101562 sec\n",
      "Episode 1757, loss:3.2802, succeed, steps:18, total reward:1.0000, 0.04538559913635254 sec\n",
      "Episode 1758, loss:-0.2970, fail, steps:30, total reward:1.6000, 0.07432270050048828 sec\n",
      "Episode 1759, loss:-1.3532, fail, steps:30, total reward:-0.0000, 0.07561421394348145 sec\n",
      "Episode 1760, loss:0.1896, succeed, steps:12, total reward:1.6000, 0.03226637840270996 sec\n",
      "Episode 1761, loss:0.0134, succeed, steps:12, total reward:1.6000, 0.031127452850341797 sec\n",
      "Episode 1762, loss:3.3361, succeed, steps:18, total reward:1.0000, 0.04532623291015625 sec\n",
      "Episode 1763, loss:2.5312, succeed, steps:16, total reward:2.3000, 0.04074859619140625 sec\n",
      "Episode 1764, loss:-1.1262, fail, steps:30, total reward:1.6000, 0.07459712028503418 sec\n",
      "Episode 1765, loss:-1.4803, fail, steps:29, total reward:-2.3000, 0.07280993461608887 sec\n",
      "Episode 1766, loss:1.4653, succeed, steps:15, total reward:1.3000, 0.03958845138549805 sec\n",
      "Episode 1767, loss:0.7146, succeed, steps:18, total reward:1.0000, 0.04560995101928711 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1768, loss:-0.8835, fail, steps:29, total reward:-0.7000, 0.0723268985748291 sec\n",
      "Episode 1769, loss:2.1983, succeed, steps:28, total reward:1.1000, 0.0705265998840332 sec\n",
      "Episode 1770, loss:0.2624, succeed, steps:4, total reward:0.2000, 0.012622833251953125 sec\n",
      "Episode 1771, loss:0.4650, succeed, steps:12, total reward:1.6000, 0.030599355697631836 sec\n",
      "Episode 1772, loss:4.0954, succeed, steps:21, total reward:0.7000, 0.05203557014465332 sec\n",
      "Episode 1773, loss:0.9061, succeed, steps:22, total reward:-1.6000, 0.055258989334106445 sec\n",
      "Episode 1774, loss:-1.0065, fail, steps:29, total reward:-0.7000, 0.07238602638244629 sec\n",
      "Episode 1775, loss:-1.0630, fail, steps:29, total reward:-1.7000, 0.07268071174621582 sec\n",
      "Episode 1776, loss:1.9657, succeed, steps:18, total reward:1.0000, 0.046639442443847656 sec\n",
      "Episode 1777, loss:2.0000, succeed, steps:25, total reward:1.4000, 0.06328654289245605 sec\n",
      "Episode 1778, loss:0.5907, succeed, steps:17, total reward:0.0000, 0.04361987113952637 sec\n",
      "Episode 1779, loss:1.2838, succeed, steps:14, total reward:0.3000, 0.03630971908569336 sec\n",
      "Episode 1780, loss:-0.4317, fail, steps:30, total reward:0.3000, 0.07756924629211426 sec\n",
      "Episode 1781, loss:0.6805, fail, steps:30, total reward:1.6000, 0.07805776596069336 sec\n",
      "Episode 1782, loss:-0.7920, fail, steps:30, total reward:0.3000, 0.07727909088134766 sec\n",
      "Episode 1783, loss:-0.3751, fail, steps:30, total reward:0.3000, 0.07756209373474121 sec\n",
      "Episode 1784, loss:-3.1968, fail, steps:29, total reward:-2.7000, 0.07560467720031738 sec\n",
      "Episode 1785, loss:0.1988, fail, steps:30, total reward:-0.3000, 0.075927734375 sec\n",
      "Episode 1786, loss:0.5235, succeed, steps:17, total reward:0.0000, 0.04431486129760742 sec\n",
      "Episode 1787, loss:0.9996, succeed, steps:10, total reward:-0.4000, 0.026767969131469727 sec\n",
      "Episode 1788, loss:-12.2344, fail, steps:1, total reward:-10.0000, 0.0044629573822021484 sec\n",
      "Episode 1789, loss:0.1256, succeed, steps:8, total reward:0.9000, 0.020722389221191406 sec\n",
      "Episode 1790, loss:-1.2231, fail, steps:30, total reward:0.3000, 0.07392573356628418 sec\n",
      "Episode 1791, loss:2.2842, succeed, steps:23, total reward:-0.6000, 0.058190345764160156 sec\n",
      "Episode 1792, loss:1.5071, succeed, steps:8, total reward:0.9000, 0.02194523811340332 sec\n",
      "Episode 1793, loss:-0.1630, fail, steps:29, total reward:-0.7000, 0.07137393951416016 sec\n",
      "Episode 1794, loss:0.7026, succeed, steps:14, total reward:0.3000, 0.036405324935913086 sec\n",
      "Episode 1795, loss:2.5459, succeed, steps:21, total reward:0.7000, 0.05321168899536133 sec\n",
      "Episode 1796, loss:-5.5950, fail, steps:9, total reward:-8.6000, 0.02434515953063965 sec\n",
      "Episode 1797, loss:2.3935, succeed, steps:25, total reward:1.4000, 0.06202077865600586 sec\n",
      "Episode 1798, loss:0.2016, fail, steps:29, total reward:-1.7000, 0.07240462303161621 sec\n",
      "Episode 1799, loss:-0.7805, fail, steps:29, total reward:-0.7000, 0.0736393928527832 sec\n",
      "Episode 1800, loss:-1.5073, fail, steps:29, total reward:-3.3000, 0.0731055736541748 sec\n",
      "Episode 1801, loss:1.8934, succeed, steps:22, total reward:1.7000, 0.056243181228637695 sec\n",
      "Episode 1802, loss:1.9267, succeed, steps:19, total reward:2.0000, 0.0487065315246582 sec\n",
      "Episode 1803, loss:-2.4342, fail, steps:30, total reward:0.3000, 0.07533049583435059 sec\n",
      "Episode 1804, loss:2.3298, succeed, steps:27, total reward:0.1000, 0.06827378273010254 sec\n",
      "Episode 1805, loss:0.1701, fail, steps:30, total reward:1.6000, 0.07531237602233887 sec\n",
      "Episode 1806, loss:0.0005, succeed, steps:4, total reward:0.2000, 0.012737035751342773 sec\n",
      "Episode 1807, loss:1.0744, succeed, steps:19, total reward:2.0000, 0.047807931900024414 sec\n",
      "Episode 1808, loss:2.6672, succeed, steps:29, total reward:-1.2000, 0.07218170166015625 sec\n",
      "Episode 1809, loss:1.5680, succeed, steps:16, total reward:2.3000, 0.04146456718444824 sec\n",
      "Episode 1810, loss:-39.0369, fail, steps:5, total reward:-9.3000, 0.014456033706665039 sec\n",
      "Episode 1811, loss:2.1524, succeed, steps:22, total reward:1.7000, 0.054087162017822266 sec\n",
      "Episode 1812, loss:-0.9954, fail, steps:30, total reward:1.6000, 0.07472634315490723 sec\n",
      "Episode 1813, loss:1.6524, fail, steps:30, total reward:2.6000, 0.0751960277557373 sec\n",
      "Episode 1814, loss:-0.1989, fail, steps:29, total reward:-1.7000, 0.07308673858642578 sec\n",
      "Episode 1815, loss:-1.7833, fail, steps:29, total reward:-1.7000, 0.07379937171936035 sec\n",
      "Episode 1816, loss:-3.7900, fail, steps:29, total reward:-1.7000, 0.07591366767883301 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_bellman_returns(raw_rewards, gamma):\n",
    "    bellman_returns = []\n",
    "    R = 0\n",
    "    for r in raw_rewards[::-1]:\n",
    "        R = r + gamma * R\n",
    "        bellman_returns.insert(0, R)\n",
    "    return bellman_returns\n",
    "\n",
    "# Training Loop\n",
    "def train(verbose=False):\n",
    "    # Removed torch.autograd.set_detect_anomaly(True)\n",
    "    vocab_size = len(vocab)\n",
    "    model = TransformerModel(vocab_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)  # Reduced learning rate\n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=LR_SCHEDULER_GAMMA)\n",
    "    \n",
    "    # Optionally, load a checkpoint\n",
    "    checkpoint_path = os.path.join(\"/home/mcwave/code/autocode/datasets/rl_sort_transformer_curriculum/list2_transformer4_192_gamma07_step10_v1/ckpt_10000_1.0000_4.00.pth\")\n",
    "    load_checkpoint(checkpoint_path, model, optimizer)\n",
    "\n",
    "    episode_cnt = 0\n",
    "    total_reward = 0.0\n",
    "    num_successes = 0\n",
    "    total_steps = 0\n",
    "    \n",
    "    for episode in range(NUM_EPISODES):\n",
    "        t1 = time.time()\n",
    "        model.train()  # Set model to training mode\n",
    "        env = SortingEnv()\n",
    "        initial_token_id, start_pos, current_list = env.reset()\n",
    "        input_tokens = [initial_token_id, start_pos]\n",
    "        log_probs = []\n",
    "        rewards = []\n",
    "        comparisons = []\n",
    "        \n",
    "        state = 'expect_action'\n",
    "        done = False\n",
    "        success = False\n",
    "\n",
    "        while not done and len(input_tokens) < env.max_steps:\n",
    "            if verbose:\n",
    "                print(decode(input_tokens, inv_vocab))\n",
    "                print(env.get_list())\n",
    "                #print(comparisons)\n",
    "            # Prepare input tensor\n",
    "            input_seq = torch.tensor(input_tokens, dtype=torch.long, device=device).unsqueeze(1)  # (seq_len, batch_size)\n",
    "            # Get model output\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n",
    "                output = model(input_seq)  # (seq_len, batch_size, vocab_size)\n",
    "                # Get logits for the last token\n",
    "                logits = output[-1, 0, :]  # (vocab_size)\n",
    "\n",
    "                # Check for NaNs in logits\n",
    "                if torch.isnan(logits).any():\n",
    "                    print(f\"Episode {episode}, NaNs in logits before masking.\")\n",
    "                    break\n",
    "\n",
    "                # Get valid tokens based on state\n",
    "                def get_valid_tokens(state):\n",
    "                    action_tokens = [vocab['Comparison'], vocab['Swap']]\n",
    "                    index_tokens = [vocab[str(i)] for i in range(env.get_start_pos(), env.get_start_pos() + env.get_length())]\n",
    "                    if state == 'expect_action':\n",
    "                        return action_tokens\n",
    "                    elif state == 'expect_index1':\n",
    "                        return index_tokens[:-1]\n",
    "                    elif state == 'expect_index2':\n",
    "                        return [x for x in index_tokens if x > input_tokens[-1]]\n",
    "                    else:\n",
    "                        # Handle unexpected states by defaulting to expect_action\n",
    "                        return action_tokens\n",
    "\n",
    "                valid_token_ids = get_valid_tokens(state)\n",
    "\n",
    "                # Ensure valid_token_ids are within the vocab range\n",
    "                if any(idx >= vocab_size or idx < 0 for idx in valid_token_ids):\n",
    "                    print(f\"Episode {episode}, invalid indices in valid_token_ids: {valid_token_ids}\")\n",
    "                    break\n",
    "\n",
    "                # Mask invalid tokens\n",
    "                mask_value = -1e9  # Use a large negative value instead of -inf\n",
    "                mask = torch.full_like(logits, mask_value).to(device)\n",
    "                mask[valid_token_ids] = 0\n",
    "                masked_logits = logits + mask\n",
    "\n",
    "                # Sample action. Have some chance to randomly pick a valid action.\n",
    "                eps_threshold = EPS_END + (EPS_START - EPS_END) * np.exp(-1.0 * episode / EPS_DECAY)\n",
    "                if random.random() < eps_threshold:\n",
    "                    masked_logits = masked_logits / 4\n",
    "\n",
    "                # Check for NaNs in masked_logits\n",
    "                if torch.isnan(masked_logits).any():\n",
    "                    print(f\"Episode {episode}, NaNs in masked_logits after masking.\")\n",
    "                    break\n",
    "\n",
    "                # Compute probabilities\n",
    "                probs = F.softmax(masked_logits, dim=0)\n",
    "\n",
    "                # Check for NaNs in probs\n",
    "                if torch.isnan(probs).any():\n",
    "                    print(f\"Episode {episode}, NaNs in probs after softmax.\")\n",
    "                    break\n",
    "\n",
    "                try:\n",
    "                    m = torch.distributions.Categorical(probs)\n",
    "                    action_token = m.sample()\n",
    "                    log_prob = m.log_prob(action_token)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Episode {episode}, error in sampling action: {e}\")\n",
    "                    break\n",
    "\n",
    "            log_probs.append(log_prob)\n",
    "            input_tokens.append(action_token.item())\n",
    "\n",
    "            action = action_token.item()\n",
    "            reward = 0.0\n",
    "            if state == 'expect_action':\n",
    "                if action == vocab['Comparison']:\n",
    "                    state = 'expect_index1'\n",
    "                elif action == vocab['Swap']:\n",
    "                    if env.indices is None:\n",
    "                        reward = INVALID_ACTION_REWARD\n",
    "                        rewards.append(reward)\n",
    "                        done = True\n",
    "                        continue\n",
    "                    action_tokens = [vocab['Swap']]\n",
    "                    response_token, reward, done, current_list = env.step(action_tokens)\n",
    "                    if done and reward == SUCCESS_REWARD:\n",
    "                        success = True\n",
    "                        if episode % 100 == 0:\n",
    "                            print(decode(input_tokens, inv_vocab))\n",
    "                    if verbose:\n",
    "                        print(\"Reward:\", reward)\n",
    "                    state = 'expect_action'\n",
    "                else:\n",
    "                    reward = INVALID_ACTION_REWARD\n",
    "                    done = True\n",
    "            elif state == 'expect_index1':\n",
    "                index1_token = action_token\n",
    "                state = 'expect_index2'\n",
    "            elif state == 'expect_index2':\n",
    "                index2_token = action_token\n",
    "                action_tokens = [vocab['Comparison'], index1_token.item(), index2_token.item()]\n",
    "                comparisons.append((int(inv_vocab[index1_token.item()]), int(inv_vocab[index2_token.item()])))\n",
    "                response_token, reward, done, current_list = env.step(action_tokens)\n",
    "                if done and reward == SUCCESS_REWARD:\n",
    "                    success = True\n",
    "                    if episode % 100 == 0:\n",
    "                        print(1, decode(input_tokens, inv_vocab))\n",
    "                else:\n",
    "                    pass\n",
    "                    #reward += COMPARISON_ENTROPY_MULTIPLIER * compute_min_delta_entropy(comparisons)\n",
    "                if verbose:\n",
    "                    print(\"Reward:\", reward)\n",
    "                if response_token is not None:\n",
    "                    input_tokens.append(response_token)\n",
    "                state = 'expect_action'\n",
    "            else:\n",
    "                reward = INVALID_ACTION_REWARD\n",
    "                done = True\n",
    "\n",
    "            rewards.append(reward)\n",
    "        #\n",
    "        success_rewards = [0.0] * len(rewards)\n",
    "        if success: \n",
    "            num_successes += 1\n",
    "            success_rewards[-1] = SUCCESS_REWARD\n",
    "\n",
    "        # Save checkpoint\n",
    "        if episode > 0 and episode % EPISODES_SAVE == 0:\n",
    "            avg_reward = total_reward / episode_cnt\n",
    "            success_rate = num_successes / episode_cnt\n",
    "            avg_steps = total_steps / episode_cnt\n",
    "            episode_cnt = 0\n",
    "            total_reward = 0.0\n",
    "            num_successes = 0\n",
    "            total_steps = 0\n",
    "            save_checkpoint(model, optimizer, episode, OUTPUT_DIR, f\"ckpt_{episode}_{success_rate:.4f}_{avg_steps:.2f}.pth\")\n",
    "            #\n",
    "            # Reduce the lr\n",
    "            scheduler.step()\n",
    "            # Optionally, log the learning rate\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            print(f\"Learning rate = {current_lr:.6f}\")\n",
    "        #\n",
    "        assert len(log_probs) == len(rewards), \"log_probs and returns have different sizes!\"\n",
    "\n",
    "        if len(log_probs) == 0:\n",
    "            continue  # Skip if no actions were taken\n",
    "\n",
    "        # Compute returns and loss within autocast\n",
    "        with torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n",
    "            # Compute returns\n",
    "            returns1 = compute_bellman_returns(rewards, SHORTTERM_GAMMA)\n",
    "            returns2 = compute_bellman_returns(success_rewards, LONGTERM_GAMMA)\n",
    "            returns = torch.tensor(np.array(returns1) + np.array(returns2)).to(device)\n",
    "\n",
    "            # Check for NaNs in returns\n",
    "            if torch.isnan(returns).any():\n",
    "                print(f\"Episode {episode}, NaNs in returns.\")\n",
    "                continue\n",
    "\n",
    "            # Compute loss\n",
    "            loss = 0\n",
    "            for log_prob, R in zip(log_probs, returns):\n",
    "                loss -= log_prob * R\n",
    "\n",
    "            # Check for NaNs in loss\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"Episode {episode}, NaN in loss.\")\n",
    "                continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        episode_cnt += 1\n",
    "        total_reward += sum(rewards)\n",
    "        total_steps += len(rewards)\n",
    "        t2 = time.time()\n",
    "        if episode % 1 == 0:\n",
    "            print(f\"Episode {episode}, loss:{loss.item():.4f}, {'succeed' if success else 'fail'}, steps:{len(rewards)}, total reward:{sum(rewards):.4f}, {t2-t1} sec\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train(verbose=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "axiom",
   "language": "python",
   "name": "axiom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
